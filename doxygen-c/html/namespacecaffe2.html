<!-- HTML header for doxygen 1.8.14-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Caffe2 - C++ API: caffe2 Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="/static/favicon.png" type="image/x-icon">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" />
<link href="main.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo" width="56"><a href="/"><img alt="Logo" src="Caffe2-with-name-55-tall.png"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Caffe2 - C++ API
   </div>
   <div id="projectbrief">A deep learning, cross platform ML framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="/doxygen-c/html/classes.html"><span>C++&#160;API</span></a></li>
      <li><a href="/doxygen-python/html/annotated.html"><span>Python&#160;API</span></a></li>
      <li><a href="https://github.com/caffe2/caffe2"><span>GitHub</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="namespacemembers.html"><span>Namespace&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Data Structures</a> &#124;
<a href="#typedef-members">Typedefs</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">caffe2 Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> global dictionary that holds information about what Caffe2 modules have been loaded in the current runtime, and also utility functions to load modules.  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespacecaffe2_1_1detail"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2_1_1detail.html">detail</a></td></tr>
<tr class="memdesc:namespacecaffe2_1_1detail"><td class="mdescLeft">&#160;</td><td class="mdescRight">To make a <a class="el" href="namespacec10.html" title="To register your own kernel for an operator, do in one (!) cpp file: C10_REGISTER_KERNEL(OperatorHand...">c10</a> operator "C10Add" callable from <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> as "C2MyAddOpName", just write. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Data Structures</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1___caffe_highest_preallocated_type_id.html">_CaffeHighestPreallocatedTypeId</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abs_functor.html">AbsFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abs_gradient_functor.html">AbsGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_lengths_def.html">AbstractLengthsDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">AbstractLengthsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_lengths_op.html">AbstractLengthsOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Segment reduction op with optional fused embedding lookup.  <a href="classcaffe2_1_1_abstract_lengths_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_lengths_with_main_input_and_forward_output_gradient_op.html">AbstractLengthsWithMainInputAndForwardOutputGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_lengths_with_main_input_gradient_op.html">AbstractLengthsWithMainInputGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_reduce_back_def.html">AbstractReduceBackDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_reduce_front_def.html">AbstractReduceFrontDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_reduce_front_or_back_gradient_op.html">AbstractReduceFrontOrBackGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_reduce_front_or_back_op.html">AbstractReduceFrontOrBackOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Simple non-segmented reduction over the first few dimensions of the tensor.  <a href="classcaffe2_1_1_abstract_reduce_front_or_back_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_sorted_segment_def.html">AbstractSortedSegmentDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_sorted_segment_gradient_op.html">AbstractSortedSegmentGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_sorted_segment_op.html">AbstractSortedSegmentOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Segment reduction op with optional fused embedding lookup.  <a href="classcaffe2_1_1_abstract_sorted_segment_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_sorted_segment_range_def.html">AbstractSortedSegmentRangeDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_sorted_segment_range_gradient_op.html">AbstractSortedSegmentRangeGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_sorted_segment_range_op.html">AbstractSortedSegmentRangeOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Base implementation for segment reduction op that leverages continuity of the data.  <a href="classcaffe2_1_1_abstract_sorted_segment_range_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_sparse_lengths_def.html">AbstractSparseLengthsDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_sparse_sorted_segment_def.html">AbstractSparseSortedSegmentDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_sparse_unsorted_segment_def.html">AbstractSparseUnsortedSegmentDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_abstract_unsorted_segment_def.html">AbstractUnsortedSegmentDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_unsorted_segment_gradient_op.html">AbstractUnsortedSegmentGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_abstract_unsorted_segment_op.html">AbstractUnsortedSegmentOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Unsorted segment reduction op with optional fused embedding lookup.  <a href="classcaffe2_1_1_abstract_unsorted_segment_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_accumulate_histogram_op.html">AccumulateHistogramOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_accumulate_input_gradient_op.html">AccumulateInputGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_accumulate_op.html">AccumulateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_accuracy_op.html">AccuracyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_acos_functor.html">AcosFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_acos_gradient_functor.html">AcosGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_adadelta_op.html">AdadeltaOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_adagrad_op.html">AdagradOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_adam_op.html">AdamOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_add_d_n_n_low_p_op.html">AddDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_add_functor.html">AddFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_add_padding_op.html">AddPaddingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_adjust_batch_op.html">AdjustBatchOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_affine_channel_gradient_op.html">AffineChannelGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_affine_channel_op.html">AffineChannelOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_algorithms_cache.html">AlgorithmsCache</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_alias_op.html">AliasOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Alias op makes the output and the input share the same underlying storage.  <a href="classcaffe2_1_1_alias_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_aligned_deleter.html">AlignedDeleter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_alloc_aligned.html">AllocAligned</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_alternate_learning_rate.html">AlternateLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_a_p_meter_op.html">APMeterOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_arg_max_reducer.html">ArgMaxReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_arg_min_reducer.html">ArgMinReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_arg_op.html">ArgOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> helper class to index into arguments.  <a href="classcaffe2_1_1_argument_helper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_asin_functor.html">AsinFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_asin_gradient_functor.html">AsinGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_assert_op.html">AssertOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_async_net_base.html">AsyncNetBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_async_net_executor_helper.html">AsyncNetExecutorHelper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_async_scheduling_net.html">AsyncSchedulingNet</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_async_task.html">AsyncTask</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_async_task_future.html">AsyncTaskFuture</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_async_task_graph.html">AsyncTaskGraph</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_async_task_graph_base.html">AsyncTaskGraphBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_atan_functor.html">AtanFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_atan_gradient_functor.html">AtanGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_atomic_iter_op.html">AtomicIterOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_averaged_loss_gradient.html">AveragedLossGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_avg_exported_stat.html">AvgExportedStat</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_backend_transformer_base.html">BackendTransformerBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_base_input_accessor.html">BaseInputAccessor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_base_reducer.html">BaseReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_base_reducer_gradient.html">BaseReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_box_cox_op.html">BatchBoxCoxOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_bucketize_op.html">BatchBucketizeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_bucket_one_hot_op.html">BatchBucketOneHotOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_dense_to_sparse_op.html">BatchDenseToSparseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_gather_gradient_op.html">BatchGatherGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_gather_op.html">BatchGatherOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_mat_mul_d_n_n_low_p_op.html">BatchMatMulDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_mat_mul_op.html">BatchMatMulOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_moments_gradient_op.html">BatchMomentsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_moments_op.html">BatchMomentsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_one_hot_op.html">BatchOneHotOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_permutation_d_n_n_low_p_op.html">BatchPermutationDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_permutation_gradient_op.html">BatchPermutationGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_permutation_op.html">BatchPermutationOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_sparse_to_dense_op.html">BatchSparseToDenseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_batch_to_space_op.html">BatchToSpaceOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_b_box_transform_op.html">BBoxTransformOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_bernoulli_j_s_d_gradient_op.html">BernoulliJSDGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_bernoulli_j_s_d_op.html">BernoulliJSDOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_binary_elementwise_d_n_n_low_p_op.html">BinaryElementwiseDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseWithArgsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op_3_01_numeric_types_00_01_c_p_u_context_18719035c30b9048fc92376cf087945e.html">BinaryElementwiseWithArgsGradientOp&lt; NumericTypes, CPUContext, BinaryFunctorWithDefaultCtor&lt; DivFunctor&lt; CPUContext &gt; &gt;, SameTypeAsInput, SameTypeAsInput &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseWithArgsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_binary_functor_with_default_ctor.html">BinaryFunctorWithDefaultCtor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_bisect_percentile_op.html">BisectPercentileOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_blob.html">Blob</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_blob.html" title="Blob is a general container that hosts a typed pointer. ">Blob</a> is a general container that hosts a typed pointer.  <a href="classcaffe2_1_1_blob.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_blob_deserializer_base.html">BlobDeserializerBase</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_blob_deserializer_base.html" title="BlobDeserializerBase is an abstract class that deserializes a blob from a BlobProto or a TensorProto...">BlobDeserializerBase</a> is an abstract class that deserializes a blob from a BlobProto or a TensorProto.  <a href="classcaffe2_1_1_blob_deserializer_base.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_blob_serializer_base.html">BlobSerializerBase</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_blob_serializer_base.html" title="BlobSerializerBase is an abstract class that serializes a blob to a string. ">BlobSerializerBase</a> is an abstract class that serializes a blob to a string.  <a href="classcaffe2_1_1_blob_serializer_base.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_blobs_queue.html">BlobsQueue</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_blob_stat_getter.html">BlobStatGetter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_blob_stat_registry.html">BlobStatRegistry</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_blocking_counter.html">BlockingCounter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_boolean_mask_op.html">BooleanMaskOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_boolean_unmask_op.html">BooleanUnmaskOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_bound_shape_inferencer.html">BoundShapeInferencer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_bound_shape_spec.html">BoundShapeSpec</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_box_with_n_m_s_limit_op.html">BoxWithNMSLimitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_b_r_g_n_c_h_w_c_to_packed_int8_b_g_r_a_stylizer_deprocess_op.html">BRGNCHWCToPackedInt8BGRAStylizerDeprocessOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_buffered_tokenizer.html">BufferedTokenizer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_byte_weight_dequant_op.html">ByteWeightDequantOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_caffe2_annotation.html">Caffe2Annotation</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_caffe2_module_test_dynamic_dummy_op.html">Caffe2ModuleTestDynamicDummyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cast_helper.html">CastHelper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cast_helper_3_01std_1_1string_00_01_src_type_01_4.html">CastHelper&lt; std::string, SrcType &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cast_op.html">CastOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cbrt_functor.html">CbrtFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cbrt_gradient_functor.html">CbrtGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ceil_op.html">CeilOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_channel_backprop_stats_op.html">ChannelBackpropStatsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_channel_shuffle_d_n_n_low_p_op.html">ChannelShuffleDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_channel_shuffle_gradient_op.html">ChannelShuffleGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_channel_shuffle_op.html">ChannelShuffleOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_channel_stats_op.html">ChannelStatsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_char_range.html">CharRange</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_check_counter_done_op.html">CheckCounterDoneOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_checkpoint_op.html">CheckpointOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_clip_gradient_op.html">ClipGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_clip_op.html">ClipOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_clip_tensor_by_scaling_op.html">ClipTensorByScalingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_close_blobs_queue_op.html">CloseBlobsQueueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_close_rebatching_queue_op.html">CloseRebatchingQueueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_col2_im_op.html">Col2ImOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_collect_and_distribute_fpn_rpn_proposals_op.html">CollectAndDistributeFpnRpnProposalsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_common_subexpression_elimination_transform.html">CommonSubexpressionEliminationTransform</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Common Subexpression Elimination.  <a href="classcaffe2_1_1_common_subexpression_elimination_transform.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_composite_learning_rate.html">CompositeLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_composite_learning_rate_item.html">CompositeLearningRateItem</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_concat_d_n_n_low_p_op.html">ConcatDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_concat_op.html">ConcatOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conditional_op.html">ConditionalOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_constant_fill_op.html">ConstantFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_constant_warmup_learning_rate.html">ConstantWarmupLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_conv_args.html">ConvArgs</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_acc16_op.html">ConvDNNLowPAcc16Op</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Quantized <a class="el" href="class_conv.html">Conv</a> operator with 16-bit accumulation.  <a href="classcaffe2_1_1_conv_d_n_n_low_p_acc16_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_op.html">ConvDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_pack_weight_op.html">ConvDNNLowPPackWeightOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pack a weight matrix that can be used by DNNLOWP Int8Conv operators.  <a href="classcaffe2_1_1_conv_d_n_n_low_p_pack_weight_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_converter.html">Converter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_pool_d_n_n_low_p_op_base.html">ConvPoolDNNLowPOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_relu_op.html">ConvReluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_to_n_n_pack_transform.html">ConvToNNPackTransform</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_transpose_gradient_op.html">ConvTransposeGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_transpose_op.html">ConvTransposeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_conv_transpose_unpool_base.html">ConvTransposeUnpoolBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_copy_c_p_u_to_i_d_e_e_p_op.html">CopyCPUToIDEEPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_copy_i_d_e_e_p_to_c_p_u_op.html">CopyIDEEPToCPUOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_copy_on_device_like_op.html">CopyOnDeviceLikeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_copy_op.html">CopyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cos_functor.html">CosFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cos_gradient_functor.html">CosGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cosh_functor.html">CoshFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cosh_gradient_functor.html">CoshGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cosine_embedding_criterion_gradient_op.html">CosineEmbeddingCriterionGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cosine_embedding_criterion_op.html">CosineEmbeddingCriterionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cosine_similarity_gradient_op.html">CosineSimilarityGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cosine_similarity_op.html">CosineSimilarityOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_count_down_op.html">CountDownOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_counter.html">Counter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_count_up_op.html">CountUpOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The CPU Context, representing the bare minimum of what a Context class in Caffe2 should implement.  <a href="classcaffe2_1_1_c_p_u_context.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_c_p_u_event_wrapper.html">CPUEventWrapper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cpu_id.html">CpuId</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Identification of an Intel CPU.  <a href="classcaffe2_1_1_cpu_id.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">CPUSparseLengthsReductionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_create_blobs_queue_op.html">CreateBlobsQueueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_create_counter_op.html">CreateCounterOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_create_d_b_op.html">CreateDBOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_create_map_op.html">CreateMapOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_create_rebatching_queue_op.html">CreateRebatchingQueueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_create_scope_op.html">CreateScopeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_create_text_file_reader_op.html">CreateTextFileReaderOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cross_entropy_gradient_op.html">CrossEntropyGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cross_entropy_op.html">CrossEntropyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_c_t_c_beam_search_decoder_op.html">CTCBeamSearchDecoderOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_c_t_c_greedy_decoder_op.html">CTCGreedyDecoderOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cube_functor.html">CubeFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cube_gradient_functor.html">CubeGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cuda_device_prop_wrapper.html">CudaDevicePropWrapper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cuda_event_wrapper.html">CudaEventWrapper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_c_u_d_a_recurrent_network_executor.html">CUDARecurrentNetworkExecutor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cuda_r_t_c_function.html">CudaRTCFunction</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_gradient_op.html">CuDNNActivationGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_gradient_op_3_01_c_u_d_n_n___a_c_t_i_v_a_t_i_o_n___e_l_u_01_4.html">CuDNNActivationGradientOp&lt; CUDNN_ACTIVATION_ELU &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_op.html">CuDNNActivationOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_op_3_01_c_u_d_n_n___a_c_t_i_v_a_t_i_o_n___e_l_u_01_4.html">CuDNNActivationOp&lt; CUDNN_ACTIVATION_ELU &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_op_base.html">CuDNNActivationOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cudnn_conv_gradient_op.html">CudnnConvGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cudnn_conv_op.html">CudnnConvOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cudnn_conv_op_base.html">CudnnConvOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cudnn_conv_transpose_gradient_op.html">CudnnConvTransposeGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cudnn_conv_transpose_op.html">CudnnConvTransposeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cudnn_conv_transpose_op_base.html">CudnnConvTransposeOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1cudnn_filter_desc_wrapper.html">cudnnFilterDescWrapper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_l_r_n_gradient_op.html">CuDNNLRNGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_l_r_n_op.html">CuDNNLRNOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_softmax_gradient_op.html">CuDNNSoftmaxGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_softmax_op.html">CuDNNSoftmaxOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_state.html">CuDNNState</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1cudnn_tensor_desc_wrapper.html">cudnnTensorDescWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1cudnn_tensor_desc_wrapper.html" title="cudnnTensorDescWrapper is the placeholder that wraps around a cudnnTensorDescriptor_t, allowing us to do descriptor change as-needed during runtime. ">cudnnTensorDescWrapper</a> is the placeholder that wraps around a cudnnTensorDescriptor_t, allowing us to do descriptor change as-needed during runtime.  <a href="classcaffe2_1_1cudnn_tensor_desc_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1cudnn_type_wrapper.html">cudnnTypeWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1cudnn_type_wrapper.html" title="cudnnTypeWrapper is a wrapper class that allows us to refer to the cudnn type in a template function...">cudnnTypeWrapper</a> is a wrapper class that allows us to refer to the cudnn type in a template function.  <a href="classcaffe2_1_1cudnn_type_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1cudnn_type_wrapper_3_01at_1_1_half_01_4.html">cudnnTypeWrapper&lt; at::Half &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1cudnn_type_wrapper_3_01double_01_4.html">cudnnTypeWrapper&lt; double &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1cudnn_type_wrapper_3_01float_01_4.html">cudnnTypeWrapper&lt; float &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_weighted_sum_op.html">CuDNNWeightedSumOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_cu_d_n_n_workspace.html">CuDNNWorkspace</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="structcaffe2_1_1_cu_d_n_n_workspace.html" title="CuDNNWorkspace is a wrapper around a raw cuda pointer that holds the cudnn scratch space...">CuDNNWorkspace</a> is a wrapper around a raw cuda pointer that holds the cudnn scratch space.  <a href="structcaffe2_1_1_cu_d_n_n_workspace.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_cu_d_n_n_wrapper.html">CuDNNWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_cu_d_n_n_wrapper.html" title="CuDNNWrapper is a class that wraps the cudnn handles and cudnn workspaces. ">CuDNNWrapper</a> is a class that wraps the cudnn handles and cudnn workspaces.  <a href="classcaffe2_1_1_cu_d_n_n_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_data_couple_op.html">DataCoupleOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_d_b_exists_op.html">DBExistsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_decoded_frame.html">DecodedFrame</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_default_engine.html">DefaultEngine</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_deform_conv_gradient_op.html">DeformConvGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_deform_conv_op.html">DeformConvOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_deform_conv_op_base.html">DeformConvOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dense_vector_to_id_list_op.html">DenseVectorToIdListOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dequeue_blobs_op.html">DequeueBlobsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dequeue_rebatching_queue_op.html">DequeueRebatchingQueueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_detailed_exported_stat.html">DetailedExportedStat</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_device_type_registerer.html">DeviceTypeRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_diagonal_fill_op.html">DiagonalFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_dispatch_helper.html">DispatchHelper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_dispatch_helper_3_01_fixed_values_3_01_first_val_00_01_values_8_8_8_01_4_00_01_extra_args_8_8_8_01_4.html">DispatchHelper&lt; FixedValues&lt; FirstVal, Values... &gt;, ExtraArgs... &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_dispatch_helper_3_01_fixed_values_3_4_00_01_extra_args_8_8_8_01_4.html">DispatchHelper&lt; FixedValues&lt;&gt;, ExtraArgs... &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_div_functor.html">DivFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_d_n_n_low_p_op.html">DNNLowPOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> convenient base class for C2 operators with DNNLOWP engine.  <a href="classcaffe2_1_1_d_n_n_low_p_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_do_op.html">DoOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dot_product_gradient_op.html">DotProductGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dot_product_op.html">DotProductOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dot_product_with_padding_gradient_op.html">DotProductWithPaddingGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dot_product_with_padding_op.html">DotProductWithPaddingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dropout_gradient_op.html">DropoutGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_dropout_op.html">DropoutOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_eigen_pow_functor.html">EigenPowFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_elementwise_linear_d_n_n_low_p_op.html">ElementwiseLinearDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_elementwise_linear_gradient_op.html">ElementwiseLinearGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_elementwise_linear_op.html">ElementwiseLinearOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_elementwise_r_t_c_op.html">ElementwiseRTCOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> GPU operator that can generate limited elementwise operations.  <a href="classcaffe2_1_1_elementwise_r_t_c_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_elu_functor.html">EluFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_elu_gradient_functor.html">EluGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_enforce_finite_op.html">EnforceFiniteOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_enqueue_blobs_op.html">EnqueueBlobsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_enqueue_rebatching_queue_op.html">EnqueueRebatchingQueueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ensure_clipped_op.html">EnsureClippedOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ensure_c_p_u_output_op.html">EnsureCPUOutputOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ensure_dense_op.html">EnsureDenseOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pass inputs to outputs.  <a href="classcaffe2_1_1_ensure_dense_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_erf_functor.html">ErfFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_erf_gradient_functor.html">ErfGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_event.html">Event</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_create_function_registerer.html">EventCreateFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_error_message_function_registerer.html">EventErrorMessageFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_finish_function_registerer.html">EventFinishFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_query_function_registerer.html">EventQueryFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_record_function_registerer.html">EventRecordFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_reset_function_registerer.html">EventResetFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_set_callback_function_registerer.html">EventSetCallbackFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_set_finished_function_registerer.html">EventSetFinishedFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_event_wait_function_registerer.html">EventWaitFunctionRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_execution_options.html">ExecutionOptions</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_executor_helper.html">ExecutorHelper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_expand_dims_op.html">ExpandDimsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_expand_gradient_op.html">ExpandGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_expand_op.html">ExpandOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_exp_functor.html">ExpFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_exp_learning_rate.html">ExpLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_exported_stat.html">ExportedStat</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_exported_stat_value.html">ExportedStatValue</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fail_op.html">FailOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_feed_blob_op.html">FeedBlobOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_file_reader.html">FileReader</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_file_store_handler.html">FileStoreHandler</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_file_store_handler_create_op.html">FileStoreHandlerCreateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_filler_op.html">FillerOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_find_duplicate_elements_op.html">FindDuplicateElementsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_find_op.html">FindOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fixed_divisor.html">FixedDivisor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fixed_divisor_3_01std_1_1int32__t_01_4.html">FixedDivisor&lt; std::int32_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fixed_learning_rate.html">FixedLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_fixed_type.html">FixedType</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_fixed_values.html">FixedValues</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_flatten_op.html">FlattenOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_flatten_to_vec_op.html">FlattenToVecOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_flexible_top_k_gradient_op.html">FlexibleTopKGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_flexible_top_k_op.html">FlexibleTopKOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_float16_constant_fill_op.html">Float16ConstantFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_float16_uniform_fill_op.html">Float16UniformFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_float_to_fused8_bit_rowwise_quantized_op.html">FloatToFused8BitRowwiseQuantizedOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_float_to_fused_rand_rowwise_quantized_op.html">FloatToFusedRandRowwiseQuantizedOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_float_to_half_op.html">FloatToHalfOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_float_to_rowwise_quantized8_bits_op.html">FloatToRowwiseQuantized8BitsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_floor_op.html">FloorOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_for_each.html">ForEach</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="structcaffe2_1_1_for_each.html" title="ForEach is a unary functor that forwards each element of the input array into the elementwise Functor...">ForEach</a> is a unary functor that forwards each element of the input array into the elementwise Functor provided, and gathers the results of each call into the resulting array.  <a href="structcaffe2_1_1_for_each.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_f_p16_momentum_s_g_d_update_op.html">FP16MomentumSGDUpdateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_f_p32_momentum_s_g_d_update_op.html">FP32MomentumSGDUpdateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_free_op.html">FreeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ftrl_op.html">FtrlOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_ftrl_params.html">FtrlParams</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_decomp_gradient_op.html">FullyConnectedDecompGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_acc16_op.html">FullyConnectedDNNLowPAcc16Op</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Quantized <a class="el" href="class_f_c.html">FC</a> operator with 16-bit accumulation.  <a href="classcaffe2_1_1_fully_connected_d_n_n_low_p_acc16_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_op.html">FullyConnectedDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_pack_weight_op.html">FullyConnectedDNNLowPPackWeightOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_fake_lowp_f_p_op.html">FullyConnectedFakeLowpFPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_gradient_fake_lowp_f_p_op.html">FullyConnectedGradientFakeLowpFPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_gradient_op.html">FullyConnectedGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_op.html">FullyConnectedOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_op___s_p_a_r_s_e.html">FullyConnectedOp_SPARSE</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_op_decomp.html">FullyConnectedOpDecomp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_op_prune.html">FullyConnectedOpPrune</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fully_connected_prune_gradient_op.html">FullyConnectedPruneGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fun_hash_gradient_op.html">FunHashGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fun_hash_op.html">FunHashOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fused8_bit_rowwise_quantized_to_float_op.html">Fused8BitRowwiseQuantizedToFloatOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_fused_rand_rowwise_quantized_to_float_op.html">FusedRandRowwiseQuantizedToFloatOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gather_by_key_op.html">GatherByKeyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gather_d_n_n_low_p_op.html">GatherDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gather_fused8_bit_rowwise_op.html">GatherFused8BitRowwiseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gather_op.html">GatherOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gather_padding_op.html">GatherPaddingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gather_ranges_op.html">GatherRangesOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gather_ranges_to_dense_op.html">GatherRangesToDenseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gaussian_fill_op.html">GaussianFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_generate_proposals_op.html">GenerateProposalsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_generic_tensor_implementation.html">GenericTensorImplementation</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_add_padding_gradient.html">GetAddPaddingGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_averaged_loss_gradient.html">GetAveragedLossGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_batch_gather_gradient.html">GetBatchGatherGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_batch_permutation_gradient.html">GetBatchPermutationGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_batch_to_space_gradient.html">GetBatchToSpaceGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_bernoulli_j_s_d_gradient.html">GetBernoulliJSDGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_cast_gradient.html">GetCastGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_col2_im_gradient.html">GetCol2ImGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_conv_gradient.html">GetConvGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_conv_transpose_gradient.html">GetConvTransposeGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_copy_gradient.html">GetCopyGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_cosine_similarity_gradient.html">GetCosineSimilarityGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_c_p_u_to_g_p_u_gradient.html">GetCPUToGPUGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_cross_entropy_gradient.html">GetCrossEntropyGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_dot_product_gradient.html">GetDotProductGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_dot_product_with_padding_gradient.html">GetDotProductWithPaddingGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_dropout_gradient.html">GetDropoutGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_elementwise_linear_gradient.html">GetElementwiseLinearGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_expand_dims_gradient.html">GetExpandDimsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_f_c_decomp_gradient.html">GetFCDecompGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_float_to_half_gradient.html">GetFloatToHalfGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_g_p_u_to_c_p_u_gradient.html">GetGPUToCPUGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_group_spatial_softmax_gradient.html">GetGroupSpatialSoftmaxGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_g_r_u_unit_gradient.html">GetGRUUnitGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_half_to_float_gradient.html">GetHalfToFloatGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_im2_col_gradient.html">GetIm2ColGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_instance_norm_gradient.html">GetInstanceNormGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_integral_image_gradient.html">GetIntegralImageGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_l1_distance_gradient.html">GetL1DistanceGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_label_cross_entropy_gradient.html">GetLabelCrossEntropyGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_leaky_relu_gradient.html">GetLeakyReluGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_l_r_n_gradient.html">GetLRNGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_l_s_t_m_unit_gradient.html">GetLSTMUnitGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_make_two_class_gradient.html">GetMakeTwoClassGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_mat_mul_gradient.html">GetMatMulGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_mean_gradient.html">GetMeanGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_nan_check_gradient.html">GetNanCheckGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_negate_gradient_gradient.html">GetNegateGradientGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_normalize_gradient.html">GetNormalizeGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_pack_segments_gradient.html">GetPackSegmentsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_pad_image_gradient.html">GetPadImageGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_prepend_dim_gradient.html">GetPrependDimGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_recurrent_gradient.html">GetRecurrentGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_recurrent_network_gradient.html">GetRecurrentNetworkGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_reduce_back_max_gradient.html">GetReduceBackMaxGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_reduce_back_sum_gradient.html">GetReduceBackSumGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_reduce_front_max_gradient.html">GetReduceFrontMaxGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_reduce_front_mean_gradient.html">GetReduceFrontMeanGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_reduce_front_sum_gradient.html">GetReduceFrontSumGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_remove_padding_gradient.html">GetRemovePaddingGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_resize_nearest_gradient.html">GetResizeNearestGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_reverse_packed_segs_gradient.html">GetReversePackedSegsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_ro_i_pool_gradient.html">GetRoIPoolGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_sample_as_gradient.html">GetSampleAsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_scale_gradient.html">GetScaleGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_select_smooth_l1_loss_gradient.html">GetSelectSmoothL1LossGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_selu_gradient.html">GetSeluGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_sigmoid_cross_entropy_loss_gradient.html">GetSigmoidCrossEntropyLossGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_sigmoid_cross_entropy_with_logits_gradient.html">GetSigmoidCrossEntropyWithLogitsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_sigmoid_focal_loss_gradient.html">GetSigmoidFocalLossGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_smooth_l1_loss_gradient.html">GetSmoothL1LossGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_softmax_focal_loss_gradient.html">GetSoftmaxFocalLossGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_softplus_gradient.html">GetSoftplusGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_space_to_batch_gradient.html">GetSpaceToBatchGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_squared_l2_distance_gradient.html">GetSquaredL2DistanceGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_square_root_divide_gradient.html">GetSquareRootDivideGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_squeeze_gradient.html">GetSqueezeGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_sum_elements_gradient.html">GetSumElementsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_top_k_gradient.html">GetTopKGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_transpose_gradient.html">GetTransposeGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_unpack_segments_gradient.html">GetUnpackSegmentsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_upsample_bilinear_gradient.html">GetUpsampleBilinearGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_get_upsample_nearest_gradient.html">GetUpsampleNearestGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_weighted_sigmoid_cross_entropy_with_logits_gradient.html">GetWeightedSigmoidCrossEntropyWithLogitsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_get_zero_gradient_op_gradient.html">GetZeroGradientOpGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_g_ftrl_op.html">GFtrlOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_g_ftrl_params.html">GFtrlParams</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_given_tensor_byte_string_to_u_int8_fill_op.html">GivenTensorByteStringToUInt8FillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_global_init_is_called_guard.html">GlobalInitIsCalledGuard</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_glu_op.html">GluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_g_p_u_fallback_op_ex.html">GPUFallbackOpEx</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> templated class to allow one to wrap a CPU operator as a CUDA operator.  <a href="classcaffe2_1_1_g_p_u_fallback_op_ex.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_gradient_maker_base.html">GradientMakerBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_gradient_not_implemented_yet.html">GradientNotImplementedYet</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> helper class to indicate that the gradient mechanism is not ready.  <a href="structcaffe2_1_1_gradient_not_implemented_yet.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_gradient_ops_meta.html">GradientOpsMeta</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> struct that holds the gradient operators and related gradient maps.  <a href="structcaffe2_1_1_gradient_ops_meta.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_gradient_wrapper.html">GradientWrapper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_group_norm_d_n_n_low_p_op.html">GroupNormDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_group_norm_gradient_op.html">GroupNormGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_group_norm_op.html">GroupNormOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_group_spatial_softmax_gradient_op.html">GroupSpatialSoftmaxGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_group_spatial_softmax_op.html">GroupSpatialSoftmaxOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_g_r_u_unit_gradient_op.html">GRUUnitGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_g_r_u_unit_op.html">GRUUnitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_half_to_float_op.html">HalfToFloatOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_hard_sigmoid_functor.html">HardSigmoidFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_hard_sigmoid_gradient_functor.html">HardSigmoidGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_has_elements_op.html">HasElementsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_has_scope_op.html">HasScopeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_heatmap_max_keypoint_op.html">HeatmapMaxKeypointOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_hill_learning_rate.html">HillLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_histogram_net_observer.html">HistogramNetObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_histogram_observer.html">HistogramObserver</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given min/max, collect histogram.  <a href="classcaffe2_1_1_histogram_observer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_h_softmax_gradient_op.html">HSoftmaxGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_h_softmax_op.html">HSoftmaxOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_h_softmax_op_base.html">HSoftmaxOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_h_softmax_search_op.html">HSoftmaxSearchOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_huffman_tree_hierarchy_op.html">HuffmanTreeHierarchyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_adam_op.html">IDEEPAdamOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_concat_op.html">IDEEPConcatOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_context.html">IDEEPContext</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_fusion_op.html">IDEEPConvFusionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_gradient_op.html">IDEEPConvGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_op.html">IDEEPConvOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_pool_op_base.html">IDEEPConvPoolOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_transpose_gradient_op.html">IDEEPConvTransposeGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_transpose_op.html">IDEEPConvTransposeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_transpose_unpool_base.html">IDEEPConvTransposeUnpoolBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_copy_op.html">IDEEPCopyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_create_blobs_queue_op.html">IDEEPCreateBlobsQueueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_dropout_gradient_op.html">IDEEPDropoutGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_dropout_op.html">IDEEPDropoutOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_expand_dims_op.html">IDEEPExpandDimsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> templated class to allow one to wrap a CPU operator as an IDEEP operator.  <a href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_fully_connected_gradient_op.html">IDEEPFullyConnectedGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_fully_connected_op.html">IDEEPFullyConnectedOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_l_r_n_gradient_op.html">IDEEPLRNGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_l_r_n_op.html">IDEEPLRNOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_momentum_s_g_d_op.html">IDEEPMomentumSGDOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_momentum_s_g_d_update_op.html">IDEEPMomentumSGDUpdateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_operator.html">IDEEPOperator</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_pool_gradient_op.html">IDEEPPoolGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_pool_op.html">IDEEPPoolOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_relu_gradient_op.html">IDEEPReluGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_relu_op.html">IDEEPReluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_reshape_op.html">IDEEPReshapeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_safe_enqueue_blobs_op.html">IDEEPSafeEnqueueBlobsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_shape_op.html">IDEEPShapeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_sigmoid_gradient_op.html">IDEEPSigmoidGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_sigmoid_op.html">IDEEPSigmoidOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_spatial_b_n_gradient_op.html">IDEEPSpatialBNGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_spatial_b_n_op.html">IDEEPSpatialBNOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_split_op.html">IDEEPSplitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_squeeze_op.html">IDEEPSqueezeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_sum_op.html">IDEEPSumOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_i_d_e_e_p_weighted_sum_op.html">IDEEPWeightedSumOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_if_op.html">IfOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_im2_col_op.html">Im2ColOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_image_input_op.html">ImageInputOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_index.html">Index</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_index_base.html">IndexBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_create_op.html">IndexCreateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_deserializer.html">IndexDeserializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_freeze_op.html">IndexFreezeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_get_op.html">IndexGetOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_hash_op.html">IndexHashOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_load_op.html">IndexLoadOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_serializer.html">IndexSerializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_size_op.html">IndexSizeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_index_store_op.html">IndexStoreOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_init_registerer.html">InitRegisterer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_instance_norm_gradient_op.html">InstanceNormGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_instance_norm_op.html">InstanceNormOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_int8_conv_d_n_n_low_p_packed_weight_blob.html">Int8ConvDNNLowPPackedWeightBlob</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Packed weight matrix for DNNLOWP Int8Conv operator.  <a href="structcaffe2_1_1_int8_conv_d_n_n_low_p_packed_weight_blob.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_int8_f_c_d_n_n_low_p_packed_weight_blob.html">Int8FCDNNLowPPackedWeightBlob</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Packed weight matrix for DNNLOWP Int8FC operator.  <a href="structcaffe2_1_1_int8_f_c_d_n_n_low_p_packed_weight_blob.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_integral_image_gradient_op.html">IntegralImageGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_integral_image_op.html">IntegralImageOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_inv_learning_rate.html">InvLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_is_empty_op.html">IsEmptyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_is_member_of_op.html">IsMemberOfOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_is_member_of_value_holder.html">IsMemberOfValueHolder</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_is_nan_op.html">IsNanOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_iter_op.html">IterOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_key_split_op.html">KeySplitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_key_value_to_map_op.html">KeyValueToMapOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l1_distance_gradient_op.html">L1DistanceGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l1_distance_op.html">L1DistanceOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_l1_reducer.html">L1Reducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_l2_reducer.html">L2Reducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_label_cross_entropy_gradient_op.html">LabelCrossEntropyGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_label_cross_entropy_op.html">LabelCrossEntropyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lambda_rank_ndcg_gradient_op.html">LambdaRankNdcgGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lambda_rank_ndcg_op.html">LambdaRankNdcgOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lars_op.html">LarsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_layer_norm_gradient_op.html">LayerNormGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_layer_norm_op.html">LayerNormOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_leaky_relu_gradient_op.html">LeakyReluGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_leaky_relu_op.html">LeakyReluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_learning_rate_adaption_op.html">LearningRateAdaptionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_learning_rate_functor.html">LearningRateFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_learning_rate_op.html">LearningRateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_gather_op.html">LengthsGatherOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_lengths_op_get_gradient.html">LengthsOpGetGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_pad_op.html">LengthsPadOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_partition_op.html">LengthsPartitionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_range_fill_op.html">LengthsRangeFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_split_op.html">LengthsSplitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_tile_op.html">LengthsTileOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_top_k_gradient_op.html">LengthsTopKGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_top_k_op.html">LengthsTopKOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_to_ranges_op.html">LengthsToRangesOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_to_segment_ids_op.html">LengthsToSegmentIdsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_to_shape_op.html">LengthsToShapeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lengths_to_weights_op.html">LengthsToWeightsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_linear_warmup_learning_rate.html">LinearWarmupLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_load_op.html">LoadOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_log_fatal_op.html">LogFatalOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_log_functor.html">LogFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_logit_functor.html">LogitFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_logit_gradient_op.html">LogitGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_log_mean_exp_range_reducer.html">LogMeanExpRangeReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_log_mean_exp_range_reducer_3_01_t_00_01_c_p_u_context_01_4.html">LogMeanExpRangeReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_log_mean_exp_range_reducer_def.html">LogMeanExpRangeReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_log_mean_exp_range_reducer_gradient.html">LogMeanExpRangeReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_log_sum_exp_range_reducer.html">LogSumExpRangeReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_log_sum_exp_range_reducer_3_01_t_00_01_c_p_u_context_01_4.html">LogSumExpRangeReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_log_sum_exp_range_reducer_def.html">LogSumExpRangeReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_log_sum_exp_range_reducer_gradient.html">LogSumExpRangeReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lp_norm_gradient_op.html">LpNormGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_lp_norm_op.html">LpNormOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_lp_pool_functor.html">LpPoolFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l_r_n_gradient_op.html">LRNGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l_r_n_op.html">LRNOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l_r_n_op_base.html">LRNOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l_s_t_m_unit_d_n_n_low_p_op.html">LSTMUnitDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l_s_t_m_unit_gradient_op.html">LSTMUnitGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_l_s_t_m_unit_op.html">LSTMUnitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_make_aligned.html">MakeAligned</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_make_two_class_gradient_op.html">MakeTwoClassGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_make_two_class_op.html">MakeTwoClassOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_map_deserializer.html">MapDeserializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_map_serializer.html">MapSerializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_map_to_key_value_op.html">MapToKeyValueOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_map_type_traits.html">MapTypeTraits</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_margin_ranking_criterion_gradient_op.html">MarginRankingCriterionGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_margin_ranking_criterion_op.html">MarginRankingCriterionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mat_mul_op.html">MatMulOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_gradient_op.html">MaxGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_op.html">MaxOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_pool_gradient_r_t_c_op.html">MaxPoolGradientRTCOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_pool_r_t_c_op.html">MaxPoolRTCOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_pool_with_index_gradient_op.html">MaxPoolWithIndexGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_pool_with_index_op.html">MaxPoolWithIndexOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_range_reducer.html">MaxRangeReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_range_reducer_3_01_t_00_01_c_p_u_context_01_4.html">MaxRangeReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_max_range_reducer_def.html">MaxRangeReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_range_reducer_gradient.html">MaxRangeReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_reduce_dims_gradient_op.html">MaxReduceDimsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_reduce_dims_op.html">MaxReduceDimsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_max_reducer.html">MaxReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_reducer_3_01_t_00_01_c_p_u_context_01_4.html">MaxReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_max_reducer_def.html">MaxReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_reducer_gradient.html">MaxReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_reduction_gradient_op.html">MaxReductionGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_max_reduction_op.html">MaxReductionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mean_gradient_op.html">MeanGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mean_op.html">MeanOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mean_range_reducer.html">MeanRangeReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mean_range_reducer_3_01_t_00_01_c_p_u_context_01_4.html">MeanRangeReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_mean_range_reducer_def.html">MeanRangeReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mean_range_reducer_gradient.html">MeanRangeReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_mean_reducer.html">MeanReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mean_reducer_3_01_t_00_01_c_p_u_context_01_4.html">MeanReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_mean_reducer_def.html">MeanReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mean_reducer_gradient.html">MeanReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_dim_op.html">MergeDimOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_id_lists_op.html">MergeIdListsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_multi_list_feature_tensors_op.html">MergeMultiListFeatureTensorsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_multi_list_or_map_feature_tensors_gradient_op.html">MergeMultiListOrMapFeatureTensorsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_multi_map_feature_tensors_op.html">MergeMultiMapFeatureTensorsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_multi_scalar_feature_tensors_gradient_op.html">MergeMultiScalarFeatureTensorsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_multi_scalar_feature_tensors_op.html">MergeMultiScalarFeatureTensorsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_single_list_feature_tensors_op.html">MergeSingleListFeatureTensorsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_single_list_or_map_feature_tensors_gradient_op.html">MergeSingleListOrMapFeatureTensorsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_single_map_feature_tensors_op.html">MergeSingleMapFeatureTensorsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_single_scalar_feature_tensors_gradient_op.html">MergeSingleScalarFeatureTensorsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_merge_single_scalar_feature_tensors_op.html">MergeSingleScalarFeatureTensorsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_min_gradient_op.html">MinGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_min_op.html">MinOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_min_reducer.html">MinReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_i_o_p_e_n_activation_gradient_op.html">MIOPENActivationGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_i_o_p_e_n_activation_op.html">MIOPENActivationOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_i_o_p_e_n_activation_op_base.html">MIOPENActivationOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_i_o_p_e_n_state.html">MIOPENState</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1miopen_tensor_desc_wrapper.html">miopenTensorDescWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1miopen_tensor_desc_wrapper.html" title="miopenTensorDescWrapper is the placeholder that wraps around a miopenTensorDescriptor_t, allowing us to do descriptor change as-needed during runtime. ">miopenTensorDescWrapper</a> is the placeholder that wraps around a miopenTensorDescriptor_t, allowing us to do descriptor change as-needed during runtime.  <a href="classcaffe2_1_1miopen_tensor_desc_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1miopen_type_wrapper.html">miopenTypeWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1miopen_type_wrapper.html" title="miopenTypeWrapper is a wrapper class that allows us to refer to the miopen type in a template functio...">miopenTypeWrapper</a> is a wrapper class that allows us to refer to the miopen type in a template function.  <a href="classcaffe2_1_1miopen_type_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1miopen_type_wrapper_3_01at_1_1_half_01_4.html">miopenTypeWrapper&lt; at::Half &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1miopen_type_wrapper_3_01float_01_4.html">miopenTypeWrapper&lt; float &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_m_i_o_p_e_n_workspace.html">MIOPENWorkspace</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="structcaffe2_1_1_m_i_o_p_e_n_workspace.html" title="MIOPENWorkspace is a wrapper around a raw cuda pointer that holds the miopen scratch space...">MIOPENWorkspace</a> is a wrapper around a raw cuda pointer that holds the miopen scratch space.  <a href="structcaffe2_1_1_m_i_o_p_e_n_workspace.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_i_o_p_e_n_wrapper.html">MIOPENWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_m_i_o_p_e_n_wrapper.html" title="MIOPENWrapper is a class that wraps the miopen handles and miopen workspaces. ">MIOPENWrapper</a> is a class that wraps the miopen handles and miopen workspaces.  <a href="classcaffe2_1_1_m_i_o_p_e_n_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mod_op.html">ModOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_module_schema.html">ModuleSchema</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> module schema that can be used to store specific information about different modules.  <a href="classcaffe2_1_1_module_schema.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_moments_gradient_op.html">MomentsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_moments_op.html">MomentsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_momentum_s_g_d_op.html">MomentumSGDOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_momentum_s_g_d_update_op.html">MomentumSGDUpdateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_p_i_common_world_wrapper.html">MPICommonWorldWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> simple wrapper over an MPI common world.  <a href="classcaffe2_1_1_m_p_i_common_world_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_p_i_data_type_wrapper.html">MPIDataTypeWrapper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_m_p_s_c_n_n_context.html">MPSCNNContext</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_m_s_r_a_fill_op.html">MSRAFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mul_d_n_n_low_p_op.html">MulDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_mul_functor.html">MulFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_multi_class_accuracy_op.html">MultiClassAccuracyOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mutex_deserializer.html">MutexDeserializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_mutex_serializer.html">MutexSerializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_nan_check_op.html">NanCheckOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_n_c_h_w2_n_h_w_c_op.html">NCHW2NHWCOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_negate_gradient_op.html">NegateGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_negative_functor.html">NegativeFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_net_observer_reporter.html">NetObserverReporter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_net_observer_reporter_print.html">NetObserverReporterPrint</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_n_gram_from_categorical_op.html">NGramFromCategoricalOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_n_h_w_c2_n_c_h_w_op.html">NHWC2NCHWOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_n_n_api.html">NNApi</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_n_n_p_a_c_k_conv_op.html">NNPACKConvOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> helper class to denote that an op does not have a default engine.  <a href="classcaffe2_1_1_no_default_engine_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_no_gradient.html">NoGradient</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> helper class to indicate that the operator does not need gradient computation.  <a href="classcaffe2_1_1_no_gradient.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_normalize_gradient_op.html">NormalizeGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_normalize_l1_op.html">NormalizeL1Op</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_normalize_op.html">NormalizeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_not_functor.html">NotFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_numpy_tile_op.html">NumpyTileOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_observable.html">Observable</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Inherit to make your class observable.  <a href="classcaffe2_1_1_observable.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_observer_base.html">ObserverBase</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Use this to implement a Observer using the Observer Pattern template.  <a href="classcaffe2_1_1_observer_base.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_observer_config.html">ObserverConfig</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_one_hot_op.html">OneHotOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_onnxifi_op.html">OnnxifiOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_onnxifi_transformer.html">OnnxifiTransformer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_onnxifi_transformer_options.html">OnnxifiTransformerOptions</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_o_n_n_x_while_op.html">ONNXWhileOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_operator.html">Operator</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_operator_attaching_net_observer.html">OperatorAttachingNetObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> class to record the schema of an op.  <a href="classcaffe2_1_1_op_schema.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_op_schema_registry.html">OpSchemaRegistry</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> registry to hold all the operator schemas.  <a href="classcaffe2_1_1_op_schema_registry.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_op_task.html">OpTask</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Data structure for a scheduled task in the task queue.  <a href="structcaffe2_1_1_op_task.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_optimization_pass.html">OptimizationPass</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_op_wrapper.html">OpWrapper</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Wrap a floating-point operator with quantized inputs with type <a class="el" href="struct_t.html">T</a>.  <a href="classcaffe2_1_1_op_wrapper.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_output_min_max_net_observer.html">OutputMinMaxNetObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_output_min_max_observer.html">OutputMinMaxObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_packed_int8_b_g_r_a_n_h_w_c_to_n_c_h_w_c_stylizer_preprocess_op.html">PackedInt8BGRANHWCToNCHWCStylizerPreprocessOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pack_r_n_n_sequence_op_base.html">PackRNNSequenceOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pack_segments_op.html">PackSegmentsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pad_empty_samples_op.html">PadEmptySamplesOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pad_image_gradient_op.html">PadImageGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pad_image_op.html">PadImageOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pair_wise_loss_gradient_op.html">PairWiseLossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pair_wise_loss_op.html">PairWiseLossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_parallel_net.html">ParallelNet</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_parallel_net_executor_helper.html">ParallelNetExecutorHelper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_params.html">Params</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_partition_op.html">PartitionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_partition_op_base.html">PartitionOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pattern_net_transform.html">PatternNetTransform</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_pattern_net_transform.html" title="PatternNetTransform allows you to create transforms using a simple interface. ">PatternNetTransform</a> allows you to create transforms using a simple interface.  <a href="classcaffe2_1_1_pattern_net_transform.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_percentile_op.html">PercentileOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_perf_net_observer.html">PerfNetObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_perf_operator_observer.html">PerfOperatorObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_performance_information.html">PerformanceInformation</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_perplexity_op.html">PerplexityOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_piecewise_linear_transform_op.html">PiecewiseLinearTransformOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_poly_learning_rate.html">PolyLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_pow_op.html">PowOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_predictor.html">Predictor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_predictor_config.html">PredictorConfig</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Stores parameters nessasary for creating a PredictorInterface object.  <a href="structcaffe2_1_1_predictor_config.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_prefetch_operator.html">PrefetchOperator</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_p_relu_gradient_op.html">PReluGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_p_relu_op.html">PReluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_prepend_dim_op.html">PrependDimOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_print_op.html">PrintOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_prof_d_a_g_counters.html">ProfDAGCounters</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> simple wrapper around prof_dag's counters.  <a href="classcaffe2_1_1_prof_d_a_g_counters.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_prof_d_a_g_report.html">ProfDAGReport</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_prof_d_a_g_stats.html">ProfDAGStats</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_profile_counter.html">ProfileCounter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_profile_observer.html">ProfileObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_profile_operator_observer.html">ProfileOperatorObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_p_s_ro_i_pool_gradient_op.html">PSRoIPoolGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_p_s_ro_i_pool_op.html">PSRoIPoolOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_q_conv_op.html">QConvOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_q_conv_state.html">QConvState</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_q_tensor.html">QTensor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_q_tensor_deserializer.html">QTensorDeserializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_q_tensor_serializer.html">QTensorSerializer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_quant_decode_gradient_op.html">QuantDecodeGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_quant_decode_op.html">QuantDecodeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_quant_decomp_zstd_op.html">QuantDecompZstdOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_quantize_d_n_n_low_p_op.html">QuantizeDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_range_fill_op.html">RangeFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_range_op.html">RangeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_rebatching_queue.html">RebatchingQueue</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_reciprocal_functor.html">ReciprocalFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_reciprocal_gradient_functor.html">ReciprocalGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_base_op.html">RecurrentBaseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_gradient_op.html">RecurrentGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_network_blob_fetcher_op.html">RecurrentNetworkBlobFetcherOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_network_executor_base.html">RecurrentNetworkExecutorBase</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">RecurrentNetworkExecutor is a specialized runtime for recurrent neural networks (RNNs).  <a href="classcaffe2_1_1_recurrent_network_executor_base.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_network_gradient_op.html">RecurrentNetworkGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_network_op.html">RecurrentNetworkOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_op.html">RecurrentOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_recurrent_param_access_op.html">RecurrentParamAccessOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_redis_store_handler.html">RedisStoreHandler</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_redis_store_handler_create_op.html">RedisStoreHandlerCreateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_reduce_gradient_op.html">ReduceGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_reduce_op.html">ReduceOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_reduce_tail_sum_op.html">ReduceTailSumOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_register_quantization_params_net_observer.html">RegisterQuantizationParamsNetObserver</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set quantization parameters of operators based on min/max collected from <a class="el" href="classcaffe2_1_1_output_min_max_observer.html">OutputMinMaxObserver</a>.  <a href="classcaffe2_1_1_register_quantization_params_net_observer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_register_quantization_params_with_histogram_net_observer.html">RegisterQuantizationParamsWithHistogramNetObserver</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set quantization parameters of operators based on min/max collected from <a class="el" href="classcaffe2_1_1_output_min_max_observer.html">OutputMinMaxObserver</a>.  <a href="classcaffe2_1_1_register_quantization_params_with_histogram_net_observer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_relu_d_n_n_low_p_op.html">ReluDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_relu_functor.html">ReluFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_relu_gradient_functor.html">ReluGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_relu_n_functor.html">ReluNFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_relu_n_gradient_functor.html">ReluNGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_remove_data_blocks_op.html">RemoveDataBlocksOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_remove_padding_op.html">RemovePaddingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_replace_na_n_op.html">ReplaceNaNOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_reset_counter_op.html">ResetCounterOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_reshape_op.html">ReshapeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_resize_like_op.html">ResizeLikeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_resize_nearest_d_n_n_low_p_op.html">ResizeNearestDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_resize_nearest_gradient_op.html">ResizeNearestGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_resize_nearest_op.html">ResizeNearestOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_retrieve_count_op.html">RetrieveCountOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_reverse_packed_segs_op.html">ReversePackedSegsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_r_m_a_c_regions_op.html">RMACRegionsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_rms_prop_op.html">RmsPropOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_r_n_n_apply_link_op.html">RNNApplyLinkOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_r_n_n_net_operator.html">RNNNetOperator</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Struct for operator in a timestep and its dependenceis.  <a href="structcaffe2_1_1_r_n_n_net_operator.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_align_gradient_op.html">RoIAlignGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_align_op.html">RoIAlignOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_align_rotated_gradient_op.html">RoIAlignRotatedGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_align_rotated_op.html">RoIAlignRotatedOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_pool_f_gradient_op.html">RoIPoolFGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_pool_f_op.html">RoIPoolFOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_pool_gradient_op.html">RoIPoolGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_ro_i_pool_op.html">RoIPoolOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_row_mul_op.html">RowMulOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_rowwise8_bit_quantized_to_float_op.html">Rowwise8BitQuantizedToFloatOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_row_wise_sparse_adagrad_op.html">RowWiseSparseAdagradOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_row_wise_sparse_adam_op.html">RowWiseSparseAdamOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_rsqrt_functor.html">RsqrtFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_rsqrt_gradient_functor.html">RsqrtGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_run_count_net_observer.html">RunCountNetObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_run_count_operator_observer.html">RunCountOperatorObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_safe_dequeue_blobs_op.html">SafeDequeueBlobsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_safe_enqueue_blobs_op.html">SafeEnqueueBlobsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_same_type_as_input.html">SameTypeAsInput</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sample_as_gradient_op.html">SampleAsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sample_as_op.html">SampleAsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sample_interval.html">SampleInterval</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_save_op.html">SaveOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_scale_op.html">ScaleOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_scatter_assign_op.html">ScatterAssignOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update slices of the tensor in-place by overriding.  <a href="classcaffe2_1_1_scatter_assign_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_scatter_weighted_sum_op.html">ScatterWeightedSumOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update slices of the tensor in-place with weighted sum.  <a href="classcaffe2_1_1_scatter_weighted_sum_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_segment_ids_to_lengths_op.html">SegmentIdsToLengthsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_segment_ids_to_ranges_op.html">SegmentIdsToRangesOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_segment_one_hot_op.html">SegmentOneHotOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_segment_op_get_gradient.html">SegmentOpGetGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_select_gradient_op_base.html">SelectGradientOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_select_smooth_l1_loss_gradient_op.html">SelectSmoothL1LossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_select_smooth_l1_loss_op.html">SelectSmoothL1LossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_selu_gradient_op.html">SeluGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_selu_op.html">SeluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sequence_mask_op.html">SequenceMaskOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_shape_info.html">ShapeInfo</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_shape_op.html">ShapeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_loss_gradient_op.html">SigmoidCrossEntropyLossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_loss_op.html">SigmoidCrossEntropyLossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_with_logits_gradient_op.html">SigmoidCrossEntropyWithLogitsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_with_logits_op.html">SigmoidCrossEntropyWithLogitsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sigmoid_focal_loss_gradient_op.html">SigmoidFocalLossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sigmoid_focal_loss_op.html">SigmoidFocalLossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sigmoid_functor.html">SigmoidFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sigmoid_gradient_functor.html">SigmoidGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_signal_handler.html">SignalHandler</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sign_functor.html">SignFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_simple_array.html">SimpleArray</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_simple_net.html">SimpleNet</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_simple_queue.html">SimpleQueue</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_simple_ref_count_net.html">SimpleRefCountNet</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sin_functor.html">SinFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_single_op_transform.html">SingleOpTransform</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Single Op <a class="el" href="classcaffe2_1_1_transform.html" title="The Transform Base Object. ">Transform</a> Base class.  <a href="classcaffe2_1_1_single_op_transform.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sin_gradient_functor.html">SinGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sinh_functor.html">SinhFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sinh_gradient_functor.html">SinhGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sinusoid_position_encoding_op.html">SinusoidPositionEncodingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_size_op.html">SizeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_skip_indices_3_4.html">SkipIndices&lt;&gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_slice_gradient_op.html">SliceGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_slice_op.html">SliceOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_smart_tensor_printer.html">SmartTensorPrinter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_smooth_l1_loss_gradient_op.html">SmoothL1LossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_smooth_l1_loss_op.html">SmoothL1LossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_s_n_p_e_op.html">SNPEOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softmax_focal_loss_gradient_op.html">SoftmaxFocalLossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softmax_focal_loss_op.html">SoftmaxFocalLossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softmax_gradient_op.html">SoftmaxGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softmax_op.html">SoftmaxOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softmax_with_loss_gradient_op.html">SoftmaxWithLossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softmax_with_loss_op.html">SoftmaxWithLossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softplus_gradient_op.html">SoftplusGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_softplus_op.html">SoftplusOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_softsign_functor.html">SoftsignFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_softsign_gradient_functor.html">SoftsignGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_space_batch_op_base.html">SpaceBatchOpBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_space_to_batch_op.html">SpaceToBatchOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_adadelta_op.html">SparseAdadeltaOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_adagrad_op.html">SparseAdagradOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_adam_op.html">SparseAdamOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_ftrl_op.html">SparseFtrlOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_fun_hash_gradient_op.html">SparseFunHashGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_fun_hash_op.html">SparseFunHashOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_matrix_reshape_op.html">SparseMatrixReshapeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_momentum_s_g_d_update_op.html">SparseMomentumSGDUpdateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_normalize_op.html">SparseNormalizeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_to_dense_mask_base.html">SparseToDenseMaskBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_to_dense_mask_gradient_op.html">SparseToDenseMaskGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_to_dense_mask_op.html">SparseToDenseMaskOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_to_dense_op.html">SparseToDenseOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sparse_wngrad_op.html">SparseWngradOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_b_n_d_n_n_low_p_op.html">SpatialBNDNNLowPOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Note this implementation assumes SCALE, BIAS, EST_MEAN, and EST_VAR inputs are still in fp32, so is epsilon argument.  <a href="classcaffe2_1_1_spatial_b_n_d_n_n_low_p_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_b_n_gradient_op.html">SpatialBNGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_b_n_op.html">SpatialBNOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_narrow_as_gradient.html">SpatialNarrowAsGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_narrow_as_gradient_op.html">SpatialNarrowAsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_narrow_as_op.html">SpatialNarrowAsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_softmax_with_loss_gradient_op.html">SpatialSoftmaxWithLossGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_spatial_softmax_with_loss_op.html">SpatialSoftmaxWithLossOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_split_by_lengths_op.html">SplitByLengthsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_split_op.html">SplitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sqr_functor.html">SqrFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sqrt_functor.html">SqrtFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_squared_l2_distance_gradient_op.html">SquaredL2DistanceGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_squared_l2_distance_op.html">SquaredL2DistanceOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_square_root_divide_op.html">SquareRootDivideOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_squeeze_op.html">SqueezeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_stat.html">Stat</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_static_linking_protector.html">StaticLinkingProtector</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_static_stat.html">StaticStat</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stat_registry.html">StatRegistry</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Holds a map of atomic counters keyed by name.  <a href="classcaffe2_1_1_stat_registry.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stat_registry_create_op.html">StatRegistryCreateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stat_registry_export_op.html">StatRegistryExportOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stat_registry_update_op.html">StatRegistryUpdateOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stat_value.html">StatValue</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_std_dev_exported_stat.html">StdDevExportedStat</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_step_learning_rate.html">StepLearningRate</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stop_gradient_op.html">StopGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_stop_on_signal.html">StopOnSignal</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_store_add_op.html">StoreAddOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_store_get_op.html">StoreGetOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_store_handler_not_available_exception.html">StoreHandlerNotAvailableException</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_store_handler_timeout_exception.html">StoreHandlerTimeoutException</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_store_set_op.html">StoreSetOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_store_wait_op.html">StoreWaitOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_string_deserializer.html">StringDeserializer</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_string_deserializer.html" title="StringDeserializer is the deserializer for Strings. ">StringDeserializer</a> is the deserializer for Strings.  <a href="classcaffe2_1_1_string_deserializer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_string_join_op.html">StringJoinOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_string_provider.html">StringProvider</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_string_serializer.html">StringSerializer</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_string_serializer.html" title="StringSerializer is the serializer for String. ">StringSerializer</a> is the serializer for String.  <a href="classcaffe2_1_1_string_serializer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stump_func_index_op.html">StumpFuncIndexOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_stump_func_op.html">StumpFuncOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sub_functor.html">SubFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_d_n_n_low_p_op.html">SumDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_elements_gradient_op.html">SumElementsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_elements_int_op.html">SumElementsIntOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_elements_op.html">SumElementsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_summarize_op.html">SummarizeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_op.html">SumOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_range_reducer.html">SumRangeReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_range_reducer_3_01_t_00_01_c_p_u_context_01_4.html">SumRangeReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sum_range_reducer_def.html">SumRangeReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_range_reducer_gradient.html">SumRangeReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_reduce_dims_gradient_op.html">SumReduceDimsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_reduce_dims_op.html">SumReduceDimsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_reduce_like_op.html">SumReduceLikeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sum_reducer.html">SumReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_reducer_3_01_t_00_01_c_p_u_context_01_4.html">SumReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_sum_reducer_def.html">SumReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_reducer_gradient.html">SumReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_relu_op.html">SumReluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_sum_sqr_elements_op.html">SumSqrElementsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_swish_functor.html">SwishFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_swish_gradient_op.html">SwishGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_tan_functor.html">TanFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_tan_gradient_functor.html">TanGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_tanh_functor.html">TanhFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_tanh_gradient_functor.html">TanhGradientFunctor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_task.html">Task</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_template_put_op.html">TemplatePutOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tensor.html">Tensor</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_tensor.html" title="Tensor class holds a shared pointer to the implementation TensorImpl, redirects API calls to TensorIm...">Tensor</a> class holds a shared pointer to the implementation TensorImpl, redirects API calls to TensorImpl; Copying of <a class="el" href="classcaffe2_1_1_tensor.html" title="Tensor class holds a shared pointer to the implementation TensorImpl, redirects API calls to TensorIm...">Tensor</a> results in sharing the same underlying implementation object.  <a href="classcaffe2_1_1_tensor.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tensor_deserializer.html">TensorDeserializer</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_tensor_deserializer.html" title="TensorDeserializer is the deserializer for Tensors. ">TensorDeserializer</a> is the deserializer for Tensors.  <a href="classcaffe2_1_1_tensor_deserializer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tensor_filler.html">TensorFiller</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tensor_printer.html">TensorPrinter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tensor_serializer.html">TensorSerializer</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_tensor_serializer.html" title="TensorSerializer is the serializer for Tensors. ">TensorSerializer</a> is the serializer for Tensors.  <a href="classcaffe2_1_1_tensor_serializer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_tensor_types2.html">TensorTypes2</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_text_file_reader_instance.html">TextFileReaderInstance</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_text_file_reader_read_op.html">TextFileReaderReadOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_threaded_recurrent_network_executor.html">ThreadedRecurrentNetworkExecutor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_thread_local_c_u_d_a_objects.html">ThreadLocalCUDAObjects</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> struct to host thread-local cuda objects.  <a href="classcaffe2_1_1_thread_local_c_u_d_a_objects.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_thread_pool.html">ThreadPool</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_thresholded_relu_gradient_op.html">ThresholdedReluGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_thresholded_relu_op.html">ThresholdedReluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_throw_child_thread_exception_op.html">ThrowChildThreadExceptionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_throw_exception_op.html">ThrowExceptionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_throw_in_the_towel_if_gradient_is_called.html">ThrowInTheTowelIfGradientIsCalled</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> helper class to indicate that the operator should have no gradient.  <a href="structcaffe2_1_1_throw_in_the_towel_if_gradient_is_called.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tile_gradient_op.html">TileGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tile_op.html">TileOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_time_counter.html">TimeCounter</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_time_observer.html">TimeObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_time_operator_observer.html">TimeOperatorObserver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_timer.html">Timer</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> simple timer object for measuring time.  <a href="classcaffe2_1_1_timer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_timer_begin_op.html">TimerBeginOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_timer_end_op.html">TimerEndOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_timer_get_and_end_op.html">TimerGetAndEndOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_timer_get_op.html">TimerGetOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_timer_instance.html">TimerInstance</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_token.html">Token</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tokenized_string.html">TokenizedString</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_tokenizer.html">Tokenizer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_top_k_gradient_op.html">TopKGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_top_k_op.html">TopKOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_transform.html">Transform</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The <a class="el" href="classcaffe2_1_1_transform.html" title="The Transform Base Object. ">Transform</a> Base Object.  <a href="classcaffe2_1_1_transform.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_transpose_op.html">TransposeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_t_t_contraction_gradient_op.html">TTContractionGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_t_t_contraction_op.html">TTContractionOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_t_t_linear_gradient_op.html">TTLinearGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_t_t_linear_op.html">TTLinearOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_t_t_pad_gradient_op.html">TTPadGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_t_t_pad_op.html">TTPadOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> type id is a unique id for a given C++ type.  <a href="classcaffe2_1_1_type_identifier.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_type_meta.html" title="TypeMeta is a thin class that allows us to store the type of a container such as a blob...">TypeMeta</a> is a thin class that allows us to store the type of a container such as a blob, or the data type of a tensor, with a unique run-time id.  <a href="classcaffe2_1_1_type_meta.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_type_name_traits.html">TypeNameTraits</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_type_name_traits_3_01int32__t_01_4.html">TypeNameTraits&lt; int32_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_type_name_traits_3_01int64__t_01_4.html">TypeNameTraits&lt; int64_t &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_d_n_n_low_p_op.html">UnaryElementwiseWithArgsDNNLowPOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseWithArgsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_unary_functor_with_default_ctor.html">UnaryFunctorWithDefaultCtor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_uniform_fill_op.html">UniformFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_unique_op.html">UniqueOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Deduplicates input indices vector and optionally produces reverse remapping.  <a href="classcaffe2_1_1_unique_op.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_unique_uniform_fill_op.html">UniqueUniformFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_unpack_segments_op.html">UnpackSegmentsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_unsupported_operator_feature.html">UnsupportedOperatorFeature</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_upsample_bilinear_gradient_op.html">UpsampleBilinearGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_upsample_bilinear_op.html">UpsampleBilinearOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_upsample_nearest_gradient_op.html">UpsampleNearestGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_upsample_nearest_op.html">UpsampleNearestOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_variable_length_sequence_padding_op.html">VariableLengthSequencePaddingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_video_decoder.html">VideoDecoder</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_video_input_op.html">VideoInputOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_video_i_o_context.html">VideoIOContext</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_video_meta.html">VideoMeta</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_wall_clock_time_op.html">WallClockTimeOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_multi_sampling_op.html">WeightedMultiSamplingOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sample_dequeue_blobs_op.html">WeightedSampleDequeueBlobsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sample_op.html">WeightedSampleOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sigmoid_cross_entropy_with_logits_gradient_op.html">WeightedSigmoidCrossEntropyWithLogitsGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sigmoid_cross_entropy_with_logits_op.html">WeightedSigmoidCrossEntropyWithLogitsOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sum_gradient_op.html">WeightedSumGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sum_op.html">WeightedSumOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sum_reducer.html">WeightedSumReducer</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sum_reducer_3_01_t_00_01_c_p_u_context_01_4.html">WeightedSumReducer&lt; T, CPUContext &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcaffe2_1_1_weighted_sum_reducer_def.html">WeightedSumReducerDef</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_weighted_sum_reducer_gradient.html">WeightedSumReducerGradient</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_where_op.html">WhereOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_while_op.html">WhileOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_wngrad_op.html">WngradOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_worker.html">Worker</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_workers_pool.html">WorkersPool</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcaffe2_1_1_workspace.html" title="Workspace is a class that holds all the related objects created during runtime: (1) all blobs...">Workspace</a> is a class that holds all the related objects created during runtime: (1) all blobs, and (2) all instantiated networks.  <a href="classcaffe2_1_1_workspace.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_workspace_optimization_pass.html">WorkspaceOptimizationPass</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_xavier_fill_op.html">XavierFillOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_yellow_fin_op.html">YellowFinOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_zero_gradient_op.html">ZeroGradientOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_zmq_context.html">ZmqContext</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_zmq_message.html">ZmqMessage</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe2_1_1_zmq_socket.html">ZmqSocket</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:ac3fb8907c4895c3f71c924e41fa6c87e"><td class="memTemplParams" colspan="2"><a class="anchor" id="ac3fb8907c4895c3f71c924e41fa6c87e"></a>
template&lt;typename Key , typename Value &gt; </td></tr>
<tr class="memitem:ac3fb8907c4895c3f71c924e41fa6c87e"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>CaffeMap</b> = std::map&lt; Key, <a class="el" href="classnom_1_1repr_1_1_value.html">Value</a> &gt;</td></tr>
<tr class="separator:ac3fb8907c4895c3f71c924e41fa6c87e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4e69eb0f31d53a570c047c59473c0f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4e69eb0f31d53a570c047c59473c0f5"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>CUDAGuard</b> = <a class="el" href="structc10_1_1cuda_1_1_c_u_d_a_guard.html">c10::cuda::CUDAGuard</a></td></tr>
<tr class="separator:aa4e69eb0f31d53a570c047c59473c0f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa732380e9112745cb4e1819c5cdf3f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa732380e9112745cb4e1819c5cdf3f5"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>TensorCUDA</b> = <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a></td></tr>
<tr class="separator:aaa732380e9112745cb4e1819c5cdf3f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad40511c6a34816a79b326a1145d2142b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad40511c6a34816a79b326a1145d2142b"></a>
typedef void(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventCreateFunction</b>) (const DeviceOption &amp;option, <a class="el" href="classcaffe2_1_1_event.html">Event</a> *)</td></tr>
<tr class="separator:ad40511c6a34816a79b326a1145d2142b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ff8832a06132655c341ee77e8e23d9d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9ff8832a06132655c341ee77e8e23d9d"></a>
typedef void(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventRecordFunction</b>) (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *, const void *, const char *)</td></tr>
<tr class="separator:a9ff8832a06132655c341ee77e8e23d9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11a3d0f77afbc3e3bd658ca02345a11c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a11a3d0f77afbc3e3bd658ca02345a11c"></a>
typedef void(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventWaitFunction</b>) (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *, void *)</td></tr>
<tr class="separator:a11a3d0f77afbc3e3bd658ca02345a11c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c8905aa87e0470ae1fbdfea83397c5f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c8905aa87e0470ae1fbdfea83397c5f"></a>
typedef void(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventFinishFunction</b>) (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *)</td></tr>
<tr class="separator:a6c8905aa87e0470ae1fbdfea83397c5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a207a754e7e771e2cb7f4a94db2975d14"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a207a754e7e771e2cb7f4a94db2975d14"></a>
typedef EventStatus(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventQueryFunction</b>) (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *)</td></tr>
<tr class="separator:a207a754e7e771e2cb7f4a94db2975d14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29abe9cc13481e767ef952a877feb7c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29abe9cc13481e767ef952a877feb7c7"></a>
typedef const std::string &amp;(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventErrorMessageFunction</b>) (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *)</td></tr>
<tr class="separator:a29abe9cc13481e767ef952a877feb7c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8890d6156fb78e8999a89d62beb259f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8890d6156fb78e8999a89d62beb259f0"></a>
typedef void(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventSetFinishedFunction</b>) (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *, const char *)</td></tr>
<tr class="separator:a8890d6156fb78e8999a89d62beb259f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a783d65faf77c762f145c1dd4c7e4bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a783d65faf77c762f145c1dd4c7e4bd"></a>
typedef void(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventResetFunction</b>) (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *)</td></tr>
<tr class="separator:a9a783d65faf77c762f145c1dd4c7e4bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec2fcc56c8cdbf15f557f075204225fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec2fcc56c8cdbf15f557f075204225fd"></a>
typedef std::function&lt; void()&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>EventCallbackFunction</b></td></tr>
<tr class="separator:aec2fcc56c8cdbf15f557f075204225fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93d917a11ef8326fab5cbb92919bd4f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a93d917a11ef8326fab5cbb92919bd4f0"></a>
typedef void(*&#160;</td><td class="memItemRight" valign="bottom"><b>EventSetCallbackFunction</b>) (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *, EventCallbackFunction)</td></tr>
<tr class="separator:a93d917a11ef8326fab5cbb92919bd4f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67383b45c782e11815cbe59f1eac9a36"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67383b45c782e11815cbe59f1eac9a36"></a>
typedef <a class="el" href="classcaffe2_1_1_observer_base.html">ObserverBase</a>&lt; <a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>NetObserver</b></td></tr>
<tr class="separator:a67383b45c782e11815cbe59f1eac9a36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45628c528e48494f9eda62134261812a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a45628c528e48494f9eda62134261812a"></a>
typedef std::function&lt; std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_observer_base.html">NetObserver</a> &gt;<a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a> *)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>NetObserverCreator</b></td></tr>
<tr class="separator:a45628c528e48494f9eda62134261812a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66ef186a62d2ad09644bf50c3862e23b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a66ef186a62d2ad09644bf50c3862e23b"></a>
typedef <a class="el" href="classcaffe2_1_1_observer_base.html">ObserverBase</a>&lt; <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>OperatorObserver</b></td></tr>
<tr class="separator:a66ef186a62d2ad09644bf50c3862e23b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81298fa36950f89102eb2542eb6a4aca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a81298fa36950f89102eb2542eb6a4aca"></a>
typedef <a class="el" href="classc10_1_1_registry.html">c10::Registry</a>&lt; std::string, std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a> &gt;, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> * &gt; *(*&#160;</td><td class="memItemRight" valign="bottom"><b>RegistryFunction</b>) ()</td></tr>
<tr class="separator:a81298fa36950f89102eb2542eb6a4aca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32f8d16aa5d76f9f5363279130144d4e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32f8d16aa5d76f9f5363279130144d4e"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EnginePrefType</b> = std::vector&lt; std::string &gt;</td></tr>
<tr class="separator:a32f8d16aa5d76f9f5363279130144d4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d35524b825628d2b6efcc6f80a947e2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d35524b825628d2b6efcc6f80a947e2"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>PerOpEnginePrefType</b> = CaffeMap&lt; DeviceType, CaffeMap&lt; std::string, EnginePrefType &gt;&gt;</td></tr>
<tr class="separator:a4d35524b825628d2b6efcc6f80a947e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b1e0bcf0931e2188888a2e0d859e425"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6b1e0bcf0931e2188888a2e0d859e425"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>GlobalEnginePrefType</b> = CaffeMap&lt; DeviceType, EnginePrefType &gt;</td></tr>
<tr class="separator:a6b1e0bcf0931e2188888a2e0d859e425"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f4d01f9e389d63213b288f4743b53c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2f4d01f9e389d63213b288f4743b53c9"></a>
typedef std::function&lt; bool(int)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>ShouldContinue</b></td></tr>
<tr class="separator:a2f4d01f9e389d63213b288f4743b53c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8eb1578901c4027246db0d3e46305c7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8eb1578901c4027246db0d3e46305c7f"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a8eb1578901c4027246db0d3e46305c7f">ExportedStatList</a> = std::vector&lt; <a class="el" href="structcaffe2_1_1_exported_stat_value.html">ExportedStatValue</a> &gt;</td></tr>
<tr class="memdesc:a8eb1578901c4027246db0d3e46305c7f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Holds names and values of counters exported from a <a class="el" href="classcaffe2_1_1_stat_registry.html" title="Holds a map of atomic counters keyed by name. ">StatRegistry</a>. <br /></td></tr>
<tr class="separator:a8eb1578901c4027246db0d3e46305c7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22bc270d52b7b38692a572f374d13a23"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a22bc270d52b7b38692a572f374d13a23"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ExportedStatMap</b> = std::unordered_map&lt; std::string, int64_t &gt;</td></tr>
<tr class="separator:a22bc270d52b7b38692a572f374d13a23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a257c712bdaa8382bd6f6d6645e908b85"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a257c712bdaa8382bd6f6d6645e908b85"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>StorageImpl</b> = <a class="el" href="structc10_1_1_storage_impl.html">at::StorageImpl</a></td></tr>
<tr class="separator:a257c712bdaa8382bd6f6d6645e908b85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a670b7fc70515874f5494284c876d3cbb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a670b7fc70515874f5494284c876d3cbb"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>Storage</b> = <a class="el" href="structc10_1_1_storage.html">at::Storage</a></td></tr>
<tr class="separator:a670b7fc70515874f5494284c876d3cbb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b080f35a9820b0c085770ba95e8c787"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7b080f35a9820b0c085770ba95e8c787"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>TensorCPU</b> = <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a></td></tr>
<tr class="separator:a7b080f35a9820b0c085770ba95e8c787"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a019bdb3c7f9b31b06dbf91c93d245757"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a019bdb3c7f9b31b06dbf91c93d245757"></a>
typedef <a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a>(*&#160;</td><td class="memItemRight" valign="bottom"><b>TypeCall</b>) (const void *)</td></tr>
<tr class="separator:a019bdb3c7f9b31b06dbf91c93d245757"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad588ebc5e25e663606e0ef4b336694e0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad588ebc5e25e663606e0ef4b336694e0"></a>
typedef vector&lt; int64_t &gt;(*&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInfoCall</b>) (const void *, size_t *capacity, DeviceOption *device)</td></tr>
<tr class="separator:ad588ebc5e25e663606e0ef4b336694e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16f9d1cc1eb3ff7f371541e2dbf1cb3b"><td class="memTemplParams" colspan="2"><a class="anchor" id="a16f9d1cc1eb3ff7f371541e2dbf1cb3b"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a16f9d1cc1eb3ff7f371541e2dbf1cb3b"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>deleted_unique_ptr</b> = std::unique_ptr&lt; <a class="el" href="struct_t.html">T</a>, std::function&lt; void(<a class="el" href="struct_t.html">T</a> *)&gt;&gt;</td></tr>
<tr class="separator:a16f9d1cc1eb3ff7f371541e2dbf1cb3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a843b09ff1b7f933ccafee91a37166f1f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a843b09ff1b7f933ccafee91a37166f1f"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ParallelFor</b> = std::function&lt; void(size_t, std::function&lt; void(size_t)&gt;)&gt;</td></tr>
<tr class="separator:a843b09ff1b7f933ccafee91a37166f1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ea6e82ca849db18c8787d3b6120234c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2ea6e82ca849db18c8787d3b6120234c"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>NumericTypes</b> = <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; int32_t, int64_t, float, double &gt;</td></tr>
<tr class="separator:a2ea6e82ca849db18c8787d3b6120234c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab045ba250e9944f3f7811fd99dedaae7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab045ba250e9944f3f7811fd99dedaae7"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>IntTypes</b> = <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; int32_t, int64_t &gt;</td></tr>
<tr class="separator:ab045ba250e9944f3f7811fd99dedaae7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0aa97ad24133ca3efbf5f8994d62f25c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0aa97ad24133ca3efbf5f8994d62f25c"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>BoolTypes</b> = <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; bool &gt;</td></tr>
<tr class="separator:a0aa97ad24133ca3efbf5f8994d62f25c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a803395e5d8f74b61b36d4f92a6bb3c5b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a803395e5d8f74b61b36d4f92a6bb3c5b"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>IntBoolTypes</b> = <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; int32_t, int64_t, bool &gt;</td></tr>
<tr class="separator:a803395e5d8f74b61b36d4f92a6bb3c5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f1a1fc2f773912786454eec090b7a12"><td class="memTemplParams" colspan="2"><a class="anchor" id="a6f1a1fc2f773912786454eec090b7a12"></a>
template&lt;typename InputTypes , class Context , class Functor , class OutputTypeMap  = SameTypeAsInput&gt; </td></tr>
<tr class="memitem:a6f1a1fc2f773912786454eec090b7a12"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>UnaryElementwiseOp</b> = <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseWithArgsOp</a>&lt; InputTypes, Context, <a class="el" href="structcaffe2_1_1_unary_functor_with_default_ctor.html">UnaryFunctorWithDefaultCtor</a>&lt; Functor &gt;, OutputTypeMap &gt;</td></tr>
<tr class="separator:a6f1a1fc2f773912786454eec090b7a12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a311930bdff700fec7dd598a454df07f7"><td class="memTemplParams" colspan="2"><a class="anchor" id="a311930bdff700fec7dd598a454df07f7"></a>
template&lt;typename InputTypes , class Context , class Functor , class TypeMap  = SameTypeAsInput&gt; </td></tr>
<tr class="memitem:a311930bdff700fec7dd598a454df07f7"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>BinaryElementwiseOp</b> = <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseWithArgsOp</a>&lt; InputTypes, Context, <a class="el" href="structcaffe2_1_1_binary_functor_with_default_ctor.html">BinaryFunctorWithDefaultCtor</a>&lt; Functor &gt;, TypeMap &gt;</td></tr>
<tr class="separator:a311930bdff700fec7dd598a454df07f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a8c7b4a7e6ab7aa1f52145a05e39b5a"><td class="memTemplParams" colspan="2"><a class="anchor" id="a6a8c7b4a7e6ab7aa1f52145a05e39b5a"></a>
template&lt;typename InputTypes , class Context , class Functor , class OutputTypeMap  = SameTypeAsInput, class GradientTypeMap  = SameTypeAsInput&gt; </td></tr>
<tr class="memitem:a6a8c7b4a7e6ab7aa1f52145a05e39b5a"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>BinaryElementwiseGradientOp</b> = <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseWithArgsGradientOp</a>&lt; InputTypes, Context, <a class="el" href="structcaffe2_1_1_binary_functor_with_default_ctor.html">BinaryFunctorWithDefaultCtor</a>&lt; Functor &gt;, OutputTypeMap, GradientTypeMap &gt;</td></tr>
<tr class="separator:a6a8c7b4a7e6ab7aa1f52145a05e39b5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67ff705caeb1c0e60b751a535e83ebe1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67ff705caeb1c0e60b751a535e83ebe1"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>SparseLengthsSumOp</b> = <a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">CPUSparseLengthsReductionOp</a>&lt; float, <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float, <a class="el" href="structc10_1_1_half.html">at::Half</a> &gt;, 0, 0 &gt;</td></tr>
<tr class="separator:a67ff705caeb1c0e60b751a535e83ebe1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a714f35d830f5830a0225379f551b71f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a714f35d830f5830a0225379f551b71f6"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>SparseLengthsWeightedSumOp</b> = <a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">CPUSparseLengthsReductionOp</a>&lt; float, <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float, <a class="el" href="structc10_1_1_half.html">at::Half</a> &gt;, 1, 0 &gt;</td></tr>
<tr class="separator:a714f35d830f5830a0225379f551b71f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a601bee3b471ebc99c4e0bb5f583ca9db"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a601bee3b471ebc99c4e0bb5f583ca9db"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>SparseLengthsMeanOp</b> = <a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">CPUSparseLengthsReductionOp</a>&lt; float, <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float, <a class="el" href="structc10_1_1_half.html">at::Half</a> &gt;, 0, 1 &gt;</td></tr>
<tr class="separator:a601bee3b471ebc99c4e0bb5f583ca9db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ec431de676b9085b4e5d4cecdc5dc17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3ec431de676b9085b4e5d4cecdc5dc17"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>SparseLengthsSumDef</b> = <a class="el" href="structcaffe2_1_1_abstract_sparse_lengths_def.html">AbstractSparseLengthsDef</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sum_reducer_def.html">SumReducerDef</a>, true &gt;</td></tr>
<tr class="separator:a3ec431de676b9085b4e5d4cecdc5dc17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3223cf40bbb85a0ba14ed37d941a60b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3223cf40bbb85a0ba14ed37d941a60b5"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>SparseLengthsWeightedSumDef</b> = <a class="el" href="structcaffe2_1_1_abstract_sparse_lengths_def.html">AbstractSparseLengthsDef</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_weighted_sum_reducer_def.html">WeightedSumReducerDef</a>, true &gt;</td></tr>
<tr class="separator:a3223cf40bbb85a0ba14ed37d941a60b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5c0ceac2d49bca5216c9907ac507867"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5c0ceac2d49bca5216c9907ac507867"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>op</b> = core.CreateOperator(&quot;Save&quot;,[&quot;X&quot;,&quot;Y&quot;,&quot;Z&quot;],[], db=&quot;test_db2&quot;, db_type=&quot;leveldb&quot;, blob_name_overrides=[&quot;x_scores&quot;,&quot;y_scores&quot;,&quot;z_scores&quot;]) workspace.FeedBlob(&quot;X&quot;, np.random.randint(20, size=(5, 5))) workspace.FeedBlob(&quot;Y&quot;, np.random.randint(20, size=(5, 5))) workspace.FeedBlob(&quot;Z&quot;, np.random.randint(20, size=(5, 5))) workspace.RunOperatorOnce(op)```&lt;/details &gt;) DOC&quot;) .Arg( &quot;absolute_path&quot;, &quot;*(type:int</td></tr>
<tr class="separator:aa5c0ceac2d49bca5216c9907ac507867"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af498b94e8bf308ff2f7a23dc58fb49e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af498b94e8bf308ff2f7a23dc58fb49e6"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>MapType64To64</b> = <a class="el" href="structcaffe2_1_1_map_type_traits.html">MapTypeTraits</a>&lt; int64_t, int64_t &gt;::MapType</td></tr>
<tr class="separator:af498b94e8bf308ff2f7a23dc58fb49e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d525a7195f5527ce4a3205004c76599"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8d525a7195f5527ce4a3205004c76599"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>MapType64To32</b> = <a class="el" href="structcaffe2_1_1_map_type_traits.html">MapTypeTraits</a>&lt; int64_t, int32_t &gt;::MapType</td></tr>
<tr class="separator:a8d525a7195f5527ce4a3205004c76599"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab63037963716071ea7e8f7b177542599"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab63037963716071ea7e8f7b177542599"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>MapType32To32</b> = <a class="el" href="structcaffe2_1_1_map_type_traits.html">MapTypeTraits</a>&lt; int32_t, int32_t &gt;::MapType</td></tr>
<tr class="separator:ab63037963716071ea7e8f7b177542599"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37567932357954efed10a870ed2e6512"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a37567932357954efed10a870ed2e6512"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>MapType32To64</b> = <a class="el" href="structcaffe2_1_1_map_type_traits.html">MapTypeTraits</a>&lt; int32_t, int64_t &gt;::MapType</td></tr>
<tr class="separator:a37567932357954efed10a870ed2e6512"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ed2c4265405ce3279c3a43e8e537bef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ed2c4265405ce3279c3a43e8e537bef"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>GPUFallbackOp</b> = <a class="el" href="classcaffe2_1_1_g_p_u_fallback_op_ex.html">GPUFallbackOpEx</a>&lt; <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt;&gt;&gt;</td></tr>
<tr class="separator:a4ed2c4265405ce3279c3a43e8e537bef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af41406072a99cf57e0f8700827ce061c"><td class="memTemplParams" colspan="2"><a class="anchor" id="af41406072a99cf57e0f8700827ce061c"></a>
template&lt;typename ScalarFunctor , typename TypeMap  = FixedType&lt;std::string&gt;&gt; </td></tr>
<tr class="memitem:af41406072a99cf57e0f8700827ce061c"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>StringElementwiseOp</b> = <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::string &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_for_each.html">ForEach</a>&lt; ScalarFunctor &gt;, TypeMap &gt;</td></tr>
<tr class="separator:af41406072a99cf57e0f8700827ce061c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad557dc0dc7699ed1131d1b5bbea7c1b1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad557dc0dc7699ed1131d1b5bbea7c1b1"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ShapeInfoMap</b> = std::unordered_map&lt; std::string, <a class="el" href="structcaffe2_1_1_shape_info.html">ShapeInfo</a> &gt;</td></tr>
<tr class="separator:ad557dc0dc7699ed1131d1b5bbea7c1b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff5ec472cded331410828b95b277bb87"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff5ec472cded331410828b95b277bb87"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>PredictorParameters</b> = std::map&lt; std::string, std::shared_ptr&lt; <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &gt;&gt;</td></tr>
<tr class="separator:aff5ec472cded331410828b95b277bb87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1156417c2db3c67a8e8f238db8e805ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1156417c2db3c67a8e8f238db8e805ad"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>DeviceType</b> = at::DeviceType</td></tr>
<tr class="separator:a1156417c2db3c67a8e8f238db8e805ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4925f85ac6882b1f886faf7dd253070"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af4925f85ac6882b1f886faf7dd253070"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>BatchPermutationFP32Op</b> = <a class="el" href="classcaffe2_1_1_copy_op.html">CopyOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;</td></tr>
<tr class="separator:af4925f85ac6882b1f886faf7dd253070"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5546526122b223341dcf6235de978e45"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5546526122b223341dcf6235de978e45"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ConvFp32Op</b> = <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;</td></tr>
<tr class="separator:a5546526122b223341dcf6235de978e45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fe979aa02016e326f992ab35e5c2fe0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7fe979aa02016e326f992ab35e5c2fe0"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>AddFp32Op</b> = <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_add_functor.html">AddFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;</td></tr>
<tr class="separator:a7fe979aa02016e326f992ab35e5c2fe0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f5aae71816905adb063f742a9025f61"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6f5aae71816905adb063f742a9025f61"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ElementwiseLinearFp32Op</b> = <a class="el" href="classcaffe2_1_1_elementwise_linear_op.html">ElementwiseLinearOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;</td></tr>
<tr class="separator:a6f5aae71816905adb063f742a9025f61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ea722d656d92b1c62e38523d272ed4c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8ea722d656d92b1c62e38523d272ed4c"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>MulFp32Op</b> = <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_mul_functor.html">MulFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;</td></tr>
<tr class="separator:a8ea722d656d92b1c62e38523d272ed4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f6e748e3b4f15b074afb48b64aeb4b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8f6e748e3b4f15b074afb48b64aeb4b9"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>FCFp32Op</b> = <a class="el" href="classcaffe2_1_1_fully_connected_op.html">FullyConnectedOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;</td></tr>
<tr class="separator:a8f6e748e3b4f15b074afb48b64aeb4b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addc694fc6493322f2ff36848fd2fc5e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="addc694fc6493322f2ff36848fd2fc5e8"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>GroupNormFP32Op</b> = <a class="el" href="classcaffe2_1_1_group_norm_op.html">GroupNormOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;</td></tr>
<tr class="separator:addc694fc6493322f2ff36848fd2fc5e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa938cac3eace64f132b95c50a76adadf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa938cac3eace64f132b95c50a76adadf"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ResizeNearestFP32Op</b> = <a class="el" href="classcaffe2_1_1_resize_nearest_op.html">ResizeNearestOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;</td></tr>
<tr class="separator:aa938cac3eace64f132b95c50a76adadf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55da53004c68821d605bc203b85329d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55da53004c68821d605bc203b85329d7"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>RebatchingQueuePtr</b> = std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_rebatching_queue.html">RebatchingQueue</a> &gt;</td></tr>
<tr class="separator:a55da53004c68821d605bc203b85329d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02e7fe2056c1c2cefa3083a913082635"><td class="memTemplParams" colspan="2"><a class="anchor" id="a02e7fe2056c1c2cefa3083a913082635"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a02e7fe2056c1c2cefa3083a913082635"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenMatrixMap</b> = Eigen::Map&lt; Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;&gt;</td></tr>
<tr class="separator:a02e7fe2056c1c2cefa3083a913082635"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad36650e1a216816172f1fe41ee0d0076"><td class="memTemplParams" colspan="2"><a class="anchor" id="ad36650e1a216816172f1fe41ee0d0076"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ad36650e1a216816172f1fe41ee0d0076"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenArrayMap</b> = Eigen::Map&lt; Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;&gt;</td></tr>
<tr class="separator:ad36650e1a216816172f1fe41ee0d0076"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f4091d034aebc53a7b38a16a2863dde"><td class="memTemplParams" colspan="2"><a class="anchor" id="a8f4091d034aebc53a7b38a16a2863dde"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a8f4091d034aebc53a7b38a16a2863dde"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenVectorMap</b> = Eigen::Map&lt; Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, 1 &gt;&gt;</td></tr>
<tr class="separator:a8f4091d034aebc53a7b38a16a2863dde"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f66fe779a20c8c8fb32930404dd711e"><td class="memTemplParams" colspan="2"><a class="anchor" id="a0f66fe779a20c8c8fb32930404dd711e"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a0f66fe779a20c8c8fb32930404dd711e"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenVectorArrayMap</b> = Eigen::Map&lt; Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, 1 &gt;&gt;</td></tr>
<tr class="separator:a0f66fe779a20c8c8fb32930404dd711e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a002b6cf5091a4234b9bc10e82038cacd"><td class="memTemplParams" colspan="2"><a class="anchor" id="a002b6cf5091a4234b9bc10e82038cacd"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a002b6cf5091a4234b9bc10e82038cacd"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenMatrixMap</b> = Eigen::Map&lt; const Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;&gt;</td></tr>
<tr class="separator:a002b6cf5091a4234b9bc10e82038cacd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a915ad4b7ae357d421e72e1058e88bbfc"><td class="memTemplParams" colspan="2"><a class="anchor" id="a915ad4b7ae357d421e72e1058e88bbfc"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a915ad4b7ae357d421e72e1058e88bbfc"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenArrayMap</b> = Eigen::Map&lt; const Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;&gt;</td></tr>
<tr class="separator:a915ad4b7ae357d421e72e1058e88bbfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b04110f3009ca3f8a2e6d274444d833"><td class="memTemplParams" colspan="2"><a class="anchor" id="a3b04110f3009ca3f8a2e6d274444d833"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a3b04110f3009ca3f8a2e6d274444d833"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenVectorMap</b> = Eigen::Map&lt; const Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, 1 &gt;&gt;</td></tr>
<tr class="separator:a3b04110f3009ca3f8a2e6d274444d833"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b08c8d20520baa5ec518265c3a0a109"><td class="memTemplParams" colspan="2"><a class="anchor" id="a8b08c8d20520baa5ec518265c3a0a109"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a8b08c8d20520baa5ec518265c3a0a109"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenVectorArrayMap</b> = Eigen::Map&lt; const Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, 1 &gt;&gt;</td></tr>
<tr class="separator:a8b08c8d20520baa5ec518265c3a0a109"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefcb1bca1269d1bd6710be0a06cf1bea"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aefcb1bca1269d1bd6710be0a06cf1bea"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EigenOuterStride</b> = Eigen::OuterStride&lt; Eigen::Dynamic &gt;</td></tr>
<tr class="separator:aefcb1bca1269d1bd6710be0a06cf1bea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1192beee08fa3853c2abac52b564cd37"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1192beee08fa3853c2abac52b564cd37"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EigenInnerStride</b> = Eigen::InnerStride&lt; Eigen::Dynamic &gt;</td></tr>
<tr class="separator:a1192beee08fa3853c2abac52b564cd37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfd3e59df212ba00b03f41a0b138fdac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abfd3e59df212ba00b03f41a0b138fdac"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EigenStride</b> = Eigen::Stride&lt; Eigen::Dynamic, Eigen::Dynamic &gt;</td></tr>
<tr class="separator:abfd3e59df212ba00b03f41a0b138fdac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19d2b67508037a93dc53742d9c2d3295"><td class="memTemplParams" colspan="2"><a class="anchor" id="a19d2b67508037a93dc53742d9c2d3295"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a19d2b67508037a93dc53742d9c2d3295"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenOuterStridedMatrixMap</b> = Eigen::Map&lt; Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenOuterStride &gt;</td></tr>
<tr class="separator:a19d2b67508037a93dc53742d9c2d3295"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31f33cb07668b45bb3aee0614bf3e1b4"><td class="memTemplParams" colspan="2"><a class="anchor" id="a31f33cb07668b45bb3aee0614bf3e1b4"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a31f33cb07668b45bb3aee0614bf3e1b4"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenOuterStridedArrayMap</b> = Eigen::Map&lt; Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenOuterStride &gt;</td></tr>
<tr class="separator:a31f33cb07668b45bb3aee0614bf3e1b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a183ee55b5693a4492b284e9bda11b98c"><td class="memTemplParams" colspan="2"><a class="anchor" id="a183ee55b5693a4492b284e9bda11b98c"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a183ee55b5693a4492b284e9bda11b98c"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenOuterStridedMatrixMap</b> = Eigen::Map&lt; const Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenOuterStride &gt;</td></tr>
<tr class="separator:a183ee55b5693a4492b284e9bda11b98c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46e4b86843409c6fe4a3e7ed927c1cd7"><td class="memTemplParams" colspan="2"><a class="anchor" id="a46e4b86843409c6fe4a3e7ed927c1cd7"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a46e4b86843409c6fe4a3e7ed927c1cd7"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenOuterStridedArrayMap</b> = Eigen::Map&lt; const Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenOuterStride &gt;</td></tr>
<tr class="separator:a46e4b86843409c6fe4a3e7ed927c1cd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad92d34ebe54e482d01cb2ca5e5b21b58"><td class="memTemplParams" colspan="2"><a class="anchor" id="ad92d34ebe54e482d01cb2ca5e5b21b58"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ad92d34ebe54e482d01cb2ca5e5b21b58"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenStridedMatrixMap</b> = Eigen::Map&lt; Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenStride &gt;</td></tr>
<tr class="separator:ad92d34ebe54e482d01cb2ca5e5b21b58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5023ccc43319e14af580c8e987b233fb"><td class="memTemplParams" colspan="2"><a class="anchor" id="a5023ccc43319e14af580c8e987b233fb"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a5023ccc43319e14af580c8e987b233fb"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EigenStridedArrayMap</b> = Eigen::Map&lt; Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenStride &gt;</td></tr>
<tr class="separator:a5023ccc43319e14af580c8e987b233fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09fb931d9006041a359f62ce0d2009b2"><td class="memTemplParams" colspan="2"><a class="anchor" id="a09fb931d9006041a359f62ce0d2009b2"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a09fb931d9006041a359f62ce0d2009b2"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenStridedMatrixMap</b> = Eigen::Map&lt; const Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenStride &gt;</td></tr>
<tr class="separator:a09fb931d9006041a359f62ce0d2009b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46ed5c7e83c3755017fc6956555a0e3f"><td class="memTemplParams" colspan="2"><a class="anchor" id="a46ed5c7e83c3755017fc6956555a0e3f"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a46ed5c7e83c3755017fc6956555a0e3f"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ConstEigenStridedArrayMap</b> = Eigen::Map&lt; const Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;, 0, EigenStride &gt;</td></tr>
<tr class="separator:a46ed5c7e83c3755017fc6956555a0e3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30cf33f52b2ac8ede56c7b9eade8714e"><td class="memTemplParams" colspan="2"><a class="anchor" id="a30cf33f52b2ac8ede56c7b9eade8714e"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a30cf33f52b2ac8ede56c7b9eade8714e"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EArrXt</b> = Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, 1 &gt;</td></tr>
<tr class="separator:a30cf33f52b2ac8ede56c7b9eade8714e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05ca06381eb83d01882f3ddcf1ea9f85"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a05ca06381eb83d01882f3ddcf1ea9f85"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EArrXf</b> = Eigen::ArrayXf</td></tr>
<tr class="separator:a05ca06381eb83d01882f3ddcf1ea9f85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9efee42e9d5416a76af6cbf52fef267"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9efee42e9d5416a76af6cbf52fef267"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EArrXd</b> = Eigen::ArrayXd</td></tr>
<tr class="separator:aa9efee42e9d5416a76af6cbf52fef267"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57bfd31737ed431da40d4c2d531fcab4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a57bfd31737ed431da40d4c2d531fcab4"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EArrXi</b> = Eigen::ArrayXi</td></tr>
<tr class="separator:a57bfd31737ed431da40d4c2d531fcab4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a423d78fd9e1ec22dc24119a52ffda491"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a423d78fd9e1ec22dc24119a52ffda491"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EArrXb</b> = EArrXt&lt; bool &gt;</td></tr>
<tr class="separator:a423d78fd9e1ec22dc24119a52ffda491"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9545a4bb09336e69fb899e5b26268f6"><td class="memTemplParams" colspan="2"><a class="anchor" id="ac9545a4bb09336e69fb899e5b26268f6"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ac9545a4bb09336e69fb899e5b26268f6"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EArrXXt</b> = Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;</td></tr>
<tr class="separator:ac9545a4bb09336e69fb899e5b26268f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0489b43c6cb59022a125b7d2f7f3b60"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae0489b43c6cb59022a125b7d2f7f3b60"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EArrXXf</b> = Eigen::ArrayXXf</td></tr>
<tr class="separator:ae0489b43c6cb59022a125b7d2f7f3b60"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a668da8c72dfbee70c634752ddfc2cca2"><td class="memTemplParams" colspan="2"><a class="anchor" id="a668da8c72dfbee70c634752ddfc2cca2"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a668da8c72dfbee70c634752ddfc2cca2"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ERArrXXt</b> = Eigen::Array&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor &gt;</td></tr>
<tr class="separator:a668da8c72dfbee70c634752ddfc2cca2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a858fbd0105e125f947d8e0c7cc6fa2f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a858fbd0105e125f947d8e0c7cc6fa2f5"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ERArrXXf</b> = ERArrXXt&lt; float &gt;</td></tr>
<tr class="separator:a858fbd0105e125f947d8e0c7cc6fa2f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac860d4911dfc0d4a14d04ab836a115ce"><td class="memTemplParams" colspan="2"><a class="anchor" id="ac860d4911dfc0d4a14d04ab836a115ce"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ac860d4911dfc0d4a14d04ab836a115ce"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EVecXt</b> = Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, 1 &gt;</td></tr>
<tr class="separator:ac860d4911dfc0d4a14d04ab836a115ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af28be7f7774b322d8713c8cab499bb0f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af28be7f7774b322d8713c8cab499bb0f"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EVecXd</b> = Eigen::VectorXd</td></tr>
<tr class="separator:af28be7f7774b322d8713c8cab499bb0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac91be26e88343892f4a0f864167a8cb0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac91be26e88343892f4a0f864167a8cb0"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EVecXf</b> = Eigen::VectorXf</td></tr>
<tr class="separator:ac91be26e88343892f4a0f864167a8cb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fb33befb475f7d9486815061285e6d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7fb33befb475f7d9486815061285e6d2"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ERVecXd</b> = Eigen::RowVectorXd</td></tr>
<tr class="separator:a7fb33befb475f7d9486815061285e6d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b2e9747ffe824ff7d21b13fdbac6fd6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5b2e9747ffe824ff7d21b13fdbac6fd6"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ERVecXf</b> = Eigen::RowVectorXf</td></tr>
<tr class="separator:a5b2e9747ffe824ff7d21b13fdbac6fd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03ddc117686768238b132b3cb9928d30"><td class="memTemplParams" colspan="2"><a class="anchor" id="a03ddc117686768238b132b3cb9928d30"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a03ddc117686768238b132b3cb9928d30"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>EMatXt</b> = Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic &gt;</td></tr>
<tr class="separator:a03ddc117686768238b132b3cb9928d30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b2568e3d8fe1b68cb6e98b9f14c7c26"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4b2568e3d8fe1b68cb6e98b9f14c7c26"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EMatXd</b> = Eigen::MatrixXd</td></tr>
<tr class="separator:a4b2568e3d8fe1b68cb6e98b9f14c7c26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a675336bbaa8dedbc5a26b534f90b41e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a675336bbaa8dedbc5a26b534f90b41e8"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>EMatXf</b> = Eigen::MatrixXf</td></tr>
<tr class="separator:a675336bbaa8dedbc5a26b534f90b41e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22b24c4c79d9860bef56bcdfe2a9ee6a"><td class="memTemplParams" colspan="2"><a class="anchor" id="a22b24c4c79d9860bef56bcdfe2a9ee6a"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a22b24c4c79d9860bef56bcdfe2a9ee6a"><td class="memTemplItemLeft" align="right" valign="top">using&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ERMatXt</b> = Eigen::Matrix&lt; <a class="el" href="struct_t.html">T</a>, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor &gt;</td></tr>
<tr class="separator:a22b24c4c79d9860bef56bcdfe2a9ee6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77c0c7b7a26e639dd9be7d459a1bd529"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a77c0c7b7a26e639dd9be7d459a1bd529"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ERMatXd</b> = ERMatXt&lt; double &gt;</td></tr>
<tr class="separator:a77c0c7b7a26e639dd9be7d459a1bd529"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5545c2cf90bb5aa1136ddfdf1b755038"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5545c2cf90bb5aa1136ddfdf1b755038"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>ERMatXf</b> = ERMatXt&lt; float &gt;</td></tr>
<tr class="separator:a5545c2cf90bb5aa1136ddfdf1b755038"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:ac973c115b0c808cb638fe0262823ec48"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac973c115b0c808cb638fe0262823ec48"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>CudaMemoryPoolType</b> { <b>NONE</b> = 0, 
<b>CUB</b> = 1, 
<b>THC</b> = 2
 }</td></tr>
<tr class="separator:ac973c115b0c808cb638fe0262823ec48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a636c061e50a818d89fa07008067420ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a636c061e50a818d89fa07008067420ff"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>EventStatus</b> { <b>EVENT_INITIALIZED</b> = 0, 
<b>EVENT_SCHEDULED</b> = 1, 
<b>EVENT_SUCCESS</b> = 2, 
<b>EVENT_FAILED</b> = 3
 }</td></tr>
<tr class="separator:a636c061e50a818d89fa07008067420ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa25e17b4d7a08766797f73811bf8fd21"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa25e17b4d7a08766797f73811bf8fd21"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>StorageOrder</b> { <b>UNKNOWN</b> = 0, 
<b>NHWC</b> = 1, 
<b>NCHW</b> = 2
 }</td></tr>
<tr class="separator:aa25e17b4d7a08766797f73811bf8fd21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52ba308d47c752118685a6ca2bb5674a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a52ba308d47c752118685a6ca2bb5674a"></a>enum &#160;</td><td class="memItemRight" valign="bottom">{ <b>ALGO_FWD</b> = 0, 
<b>ALGO_WGRAD</b> = 1, 
<b>ALGO_DGRAD</b> = 2
 }</td></tr>
<tr class="separator:a52ba308d47c752118685a6ca2bb5674a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18517bbe9b4899f83107e74f7a8e7544"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a18517bbe9b4899f83107e74f7a8e7544"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>PadMode</b> { <b>CONSTANT</b> = 0, 
<b>REFLECT</b> = 1, 
<b>EDGE</b> = 2
 }</td></tr>
<tr class="separator:a18517bbe9b4899f83107e74f7a8e7544"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6d3588b4cedfae0bc093b8c14038db4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6d3588b4cedfae0bc093b8c14038db4"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>QuantDecodeRunTy</b> { <b>RUN_ALWAYS</b>, 
<b>RUN_ONCE</b>
 }</td></tr>
<tr class="separator:ae6d3588b4cedfae0bc093b8c14038db4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68bf872d0c5886a30aa362374395abd4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a68bf872d0c5886a30aa362374395abd4"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>RecurrentParamOpMode</b> { <b>SET_PARAM</b>, 
<b>GET_PARAM</b>, 
<b>SET_PARAM</b>, 
<b>GET_PARAM</b>
 }</td></tr>
<tr class="separator:a68bf872d0c5886a30aa362374395abd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68bf872d0c5886a30aa362374395abd4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a68bf872d0c5886a30aa362374395abd4"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>RecurrentParamOpMode</b> { <b>SET_PARAM</b>, 
<b>GET_PARAM</b>, 
<b>SET_PARAM</b>, 
<b>GET_PARAM</b>
 }</td></tr>
<tr class="separator:a68bf872d0c5886a30aa362374395abd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8aef7c5eef92eba06dac54d5d561ad81"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8aef7c5eef92eba06dac54d5d561ad81"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>FillerDistribution</b> { <b>FD_UNIFORM</b>, 
<b>FD_FIXEDSUM</b>, 
<b>FD_SYNTHETIC</b>
 }</td></tr>
<tr class="separator:a8aef7c5eef92eba06dac54d5d561ad81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d7be8290b439c790c5f304286cc877a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6d7be8290b439c790c5f304286cc877a"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>FLowAlgType</b> { <b>FarnebackOpticalFlow</b> = 0, 
<b>DensePyrLKOpticalFlow</b> = 1, 
<b>BroxOpticalFlow</b> = 2, 
<b>OpticalFlowDual_TVL1</b> = 3
 }</td></tr>
<tr class="separator:a6d7be8290b439c790c5f304286cc877a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed100c8a2b5b0cab3470d046f5fb8ee5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed100c8a2b5b0cab3470d046f5fb8ee5"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>FlowDataType</b> { <b>Flow2C</b> = 0, 
<b>Flow3C</b> = 1, 
<b>FlowWithGray</b> = 2, 
<b>FlowWithRGB</b> = 3
 }</td></tr>
<tr class="separator:aed100c8a2b5b0cab3470d046f5fb8ee5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af665e0722cfd3ab685a8c41d47dc9d77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af665e0722cfd3ab685a8c41d47dc9d77"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>SpecialFps</b> { <b>SAMPLE_NO_FRAME</b> = 0, 
<b>SAMPLE_ALL_FRAMES</b> = -1, 
<b>SAMPLE_TIMESTAMP_ONLY</b> = -2
 }</td></tr>
<tr class="separator:af665e0722cfd3ab685a8c41d47dc9d77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acefa7f39f0186e26042ce8ac22b7cb83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acefa7f39f0186e26042ce8ac22b7cb83"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>VideoResType</b> { <b>USE_WIDTH_HEIGHT</b> = 0, 
<b>USE_MINIMAL_WIDTH_HEIGHT</b> = 1, 
<b>ORIGINAL_RES</b> = 2
 }</td></tr>
<tr class="separator:acefa7f39f0186e26042ce8ac22b7cb83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a340bb1b8d1972f340913e1eefb06e8de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a340bb1b8d1972f340913e1eefb06e8de"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><b>DecodeType</b> { <b>DO_TMP_JITTER</b> = 0, 
<b>DO_UNIFORM_SMP</b> = 1, 
<b>USE_START_FRM</b> = 2
 }</td></tr>
<tr class="separator:a340bb1b8d1972f340913e1eefb06e8de"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:af5ba5ddb3cab35a4fef6962b772a704d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af5ba5ddb3cab35a4fef6962b772a704d"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>swap</b> (<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;lhs, <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;rhs)</td></tr>
<tr class="separator:af5ba5ddb3cab35a4fef6962b772a704d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade09e0ab8ebb1d1d3af803a8ab40ad55"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade09e0ab8ebb1d1d3af803a8ab40ad55"></a>
std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>operator&lt;&lt;</b> (std::ostream &amp;out, const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;v)</td></tr>
<tr class="separator:ade09e0ab8ebb1d1d3af803a8ab40ad55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a592e0241723c57d1449e28822ca2a909"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a592e0241723c57d1449e28822ca2a909"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>reportTime</b> (std::string type, double ts, std::string metric, std::string unit)</td></tr>
<tr class="separator:a592e0241723c57d1449e28822ca2a909"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49e058d99de7826ea399654d55e2ec26"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a49e058d99de7826ea399654d55e2ec26"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>splitSizes</b> (const std::string &amp;arg, int *ptr0, int *ptr1)</td></tr>
<tr class="separator:a49e058d99de7826ea399654d55e2ec26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c547f9016d3747b0b39e637bfeae7d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8c547f9016d3747b0b39e637bfeae7d6"></a>
cv::Mat&#160;</td><td class="memItemRight" valign="bottom"><b>resizeImage</b> (cv::Mat &amp;img)</td></tr>
<tr class="separator:a8c547f9016d3747b0b39e637bfeae7d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0604b71fb328d48f8a51096a8a1e10a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af0604b71fb328d48f8a51096a8a1e10a"></a>
cv::Mat&#160;</td><td class="memItemRight" valign="bottom"><b>cropToRec</b> (cv::Mat &amp;img, int *height_ptr, int *width_ptr)</td></tr>
<tr class="separator:af0604b71fb328d48f8a51096a8a1e10a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c3db209aaab54f4e223077bb72a636c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4c3db209aaab54f4e223077bb72a636c"></a>
std::vector&lt; float &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>convertToVector</b> (cv::Mat &amp;img)</td></tr>
<tr class="separator:a4c3db209aaab54f4e223077bb72a636c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2a70a0a4d7143321892d486af8d9782"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2a70a0a4d7143321892d486af8d9782"></a>
std::vector&lt; float &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>convertOneImage</b> (std::string &amp;filename, int *height_ptr, int *width_ptr)</td></tr>
<tr class="separator:ac2a70a0a4d7143321892d486af8d9782"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab486f3689cf28499b6dc850c8186daff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab486f3689cf28499b6dc850c8186daff"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>getBatchSize</b> (int num_items)</td></tr>
<tr class="separator:ab486f3689cf28499b6dc850c8186daff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada88fcb346aa902010c5a2850cbf1e9e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada88fcb346aa902010c5a2850cbf1e9e"></a>
TensorProtos&#160;</td><td class="memItemRight" valign="bottom"><b>writeValues</b> (std::vector&lt; std::vector&lt; std::vector&lt; float &gt;&gt;&gt; &amp;values, std::vector&lt; std::vector&lt; int &gt;&gt; &amp;dims)</td></tr>
<tr class="separator:ada88fcb346aa902010c5a2850cbf1e9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a857b1e7075d533ac87e618ebc1c45f41"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a857b1e7075d533ac87e618ebc1c45f41"></a>
TensorProtos&#160;</td><td class="memItemRight" valign="bottom"><b>convertImages</b> (std::string &amp;image_file)</td></tr>
<tr class="separator:a857b1e7075d533ac87e618ebc1c45f41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60a8dce9f67e2ffd00261da075f75928"><td class="memTemplParams" colspan="2"><a class="anchor" id="a60a8dce9f67e2ffd00261da075f75928"></a>
template&lt;class TYPE &gt; </td></tr>
<tr class="memitem:a60a8dce9f67e2ffd00261da075f75928"><td class="memTemplItemLeft" align="right" valign="top">vector&lt; TYPE &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>splitString</b> (std::string &amp;line)</td></tr>
<tr class="separator:a60a8dce9f67e2ffd00261da075f75928"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8bc4931f6493d107ab398df7ddd49eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa8bc4931f6493d107ab398df7ddd49eb"></a>
TensorProtos&#160;</td><td class="memItemRight" valign="bottom"><b>convertValues</b> (std::string &amp;file_name)</td></tr>
<tr class="separator:aa8bc4931f6493d107ab398df7ddd49eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58b6a67aa6f46d1518d6752955ab92fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a58b6a67aa6f46d1518d6752955ab92fe"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ConvertToRawDataset</b> (const string &amp;input_db_name, const string &amp;output_db_name)</td></tr>
<tr class="separator:a58b6a67aa6f46d1518d6752955ab92fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96dac7d508fbab84a441ab4a5abba3db"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96dac7d508fbab84a441ab4a5abba3db"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>writeValues</b> (std::vector&lt; std::vector&lt; std::vector&lt; float &gt;&gt;&gt; &amp;values, std::vector&lt; std::vector&lt; int &gt;&gt; &amp;dims, std::string output_file)</td></tr>
<tr class="separator:a96dac7d508fbab84a441ab4a5abba3db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6659dcf2bf201b29d8b5940189c719de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6659dcf2bf201b29d8b5940189c719de"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>convertImages</b> ()</td></tr>
<tr class="separator:a6659dcf2bf201b29d8b5940189c719de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2335504a3033438916ee5040a7c681f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2335504a3033438916ee5040a7c681f3"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>convertValues</b> ()</td></tr>
<tr class="separator:a2335504a3033438916ee5040a7c681f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d283b84e27caae9f7e8160fa9dd0d91"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d283b84e27caae9f7e8160fa9dd0d91"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ReadImage</b> (std::ifstream *file, int *label, char *buffer)</td></tr>
<tr class="separator:a7d283b84e27caae9f7e8160fa9dd0d91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a718615c5cb01902ac0d530fa190f6a29"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a718615c5cb01902ac0d530fa190f6a29"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>WriteToDB</b> (const string &amp;filename, const int num_items, const int &amp;offset, <a class="el" href="classcaffe2_1_1db_1_1_d_b.html">db::DB</a> *db)</td></tr>
<tr class="separator:a718615c5cb01902ac0d530fa190f6a29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af57ad87163474085d886931920e539c0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af57ad87163474085d886931920e539c0"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ConvertCIFAR</b> ()</td></tr>
<tr class="separator:af57ad87163474085d886931920e539c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8458f4e5bd1f3f8147feb42fcba53338"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8458f4e5bd1f3f8147feb42fcba53338"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ConvertImageDataset</b> (const string &amp;input_folder, const string &amp;list_filename, const string &amp;output_db_name, const bool)</td></tr>
<tr class="separator:a8458f4e5bd1f3f8147feb42fcba53338"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1098b342cfbdc5ed5ff70419d50b38bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1098b342cfbdc5ed5ff70419d50b38bb"></a>
uint32_t&#160;</td><td class="memItemRight" valign="bottom"><b>swap_endian</b> (uint32_t val)</td></tr>
<tr class="separator:a1098b342cfbdc5ed5ff70419d50b38bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed294171c927c0538aff40a864baded9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed294171c927c0538aff40a864baded9"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>convert_dataset</b> (const char *image_filename, const char *label_filename, const char *db_path, const int data_limit)</td></tr>
<tr class="separator:aed294171c927c0538aff40a864baded9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4da950463d9578262d08f0909123b89d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4da950463d9578262d08f0909123b89d"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>run</b> ()</td></tr>
<tr class="separator:a4da950463d9578262d08f0909123b89d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa08f975d7c47616b21d7fe9041dcab1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa08f975d7c47616b21d7fe9041dcab1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (TypeMetaTestFoo)</td></tr>
<tr class="separator:aaa08f975d7c47616b21d7fe9041dcab1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8908b01af4eeee7b23074478ebc204b1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8908b01af4eeee7b23074478ebc204b1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (TypeMetaTestBar)</td></tr>
<tr class="separator:a8908b01af4eeee7b23074478ebc204b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9cfa4bea39a12e80fbbe838266b846e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af9cfa4bea39a12e80fbbe838266b846e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (ClassAllowAssignment)</td></tr>
<tr class="separator:af9cfa4bea39a12e80fbbe838266b846e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb2bf3ba764bce08c090496d04e8b9a6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb2bf3ba764bce08c090496d04e8b9a6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (ClassNoAssignment)</td></tr>
<tr class="separator:acb2bf3ba764bce08c090496d04e8b9a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cd88006cf6927d6c82a5282fe53689c"><td class="memTemplParams" colspan="2"><a class="anchor" id="a0cd88006cf6927d6c82a5282fe53689c"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a0cd88006cf6927d6c82a5282fe53689c"><td class="memTemplItemLeft" align="right" valign="top">C10_EXPORT const <a class="el" href="structcaffe2_1_1detail_1_1_type_meta_data.html">detail::TypeMetaData</a> *&#160;</td><td class="memTemplItemRight" valign="bottom"><b>TypeMeta::_typeMetaDataInstance&lt; detail::_Uninitialized &gt;</b> () noexcept</td></tr>
<tr class="separator:a0cd88006cf6927d6c82a5282fe53689c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e8878985d4346a7f23ca1e5abe203e2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9e8878985d4346a7f23ca1e5abe203e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE</b> (25, detail::_guard_long_unique&lt; long &gt;)</td></tr>
<tr class="separator:a9e8878985d4346a7f23ca1e5abe203e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0eb2951c0aeb274b3e8cb7fe245fe6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0eb2951c0aeb274b3e8cb7fe245fe6d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE</b> (26, detail::_guard_long_unique&lt; std::vector&lt; long &gt;&gt;)</td></tr>
<tr class="separator:ac0eb2951c0aeb274b3e8cb7fe245fe6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09f4f0ae7436ff8d1b0417b7b1ab0650"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09f4f0ae7436ff8d1b0417b7b1ab0650"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>operator&lt;</b> (<a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a> lhs, <a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a> rhs)</td></tr>
<tr class="separator:a09f4f0ae7436ff8d1b0417b7b1ab0650"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96c73c5167baa94a25ec0562a565c55d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96c73c5167baa94a25ec0562a565c55d"></a>
std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>operator&lt;&lt;</b> (std::ostream &amp;stream, <a class="el" href="classcaffe2_1_1_type_identifier.html">caffe2::TypeIdentifier</a> typeId)</td></tr>
<tr class="separator:a96c73c5167baa94a25ec0562a565c55d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5ab85517da44c9638d937689ec5463b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad5ab85517da44c9638d937689ec5463b"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>operator==</b> (const <a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a> &amp;lhs, const <a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a> &amp;rhs) noexcept</td></tr>
<tr class="separator:ad5ab85517da44c9638d937689ec5463b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1be4021d3388e8d15db4b68afe415a7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1be4021d3388e8d15db4b68afe415a7"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>operator!=</b> (const <a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a> &amp;lhs, const <a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a> &amp;rhs) noexcept</td></tr>
<tr class="separator:ab1be4021d3388e8d15db4b68afe415a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6b3d0b08d9ca201a75d1d0b2e458a48"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6b3d0b08d9ca201a75d1d0b2e458a48"></a>
std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>operator&lt;&lt;</b> (std::ostream &amp;stream, <a class="el" href="classcaffe2_1_1_type_meta.html">caffe2::TypeMeta</a> typeMeta)</td></tr>
<tr class="separator:aa6b3d0b08d9ca201a75d1d0b2e458a48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6d542c4a5caeb2fdf6d2defa922e862"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6d542c4a5caeb2fdf6d2defa922e862"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>BlobIsTensorType</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, DeviceType device_type)</td></tr>
<tr class="separator:ae6d542c4a5caeb2fdf6d2defa922e862"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4020e5fdc385d6bfca57c49faa88247"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae4020e5fdc385d6bfca57c49faa88247"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>BlobSetTensor</b> (<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *blob, <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;&amp;tensor)</td></tr>
<tr class="separator:ae4020e5fdc385d6bfca57c49faa88247"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bdefa24b3e2ca97282d0a350c0cafb5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0bdefa24b3e2ca97282d0a350c0cafb5"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>GetSizedTensorWithOptions</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;&amp;previous_tensor, <a class="el" href="classc10_1_1_array_ref.html">at::IntArrayRef</a> dims, <a class="el" href="structc10_1_1_tensor_options.html">at::TensorOptions</a> options)</td></tr>
<tr class="separator:a0bdefa24b3e2ca97282d0a350c0cafb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08e343388496f305a87c897ec8c4eb17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08e343388496f305a87c897ec8c4eb17"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>BlobGetMutableTensor</b> (<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *blob, <a class="el" href="classc10_1_1_array_ref.html">at::IntArrayRef</a> dims, <a class="el" href="structc10_1_1_tensor_options.html">at::TensorOptions</a> options)</td></tr>
<tr class="separator:a08e343388496f305a87c897ec8c4eb17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95e371ab64304b19c583aad6fa9b38eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a95e371ab64304b19c583aad6fa9b38eb"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>XBlobGetMutableTensor</b> (<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *blob, <a class="el" href="classc10_1_1_array_ref.html">at::IntArrayRef</a> dims, <a class="el" href="structc10_1_1_tensor_options.html">at::TensorOptions</a> options)</td></tr>
<tr class="separator:a95e371ab64304b19c583aad6fa9b38eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a093d16ec25720eec34aa601d2de88f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a093d16ec25720eec34aa601d2de88f"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>BlobGetMutableTensor</b> (<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *blob, DeviceType device_type)</td></tr>
<tr class="separator:a9a093d16ec25720eec34aa601d2de88f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d638a744bb1d15bd9a8b4fb97e3544c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d638a744bb1d15bd9a8b4fb97e3544c"></a>
const <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>BlobGetTensor</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, DeviceType device_type)</td></tr>
<tr class="separator:a1d638a744bb1d15bd9a8b4fb97e3544c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61c81ebc46b26e7ec841fecd962b8a50"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a61c81ebc46b26e7ec841fecd962b8a50"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>BlobGetTensorOrUndefined</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob)</td></tr>
<tr class="separator:a61c81ebc46b26e7ec841fecd962b8a50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7f0e8205348ebe02da420eca59a942f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ac7f0e8205348ebe02da420eca59a942f">SerializeBlob</a> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, const string &amp;name, BlobSerializerBase::SerializationAcceptor acceptor, int chunk_size=kDefaultChunkSize)</td></tr>
<tr class="memdesc:ac7f0e8205348ebe02da420eca59a942f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Serializes the given blob, if possible.  <a href="#ac7f0e8205348ebe02da420eca59a942f">More...</a><br /></td></tr>
<tr class="separator:ac7f0e8205348ebe02da420eca59a942f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac88344ce83b47dcf2290d09f0f500164"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ac88344ce83b47dcf2290d09f0f500164">SerializeBlob</a> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, const string &amp;name)</td></tr>
<tr class="memdesc:ac88344ce83b47dcf2290d09f0f500164"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convenience function to serialize a blob to a string.  <a href="#ac88344ce83b47dcf2290d09f0f500164">More...</a><br /></td></tr>
<tr class="separator:ac88344ce83b47dcf2290d09f0f500164"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47fded6ff24bcf074e5c78701ebe70f2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a47fded6ff24bcf074e5c78701ebe70f2"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a47fded6ff24bcf074e5c78701ebe70f2">GetGPUIDForPointer</a> (const void *ptr)</td></tr>
<tr class="memdesc:a47fded6ff24bcf074e5c78701ebe70f2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the GPU id that the current pointer is located at. <br /></td></tr>
<tr class="separator:a47fded6ff24bcf074e5c78701ebe70f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf9e3fc7537e5ae9bcd2846517c47ae5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acf9e3fc7537e5ae9bcd2846517c47ae5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_TYPED_REGISTRY</b> (BlobSerializerRegistry, <a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a>, <a class="el" href="classcaffe2_1_1_blob_serializer_base.html">BlobSerializerBase</a>, std::unique_ptr)</td></tr>
<tr class="separator:acf9e3fc7537e5ae9bcd2846517c47ae5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa79f66bae350a172a6258d7abe63c8ce"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa79f66bae350a172a6258d7abe63c8ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (BlobDeserializerRegistry, <a class="el" href="classcaffe2_1_1_blob_deserializer_base.html">BlobDeserializerBase</a>)</td></tr>
<tr class="separator:aa79f66bae350a172a6258d7abe63c8ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b05dd11e7a9e3d8318df5c99008fb46"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a6b05dd11e7a9e3d8318df5c99008fb46">DeserializeBlob</a> (const string &amp;content, <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *result)</td></tr>
<tr class="memdesc:a6b05dd11e7a9e3d8318df5c99008fb46"><td class="mdescLeft">&#160;</td><td class="mdescRight">Deserializes from a string containing either BlobProto or TensorProto.  <a href="#a6b05dd11e7a9e3d8318df5c99008fb46">More...</a><br /></td></tr>
<tr class="separator:a6b05dd11e7a9e3d8318df5c99008fb46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31ca856ae6b008a46edc6c83a8c0f4b3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a31ca856ae6b008a46edc6c83a8c0f4b3"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>DeserializeBlob</b> (const BlobProto &amp;blob_proto, <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *result)</td></tr>
<tr class="separator:a31ca856ae6b008a46edc6c83a8c0f4b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae337e8ad0b597f5da283f39b51d62d52"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae337e8ad0b597f5da283f39b51d62d52"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>EmptyTensorFromProto</b> (const TensorProto &amp;tensor_proto)</td></tr>
<tr class="separator:ae337e8ad0b597f5da283f39b51d62d52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35c8f324468b6dd35e7daa25282de8b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35c8f324468b6dd35e7daa25282de8b6"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><b>SerializeAsString_EnforceCheck</b> (const google::protobuf::MessageLite &amp;msg, const char *error_location)</td></tr>
<tr class="separator:a35c8f324468b6dd35e7daa25282de8b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cecbafb21cece8de03ce8b1284280ba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4cecbafb21cece8de03ce8b1284280ba"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><b>SerializeBlobProtoAsString_EnforceCheck</b> (const BlobProto &amp;blob)</td></tr>
<tr class="separator:a4cecbafb21cece8de03ce8b1284280ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9794304c8ab1863fa6bce5a7f9e8487f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9794304c8ab1863fa6bce5a7f9e8487f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_TYPED_REGISTRY</b> (BlobSerializerRegistry, <a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a>, <a class="el" href="classcaffe2_1_1_blob_serializer_base.html">BlobSerializerBase</a>, std::unique_ptr)</td></tr>
<tr class="separator:a9794304c8ab1863fa6bce5a7f9e8487f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2c7e48435abf029cdf1aee07574dd71"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa2c7e48435abf029cdf1aee07574dd71"></a>
unique_ptr&lt; <a class="el" href="classcaffe2_1_1_blob_serializer_base.html">BlobSerializerBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>CreateSerializer</b> (<a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a> id)</td></tr>
<tr class="separator:aa2c7e48435abf029cdf1aee07574dd71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a0dc00621b473407fa94eaabe824a0a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a0dc00621b473407fa94eaabe824a0a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (BlobDeserializerRegistry, <a class="el" href="classcaffe2_1_1_blob_deserializer_base.html">BlobDeserializerBase</a>)</td></tr>
<tr class="separator:a0a0dc00621b473407fa94eaabe824a0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab22598778f6a6b1817b0081f79a8195"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aab22598778f6a6b1817b0081f79a8195"></a>
unique_ptr&lt; <a class="el" href="classcaffe2_1_1_blob_deserializer_base.html">BlobDeserializerBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>CreateDeserializer</b> (const string &amp;type)</td></tr>
<tr class="separator:aab22598778f6a6b1817b0081f79a8195"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aced370748e9b49f94f79f1124a26a3a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aced370748e9b49f94f79f1124a26a3a0"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>HasCudaRuntime</b> ()</td></tr>
<tr class="separator:aced370748e9b49f94f79f1124a26a3a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a844873a786f3a88e127b9207ab322885"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a844873a786f3a88e127b9207ab322885"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>HasHipRuntime</b> ()</td></tr>
<tr class="separator:a844873a786f3a88e127b9207ab322885"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2bd1a0edee23e2345efa23c6f477a85"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2bd1a0edee23e2345efa23c6f477a85"></a>
const std::map&lt; string, string &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>GetBuildOptions</b> ()</td></tr>
<tr class="separator:ab2bd1a0edee23e2345efa23c6f477a85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ceeaed4853a8fe83f17f6f5754d5de5"><td class="memTemplParams" colspan="2"><a class="anchor" id="a9ceeaed4853a8fe83f17f6f5754d5de5"></a>
template&lt;typename T , typename... Args&gt; </td></tr>
<tr class="memitem:a9ceeaed4853a8fe83f17f6f5754d5de5"><td class="memTemplItemLeft" align="right" valign="top">std::enable_if&lt;!std::is_array&lt; <a class="el" href="struct_t.html">T</a> &gt;::value, std::unique_ptr&lt; <a class="el" href="struct_t.html">T</a> &gt; &gt;::type&#160;</td><td class="memTemplItemRight" valign="bottom"><b>make_unique</b> (Args &amp;&amp;...args)</td></tr>
<tr class="separator:a9ceeaed4853a8fe83f17f6f5754d5de5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34b77c9dbea4e60718a4f2cf2c7a6b06"><td class="memTemplParams" colspan="2"><a class="anchor" id="a34b77c9dbea4e60718a4f2cf2c7a6b06"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a34b77c9dbea4e60718a4f2cf2c7a6b06"><td class="memTemplItemLeft" align="right" valign="top">std::enable_if&lt; std::is_array&lt; <a class="el" href="struct_t.html">T</a> &gt;::value, std::unique_ptr&lt; <a class="el" href="struct_t.html">T</a> &gt; &gt;::type&#160;</td><td class="memTemplItemRight" valign="bottom"><b>make_unique</b> (const size_t n)</td></tr>
<tr class="separator:a34b77c9dbea4e60718a4f2cf2c7a6b06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af206045e6c725a1a3819e9647fae85bc"><td class="memTemplParams" colspan="2"><a class="anchor" id="af206045e6c725a1a3819e9647fae85bc"></a>
template&lt;typename T , typename... Args&gt; </td></tr>
<tr class="memitem:af206045e6c725a1a3819e9647fae85bc"><td class="memTemplItemLeft" align="right" valign="top">std::enable_if&lt; std::extent&lt; <a class="el" href="struct_t.html">T</a> &gt;::value!=0, std::unique_ptr&lt; <a class="el" href="struct_t.html">T</a> &gt; &gt;::type&#160;</td><td class="memTemplItemRight" valign="bottom"><b>make_unique</b> (Args &amp;&amp;...)=delete</td></tr>
<tr class="separator:af206045e6c725a1a3819e9647fae85bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc93877ba8e3cb6ad6f874582a22da80"><td class="memTemplParams" colspan="2"><a class="anchor" id="acc93877ba8e3cb6ad6f874582a22da80"></a>
template&lt;typename Dst , typename Src &gt; </td></tr>
<tr class="memitem:acc93877ba8e3cb6ad6f874582a22da80"><td class="memTemplItemLeft" align="right" valign="top">Dst&#160;</td><td class="memTemplItemRight" valign="bottom"><b>dynamic_cast_if_rtti</b> (Src ptr)</td></tr>
<tr class="separator:acc93877ba8e3cb6ad6f874582a22da80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4413739415b39b948f054531e05544e0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4413739415b39b948f054531e05544e0"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><b>cudnnCompiledVersion</b> ()</td></tr>
<tr class="separator:a4413739415b39b948f054531e05544e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0eea2b165a0f944edbd54cf85fe841b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0eea2b165a0f944edbd54cf85fe841b4"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><b>cudnnRuntimeVersion</b> ()</td></tr>
<tr class="separator:a0eea2b165a0f944edbd54cf85fe841b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbd772f611b05663e9ea099d31e6bb53"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adbd772f611b05663e9ea099d31e6bb53"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>CheckCuDNNVersions</b> ()</td></tr>
<tr class="separator:adbd772f611b05663e9ea099d31e6bb53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87a6f5f6d9bed583a8e4db51d96c854b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87a6f5f6d9bed583a8e4db51d96c854b"></a>
cudnnTensorFormat_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a87a6f5f6d9bed583a8e4db51d96c854b">GetCudnnTensorFormat</a> (const StorageOrder &amp;order)</td></tr>
<tr class="memdesc:a87a6f5f6d9bed583a8e4db51d96c854b"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> wrapper function to convert the Caffe storage order to cudnn storage order enum values. <br /></td></tr>
<tr class="separator:a87a6f5f6d9bed583a8e4db51d96c854b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac12fc41f74ddff2539f3962bda040d0f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac12fc41f74ddff2539f3962bda040d0f"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ac12fc41f74ddff2539f3962bda040d0f">NumCudaDevices</a> ()</td></tr>
<tr class="memdesc:ac12fc41f74ddff2539f3962bda040d0f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the number of devices. <br /></td></tr>
<tr class="separator:ac12fc41f74ddff2539f3962bda040d0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad461eced97a6ba2c1959ba262f1a3a3c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad461eced97a6ba2c1959ba262f1a3a3c"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>SetDefaultGPUID</b> (const int deviceid)</td></tr>
<tr class="separator:ad461eced97a6ba2c1959ba262f1a3a3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7cd1e125dba2165f692bc0b681cf0a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af7cd1e125dba2165f692bc0b681cf0a5"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>GetDefaultGPUID</b> ()</td></tr>
<tr class="separator:af7cd1e125dba2165f692bc0b681cf0a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f6369bbf216f45519638f9aceb22773"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a4f6369bbf216f45519638f9aceb22773">CaffeCudaGetDevice</a> ()</td></tr>
<tr class="memdesc:a4f6369bbf216f45519638f9aceb22773"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the current GPU id.  <a href="#a4f6369bbf216f45519638f9aceb22773">More...</a><br /></td></tr>
<tr class="separator:a4f6369bbf216f45519638f9aceb22773"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5ded10391eee674b0aaa6d61353e0ab"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ae5ded10391eee674b0aaa6d61353e0ab">CaffeCudaSetDevice</a> (const int id)</td></tr>
<tr class="memdesc:ae5ded10391eee674b0aaa6d61353e0ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the current GPU id.  <a href="#ae5ded10391eee674b0aaa6d61353e0ab">More...</a><br /></td></tr>
<tr class="separator:ae5ded10391eee674b0aaa6d61353e0ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7078d33f22df2864a57ac382257afec"><td class="memItemLeft" align="right" valign="top">const cudaDeviceProp &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#aa7078d33f22df2864a57ac382257afec">GetDeviceProperty</a> (const int device)</td></tr>
<tr class="memdesc:aa7078d33f22df2864a57ac382257afec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the device property for the given device.  <a href="#aa7078d33f22df2864a57ac382257afec">More...</a><br /></td></tr>
<tr class="separator:aa7078d33f22df2864a57ac382257afec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b043e81405e2d951913d72bef4e9bbe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b043e81405e2d951913d72bef4e9bbe"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a3b043e81405e2d951913d72bef4e9bbe">DeviceQuery</a> (const int deviceid)</td></tr>
<tr class="memdesc:a3b043e81405e2d951913d72bef4e9bbe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Runs a device query function and prints out the results to LOG(INFO). <br /></td></tr>
<tr class="separator:a3b043e81405e2d951913d72bef4e9bbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a446da244aca2a8c6808963912cd5cdfc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a446da244aca2a8c6808963912cd5cdfc"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>GetCudaPeerAccessPattern</b> (vector&lt; vector&lt; bool &gt; &gt; *pattern)</td></tr>
<tr class="separator:a446da244aca2a8c6808963912cd5cdfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9049d5f39d0031e8d1a95e8cfd2d7748"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9049d5f39d0031e8d1a95e8cfd2d7748"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a9049d5f39d0031e8d1a95e8cfd2d7748">TensorCoreAvailable</a> ()</td></tr>
<tr class="memdesc:a9049d5f39d0031e8d1a95e8cfd2d7748"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the availability of TensorCores for math. <br /></td></tr>
<tr class="separator:a9049d5f39d0031e8d1a95e8cfd2d7748"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ac24d3074466d00d7a3d3c6fd89882f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ac24d3074466d00d7a3d3c6fd89882f"></a>
const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a4ac24d3074466d00d7a3d3c6fd89882f">cublasGetErrorString</a> (cublasStatus_t error)</td></tr>
<tr class="memdesc:a4ac24d3074466d00d7a3d3c6fd89882f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return a human readable cublas error string. <br /></td></tr>
<tr class="separator:a4ac24d3074466d00d7a3d3c6fd89882f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38bebb3ccba4e3a364d8475e8e99c303"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38bebb3ccba4e3a364d8475e8e99c303"></a>
const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a38bebb3ccba4e3a364d8475e8e99c303">curandGetErrorString</a> (curandStatus_t error)</td></tr>
<tr class="memdesc:a38bebb3ccba4e3a364d8475e8e99c303"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return a human readable curand error string. <br /></td></tr>
<tr class="separator:a38bebb3ccba4e3a364d8475e8e99c303"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad503e334918c94362ff2758be80b0f56"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad503e334918c94362ff2758be80b0f56"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ad503e334918c94362ff2758be80b0f56">CudaVersion</a> ()</td></tr>
<tr class="memdesc:ad503e334918c94362ff2758be80b0f56"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> runtime function to report the cuda version that Caffe2 is built with. <br /></td></tr>
<tr class="separator:ad503e334918c94362ff2758be80b0f56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48638afbef9a25309bf7ef40a6e97919"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a48638afbef9a25309bf7ef40a6e97919">HasCudaGPU</a> ()</td></tr>
<tr class="memdesc:a48638afbef9a25309bf7ef40a6e97919"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if the current running session has a cuda gpu present.  <a href="#a48638afbef9a25309bf7ef40a6e97919">More...</a><br /></td></tr>
<tr class="separator:a48638afbef9a25309bf7ef40a6e97919"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e1e6fbe09090c25f04ce1bdacc9f030"><td class="memItemLeft" align="right" valign="top">CAFFE2_CUDA_API bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a8e1e6fbe09090c25f04ce1bdacc9f030">GetCudaPeerAccessPattern</a> (vector&lt; vector&lt; bool &gt;&gt; *pattern)</td></tr>
<tr class="memdesc:a8e1e6fbe09090c25f04ce1bdacc9f030"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return a peer access pattern by returning a matrix (in the format of a nested vector) of boolean values specifying whether peer access is possible.  <a href="#a8e1e6fbe09090c25f04ce1bdacc9f030">More...</a><br /></td></tr>
<tr class="separator:a8e1e6fbe09090c25f04ce1bdacc9f030"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa7bf47b9067ef9d15605a5d8746fddd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa7bf47b9067ef9d15605a5d8746fddd"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#afa7bf47b9067ef9d15605a5d8746fddd">CAFFE_GET_BLOCKS</a> (const int N)</td></tr>
<tr class="memdesc:afa7bf47b9067ef9d15605a5d8746fddd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the number of blocks needed to run N threads. <br /></td></tr>
<tr class="separator:afa7bf47b9067ef9d15605a5d8746fddd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aede36ec9b29ebcd3e99487a40fafa134"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aede36ec9b29ebcd3e99487a40fafa134"></a>
dim3&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#aede36ec9b29ebcd3e99487a40fafa134">CAFFE_GET_BLOCKS_2D</a> (const int N, const int)</td></tr>
<tr class="memdesc:aede36ec9b29ebcd3e99487a40fafa134"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the number of blocks needed to run N threads for a 2D grid. <br /></td></tr>
<tr class="separator:aede36ec9b29ebcd3e99487a40fafa134"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f6b40d0997aec03670ceffef4cea984"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f6b40d0997aec03670ceffef4cea984"></a>
uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a7f6b40d0997aec03670ceffef4cea984">RandomNumberSeed</a> ()</td></tr>
<tr class="memdesc:a7f6b40d0997aec03670ceffef4cea984"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> function to generate a random number seed that is unique in a best-effort basis, using an ever-incrementing seed and the current time. <br /></td></tr>
<tr class="separator:a7f6b40d0997aec03670ceffef4cea984"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab645e4c1c84a791406d55a16f31a7e80"><td class="memItemLeft" align="right" valign="top">CAFFE2_CUDA_API CudaMemoryPoolType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ab645e4c1c84a791406d55a16f31a7e80">GetCudaMemoryPoolType</a> ()</td></tr>
<tr class="memdesc:ab645e4c1c84a791406d55a16f31a7e80"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the current memory pool type used by Caffe2.  <a href="#ab645e4c1c84a791406d55a16f31a7e80">More...</a><br /></td></tr>
<tr class="separator:ab645e4c1c84a791406d55a16f31a7e80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19bf17d6878d8180468f6127da0470a2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a19bf17d6878d8180468f6127da0470a2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="classcaffe2_1_1db_1_1_d_b_reader.html">db::DBReader</a>)</td></tr>
<tr class="separator:a19bf17d6878d8180468f6127da0470a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade9fe276cadd651f79cbaee58b726b6f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade9fe276cadd651f79cbaee58b726b6f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="classcaffe2_1_1db_1_1_cursor.html">db::Cursor</a>)</td></tr>
<tr class="separator:ade9fe276cadd651f79cbaee58b726b6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d4b1ea830ff2a0a9974aa19e3e03278"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d4b1ea830ff2a0a9974aa19e3e03278"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventCreateCPU</b> (const DeviceOption &amp;option, <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:a9d4b1ea830ff2a0a9974aa19e3e03278"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75f7d1b36073478d998eb6cdcfc4fe4a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75f7d1b36073478d998eb6cdcfc4fe4a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventRecordCPU</b> (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, const void *, const char *err_msg)</td></tr>
<tr class="separator:a75f7d1b36073478d998eb6cdcfc4fe4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affd03a6ca080d94dabbe360bd9758bb7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="affd03a6ca080d94dabbe360bd9758bb7"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventFinishCPU</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:affd03a6ca080d94dabbe360bd9758bb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c99f40be4b3bad6406d09e22e8186c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5c99f40be4b3bad6406d09e22e8186c5"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventWaitCPUCPU</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, void *)</td></tr>
<tr class="separator:a5c99f40be4b3bad6406d09e22e8186c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3eae3b94f5eb50129a2bae2d0062652d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3eae3b94f5eb50129a2bae2d0062652d"></a>
EventStatus&#160;</td><td class="memItemRight" valign="bottom"><b>EventQueryCPU</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:a3eae3b94f5eb50129a2bae2d0062652d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf052f727ddbc93e195ea78ed514fca2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acf052f727ddbc93e195ea78ed514fca2"></a>
const std::string &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>EventErrorMessageCPU</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:acf052f727ddbc93e195ea78ed514fca2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0984479c946c8930de5f673a0f08b688"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0984479c946c8930de5f673a0f08b688"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventSetFinishedCPU</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, const char *err_msg)</td></tr>
<tr class="separator:a0984479c946c8930de5f673a0f08b688"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c02ef06b0e7e8adf23eb01f030cb4de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c02ef06b0e7e8adf23eb01f030cb4de"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventSetCallbackCPU</b> (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, EventCallbackFunction callback)</td></tr>
<tr class="separator:a9c02ef06b0e7e8adf23eb01f030cb4de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92b96d1579b04ccabf7b36290922ff49"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92b96d1579b04ccabf7b36290922ff49"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventResetCPU</b> (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:a92b96d1579b04ccabf7b36290922ff49"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00a5e31dbda40b6d4b59e79fa1f4a690"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a00a5e31dbda40b6d4b59e79fa1f4a690"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_CREATE_FUNCTION</b> (CPU, EventCreateCPU)</td></tr>
<tr class="separator:a00a5e31dbda40b6d4b59e79fa1f4a690"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6dc4485f5e8424c1b31a81e3bd72942e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6dc4485f5e8424c1b31a81e3bd72942e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_RECORD_FUNCTION</b> (CPU, EventRecordCPU)</td></tr>
<tr class="separator:a6dc4485f5e8424c1b31a81e3bd72942e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4981591aaa121f0fff77ec2053c7db1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab4981591aaa121f0fff77ec2053c7db1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (CPU, CPU, EventWaitCPUCPU)</td></tr>
<tr class="separator:ab4981591aaa121f0fff77ec2053c7db1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6346ec5ed3c38916277dc2924697cd97"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6346ec5ed3c38916277dc2924697cd97"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_FINISH_FUNCTION</b> (CPU, EventFinishCPU)</td></tr>
<tr class="separator:a6346ec5ed3c38916277dc2924697cd97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2260c24ce5245586014356a3ef7fd7e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2260c24ce5245586014356a3ef7fd7e4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_QUERY_FUNCTION</b> (CPU, EventQueryCPU)</td></tr>
<tr class="separator:a2260c24ce5245586014356a3ef7fd7e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac139290fdee69ebbe8e58a01bb13335c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac139290fdee69ebbe8e58a01bb13335c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_ERROR_MESSAGE_FUNCTION</b> (CPU, EventErrorMessageCPU)</td></tr>
<tr class="separator:ac139290fdee69ebbe8e58a01bb13335c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae09e628a4b0f62bc690c400226f4e7ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae09e628a4b0f62bc690c400226f4e7ed"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_SET_FINISHED_FUNCTION</b> (CPU, EventSetFinishedCPU)</td></tr>
<tr class="separator:ae09e628a4b0f62bc690c400226f4e7ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3414fc5a843cacb019fddc19c8187f25"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3414fc5a843cacb019fddc19c8187f25"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_RESET_FUNCTION</b> (CPU, EventResetCPU)</td></tr>
<tr class="separator:a3414fc5a843cacb019fddc19c8187f25"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99d6ac8070175f66f326356d337739b3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a99d6ac8070175f66f326356d337739b3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_SET_CALLBACK_FUNCTION</b> (CPU, EventSetCallbackCPU)</td></tr>
<tr class="separator:a99d6ac8070175f66f326356d337739b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2e593e92c534d0f613b2af800cf9884"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af2e593e92c534d0f613b2af800cf9884"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EventCanScheduleCPU</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *, const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *)</td></tr>
<tr class="separator:af2e593e92c534d0f613b2af800cf9884"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3de9b96755ed2723ceb0ff02f00fbc23"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3de9b96755ed2723ceb0ff02f00fbc23"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventCreateCUDA</b> (const DeviceOption &amp;option, <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:a3de9b96755ed2723ceb0ff02f00fbc23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a794d72658b8f476fba85fb48907a7adb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a794d72658b8f476fba85fb48907a7adb"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventRecordCUDA</b> (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, const void *context, const char *err_msg)</td></tr>
<tr class="separator:a794d72658b8f476fba85fb48907a7adb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69fd1eefd56e92d17a96827f412c8b97"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a69fd1eefd56e92d17a96827f412c8b97"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventFinishCUDA</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:a69fd1eefd56e92d17a96827f412c8b97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7285207a6b79ac4af4472864e576eca8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7285207a6b79ac4af4472864e576eca8"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventWaitCUDACUDA</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, void *context)</td></tr>
<tr class="separator:a7285207a6b79ac4af4472864e576eca8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b3dca82a96fb8e14eb7583b939d8833"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5b3dca82a96fb8e14eb7583b939d8833"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventWaitCPUCUDA</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, void *context)</td></tr>
<tr class="separator:a5b3dca82a96fb8e14eb7583b939d8833"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d45b996821cb7a03ab14362677c4901"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5d45b996821cb7a03ab14362677c4901"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventWaitCUDACPU</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, void *context)</td></tr>
<tr class="separator:a5d45b996821cb7a03ab14362677c4901"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8672bcd27a7661125fb9431a1ddf5e44"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8672bcd27a7661125fb9431a1ddf5e44"></a>
EventStatus&#160;</td><td class="memItemRight" valign="bottom"><b>EventQueryCUDA</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:a8672bcd27a7661125fb9431a1ddf5e44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae72aee3b598a5be153cd54ff7b0a6c2e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae72aee3b598a5be153cd54ff7b0a6c2e"></a>
const std::string &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>EventErrorMessageCUDA</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:ae72aee3b598a5be153cd54ff7b0a6c2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6f0efdbd1ae450464c4ab064a5a96a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6f0efdbd1ae450464c4ab064a5a96a0"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventSetFinishedCUDA</b> (const <a class="el" href="classcaffe2_1_1_event.html">Event</a> *event, const char *err_msg)</td></tr>
<tr class="separator:ad6f0efdbd1ae450464c4ab064a5a96a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24f0679eb8b591c7cdaa9dca7fd22623"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a24f0679eb8b591c7cdaa9dca7fd22623"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>EventResetCUDA</b> (<a class="el" href="classcaffe2_1_1_event.html">Event</a> *event)</td></tr>
<tr class="separator:a24f0679eb8b591c7cdaa9dca7fd22623"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab29709ed5cbb863dcef6dc6f0f9a431c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab29709ed5cbb863dcef6dc6f0f9a431c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_CREATE_FUNCTION</b> (CUDA, EventCreateCUDA)</td></tr>
<tr class="separator:ab29709ed5cbb863dcef6dc6f0f9a431c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff021463f822f8104037da552a9da48c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff021463f822f8104037da552a9da48c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_RECORD_FUNCTION</b> (CUDA, EventRecordCUDA)</td></tr>
<tr class="separator:aff021463f822f8104037da552a9da48c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9838e883f710f448e898c734b08ce625"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9838e883f710f448e898c734b08ce625"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (CUDA, CUDA, EventWaitCUDACUDA)</td></tr>
<tr class="separator:a9838e883f710f448e898c734b08ce625"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31748deb693ec49b1cd132be1805154b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a31748deb693ec49b1cd132be1805154b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (CPU, CUDA, EventWaitCPUCUDA)</td></tr>
<tr class="separator:a31748deb693ec49b1cd132be1805154b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfeeb42807c3d26a7acbf45b9b3bd429"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abfeeb42807c3d26a7acbf45b9b3bd429"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (CUDA, CPU, EventWaitCUDACPU)</td></tr>
<tr class="separator:abfeeb42807c3d26a7acbf45b9b3bd429"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1eac45930baf700f459675b6168bc06f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1eac45930baf700f459675b6168bc06f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_FINISH_FUNCTION</b> (CUDA, EventFinishCUDA)</td></tr>
<tr class="separator:a1eac45930baf700f459675b6168bc06f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb5d1cbe96083f03045fd24c70315fe8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb5d1cbe96083f03045fd24c70315fe8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_QUERY_FUNCTION</b> (CUDA, EventQueryCUDA)</td></tr>
<tr class="separator:acb5d1cbe96083f03045fd24c70315fe8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a601ead593addd6ab87afa33b4f4f07da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a601ead593addd6ab87afa33b4f4f07da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_ERROR_MESSAGE_FUNCTION</b> (CUDA, EventErrorMessageCUDA)</td></tr>
<tr class="separator:a601ead593addd6ab87afa33b4f4f07da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af740e501891c7ea922b6749a34ee3786"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af740e501891c7ea922b6749a34ee3786"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_SET_FINISHED_FUNCTION</b> (CUDA, EventSetFinishedCUDA)</td></tr>
<tr class="separator:af740e501891c7ea922b6749a34ee3786"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17ffea44cea509815a7d0f847fc19249"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17ffea44cea509815a7d0f847fc19249"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_RESET_FUNCTION</b> (CUDA, EventResetCUDA)</td></tr>
<tr class="separator:a17ffea44cea509815a7d0f847fc19249"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7eb30314b2436a9057a0e3f2d879e7a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7eb30314b2436a9057a0e3f2d879e7a0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (MKLDNN, CUDA, EventWaitCPUCUDA)</td></tr>
<tr class="separator:a7eb30314b2436a9057a0e3f2d879e7a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07bf69c6112545964ab825636acdea35"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a07bf69c6112545964ab825636acdea35"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (CUDA, MKLDNN, EventWaitCUDACPU)</td></tr>
<tr class="separator:a07bf69c6112545964ab825636acdea35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af94946c005aed5d51f702e3a4d7f5929"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af94946c005aed5d51f702e3a4d7f5929"></a>
OperatorDef *&#160;</td><td class="memItemRight" valign="bottom"><b>AddOp</b> (NetDef *netdef_ptr, string op_type, std::vector&lt; string &gt; inputs, std::vector&lt; string &gt; outputs)</td></tr>
<tr class="separator:af94946c005aed5d51f702e3a4d7f5929"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7105376fca14f67a44e669947c9300b0"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a7105376fca14f67a44e669947c9300b0">MatchStrings</a> (string p, string s)</td></tr>
<tr class="memdesc:a7105376fca14f67a44e669947c9300b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">This allows for the use of * and | to match operator types, engines, or any other property that is represented by strings.  <a href="#a7105376fca14f67a44e669947c9300b0">More...</a><br /></td></tr>
<tr class="separator:a7105376fca14f67a44e669947c9300b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a768dc7966940fbf3103b2e4c26d675"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6a768dc7966940fbf3103b2e4c26d675"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a6a768dc7966940fbf3103b2e4c26d675">MatchArguments</a> (const OperatorDef &amp;p_op, const OperatorDef &amp;g_op)</td></tr>
<tr class="memdesc:a6a768dc7966940fbf3103b2e4c26d675"><td class="mdescLeft">&#160;</td><td class="mdescRight">This ensures that each named arg that exists in the pattern exists in g_op, is equal in value. <br /></td></tr>
<tr class="separator:a6a768dc7966940fbf3103b2e4c26d675"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35e7200d07ca8409f442474209a9d531"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35e7200d07ca8409f442474209a9d531"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><b>miopenCompiledVersion</b> ()</td></tr>
<tr class="separator:a35e7200d07ca8409f442474209a9d531"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62c89211d689f1b6f20713e0cef53ef5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62c89211d689f1b6f20713e0cef53ef5"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><b>miopenRuntimeVersion</b> ()</td></tr>
<tr class="separator:a62c89211d689f1b6f20713e0cef53ef5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e88727c20920eef9fb87b7119f03ec1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7e88727c20920eef9fb87b7119f03ec1"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>CheckMIOPENVersions</b> ()</td></tr>
<tr class="separator:a7e88727c20920eef9fb87b7119f03ec1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92d7ca2a25f339d2a78ec01638881d68"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92d7ca2a25f339d2a78ec01638881d68"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a92d7ca2a25f339d2a78ec01638881d68">GlobalInitAlreadyRun</a> ()</td></tr>
<tr class="memdesc:a92d7ca2a25f339d2a78ec01638881d68"><td class="mdescLeft">&#160;</td><td class="mdescRight">Determine whether GlobalInit has already been run. <br /></td></tr>
<tr class="separator:a92d7ca2a25f339d2a78ec01638881d68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34ee9caa2ba0f16d7573ca9173803931"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a34ee9caa2ba0f16d7573ca9173803931">GlobalInit</a> (int *pargc, char ***argv)</td></tr>
<tr class="memdesc:a34ee9caa2ba0f16d7573ca9173803931"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialize the global environment of <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a>.  <a href="#a34ee9caa2ba0f16d7573ca9173803931">More...</a><br /></td></tr>
<tr class="separator:a34ee9caa2ba0f16d7573ca9173803931"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1d8febf62e5b0a60614a4ce5754d373"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ac1d8febf62e5b0a60614a4ce5754d373">GlobalInit</a> ()</td></tr>
<tr class="memdesc:ac1d8febf62e5b0a60614a4ce5754d373"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialize the global environment without command line arguments.  <a href="#ac1d8febf62e5b0a60614a4ce5754d373">More...</a><br /></td></tr>
<tr class="separator:ac1d8febf62e5b0a60614a4ce5754d373"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9d56bd971638247dfed4ab7cd97fa6f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9d56bd971638247dfed4ab7cd97fa6f"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Caffe2CheckIntrinsicsFeatures</b> (int *, char ***)</td></tr>
<tr class="separator:ad9d56bd971638247dfed4ab7cd97fa6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd6b100b9f9e1f38454aaf02fe09b62c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd6b100b9f9e1f38454aaf02fe09b62c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CAFFE2_INIT_FUNCTION</b> (Caffe2CheckIntrinsicsFeatures,&amp;Caffe2CheckIntrinsicsFeatures,&quot;Check intrinsics compatibility between the CPU feature and the binary.&quot;)</td></tr>
<tr class="separator:acd6b100b9f9e1f38454aaf02fe09b62c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3cdcb7acfd41aedb349910afd55eb5a8"><td class="memItemLeft" align="right" valign="top">const CaffeMap&lt; string, const <a class="el" href="classcaffe2_1_1_module_schema.html">ModuleSchema</a> * &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a3cdcb7acfd41aedb349910afd55eb5a8">CurrentModules</a> ()</td></tr>
<tr class="memdesc:a3cdcb7acfd41aedb349910afd55eb5a8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Current Modules present in the Caffe2 runtime.  <a href="#a3cdcb7acfd41aedb349910afd55eb5a8">More...</a><br /></td></tr>
<tr class="separator:a3cdcb7acfd41aedb349910afd55eb5a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1a95182461bd65dea5f7ff8c7de3570"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa1a95182461bd65dea5f7ff8c7de3570"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#aa1a95182461bd65dea5f7ff8c7de3570">HasModule</a> (const string &amp;name)</td></tr>
<tr class="memdesc:aa1a95182461bd65dea5f7ff8c7de3570"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks whether a module is already present in the current binary. <br /></td></tr>
<tr class="separator:aa1a95182461bd65dea5f7ff8c7de3570"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c2e21acb51df80158e5644031314050"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a5c2e21acb51df80158e5644031314050">LoadModule</a> (const string &amp;name, const string &amp;filename=&quot;&quot;)</td></tr>
<tr class="memdesc:a5c2e21acb51df80158e5644031314050"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a module.  <a href="#a5c2e21acb51df80158e5644031314050">More...</a><br /></td></tr>
<tr class="separator:a5c2e21acb51df80158e5644031314050"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace1716b41446d0b3832518b2951738de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ace1716b41446d0b3832518b2951738de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (NetRegistry, <a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a>, const std::shared_ptr&lt; const NetDef &gt; &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:ace1716b41446d0b3832518b2951738de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17da1803b0ad6445bc382e34a6ff48f2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17da1803b0ad6445bc382e34a6ff48f2"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>AddGlobalNetObserverCreator</b> (NetObserverCreator creator)</td></tr>
<tr class="separator:a17da1803b0ad6445bc382e34a6ff48f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7a3a7d86cfb55a3cacad61a60a3624a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7a3a7d86cfb55a3cacad61a60a3624a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ClearGlobalNetObservers</b> ()</td></tr>
<tr class="separator:ac7a3a7d86cfb55a3cacad61a60a3624a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3d440e0ce95795f9d5b9f035073195e"><td class="memItemLeft" align="right" valign="top">unique_ptr&lt; <a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ab3d440e0ce95795f9d5b9f035073195e">CreateNet</a> (const NetDef &amp;net_def, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws)</td></tr>
<tr class="memdesc:ab3d440e0ce95795f9d5b9f035073195e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a network, accessing / creating blobs in the given workspace.  <a href="#ab3d440e0ce95795f9d5b9f035073195e">More...</a><br /></td></tr>
<tr class="separator:ab3d440e0ce95795f9d5b9f035073195e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90490e786c45c3a99133eb03885bc675"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90490e786c45c3a99133eb03885bc675"></a>
unique_ptr&lt; <a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>CreateNet</b> (const std::shared_ptr&lt; const NetDef &gt; &amp;net_def, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws)</td></tr>
<tr class="separator:a90490e786c45c3a99133eb03885bc675"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f8de5b6e6dbfea04cd53983bebc0107"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4f8de5b6e6dbfea04cd53983bebc0107"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (NetRegistry, <a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a>, const std::shared_ptr&lt; const NetDef &gt; &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a4f8de5b6e6dbfea04cd53983bebc0107"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3eeaf11e4126984df21e8740299f64c3"><td class="memTemplParams" colspan="2"><a class="anchor" id="a3eeaf11e4126984df21e8740299f64c3"></a>
template&lt;class TaskThreadPoolImpl , int device_type&gt; </td></tr>
<tr class="memitem:a3eeaf11e4126984df21e8740299f64c3"><td class="memTemplItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classc10_1_1_task_thread_pool_base.html">TaskThreadPoolBase</a> &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>GetAsyncNetThreadPool</b> (int device_id, int pool_size, bool create_new)</td></tr>
<tr class="separator:a3eeaf11e4126984df21e8740299f64c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f6bd426853583761f4055254769f34f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f6bd426853583761f4055254769f34f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_NET</b> (async_scheduling, <a class="el" href="classcaffe2_1_1_async_scheduling_net.html">AsyncSchedulingNet</a>)</td></tr>
<tr class="separator:a9f6bd426853583761f4055254769f34f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c631a7cbda335db2136d094f863789e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c631a7cbda335db2136d094f863789e"></a>
std::shared_ptr&lt; <a class="el" href="classcaffe2_1_1_async_task_graph_base.html">AsyncTaskGraphBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetAsyncTaskGraph</b> (<a class="el" href="classcaffe2_1_1_executor_helper.html">ExecutorHelper</a> *helper, const <a class="el" href="structcaffe2_1_1_execution_options.html">ExecutionOptions</a> &amp;options)</td></tr>
<tr class="separator:a9c631a7cbda335db2136d094f863789e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a05d151b3ff4d0bff56f9caeb8f6278"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a05d151b3ff4d0bff56f9caeb8f6278"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_SHARED_REGISTRY</b> (TaskGraphRegistry, <a class="el" href="classcaffe2_1_1_async_task_graph_base.html">AsyncTaskGraphBase</a>, <a class="el" href="classcaffe2_1_1_executor_helper.html">ExecutorHelper</a> *, const <a class="el" href="structcaffe2_1_1_execution_options.html">ExecutionOptions</a> &amp;)</td></tr>
<tr class="separator:a7a05d151b3ff4d0bff56f9caeb8f6278"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32b9ec69f5ac3cffd6b944bd95d7b9ef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32b9ec69f5ac3cffd6b944bd95d7b9ef"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_REGISTER_CREATOR</b> (TaskGraphRegistry, futures, GetAsyncTaskGraph)</td></tr>
<tr class="separator:a32b9ec69f5ac3cffd6b944bd95d7b9ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a093f4e79f2ad471c07249461aed8f7cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a093f4e79f2ad471c07249461aed8f7cb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_NET</b> (parallel, <a class="el" href="classcaffe2_1_1_parallel_net.html">ParallelNet</a>)</td></tr>
<tr class="separator:a093f4e79f2ad471c07249461aed8f7cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6a084f7599671cfb91efce250772393"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6a084f7599671cfb91efce250772393"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_SHARED_REGISTRY</b> (TaskGraphRegistry, <a class="el" href="classcaffe2_1_1_async_task_graph_base.html">AsyncTaskGraphBase</a>, <a class="el" href="classcaffe2_1_1_executor_helper.html">ExecutorHelper</a> *, const <a class="el" href="structcaffe2_1_1_execution_options.html">ExecutionOptions</a> &amp;)</td></tr>
<tr class="separator:aa6a084f7599671cfb91efce250772393"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3fb93ef2d3c7b8c671bb07f042d6be9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3fb93ef2d3c7b8c671bb07f042d6be9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_NET</b> (simple, <a class="el" href="classcaffe2_1_1_simple_net.html">SimpleNet</a>)</td></tr>
<tr class="separator:ad3fb93ef2d3c7b8c671bb07f042d6be9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa820bb9807afe3c208849e406735ca3b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa820bb9807afe3c208849e406735ca3b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_NET</b> (simple_refcount, <a class="el" href="classcaffe2_1_1_simple_ref_count_net.html">SimpleRefCountNet</a>)</td></tr>
<tr class="separator:aa820bb9807afe3c208849e406735ca3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d85e37a2036746f5ec805fcff516115"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6d85e37a2036746f5ec805fcff516115"></a>
const std::string&#160;</td><td class="memItemRight" valign="bottom"><b>OpRegistryKey</b> (const std::string &amp;op_type, const std::string &amp;engine)</td></tr>
<tr class="separator:a6d85e37a2036746f5ec805fcff516115"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82c9d2104c1be00dff8b9038d7ba84b7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a82c9d2104c1be00dff8b9038d7ba84b7"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>SetPerOpEnginePref</b> (const PerOpEnginePrefType &amp;per_op_engine_pref)</td></tr>
<tr class="separator:a82c9d2104c1be00dff8b9038d7ba84b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a163d0b12a664ef508076b9184e62192b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a163d0b12a664ef508076b9184e62192b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>SetGlobalEnginePref</b> (const GlobalEnginePrefType &amp;global_engine_pref)</td></tr>
<tr class="separator:a163d0b12a664ef508076b9184e62192b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69c90352291c965850b37d6281112227"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a69c90352291c965850b37d6281112227"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>SetEnginePref</b> (const PerOpEnginePrefType &amp;per_op_engine_pref, const GlobalEnginePrefType &amp;global_engine_pref)</td></tr>
<tr class="separator:a69c90352291c965850b37d6281112227"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a558504267ef5a8dc99cd59e167cd0613"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a558504267ef5a8dc99cd59e167cd0613"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>SetOpEnginePref</b> (const std::string &amp;op_type, const CaffeMap&lt; DeviceType, EnginePrefType &gt; &amp;op_pref)</td></tr>
<tr class="separator:a558504267ef5a8dc99cd59e167cd0613"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9aa463184e2581a3865e3c5774fb297f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9aa463184e2581a3865e3c5774fb297f"></a>
unique_ptr&lt; <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>CreateOperator</b> (const OperatorDef &amp;operator_def, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws, int net_position)</td></tr>
<tr class="separator:a9aa463184e2581a3865e3c5774fb297f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0ca4477b5bc49a5433be796a3325293"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad0ca4477b5bc49a5433be796a3325293"></a>
std::map&lt; DeviceType, OperatorRegistry * &gt; *&#160;</td><td class="memItemRight" valign="bottom"><b>gDeviceTypeRegistry</b> ()</td></tr>
<tr class="separator:ad0ca4477b5bc49a5433be796a3325293"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1841e10774b05e72dfeb49843848f23"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa1841e10774b05e72dfeb49843848f23"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (CPUOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:aa1841e10774b05e72dfeb49843848f23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc3c1d0992637550f25e1ce9dade316d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc3c1d0992637550f25e1ce9dade316d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_REGISTER_DEVICE_TYPE</b> (CPU, CPUOperatorRegistry)</td></tr>
<tr class="separator:adc3c1d0992637550f25e1ce9dade316d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7041fa48736d62ee29e7635c84aec272"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7041fa48736d62ee29e7635c84aec272"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (CUDAOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a7041fa48736d62ee29e7635c84aec272"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20221162ba6dcbaa50bb6fa0616f8008"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a20221162ba6dcbaa50bb6fa0616f8008"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_REGISTER_DEVICE_TYPE</b> (CUDA, CUDAOperatorRegistry)</td></tr>
<tr class="separator:a20221162ba6dcbaa50bb6fa0616f8008"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9d9446185a94d58c0d46b876226cc0d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab9d9446185a94d58c0d46b876226cc0d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (HIPOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:ab9d9446185a94d58c0d46b876226cc0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35dd5c088680f020bff832d66b76c6a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35dd5c088680f020bff832d66b76c6a5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_REGISTER_DEVICE_TYPE</b> (HIP, HIPOperatorRegistry)</td></tr>
<tr class="separator:a35dd5c088680f020bff832d66b76c6a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add18b15eac4184cff83833c801ba6876"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="add18b15eac4184cff83833c801ba6876"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (GradientRegistry, <a class="el" href="classcaffe2_1_1_gradient_maker_base.html">GradientMakerBase</a>, const OperatorDef &amp;, const vector&lt; <a class="el" href="structcaffe2_1_1_gradient_wrapper.html">GradientWrapper</a> &gt; &amp;)</td></tr>
<tr class="separator:add18b15eac4184cff83833c801ba6876"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4823cf2fe6782d10ef7cfdd1441a4dbb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4823cf2fe6782d10ef7cfdd1441a4dbb"></a>
<a class="el" href="structcaffe2_1_1_gradient_ops_meta.html">GradientOpsMeta</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a4823cf2fe6782d10ef7cfdd1441a4dbb">GetGradientForOp</a> (const OperatorDef &amp;def, const vector&lt; <a class="el" href="structcaffe2_1_1_gradient_wrapper.html">GradientWrapper</a> &gt; &amp;g_output)</td></tr>
<tr class="memdesc:a4823cf2fe6782d10ef7cfdd1441a4dbb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the <a class="el" href="structcaffe2_1_1_gradient_ops_meta.html" title="A struct that holds the gradient operators and related gradient maps. ">GradientOpsMeta</a> for the given operator def. <br /></td></tr>
<tr class="separator:a4823cf2fe6782d10ef7cfdd1441a4dbb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaca9f13aaaedf8d41d7675f374a830da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaca9f13aaaedf8d41d7675f374a830da"></a>
TensorShapes&#160;</td><td class="memItemRight" valign="bottom"><b>InferBlobShapesAndTypes</b> (CaffeMap&lt; string, TensorShape &gt; &amp;blob_desc, const vector&lt; NetDef * &gt; &amp;nets)</td></tr>
<tr class="separator:aaca9f13aaaedf8d41d7675f374a830da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6be6a78bc5045c7a9c24c92b722df5f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac6be6a78bc5045c7a9c24c92b722df5f"></a>
TensorShape&#160;</td><td class="memItemRight" valign="bottom"><b>GetTensorShapeOfBlob</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *b)</td></tr>
<tr class="separator:ac6be6a78bc5045c7a9c24c92b722df5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae291249247b3103f37d40e87262f5f3b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae291249247b3103f37d40e87262f5f3b"></a>
TensorShapes&#160;</td><td class="memItemRight" valign="bottom"><b>InferBlobShapesAndTypesFromWorkspace</b> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws, const vector&lt; NetDef * &gt; &amp;nets)</td></tr>
<tr class="separator:ae291249247b3103f37d40e87262f5f3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3108f2e2527d5150102819d0525503a3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3108f2e2527d5150102819d0525503a3"></a>
TensorShapes&#160;</td><td class="memItemRight" valign="bottom"><b>InferBlobShapesAndTypesFromMap</b> (const CaffeMap&lt; std::string, std::vector&lt; int64_t &gt;&gt; &amp;blob_dimensions, const vector&lt; NetDef * &gt; &amp;nets)</td></tr>
<tr class="separator:a3108f2e2527d5150102819d0525503a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9883a46e41682c730f1b25d4f244d540"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9883a46e41682c730f1b25d4f244d540"></a>
TensorShapes&#160;</td><td class="memItemRight" valign="bottom"><b>InferBlobShapesAndTypesFromMap</b> (const CaffeMap&lt; std::string, std::vector&lt; int64_t &gt;&gt; &amp;blob_dimensions, const CaffeMap&lt; std::string, TensorProto_DataType &gt; &amp;blob_types, const vector&lt; NetDef * &gt; &amp;nets)</td></tr>
<tr class="separator:a9883a46e41682c730f1b25d4f244d540"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7b2a749162faa1174eb81793ddb8db7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab7b2a749162faa1174eb81793ddb8db7"></a>
std::map&lt; string, std::pair&lt; DeviceOption, DeviceOption &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>ValidateTensorDevices</b> (<a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a> &amp;op, const OperatorDef &amp;op_def)</td></tr>
<tr class="separator:ab7b2a749162faa1174eb81793ddb8db7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46008c81871e1134a88f619f1e27382e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46008c81871e1134a88f619f1e27382e"></a>
std::set&lt; std::string &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetRegisteredOperators</b> ()</td></tr>
<tr class="separator:a46008c81871e1134a88f619f1e27382e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae05cfdd8cfc346e951216d9b4926fd69"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae05cfdd8cfc346e951216d9b4926fd69"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>SetOperatorLogger</b> (std::function&lt; void(const OperatorDef &amp;)&gt; tracer)</td></tr>
<tr class="separator:ae05cfdd8cfc346e951216d9b4926fd69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0689f1461c549e57d526c5ee85345262"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0689f1461c549e57d526c5ee85345262"></a>
std::function&lt; void(const OperatorDef &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetOperatorLogger</b> ()</td></tr>
<tr class="separator:a0689f1461c549e57d526c5ee85345262"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a080eb79be544a014315349cc2c9fc1eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a080eb79be544a014315349cc2c9fc1eb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_TENSOR_TYPES_DISPATCHER</b> (<a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>, DoRunWithType, DoRunWithOtherType) C10_DEFINE_TENSOR_TYPES_DISPATCHER(<a class="el" href="structcaffe2_1_1_tensor_types2.html">TensorTypes2</a></td></tr>
<tr class="separator:a080eb79be544a014315349cc2c9fc1eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36a861566bb1fad8fb25709f28a527a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a36a861566bb1fad8fb25709f28a527a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (CPUOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a36a861566bb1fad8fb25709f28a527a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c1ab98fc48948e05e31154ecf0ddb31"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2c1ab98fc48948e05e31154ecf0ddb31"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (CUDAOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a2c1ab98fc48948e05e31154ecf0ddb31"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a623a668f86beda148316a93d8f67d87b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a623a668f86beda148316a93d8f67d87b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (HIPOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a623a668f86beda148316a93d8f67d87b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd276a7e84d2e2fce98e81be935f8a4d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd276a7e84d2e2fce98e81be935f8a4d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (C10OperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:acd276a7e84d2e2fce98e81be935f8a4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8fc8e3e86c32a4c290654ca40efe53e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af8fc8e3e86c32a4c290654ca40efe53e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (GradientRegistry, <a class="el" href="classcaffe2_1_1_gradient_maker_base.html">GradientMakerBase</a>, const OperatorDef &amp;, const vector&lt; <a class="el" href="structcaffe2_1_1_gradient_wrapper.html">GradientWrapper</a> &gt; &amp;)</td></tr>
<tr class="separator:af8fc8e3e86c32a4c290654ca40efe53e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af10ac2d0704345248ba54fedfcfaf210"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af10ac2d0704345248ba54fedfcfaf210"></a>
C10_EXPORT std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>operator&lt;&lt;</b> (std::ostream &amp;out, const <a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;schema)</td></tr>
<tr class="separator:af10ac2d0704345248ba54fedfcfaf210"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adff64e1d73f88f95e8d87c5284d06138"><td class="memTemplParams" colspan="2"><a class="anchor" id="adff64e1d73f88f95e8d87c5284d06138"></a>
template&lt;typename T_I  = int&gt; </td></tr>
<tr class="memitem:adff64e1d73f88f95e8d87c5284d06138"><td class="memTemplItemLeft" align="right" valign="top">TensorShape&#160;</td><td class="memTemplItemRight" valign="bottom"><b>CreateTensorShape</b> (vector&lt; T_I &gt; dims,::caffe2::TensorProto_DataType dt)</td></tr>
<tr class="separator:adff64e1d73f88f95e8d87c5284d06138"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f867b9c22d32e6a7091cfce327fda06"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f867b9c22d32e6a7091cfce327fda06"></a>
vector&lt; int64_t &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetDimsVector</b> (const TensorShape &amp;shape)</td></tr>
<tr class="separator:a7f867b9c22d32e6a7091cfce327fda06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d1caf60d443c3a10e6a66a445f2d1ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d1caf60d443c3a10e6a66a445f2d1ed"></a>
uint64_t&#160;</td><td class="memItemRight" valign="bottom"><b>nElemFromDim</b> (const TensorShape &amp;X, int dim=0)</td></tr>
<tr class="separator:a9d1caf60d443c3a10e6a66a445f2d1ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac38f66736f42804ae6783c6f56c1b998"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac38f66736f42804ae6783c6f56c1b998"></a>
uint64_t&#160;</td><td class="memItemRight" valign="bottom"><b>nElemBetweenDim</b> (const TensorShape &amp;X, int start, int stop)</td></tr>
<tr class="separator:ac38f66736f42804ae6783c6f56c1b998"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6e0910770fec5599962a43c497111c0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6e0910770fec5599962a43c497111c0"></a>
std::pair&lt; std::vector&lt; DeviceOption &gt;, std::vector&lt; DeviceOption &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>InferOpInputOutputDevice</b> (const OperatorDef &amp;op)</td></tr>
<tr class="separator:aa6e0910770fec5599962a43c497111c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411bcb87b2fa7b8e4f543076adf911cf"><td class="memTemplParams" colspan="2"><a class="anchor" id="a411bcb87b2fa7b8e4f543076adf911cf"></a>
template&lt;uint64_t OpsPerPoint&gt; </td></tr>
<tr class="memitem:a411bcb87b2fa7b8e4f543076adf911cf"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>PointwiseCostInference</b> (const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;inputs)</td></tr>
<tr class="separator:a411bcb87b2fa7b8e4f543076adf911cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5a8b5bc38099521c1af0be567ce1b1e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae5a8b5bc38099521c1af0be567ce1b1e"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>RunPlanOnWorkspace</b> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws, const PlanDef &amp;plan, ShouldContinue shouldContinue)</td></tr>
<tr class="separator:ae5a8b5bc38099521c1af0be567ce1b1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a688ad3249e176dfbae42646227a62e80"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a688ad3249e176dfbae42646227a62e80"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="classcaffe2_1_1_q_tensor.html">QTensor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a688ad3249e176dfbae42646227a62e80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ca6146615d44e0893a020304848c3d1"><td class="memTemplParams" colspan="2">template&lt;typename F &gt; </td></tr>
<tr class="memitem:a0ca6146615d44e0893a020304848c3d1"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcaffe2_1_1detail_1_1_scope_guard_impl.html">detail::ScopeGuardImplDecay</a>&lt; F &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a0ca6146615d44e0893a020304848c3d1">MakeGuard</a> (F &amp;&amp;f) noexcept(noexcept(<a class="el" href="classcaffe2_1_1detail_1_1_scope_guard_impl.html">detail::ScopeGuardImplDecay</a>&lt; F &gt;(static_cast&lt; F &amp;&amp; &gt;(f))))</td></tr>
<tr class="memdesc:a0ca6146615d44e0893a020304848c3d1"><td class="mdescLeft">&#160;</td><td class="mdescRight">ScopeGuard is a general implementation of the "Initialization is
Resource Acquisition" idiom.  <a href="#a0ca6146615d44e0893a020304848c3d1">More...</a><br /></td></tr>
<tr class="separator:a0ca6146615d44e0893a020304848c3d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac70331d1363e6a4ee109d17cc48c802d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac70331d1363e6a4ee109d17cc48c802d"></a>
ExportedStatMap&#160;</td><td class="memItemRight" valign="bottom"><b>toMap</b> (const <a class="el" href="namespacecaffe2.html#a8eb1578901c4027246db0d3e46305c7f">ExportedStatList</a> &amp;stats)</td></tr>
<tr class="separator:ac70331d1363e6a4ee109d17cc48c802d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee9fb51e2d25a800b2af2212c785320e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aee9fb51e2d25a800b2af2212c785320e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE</b> (12, <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>)</td></tr>
<tr class="separator:aee9fb51e2d25a800b2af2212c785320e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef2288f9d781f3a8c6eb11bbe097114f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef2288f9d781f3a8c6eb11bbe097114f"></a>
<a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a>&#160;</td><td class="memItemRight" valign="bottom"><b>GetTensorType</b> (const void *c)</td></tr>
<tr class="separator:aef2288f9d781f3a8c6eb11bbe097114f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25f3acc97702d52e5725e9a391b07036"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a25f3acc97702d52e5725e9a391b07036"></a>
TypeCall&#160;</td><td class="memItemRight" valign="bottom"><b>GetTypeCallFunction</b> (<a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a> id)</td></tr>
<tr class="separator:a25f3acc97702d52e5725e9a391b07036"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a308f6d08fa8cf96bc05a895c5bdbeae2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a308f6d08fa8cf96bc05a895c5bdbeae2"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>RegisterTypeCallFunction</b> (<a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a> id, TypeCall c)</td></tr>
<tr class="separator:a308f6d08fa8cf96bc05a895c5bdbeae2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0e3503fc09f09c5bbf026c5369e3ec3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa0e3503fc09f09c5bbf026c5369e3ec3"></a>
vector&lt; int64_t &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetTensorInfo</b> (const void *c, size_t *capacity, DeviceOption *device)</td></tr>
<tr class="separator:aa0e3503fc09f09c5bbf026c5369e3ec3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a508bae2c74a5e16476116fb346516b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a508bae2c74a5e16476116fb346516b"></a>
TensorInfoCall&#160;</td><td class="memItemRight" valign="bottom"><b>GetTensorInfoFunction</b> (<a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a> id)</td></tr>
<tr class="separator:a7a508bae2c74a5e16476116fb346516b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44eef305a74046b612dfa99161b808d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a44eef305a74046b612dfa99161b808d2"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>RegisterTensorInfoFunction</b> (<a class="el" href="classcaffe2_1_1_type_identifier.html">TypeIdentifier</a> id, TensorInfoCall c)</td></tr>
<tr class="separator:a44eef305a74046b612dfa99161b808d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5aa3ebbe2ae326c2822f889980c8b8f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5aa3ebbe2ae326c2822f889980c8b8f3"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>TensorVectorResize</b> (std::vector&lt; <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &gt; &amp;tensors, int size, DeviceType type)</td></tr>
<tr class="separator:a5aa3ebbe2ae326c2822f889980c8b8f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e164750f0ff0f085fb9eca538782fea"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e164750f0ff0f085fb9eca538782fea"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>empty</b> (<a class="el" href="classc10_1_1_array_ref.html">at::IntArrayRef</a> dims, <a class="el" href="structc10_1_1_tensor_options.html">at::TensorOptions</a> options)</td></tr>
<tr class="separator:a6e164750f0ff0f085fb9eca538782fea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a205fa6454dda2075530dbd2de4eab70f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a205fa6454dda2075530dbd2de4eab70f"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a205fa6454dda2075530dbd2de4eab70f">ReinitializeTensor</a> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *t, <a class="el" href="classc10_1_1_array_ref.html">at::IntArrayRef</a> dims, <a class="el" href="structc10_1_1_tensor_options.html">at::TensorOptions</a> options)</td></tr>
<tr class="memdesc:a205fa6454dda2075530dbd2de4eab70f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reinitialize a <a class="el" href="classcaffe2_1_1_tensor.html" title="Tensor class holds a shared pointer to the implementation TensorImpl, redirects API calls to TensorIm...">Tensor</a> to given dims and options if necessary, note that this will not do anything if the <a class="el" href="classcaffe2_1_1_tensor.html" title="Tensor class holds a shared pointer to the implementation TensorImpl, redirects API calls to TensorIm...">Tensor</a> already has correct size and data type. <br /></td></tr>
<tr class="separator:a205fa6454dda2075530dbd2de4eab70f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d1490d359bf8ae0bf33a3c5d363b0cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6d1490d359bf8ae0bf33a3c5d363b0cd"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ReinitializeAndCopyFrom</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *t, <a class="el" href="structc10_1_1_tensor_options.html">at::TensorOptions</a> options, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;src, bool async)</td></tr>
<tr class="separator:a6d1490d359bf8ae0bf33a3c5d363b0cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4109386aaa76859aba7efd3465d30106"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a4109386aaa76859aba7efd3465d30106"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a4109386aaa76859aba7efd3465d30106">TensorCPUFromValues</a> (<a class="el" href="classc10_1_1_array_ref.html">at::IntArrayRef</a> dims, <a class="el" href="classc10_1_1_array_ref.html">at::ArrayRef</a>&lt; <a class="el" href="struct_t.html">T</a> &gt; values)</td></tr>
<tr class="memdesc:a4109386aaa76859aba7efd3465d30106"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a CPU tensor, and fills its contents with the given values.  <a href="#a4109386aaa76859aba7efd3465d30106">More...</a><br /></td></tr>
<tr class="separator:a4109386aaa76859aba7efd3465d30106"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d09213222c086b369169f0fa6b79514"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6d09213222c086b369169f0fa6b79514"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="structcaffe2_1_1int8_1_1_int8_tensor_c_p_u.html">int8::Int8TensorCPU</a>)</td></tr>
<tr class="separator:a6d09213222c086b369169f0fa6b79514"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42c46c5794404f4a8fb08707f15cc287"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42c46c5794404f4a8fb08707f15cc287"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (TransformRegistry, <a class="el" href="classcaffe2_1_1_transform.html">Transform</a>)</td></tr>
<tr class="separator:a42c46c5794404f4a8fb08707f15cc287"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa52deb1891678bca54c00aa11664add"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa52deb1891678bca54c00aa11664add"></a>
unique_ptr&lt; <a class="el" href="classcaffe2_1_1_transform.html">Transform</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>CreateTransform</b> (string key)</td></tr>
<tr class="separator:aaa52deb1891678bca54c00aa11664add"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a749c301e202be1b393470b4cbab94b67"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a749c301e202be1b393470b4cbab94b67"></a>
NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>ApplyTransform</b> (const string &amp;key, const NetDef &amp;netdef)</td></tr>
<tr class="separator:a749c301e202be1b393470b4cbab94b67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20f7e2a2d404e67e6fdc0ce986dd0d48"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a20f7e2a2d404e67e6fdc0ce986dd0d48"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><b>average_net_run_duration</b> (const NetDef &amp;netdef, const NetDef &amp;init_netdef, const int warmup_runs, const int main_runs)</td></tr>
<tr class="separator:a20f7e2a2d404e67e6fdc0ce986dd0d48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6de5fc08295c23fbb939cae2767e553e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6de5fc08295c23fbb939cae2767e553e"></a>
NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>ApplyTransformIfFaster</b> (const string &amp;key, const NetDef &amp;netdef, const NetDef &amp;init_netdef, const int warmup_runs, const int main_runs, const double improvement_threshold)</td></tr>
<tr class="separator:a6de5fc08295c23fbb939cae2767e553e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47c1fbf2331cd541baad687c9e9092b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a47c1fbf2331cd541baad687c9e9092b2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (TransformRegistry, <a class="el" href="classcaffe2_1_1_transform.html">Transform</a>)</td></tr>
<tr class="separator:a47c1fbf2331cd541baad687c9e9092b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a756678db7464e80becf4592c1b0edded"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a756678db7464e80becf4592c1b0edded"></a>
TensorProto::DataType&#160;</td><td class="memItemRight" valign="bottom"><b>TypeMetaToDataType</b> (const <a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a> &amp;meta)</td></tr>
<tr class="separator:a756678db7464e80becf4592c1b0edded"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabde1d86cc84653719db9cd37646b1c8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabde1d86cc84653719db9cd37646b1c8"></a>
const <a class="el" href="classcaffe2_1_1_type_meta.html">TypeMeta</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>DataTypeToTypeMeta</b> (const TensorProto::DataType &amp;dt)</td></tr>
<tr class="separator:aabde1d86cc84653719db9cd37646b1c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86bbd44760a61e661c53c6cdaa7baf6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86bbd44760a61e661c53c6cdaa7baf6d"></a>
StorageOrder&#160;</td><td class="memItemRight" valign="bottom"><b>StringToStorageOrder</b> (const string &amp;str)</td></tr>
<tr class="separator:a86bbd44760a61e661c53c6cdaa7baf6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae297cfca76b377a990a2a4bff4795150"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae297cfca76b377a990a2a4bff4795150"></a>
constexpr char&#160;</td><td class="memItemRight" valign="bottom"><b>NameScopeSeparator</b> ()</td></tr>
<tr class="separator:ae297cfca76b377a990a2a4bff4795150"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb1492d6608aa1f2b649828d333a6910"><td class="memTemplParams" colspan="2"><a class="anchor" id="afb1492d6608aa1f2b649828d333a6910"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:afb1492d6608aa1f2b649828d333a6910"><td class="memTemplItemLeft" align="right" valign="top">bool&#160;</td><td class="memTemplItemRight" valign="bottom"><b>fp16_type</b> ()</td></tr>
<tr class="separator:afb1492d6608aa1f2b649828d333a6910"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22ef916cfa99eaa7ae1c7f4e6778a7d1"><td class="memTemplParams" colspan="2"><a class="anchor" id="a22ef916cfa99eaa7ae1c7f4e6778a7d1"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a22ef916cfa99eaa7ae1c7f4e6778a7d1"><td class="memTemplItemLeft" align="right" valign="top">bool&#160;</td><td class="memTemplItemRight" valign="bottom"><b>fp16_type&lt; at::Half &gt;</b> ()</td></tr>
<tr class="separator:a22ef916cfa99eaa7ae1c7f4e6778a7d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0306aadcb419780516c195f5b435897c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0306aadcb419780516c195f5b435897c"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><b>GetUniqueName</b> ()</td></tr>
<tr class="separator:a0306aadcb419780516c195f5b435897c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28b557447becfb20d0d39ff544fe9bf0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28b557447becfb20d0d39ff544fe9bf0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CreateDB, <a class="el" href="classcaffe2_1_1_create_d_b_op.html">CreateDBOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a28b557447becfb20d0d39ff544fe9bf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdcc1dfc6eddc86232b2f37132a028d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acdcc1dfc6eddc86232b2f37132a028d0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (CreateDB).NumInputs(0).NumOutputs(1)</td></tr>
<tr class="separator:acdcc1dfc6eddc86232b2f37132a028d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bc2a9a202be73d0b77dfddc91f9d677"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5bc2a9a202be73d0b77dfddc91f9d677"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (CreateDB)</td></tr>
<tr class="separator:a5bc2a9a202be73d0b77dfddc91f9d677"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16173d7eb43a9222a6fddb7f4da601cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a16173d7eb43a9222a6fddb7f4da601cd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CreateDB, <a class="el" href="classcaffe2_1_1_create_d_b_op.html">CreateDBOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a16173d7eb43a9222a6fddb7f4da601cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af76be045297e05130e27811a26458603"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af76be045297e05130e27811a26458603"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FileStoreHandlerCreate, <a class="el" href="classcaffe2_1_1_file_store_handler_create_op.html">FileStoreHandlerCreateOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af76be045297e05130e27811a26458603"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c423cab9613187844b36167c39a8826"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c423cab9613187844b36167c39a8826"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (0).NumOutputs(1).SetDoc(R&quot;DOC( Creates a unique_ptr&lt;<a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a>&gt; that uses the filesystem as backing store (typically a filesystem shared between many nodes</td></tr>
<tr class="separator:a3c423cab9613187844b36167c39a8826"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae379e84b3fcdab738b362c50beb88a89"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae379e84b3fcdab738b362c50beb88a89"></a>
such as NFS This store handler is not built to be fast Its recommended use is for integration tests and prototypes where extra dependencies are cumbersome Use an ephemeral path to ensure multiple processes or runs don t interfere DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;path&quot;,&quot;base path used by the <a class="el" href="classcaffe2_1_1_file_store_handler.html">FileStoreHandler</a>&quot;).Arg(&quot;prefix&quot;</td></tr>
<tr class="separator:ae379e84b3fcdab738b362c50beb88a89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a421cde36113163bbc490570088e1e0f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a421cde36113163bbc490570088e1e0f4"></a>
such as NFS This store handler is not built to be fast Its recommended use is for integration tests and prototypes where extra dependencies are cumbersome Use an ephemeral path to ensure multiple processes or runs don t interfere DOC prefix for all keys used by this store&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;handler&quot;,&quot;unique_ptr&lt;<a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a>&gt;&quot;)</td></tr>
<tr class="separator:a421cde36113163bbc490570088e1e0f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24607d1dba5a15796277e7fe9f50490f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a24607d1dba5a15796277e7fe9f50490f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_file_store_handler_create_op.html">FileStoreHandlerCreateOp</a>)</td></tr>
<tr class="separator:a24607d1dba5a15796277e7fe9f50490f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ea7d9f58907b76a7f6572dd83d7791f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9ea7d9f58907b76a7f6572dd83d7791f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (FileStoreHandlerCreate, <a class="el" href="classcaffe2_1_1_file_store_handler_create_op.html">FileStoreHandlerCreateOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a9ea7d9f58907b76a7f6572dd83d7791f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abdb7f7164de654982fdb560ec12e4520"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abdb7f7164de654982fdb560ec12e4520"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RedisStoreHandlerCreate, <a class="el" href="classcaffe2_1_1_redis_store_handler_create_op.html">RedisStoreHandlerCreateOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:abdb7f7164de654982fdb560ec12e4520"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3e30dfbbc07178061a2ccecae695faa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae3e30dfbbc07178061a2ccecae695faa"></a>
host name of Redis server&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;port&quot;,&quot;port number of Redis server&quot;).Arg(&quot;prefix&quot;</td></tr>
<tr class="separator:ae3e30dfbbc07178061a2ccecae695faa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51a8dd644c361881494e3250228459e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a51a8dd644c361881494e3250228459e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_redis_store_handler_create_op.html">RedisStoreHandlerCreateOp</a>)</td></tr>
<tr class="separator:a51a8dd644c361881494e3250228459e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc556e15840343912103bdcd7554f921"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc556e15840343912103bdcd7554f921"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (RedisStoreHandlerCreate, <a class="el" href="classcaffe2_1_1_redis_store_handler_create_op.html">RedisStoreHandlerCreateOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:abc556e15840343912103bdcd7554f921"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01323d7c66e4cd79858fe8baf05b95a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01323d7c66e4cd79858fe8baf05b95a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a> &gt;)</td></tr>
<tr class="separator:a01323d7c66e4cd79858fe8baf05b95a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16b16134e5567469a265c9b9502ecc6c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a16b16134e5567469a265c9b9502ecc6c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StoreSet, <a class="el" href="classcaffe2_1_1_store_set_op.html">StoreSetOp</a>)</td></tr>
<tr class="separator:a16b16134e5567469a265c9b9502ecc6c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4e7d08c6d6bb46706f9a0b23bed317e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac4e7d08c6d6bb46706f9a0b23bed317e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (2).NumOutputs(0).SetDoc(R&quot;DOC( Set a blob in a store. The key is the input blob's name and the value is the data in that blob. The key can be overridden by specifying the 'blob_name' argument. )DOC&quot;).Arg(&quot;blob_name&quot; = Ai * Bi</td></tr>
<tr class="separator:ac4e7d08c6d6bb46706f9a0b23bed317e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6cd5402bcae1f749878299a2f151ca4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac6cd5402bcae1f749878299a2f151ca4"></a>
alternative key for the&#160;</td><td class="memItemRight" valign="bottom"><b>blob</b> (<a class="el" href="classc10_1_1optional.html">optional</a>)&quot;) .Input(0</td></tr>
<tr class="separator:ac6cd5402bcae1f749878299a2f151ca4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11abbdffde28097c12f0f3f0219fa4cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a11abbdffde28097c12f0f3f0219fa4cf"></a>
alternative key for the unique_ptr&lt; <a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;data&quot;,&quot;data blob&quot;)</td></tr>
<tr class="separator:a11abbdffde28097c12f0f3f0219fa4cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba6b861e79f3fcd9f7d74f15fd6e9a01"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aba6b861e79f3fcd9f7d74f15fd6e9a01"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StoreGet, <a class="el" href="classcaffe2_1_1_store_get_op.html">StoreGetOp</a>)</td></tr>
<tr class="separator:aba6b861e79f3fcd9f7d74f15fd6e9a01"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa22f1d78ea2217ed0f39d7fbc8e32097"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa22f1d78ea2217ed0f39d7fbc8e32097"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (1).NumOutputs(1).SetDoc(R&quot;DOC( Get a blob from a store. The key is the output blob's name. The key can be overridden by specifying the 'blob_name' argument. )DOC&quot;).Arg(&quot;blob_name&quot;</td></tr>
<tr class="separator:aa22f1d78ea2217ed0f39d7fbc8e32097"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc93be35c9a6501b24702fb1244ade69"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acc93be35c9a6501b24702fb1244ade69"></a>
alternative key for the unique_ptr&lt; <a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;data&quot;,&quot;data blob&quot;)</td></tr>
<tr class="separator:acc93be35c9a6501b24702fb1244ade69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c8b8e7e21d84dd25c023dec167d81dd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7c8b8e7e21d84dd25c023dec167d81dd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StoreAdd, <a class="el" href="classcaffe2_1_1_store_add_op.html">StoreAddOp</a>)</td></tr>
<tr class="separator:a7c8b8e7e21d84dd25c023dec167d81dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d16e214b8d0cdce86eb0f4d0e144d58"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d16e214b8d0cdce86eb0f4d0e144d58"></a>
the store initializes it to and then performs the add operation The operation returns the resulting counter value DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;blob_name&quot;,&quot;key of the counter (required)&quot;).Arg(&quot;add_value&quot;</td></tr>
<tr class="separator:a7d16e214b8d0cdce86eb0f4d0e144d58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68207b990da32191700d23970ce4f3f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a68207b990da32191700d23970ce4f3f6"></a>
the store initializes it to and then performs the add operation The operation returns the resulting counter value DOC value that is&#160;</td><td class="memItemRight" valign="bottom"><b>added</b> (<a class="el" href="classc10_1_1optional.html">optional</a>, default:1)&quot;) .Input(0</td></tr>
<tr class="separator:a68207b990da32191700d23970ce4f3f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d408f06a5859408823a620efeb620a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d408f06a5859408823a620efeb620a0"></a>
the store initializes it to and then performs the add operation The operation returns the resulting counter value DOC value that is unique_ptr&lt; <a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;value&quot;,&quot;the current value of the counter&quot;)</td></tr>
<tr class="separator:a7d408f06a5859408823a620efeb620a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abeab0bd265fa66d0e05d7655cb8906ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abeab0bd265fa66d0e05d7655cb8906ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StoreWait, <a class="el" href="classcaffe2_1_1_store_wait_op.html">StoreWaitOp</a>)</td></tr>
<tr class="separator:abeab0bd265fa66d0e05d7655cb8906ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cc5fb2cd658d554bec156620367ea85"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0cc5fb2cd658d554bec156620367ea85"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (1, 2).NumOutputs(0).SetDoc(R&quot;DOC( Wait for the specified blob names to be set. The blob names can be passed either as an input blob with blob names or as an argument. )DOC&quot;).Arg(&quot;blob_names&quot;</td></tr>
<tr class="separator:a0cc5fb2cd658d554bec156620367ea85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24287b57b151acb2377d03fe2e3fa277"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a24287b57b151acb2377d03fe2e3fa277"></a>
names of the blobs to wait&#160;</td><td class="memItemRight" valign="bottom"><b>for</b> (<a class="el" href="classc10_1_1optional.html">optional</a>)&quot;) .Input(0</td></tr>
<tr class="separator:a24287b57b151acb2377d03fe2e3fa277"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff958ac079c49c5000ddab94348778e7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff958ac079c49c5000ddab94348778e7"></a>
names of the blobs to wait unique_ptr&lt; <a class="el" href="classcaffe2_1_1_store_handler.html">StoreHandler</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;names&quot;,&quot;names of the blobs to wait for (<a class="el" href="classc10_1_1optional.html">optional</a>)&quot;)</td></tr>
<tr class="separator:aff958ac079c49c5000ddab94348778e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a5fff4d0d6ba530c8ea01d6fde5fc25"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a5fff4d0d6ba530c8ea01d6fde5fc25"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FC_Decomp, <a class="el" href="classcaffe2_1_1_fully_connected_op_decomp.html">FullyConnectedOpDecomp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0a5fff4d0d6ba530c8ea01d6fde5fc25"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a911bf3beaf2f596dcc1ca5967f7475e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a911bf3beaf2f596dcc1ca5967f7475e1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FCGradient_Decomp, <a class="el" href="classcaffe2_1_1_fully_connected_decomp_gradient_op.html">FullyConnectedDecompGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a911bf3beaf2f596dcc1ca5967f7475e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6df82fe1d8375465476614a523cfea82"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6df82fe1d8375465476614a523cfea82"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (FC_Decomp).NumInputs(4).NumOutputs(1)</td></tr>
<tr class="separator:a6df82fe1d8375465476614a523cfea82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65f43040b9fb5df046e5f903083cfc03"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a65f43040b9fb5df046e5f903083cfc03"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (FCGradient_Decomp).NumInputs(4).NumOutputs(3</td></tr>
<tr class="separator:a65f43040b9fb5df046e5f903083cfc03"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a906e13e62402b32f21970ef8eb411544"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a906e13e62402b32f21970ef8eb411544"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (FC_Decomp, <a class="el" href="classcaffe2_1_1_get_f_c_decomp_gradient.html">GetFCDecompGradient</a>)</td></tr>
<tr class="separator:a906e13e62402b32f21970ef8eb411544"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75d7a26f4a4525a258e2d4f64242d694"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75d7a26f4a4525a258e2d4f64242d694"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (FC_Decomp, <a class="el" href="classcaffe2_1_1_fully_connected_op_decomp.html">FullyConnectedOpDecomp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a75d7a26f4a4525a258e2d4f64242d694"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedf49694959b5633212aa434c41b5649"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aedf49694959b5633212aa434c41b5649"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (FCGradient_Decomp, <a class="el" href="classcaffe2_1_1_fully_connected_decomp_gradient_op.html">FullyConnectedDecompGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aedf49694959b5633212aa434c41b5649"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d2a8f898a7f3db2661f2488368a171b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d2a8f898a7f3db2661f2488368a171b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TTContraction, <a class="el" href="classcaffe2_1_1_t_t_contraction_op.html">TTContractionOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1d2a8f898a7f3db2661f2488368a171b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19f61fa72acba74a260f314be17b09a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a19f61fa72acba74a260f314be17b09a5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (TTContraction, <a class="el" href="classcaffe2_1_1_t_t_contraction_op.html">TTContractionOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a19f61fa72acba74a260f314be17b09a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9af3ee2be947562ddcd01e0b3441548"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae9af3ee2be947562ddcd01e0b3441548"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (TTContractionGradient, <a class="el" href="classcaffe2_1_1_t_t_contraction_gradient_op.html">TTContractionGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ae9af3ee2be947562ddcd01e0b3441548"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32a19d7f3783aaf97d468958f8c26969"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32a19d7f3783aaf97d468958f8c26969"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adam_ideep_update</b> (int N, const float *g, const float *m, const float *v, float *ng, float *nm, float *nv, float beta1, float beta2, float eps_hat, float correction, const float *lr)</td></tr>
<tr class="separator:a32a19d7f3783aaf97d468958f8c26969"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaea78aa98b9d55ea7a114385a6b1dc16"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaea78aa98b9d55ea7a114385a6b1dc16"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adam_ideep_compute</b> (int N, const float *w, const float *g, const float *m, const float *v, float *nw, float *nm, float *nv, float beta1, float beta2, float eps_hat, float correction, const float *lr)</td></tr>
<tr class="separator:aaea78aa98b9d55ea7a114385a6b1dc16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8412f169aa56eeb6cd8fa1c8b3023021"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8412f169aa56eeb6cd8fa1c8b3023021"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adam_ideep_compute_output_grad</b> (int N, const float *w, const float *g, const float *m, const float *v, float *nw, float *nm, float *nv, float *ng, float beta1, float beta2, float eps_hat, float correction, const float *lr)</td></tr>
<tr class="separator:a8412f169aa56eeb6cd8fa1c8b3023021"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3033eb4a9491f9f242b04b6081fed6b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3033eb4a9491f9f242b04b6081fed6b2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Adam, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_adam_op.html">IDEEPAdamOp</a>&lt; float &gt;)</td></tr>
<tr class="separator:a3033eb4a9491f9f242b04b6081fed6b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91cef66778324b710da5dd928e880ede"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a91cef66778324b710da5dd928e880ede"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_channel_shuffle.html">ChannelShuffle</a>, <a class="el" href="classcaffe2_1_1_channel_shuffle_op.html">ChannelShuffleOp</a>)</td></tr>
<tr class="separator:a91cef66778324b710da5dd928e880ede"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ee0b66022100cd99ab83ee0f52491cc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0ee0b66022100cd99ab83ee0f52491cc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ChannelShuffleGradient, <a class="el" href="classcaffe2_1_1_channel_shuffle_gradient_op.html">ChannelShuffleGradientOp</a>)</td></tr>
<tr class="separator:a0ee0b66022100cd99ab83ee0f52491cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a685dc1b710864b1959ceddb7a2820d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a685dc1b710864b1959ceddb7a2820d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_concat.html">Concat</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_concat_op.html">IDEEPConcatOp</a>)</td></tr>
<tr class="separator:a5a685dc1b710864b1959ceddb7a2820d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab76cf57f5f96319a4b33c1206f0ecf2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab76cf57f5f96319a4b33c1206f0ecf2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Split, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_split_op.html">IDEEPSplitOp</a>)</td></tr>
<tr class="separator:ab76cf57f5f96319a4b33c1206f0ecf2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ee1413a23ab6506744bc911717aaa79"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1ee1413a23ab6506744bc911717aaa79"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ConvFusion, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_fusion_op.html">IDEEPConvFusionOp</a>)</td></tr>
<tr class="separator:a1ee1413a23ab6506744bc911717aaa79"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a475492b2a376db26c4ef15bb725c24c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a475492b2a376db26c4ef15bb725c24c7"></a>
std::function&lt; void(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>ConvFusionDocGenerator</b> (const char *dim)</td></tr>
<tr class="separator:a475492b2a376db26c4ef15bb725c24c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28b47d44b1802f5125a23986c6283890"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28b47d44b1802f5125a23986c6283890"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_conv.html">Conv</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_op.html">IDEEPConvOp</a>)</td></tr>
<tr class="separator:a28b47d44b1802f5125a23986c6283890"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45b80f617a6b35e9d89d9d438d3a4e43"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a45b80f617a6b35e9d89d9d438d3a4e43"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ConvGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_gradient_op.html">IDEEPConvGradientOp</a>)</td></tr>
<tr class="separator:a45b80f617a6b35e9d89d9d438d3a4e43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5691addcc12659b2194f015910822ab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad5691addcc12659b2194f015910822ab"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_conv_transpose.html">ConvTranspose</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_transpose_op.html">IDEEPConvTransposeOp</a>)</td></tr>
<tr class="separator:ad5691addcc12659b2194f015910822ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a607895093aacdcfe10c51cc5108181f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a607895093aacdcfe10c51cc5108181f0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ConvTransposeGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_conv_transpose_gradient_op.html">IDEEPConvTransposeGradientOp</a>)</td></tr>
<tr class="separator:a607895093aacdcfe10c51cc5108181f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a677eabbafb13e5a83b3c04fbcb873ce4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a677eabbafb13e5a83b3c04fbcb873ce4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Dropout, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_dropout_op.html">IDEEPDropoutOp</a>)</td></tr>
<tr class="separator:a677eabbafb13e5a83b3c04fbcb873ce4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a588cc040f6706ceb8f24c746484a05ab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a588cc040f6706ceb8f24c746484a05ab"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (DropoutGrad, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_dropout_gradient_op.html">IDEEPDropoutGradientOp</a>)</td></tr>
<tr class="separator:a588cc040f6706ceb8f24c746484a05ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7cf8c08461b59f433ace3a48b834841"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa7cf8c08461b59f433ace3a48b834841"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_sum.html">Sum</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_sum_op.html">IDEEPSumOp</a>)</td></tr>
<tr class="separator:aa7cf8c08461b59f433ace3a48b834841"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fb27385a0847f8933d6bbcee1ad88a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3fb27385a0847f8933d6bbcee1ad88a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_add.html">Add</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_sum_op.html">IDEEPSumOp</a>)</td></tr>
<tr class="separator:a3fb27385a0847f8933d6bbcee1ad88a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab460128357af583786655a7b2e485141"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab460128357af583786655a7b2e485141"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ExpandDims, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_expand_dims_op.html">IDEEPExpandDimsOp</a>)</td></tr>
<tr class="separator:ab460128357af583786655a7b2e485141"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fad739b2f0dc83db770a133f2ff29e3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3fad739b2f0dc83db770a133f2ff29e3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Squeeze, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_squeeze_op.html">IDEEPSqueezeOp</a>)</td></tr>
<tr class="separator:a3fad739b2f0dc83db770a133f2ff29e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae34d77eb43e04bf1a588b408317409ba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae34d77eb43e04bf1a588b408317409ba"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>USE_IDEEP_DEF_ALIASES</b> ()</td></tr>
<tr class="separator:ae34d77eb43e04bf1a588b408317409ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a1bcadd8c84cff55e54c38496bdfc4b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2a1bcadd8c84cff55e54c38496bdfc4b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_f_c.html">FC</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fully_connected_op.html">IDEEPFullyConnectedOp</a>)</td></tr>
<tr class="separator:a2a1bcadd8c84cff55e54c38496bdfc4b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6936fca594d07ac8da165e3061e3ee0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6936fca594d07ac8da165e3061e3ee0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (FCGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fully_connected_gradient_op.html">IDEEPFullyConnectedGradientOp</a>)</td></tr>
<tr class="separator:ae6936fca594d07ac8da165e3061e3ee0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0d96e5a1fb94475786bf3742aa04d24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa0d96e5a1fb94475786bf3742aa04d24"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (LRN, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_l_r_n_op.html">IDEEPLRNOp</a>)</td></tr>
<tr class="separator:aa0d96e5a1fb94475786bf3742aa04d24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24500a4b91540612480eacace2fe5e43"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a24500a4b91540612480eacace2fe5e43"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (LRNGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_l_r_n_gradient_op.html">IDEEPLRNGradientOp</a>)</td></tr>
<tr class="separator:a24500a4b91540612480eacace2fe5e43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5123da437fa33506052bbe171ad6fc2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5123da437fa33506052bbe171ad6fc2c"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>momentum_sgd_update</b> (const int N, const float *g, const float *m, float *ng, float *nm, const float *lr, const float momentum, const bool nesterov, float *param)</td></tr>
<tr class="separator:a5123da437fa33506052bbe171ad6fc2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8e36a442fc006e7882b5283b6faf0b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af8e36a442fc006e7882b5283b6faf0b6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (MomentumSGD, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_momentum_s_g_d_op.html">IDEEPMomentumSGDOp</a>)</td></tr>
<tr class="separator:af8e36a442fc006e7882b5283b6faf0b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab075609d9ba29727ee9817969517650d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab075609d9ba29727ee9817969517650d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (MomentumSGDUpdate, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_momentum_s_g_d_update_op.html">IDEEPMomentumSGDUpdateOp</a>)</td></tr>
<tr class="separator:ab075609d9ba29727ee9817969517650d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5fd90493a527d71079a1626ca6f082c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5fd90493a527d71079a1626ca6f082c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_COMPARE_OPERATOR</b> (EQ)</td></tr>
<tr class="separator:aa5fd90493a527d71079a1626ca6f082c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ffe20675e64df4865cd9fd0352d49ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6ffe20675e64df4865cd9fd0352d49ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_COMPARE_OPERATOR</b> (GT)</td></tr>
<tr class="separator:a6ffe20675e64df4865cd9fd0352d49ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe75b1c9bc1b83fcf3f33aa745a6491c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe75b1c9bc1b83fcf3f33aa745a6491c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_COMPARE_OPERATOR</b> (GE)</td></tr>
<tr class="separator:afe75b1c9bc1b83fcf3f33aa745a6491c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1bd5eaba0f1cbb257f4c7cc2e4079a3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad1bd5eaba0f1cbb257f4c7cc2e4079a3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_COMPARE_OPERATOR</b> (LT)</td></tr>
<tr class="separator:ad1bd5eaba0f1cbb257f4c7cc2e4079a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a142a446e96cab6ae3570533556f4f6be"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a142a446e96cab6ae3570533556f4f6be"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_COMPARE_OPERATOR</b> (LE)</td></tr>
<tr class="separator:a142a446e96cab6ae3570533556f4f6be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a1685dc5554d79367c529448c537a2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2a1685dc5554d79367c529448c537a2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_COMPARE_OPERATOR</b> (NE)</td></tr>
<tr class="separator:a2a1685dc5554d79367c529448c537a2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd1e83cfbc8e34848126653234b409c8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abd1e83cfbc8e34848126653234b409c8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_softmax.html">Softmax</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_softmax_op.html">SoftmaxOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:abd1e83cfbc8e34848126653234b409c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32891434bb1f4231db830d3dfec34afa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32891434bb1f4231db830d3dfec34afa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (LabelCrossEntropy, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_label_cross_entropy_op.html">LabelCrossEntropyOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a32891434bb1f4231db830d3dfec34afa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a718ce48c949a11c3294b404984b7b6a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a718ce48c949a11c3294b404984b7b6a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt; 0 &gt;&gt;)</td></tr>
<tr class="separator:a718ce48c949a11c3294b404984b7b6a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18c7e421b31071bff7319e89e46c2688"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a18c7e421b31071bff7319e89e46c2688"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_flatten.html">Flatten</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_flatten_op.html">FlattenOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a18c7e421b31071bff7319e89e46c2688"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afeb65ab797ca3d415cbbdbe24975b30c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afeb65ab797ca3d415cbbdbe24975b30c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ResizeLike, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_resize_like_op.html">ResizeLikeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:afeb65ab797ca3d415cbbdbe24975b30c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4eacbade25dbb3485412f60b0ea52fac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4eacbade25dbb3485412f60b0ea52fac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Transpose, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_transpose_op.html">TransposeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a4eacbade25dbb3485412f60b0ea52fac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0ff52972533979e2c7294ec9738e64d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad0ff52972533979e2c7294ec9738e64d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Slice, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_slice_op.html">SliceOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad0ff52972533979e2c7294ec9738e64d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26c3511cf6b222dacbb32048cc9a1b24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a26c3511cf6b222dacbb32048cc9a1b24"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_clip.html">Clip</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_clip_op.html">ClipOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a26c3511cf6b222dacbb32048cc9a1b24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52a904058c950309a36c74a8a12abb9d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a52a904058c950309a36c74a8a12abb9d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ScatterAssign, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_scatter_assign_op.html">ScatterAssignOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a52a904058c950309a36c74a8a12abb9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc3c817d8b906da148224a292abab23b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc3c817d8b906da148224a292abab23b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Cast, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_cast_op.html">CastOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:abc3c817d8b906da148224a292abab23b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5c7c7c99726c8785bc205054c89618d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5c7c7c99726c8785bc205054c89618d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (XavierFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_xavier_fill_op.html">XavierFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ac5c7c7c99726c8785bc205054c89618d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35c129cbeff642d97ee62b52125b2802"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35c129cbeff642d97ee62b52125b2802"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ConstantFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_constant_fill_op.html">ConstantFillOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a35c129cbeff642d97ee62b52125b2802"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc0b1ac8d3ccf9d9eac31984b5ee3c4f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc0b1ac8d3ccf9d9eac31984b5ee3c4f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GaussianFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_gaussian_fill_op.html">GaussianFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:abc0b1ac8d3ccf9d9eac31984b5ee3c4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9538df20099f97d00a9bae9cc223c1f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9538df20099f97d00a9bae9cc223c1f1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (MSRAFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_m_s_r_a_fill_op.html">MSRAFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a9538df20099f97d00a9bae9cc223c1f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c0343a2b2a37d9cf2380003fe08c4c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c0343a2b2a37d9cf2380003fe08c4c7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_given_tensor_fill.html">GivenTensorFill</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a1c0343a2b2a37d9cf2380003fe08c4c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94153588d0432ff8ac9ac94a83c419e3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a94153588d0432ff8ac9ac94a83c419e3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GivenTensorDoubleFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; double, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt; 0 &gt;&gt;)</td></tr>
<tr class="separator:a94153588d0432ff8ac9ac94a83c419e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0faf1af3d198a02c8c985ad7def0a07f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0faf1af3d198a02c8c985ad7def0a07f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GivenTensorBoolFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; bool, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt; 0 &gt;&gt;)</td></tr>
<tr class="separator:a0faf1af3d198a02c8c985ad7def0a07f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a493b0c1fa74a0a54100719a6b539a186"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a493b0c1fa74a0a54100719a6b539a186"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GivenTensorIntFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt; 0 &gt;&gt;)</td></tr>
<tr class="separator:a493b0c1fa74a0a54100719a6b539a186"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e9c75d6a08d8dcdce5e1d49ca1e6921"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e9c75d6a08d8dcdce5e1d49ca1e6921"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GivenTensorInt64Fill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt; 0 &gt;&gt;)</td></tr>
<tr class="separator:a0e9c75d6a08d8dcdce5e1d49ca1e6921"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27cccfb8104a73d8e647ed404a5aa54c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a27cccfb8104a73d8e647ed404a5aa54c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GivenTensorStringFill, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; std::string, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt; 0 &gt;&gt;)</td></tr>
<tr class="separator:a27cccfb8104a73d8e647ed404a5aa54c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93395124c48d460aed06d3c360a4ba07"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a93395124c48d460aed06d3c360a4ba07"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Load, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_load_op.html">LoadOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a93395124c48d460aed06d3c360a4ba07"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace9817b0041f7966529d0cfa42548fcc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ace9817b0041f7966529d0cfa42548fcc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Save, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_save_op.html">SaveOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ace9817b0041f7966529d0cfa42548fcc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6de73307f26d754e422b100eb931cd7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6de73307f26d754e422b100eb931cd7f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (RMACRegions, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_r_m_a_c_regions_op.html">RMACRegionsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a6de73307f26d754e422b100eb931cd7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab223418f9d44a77d781beea5ed25fd3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab223418f9d44a77d781beea5ed25fd3e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (RoIPool, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_ro_i_pool_op.html">RoIPoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ab223418f9d44a77d781beea5ed25fd3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2b1b72a8189a1a341b4981ee7e4cacf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af2b1b72a8189a1a341b4981ee7e4cacf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (RoIAlign, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_ro_i_align_op.html">RoIAlignOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:af2b1b72a8189a1a341b4981ee7e4cacf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1c3b07fe09cdbd8e3607260d3354b84"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae1c3b07fe09cdbd8e3607260d3354b84"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (RoIAlignRotated, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_ro_i_align_rotated_op.html">RoIAlignRotatedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ae1c3b07fe09cdbd8e3607260d3354b84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e233ef1d1d2f5bef8cf62943283b3db"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e233ef1d1d2f5bef8cf62943283b3db"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GenerateProposals, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_generate_proposals_op.html">GenerateProposalsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0e233ef1d1d2f5bef8cf62943283b3db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0a14bffc20a727e79411aa5f616e3e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad0a14bffc20a727e79411aa5f616e3e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (GenerateProposalsCPP, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_generate_proposals_op.html">GenerateProposalsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad0a14bffc20a727e79411aa5f616e3e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40526171992ad1ff997f22c6adcf53eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a40526171992ad1ff997f22c6adcf53eb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (CollectAndDistributeFpnRpnProposals, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_collect_and_distribute_fpn_rpn_proposals_op.html">CollectAndDistributeFpnRpnProposalsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a40526171992ad1ff997f22c6adcf53eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e245c014ddcea04caaa8fe461b68a27"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e245c014ddcea04caaa8fe461b68a27"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (BoxWithNMSLimit, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_box_with_n_m_s_limit_op.html">BoxWithNMSLimitOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, <a class="el" href="classcaffe2_1_1_skip_indices.html">SkipIndices</a>&lt; 0, 1, 2 &gt;&gt;)</td></tr>
<tr class="separator:a0e245c014ddcea04caaa8fe461b68a27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2da09f82392260c31f36e7755dec1d8f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2da09f82392260c31f36e7755dec1d8f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (BBoxTransform, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_b_box_transform_op.html">BBoxTransformOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a2da09f82392260c31f36e7755dec1d8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a251d39e0dd68163d9fb4b330d6c91ef3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a251d39e0dd68163d9fb4b330d6c91ef3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (AffineChannel, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_affine_channel_op.html">AffineChannelOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a251d39e0dd68163d9fb4b330d6c91ef3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ec5e485364ba9ca6332954baea269a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3ec5e485364ba9ca6332954baea269a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (StopGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_stop_gradient_op.html">StopGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a3ec5e485364ba9ca6332954baea269a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afbc9c125a1f7624698ea4afafe2b50af"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afbc9c125a1f7624698ea4afafe2b50af"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (PadImage, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_pad_image_op.html">PadImageOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:afbc9c125a1f7624698ea4afafe2b50af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb4a60d75279f4aea1eb85cfa5f718c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb4a60d75279f4aea1eb85cfa5f718c7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (PRelu, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_p_relu_op.html">PReluOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:acb4a60d75279f4aea1eb85cfa5f718c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc0aef1c3f6eda06948606cd380c9193"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc0aef1c3f6eda06948606cd380c9193"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (CTCGreedyDecoder, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_t_c_greedy_decoder_op.html">CTCGreedyDecoderOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:abc0aef1c3f6eda06948606cd380c9193"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73080e57758f3cea907612d6de6de215"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a73080e57758f3cea907612d6de6de215"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (CTCBeamSearchDecoder, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_t_c_beam_search_decoder_op.html">CTCBeamSearchDecoderOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a73080e57758f3cea907612d6de6de215"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb44c2484e5cb8af90ef49cca40eca29"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abb44c2484e5cb8af90ef49cca40eca29"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_averaged_loss_gradient.html">AveragedLossGradient</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_averaged_loss_gradient.html">AveragedLossGradient</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:abb44c2484e5cb8af90ef49cca40eca29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9715a6707ffd20c72621cb7efee1d6c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9715a6707ffd20c72621cb7efee1d6c9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (LabelCrossEntropyGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_label_cross_entropy_gradient_op.html">LabelCrossEntropyGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a9715a6707ffd20c72621cb7efee1d6c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a918b08eabd141d665847633c493b1d2a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a918b08eabd141d665847633c493b1d2a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (SoftmaxGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_softmax_gradient_op.html">SoftmaxGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a918b08eabd141d665847633c493b1d2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8119ea5575b6c5e91be4c1278a25153a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8119ea5575b6c5e91be4c1278a25153a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Iter, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_iter_op.html">IterOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a8119ea5575b6c5e91be4c1278a25153a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac469ee1d85e3ecbd7f1a0703bd8a306"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aac469ee1d85e3ecbd7f1a0703bd8a306"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (LearningRate, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_learning_rate_op.html">LearningRateOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aac469ee1d85e3ecbd7f1a0703bd8a306"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0ee7d55e9cfa65c704d3f8a412f4ebf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad0ee7d55e9cfa65c704d3f8a412f4ebf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Abs, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_abs_functor.html">AbsFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:ad0ee7d55e9cfa65c704d3f8a412f4ebf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad896b6550ba2e832287c76314a11f301"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad896b6550ba2e832287c76314a11f301"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Atan, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_atan_functor.html">AtanFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:ad896b6550ba2e832287c76314a11f301"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12f03b252a5e861f4399773a855ed4da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a12f03b252a5e861f4399773a855ed4da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Sqrt, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sqrt_functor.html">SqrtFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a12f03b252a5e861f4399773a855ed4da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a853ab0f0d6bb1cd1e8b2811380e5c625"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a853ab0f0d6bb1cd1e8b2811380e5c625"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Div, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_div_functor.html">DivFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a853ab0f0d6bb1cd1e8b2811380e5c625"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d15ce649a46d27a3300da43b6665042"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d15ce649a46d27a3300da43b6665042"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Mul, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_mul_functor.html">MulFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a1d15ce649a46d27a3300da43b6665042"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4352b7631be3c2f7eded821ba47df97e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4352b7631be3c2f7eded821ba47df97e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Sub, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sub_functor.html">SubFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a4352b7631be3c2f7eded821ba47df97e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55f4edbd0dc43df0bf152054aa5141d8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55f4edbd0dc43df0bf152054aa5141d8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="classdnnlowp_1_1_tanh.html">Tanh</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_tanh_functor.html">TanhFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a55f4edbd0dc43df0bf152054aa5141d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a38d501c0dc3e9ba205d711f0ce92d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a38d501c0dc3e9ba205d711f0ce92d5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (L1Distance, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_l1_distance_op.html">L1DistanceOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a5a38d501c0dc3e9ba205d711f0ce92d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad43cabd3913ca759b98965605abe65de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad43cabd3913ca759b98965605abe65de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Scale, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_scale_op.html">ScaleOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad43cabd3913ca759b98965605abe65de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83e0771b3a38a3d59bdee217942f12d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a83e0771b3a38a3d59bdee217942f12d7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Accuracy, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_accuracy_op.html">AccuracyOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a83e0771b3a38a3d59bdee217942f12d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6756a951d69de7b532764bab902ab4c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6756a951d69de7b532764bab902ab4c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (AddGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_add_functor.html">AddFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:ad6756a951d69de7b532764bab902ab4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a745fc9aca715230c9f39480b6623585a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a745fc9aca715230c9f39480b6623585a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (TanhGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_tanh_gradient_functor.html">TanhGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a745fc9aca715230c9f39480b6623585a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8aeb2de2623f49d08997a311d23d07a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8aeb2de2623f49d08997a311d23d07a4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (MulGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_mul_functor.html">MulFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a8aeb2de2623f49d08997a311d23d07a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b8e0d0ec81cdd53b12ed63338f86a3d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b8e0d0ec81cdd53b12ed63338f86a3d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a3b8e0d0ec81cdd53b12ed63338f86a3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe8744b3be9feaa294f96c8449e4662f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe8744b3be9feaa294f96c8449e4662f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (CloseBlobsQueue, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_close_blobs_queue_op.html">CloseBlobsQueueOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:afe8744b3be9feaa294f96c8449e4662f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ab2fc5228a8b1d010b44b102b206552"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6ab2fc5228a8b1d010b44b102b206552"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (SoftmaxWithLoss, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_softmax_with_loss_op.html">SoftmaxWithLossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a6ab2fc5228a8b1d010b44b102b206552"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0833a1c1899cdbcb9b0c3384117d13ab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0833a1c1899cdbcb9b0c3384117d13ab"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (SoftmaxWithLossGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_softmax_with_loss_gradient_op.html">SoftmaxWithLossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0833a1c1899cdbcb9b0c3384117d13ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac77b9677d60b4b158de502056a0fc13a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac77b9677d60b4b158de502056a0fc13a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_n_h_w_c2_n_c_h_w.html">NHWC2NCHW</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_n_h_w_c2_n_c_h_w_op.html">NHWC2NCHWOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ac77b9677d60b4b158de502056a0fc13a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acba1a66eca488778947b6f6e18e98fd8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acba1a66eca488778947b6f6e18e98fd8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_n_c_h_w2_n_h_w_c.html">NCHW2NHWC</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_n_c_h_w2_n_h_w_c_op.html">NCHW2NHWCOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:acba1a66eca488778947b6f6e18e98fd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa916f4f391313b7fcacdd4496fb58ed1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa916f4f391313b7fcacdd4496fb58ed1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Expand, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_expand_op.html">ExpandOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aa916f4f391313b7fcacdd4496fb58ed1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad72e71e0d3d2f6efd25fa2655f0ba5da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad72e71e0d3d2f6efd25fa2655f0ba5da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Gather, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_gather_op.html">GatherOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad72e71e0d3d2f6efd25fa2655f0ba5da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab49e7cdda8ea402d77ccdefb9610a501"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab49e7cdda8ea402d77ccdefb9610a501"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Normalize, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_normalize_op.html">NormalizeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ab49e7cdda8ea402d77ccdefb9610a501"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6edf19f142d612abb8f5214ec0d96124"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6edf19f142d612abb8f5214ec0d96124"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ReduceL2, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_reduce_op.html">ReduceOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_l2_reducer.html">L2Reducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a6edf19f142d612abb8f5214ec0d96124"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f1dfbbea734c9491e747293936563cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8f1dfbbea734c9491e747293936563cb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ReduceSum, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_reduce_op.html">ReduceOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sum_reducer.html">SumReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a8f1dfbbea734c9491e747293936563cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f62610c31dcce9761719065f8eb8569"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3f62610c31dcce9761719065f8eb8569"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ReduceMean, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_reduce_op.html">ReduceOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_mean_reducer.html">MeanReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;&gt;)</td></tr>
<tr class="separator:a3f62610c31dcce9761719065f8eb8569"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a225f7e04211963595c5664c8d49a791f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a225f7e04211963595c5664c8d49a791f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (BatchMatMul, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_fallback_op.html">IDEEPFallbackOp</a>&lt; <a class="el" href="classcaffe2_1_1_batch_mat_mul_op.html">BatchMatMulOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a225f7e04211963595c5664c8d49a791f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc152eaa6a15f0ec5af3b3ebfc22a944"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc152eaa6a15f0ec5af3b3ebfc22a944"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_max_pool.html">MaxPool</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_pool_op.html">IDEEPPoolOp</a>)</td></tr>
<tr class="separator:adc152eaa6a15f0ec5af3b3ebfc22a944"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08b49926272c6c01348c2470f84a9f41"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08b49926272c6c01348c2470f84a9f41"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (MaxPoolGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_pool_gradient_op.html">IDEEPPoolGradientOp</a>)</td></tr>
<tr class="separator:a08b49926272c6c01348c2470f84a9f41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17de124da4afb621616944967d2beff5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17de124da4afb621616944967d2beff5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_average_pool.html">AveragePool</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_pool_op.html">IDEEPPoolOp</a>)</td></tr>
<tr class="separator:a17de124da4afb621616944967d2beff5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5462bf88f923ee80b9288d766b8ca06b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5462bf88f923ee80b9288d766b8ca06b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (AveragePoolGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_pool_gradient_op.html">IDEEPPoolGradientOp</a>)</td></tr>
<tr class="separator:a5462bf88f923ee80b9288d766b8ca06b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a688221a90e691400b7f7867d1481f73e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a688221a90e691400b7f7867d1481f73e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (CreateBlobsQueue, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_create_blobs_queue_op.html">IDEEPCreateBlobsQueueOp</a>)</td></tr>
<tr class="separator:a688221a90e691400b7f7867d1481f73e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdb0911995689e1c06eca8ed157ac600"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acdb0911995689e1c06eca8ed157ac600"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_i_d_e_e_p_create_blobs_queue_op.html">IDEEPCreateBlobsQueueOp</a>)</td></tr>
<tr class="separator:acdb0911995689e1c06eca8ed157ac600"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4171ca256b8ab21aa5097b9f920cf34b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4171ca256b8ab21aa5097b9f920cf34b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (SafeEnqueueBlobs, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_safe_enqueue_blobs_op.html">IDEEPSafeEnqueueBlobsOp</a>)</td></tr>
<tr class="separator:a4171ca256b8ab21aa5097b9f920cf34b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1843e376c9a178b4e7e22fac70caa7b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae1843e376c9a178b4e7e22fac70caa7b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_i_d_e_e_p_safe_enqueue_blobs_op.html">IDEEPSafeEnqueueBlobsOp</a>)</td></tr>
<tr class="separator:ae1843e376c9a178b4e7e22fac70caa7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabfa5f301c14af9b08ee763c2cd58b4d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabfa5f301c14af9b08ee763c2cd58b4d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_relu.html">Relu</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_relu_op.html">IDEEPReluOp</a>)</td></tr>
<tr class="separator:aabfa5f301c14af9b08ee763c2cd58b4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa53eda7bbe58c5c9de42287959104236"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa53eda7bbe58c5c9de42287959104236"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (ReluGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_relu_gradient_op.html">IDEEPReluGradientOp</a>)</td></tr>
<tr class="separator:aa53eda7bbe58c5c9de42287959104236"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7407c61b0c419016c4485e8efeb437d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7407c61b0c419016c4485e8efeb437d1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (LeakyRelu, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_relu_op.html">IDEEPReluOp</a>)</td></tr>
<tr class="separator:a7407c61b0c419016c4485e8efeb437d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54fece5ae100e1488c870f0f6b7f4cc2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a54fece5ae100e1488c870f0f6b7f4cc2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (LeakyReluGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_relu_gradient_op.html">IDEEPReluGradientOp</a>)</td></tr>
<tr class="separator:a54fece5ae100e1488c870f0f6b7f4cc2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7d1928227fcb423ab9df03e25c79162"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae7d1928227fcb423ab9df03e25c79162"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="class_reshape.html">Reshape</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_reshape_op.html">IDEEPReshapeOp</a>)</td></tr>
<tr class="separator:ae7d1928227fcb423ab9df03e25c79162"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb18d86bc98d903c90221deae77bfe43"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeb18d86bc98d903c90221deae77bfe43"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Shape, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_shape_op.html">IDEEPShapeOp</a>)</td></tr>
<tr class="separator:aeb18d86bc98d903c90221deae77bfe43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d2264ee818c2b9fd5d9a785b77f38e9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2d2264ee818c2b9fd5d9a785b77f38e9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (<a class="el" href="classdnnlowp_1_1_sigmoid.html">Sigmoid</a>, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_sigmoid_op.html">IDEEPSigmoidOp</a>)</td></tr>
<tr class="separator:a2d2264ee818c2b9fd5d9a785b77f38e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad65eac665ad47de0c09f1dd6fa4af69c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad65eac665ad47de0c09f1dd6fa4af69c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (SigmoidGradient, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_sigmoid_gradient_op.html">IDEEPSigmoidGradientOp</a>)</td></tr>
<tr class="separator:ad65eac665ad47de0c09f1dd6fa4af69c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6bdbcf79a177b9d2787bc8437dd068ef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6bdbcf79a177b9d2787bc8437dd068ef"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (SpatialBN, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_spatial_b_n_op.html">IDEEPSpatialBNOp</a>)</td></tr>
<tr class="separator:a6bdbcf79a177b9d2787bc8437dd068ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99b17af5b045bef290efbda24f35eb47"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a99b17af5b045bef290efbda24f35eb47"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (CopyCPUToIDEEP, <a class="el" href="classcaffe2_1_1_copy_c_p_u_to_i_d_e_e_p_op.html">CopyCPUToIDEEPOp</a>)</td></tr>
<tr class="separator:a99b17af5b045bef290efbda24f35eb47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01c123f3bc7beb3f6a4ca4e0e07343f7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01c123f3bc7beb3f6a4ca4e0e07343f7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (CopyIDEEPToCPU, <a class="el" href="classcaffe2_1_1_copy_i_d_e_e_p_to_c_p_u_op.html">CopyIDEEPToCPUOp</a>)</td></tr>
<tr class="separator:a01c123f3bc7beb3f6a4ca4e0e07343f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2102d14bb7afbf5567d74df351f77b46"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2102d14bb7afbf5567d74df351f77b46"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (Copy, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_copy_op.html">IDEEPCopyOp</a>)</td></tr>
<tr class="separator:a2102d14bb7afbf5567d74df351f77b46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a032502d139a3303be4601a3852ae0a89"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a032502d139a3303be4601a3852ae0a89"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_IDEEP_OPERATOR</b> (WeightedSum, <a class="el" href="classcaffe2_1_1_i_d_e_e_p_weighted_sum_op.html">IDEEPWeightedSumOp</a>)</td></tr>
<tr class="separator:a032502d139a3303be4601a3852ae0a89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86ff21abd7316da30b7b9c2fae7c1639"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86ff21abd7316da30b7b9c2fae7c1639"></a>
The input <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> to copy&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;ideep_blob&quot;,&quot;The output IDEEP tensort to copy to&quot;)</td></tr>
<tr class="separator:a86ff21abd7316da30b7b9c2fae7c1639"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7af02836e6d1d08f05dcb279ae05b2d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7af02836e6d1d08f05dcb279ae05b2d7"></a>
The input IDEEP tensort to copy&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;cpu_blob&quot;,&quot;The output <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> to copy to&quot;)</td></tr>
<tr class="separator:a7af02836e6d1d08f05dcb279ae05b2d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01f237f99c4038fe04410325d4813e57"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01f237f99c4038fe04410325d4813e57"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (IDEEPOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a01f237f99c4038fe04410325d4813e57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab19f969c2bea83786fdb85a937314941"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab19f969c2bea83786fdb85a937314941"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (ideep::tensor)</td></tr>
<tr class="separator:ab19f969c2bea83786fdb85a937314941"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4198f4ffc67aea9225d3ab6ceeb045ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4198f4ffc67aea9225d3ab6ceeb045ed"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (IDEEPOperatorRegistry, <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a>, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a4198f4ffc67aea9225d3ab6ceeb045ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a338bcfb6882d8d39842f61aadac79d8d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a338bcfb6882d8d39842f61aadac79d8d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_REGISTER_DEVICE_TYPE</b> (DeviceType::IDEEP, IDEEPOperatorRegistry)</td></tr>
<tr class="separator:a338bcfb6882d8d39842f61aadac79d8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a7a7296882155960f8d55fc39ef06e9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a7a7296882155960f8d55fc39ef06e9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_CREATE_FUNCTION</b> (IDEEP, EventCreateCPU)</td></tr>
<tr class="separator:a3a7a7296882155960f8d55fc39ef06e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec6a5855bcb8de4126b4ca3b8d861d3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec6a5855bcb8de4126b4ca3b8d861d3e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_RECORD_FUNCTION</b> (IDEEP, EventRecordCPU)</td></tr>
<tr class="separator:aec6a5855bcb8de4126b4ca3b8d861d3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae24581ebf9680fec8d427948166802da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae24581ebf9680fec8d427948166802da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (IDEEP, IDEEP, EventWaitCPUCPU)</td></tr>
<tr class="separator:ae24581ebf9680fec8d427948166802da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29838a18c9acd59466580fb69cc645a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29838a18c9acd59466580fb69cc645a1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (IDEEP, CPU, EventWaitCPUCPU)</td></tr>
<tr class="separator:a29838a18c9acd59466580fb69cc645a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefed839ae5e04fa4007c487f90d85fb9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aefed839ae5e04fa4007c487f90d85fb9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_WAIT_FUNCTION</b> (CPU, IDEEP, EventWaitCPUCPU)</td></tr>
<tr class="separator:aefed839ae5e04fa4007c487f90d85fb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57b003acf5f9c0a82b3a10c4914f446d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a57b003acf5f9c0a82b3a10c4914f446d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_FINISH_FUNCTION</b> (IDEEP, EventFinishCPU)</td></tr>
<tr class="separator:a57b003acf5f9c0a82b3a10c4914f446d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7eb19cd1029f64619be61687db75ef63"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7eb19cd1029f64619be61687db75ef63"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_QUERY_FUNCTION</b> (IDEEP, EventQueryCPU)</td></tr>
<tr class="separator:a7eb19cd1029f64619be61687db75ef63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c64a2cff26494d69c7dffca67dbcaa0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c64a2cff26494d69c7dffca67dbcaa0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_ERROR_MESSAGE_FUNCTION</b> (IDEEP, EventErrorMessageCPU)</td></tr>
<tr class="separator:a9c64a2cff26494d69c7dffca67dbcaa0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89e26ca28564c97e7f3288c10deb8e42"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a89e26ca28564c97e7f3288c10deb8e42"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_SET_FINISHED_FUNCTION</b> (IDEEP, EventSetFinishedCPU)</td></tr>
<tr class="separator:a89e26ca28564c97e7f3288c10deb8e42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22a2056357d78a97e60d2fa4e64d5f2e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a22a2056357d78a97e60d2fa4e64d5f2e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_EVENT_RESET_FUNCTION</b> (IDEEP, EventResetCPU)</td></tr>
<tr class="separator:a22a2056357d78a97e60d2fa4e64d5f2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46881f29cd0505bf48b9dc10758d6e2a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46881f29cd0505bf48b9dc10758d6e2a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ImageInput, <a class="el" href="classcaffe2_1_1_image_input_op.html">ImageInputOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a46881f29cd0505bf48b9dc10758d6e2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2459389cb3e05cc347abd30f6480c74f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2459389cb3e05cc347abd30f6480c74f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (0, 1).NumOutputs(2</td></tr>
<tr class="separator:a2459389cb3e05cc347abd30f6480c74f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af281b4f674ddcc7a0ff297cbd260cf40"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af281b4f674ddcc7a0ff297cbd260cf40"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;){vector&lt; TensorShape &gt; out(2);<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> helper(def);int batch_size=helper.GetSingleArgument&lt; int &gt;(&quot;batch_size&quot;, 0);int crop=helper.GetSingleArgument&lt; int &gt;(&quot;crop&quot;,-1);int color=helper.GetSingleArgument&lt; int &gt;(&quot;color&quot;, 1);CHECK_GT(crop, 0);out[0]=CreateTensorShape(vector&lt; int &gt;{batch_size, crop, crop, color?3:1}, TensorProto::FLOAT);out[1]=CreateTensorShape(vector&lt; int &gt;{1, batch_size}, TensorProto::INT32);return out;}).SetDoc(R&quot;DOC( Imports and processes images from a database. For each run of the operator</td></tr>
<tr class="separator:af281b4f674ddcc7a0ff297cbd260cf40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0843dd8927171f2edb82e96bf38bfbe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0843dd8927171f2edb82e96bf38bfbe"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial&#160;</td><td class="memItemRight" valign="bottom"><b>image</b> (<a class="el" href="classc10_1_1optional.html">optional</a>)-The image is rescaled either up or down(with the scale argument) or just up(with the minsize argument)-The image is randomly cropped(crop size is passed as an argument but the location of the crop is random except if is_test is passed in which case the image in cropped at the center)-The image is normalized.Each of its color channels can have separate normalization values The dimension of the output image will always be cropxcrop) DOC&quot;) .Arg(&quot;batch_size&quot;</td></tr>
<tr class="separator:ab0843dd8927171f2edb82e96bf38bfbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb023f040c85fd09a39fe4051d18a52b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb023f040c85fd09a39fe4051d18a52b"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the&#160;</td><td class="memItemRight" valign="bottom"><b>operator&quot; &quot;.Must be 1 or greater&quot;) .Arg</b> (&quot;color&quot;,&quot;Number of color channels (1 or 3). Defaults to 1&quot;).Arg(&quot;color_jitter&quot;</td></tr>
<tr class="separator:acb023f040c85fd09a39fe4051d18a52b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad046b4618a8495950dece292ee948c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aad046b4618a8495950dece292ee948c5"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the Whether or not to do color jitter Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;img_saturation&quot;,&quot;Image saturation scale used in color jittering. &quot;&quot;Defaults to 0.4&quot;).Arg(&quot;img_brightness&quot;</td></tr>
<tr class="separator:aad046b4618a8495950dece292ee948c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5436c4be3acff2f04096a1d3d0c6c1c8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5436c4be3acff2f04096a1d3d0c6c1c8"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the Whether or not to do color jitter Defaults to Image brightness scale used in color jittering Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;img_contrast&quot;,&quot;Image contrast scale used in color jittering. &quot;&quot;Defaults to 0.4&quot;).Arg(&quot;color_lighting&quot;</td></tr>
<tr class="separator:a5436c4be3acff2f04096a1d3d0c6c1c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d265c24d83412451a4d338f2379b14e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d265c24d83412451a4d338f2379b14e"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the Whether or not to do color jitter Defaults to Image brightness scale used in color jittering Defaults to Whether or not to do color lighting Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;color_lighting_std&quot;,&quot;Std of normal distribution where color lighting&quot;&quot; scaling factor is sampled. Defaults to 0.1&quot;).Arg(&quot;scale_jitter_type&quot;</td></tr>
<tr class="separator:a7d265c24d83412451a4d338f2379b14e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a4b36418e11522d5a8ae8e8be982b12"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a4b36418e11522d5a8ae8e8be982b12"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the Whether or not to do color jitter Defaults to Image brightness scale used in color jittering Defaults to Whether or not to do color lighting Defaults to Scale the size of the smallest dimension of the image to this Scale and minsize are mutually exclusive Must be larger than crop&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;minsize&quot;,&quot;Scale the size of the smallest dimension of the image to&quot;&quot; this only if the size is initially smaller. Scale and minsize are&quot;&quot; mutually exclusive. Must be larger than crop.&quot;).Arg(&quot;warp&quot;</td></tr>
<tr class="separator:a9a4b36418e11522d5a8ae8e8be982b12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ca7edede62cb26a92b3084c689740ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2ca7edede62cb26a92b3084c689740ff"></a>
the other dimension is proportionally scaled Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;crop&quot;,&quot;Size to crop the image to. Must be provided&quot;).Arg(&quot;mirror&quot;</td></tr>
<tr class="separator:a2ca7edede62cb26a92b3084c689740ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10a1069ccf5b3b27514cc8706b436a46"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a10a1069ccf5b3b27514cc8706b436a46"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;mean&quot;,&quot;Mean by which to normalize color channels.&quot;&quot; Defaults to 0.&quot;).Arg(&quot;mean_per_channel&quot;</td></tr>
<tr class="separator:a10a1069ccf5b3b27514cc8706b436a46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68b770c25ba279f06d4960b325974282"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a68b770c25ba279f06d4960b325974282"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color&#160;</td><td class="memItemRight" valign="bottom"><b>channel</b> (1 or 3 elements).Defaults to mean argument.Channel order BGR&quot;) .Arg(&quot;std&quot;</td></tr>
<tr class="separator:a68b770c25ba279f06d4960b325974282"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69c409a294449a26bbddc45823681a26"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a69c409a294449a26bbddc45823681a26"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;std_per_channel&quot;,&quot;Vector of standard dev. per color channel &quot;&quot; (1 or 3 elements). Defaults to std argument. Channel order is BGR&quot;).Arg(&quot;bounding_ymin&quot;</td></tr>
<tr class="separator:a69c409a294449a26bbddc45823681a26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2431ce06d86fcbe00461cc50c8481b72"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2431ce06d86fcbe00461cc50c8481b72"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults&#160;</td><td class="memItemRight" valign="bottom"><b>to</b> (none)&quot;) .Arg(&quot;bounding_xmin&quot;</td></tr>
<tr class="separator:a2431ce06d86fcbe00461cc50c8481b72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1996aff9870b81551069115ccde9acea"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1996aff9870b81551069115ccde9acea"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;use_gpu_transform&quot;,&quot;1 if GPU acceleration should be used.&quot;&quot; Defaults to 0. Can only be 1 in a <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>&quot;).Arg(&quot;decode_threads&quot;</td></tr>
<tr class="separator:a1996aff9870b81551069115ccde9acea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08beef7f94f925858f4b0cd0edafca10"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08beef7f94f925858f4b0cd0edafca10"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;output_type&quot;,&quot;If gpu_transform, can set to FLOAT or FLOAT16.&quot;).Arg(&quot;db&quot;</td></tr>
<tr class="separator:a08beef7f94f925858f4b0cd0edafca10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81eb64afecbbe1ab0bc24bc583fb36bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a81eb64afecbbe1ab0bc24bc583fb36bb"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to Name of the&#160;</td><td class="memItemRight" valign="bottom"><b>database</b> (if not passed as input)&quot;) .Arg(&quot;db_type&quot;</td></tr>
<tr class="separator:a81eb64afecbbe1ab0bc24bc583fb36bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44828c60e4c07e998cd551589e3e96b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a44828c60e4c07e998cd551589e3e96b9"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to Name of the <a class="el" href="structc10_1_1_type.html">Type</a> of The sizes of any outputs besides the data and&#160;</td><td class="memItemRight" valign="bottom"><b>label</b> (should have a number of elements equal to the number of additional&quot;
         &quot;outputs)&quot;) .Arg(&quot;random_scale&quot;</td></tr>
<tr class="separator:a44828c60e4c07e998cd551589e3e96b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adddbc9ea90ecffa3f431ad2544844c4a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adddbc9ea90ecffa3f431ad2544844c4a"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to Name of the <a class="el" href="structc10_1_1_type.html">Type</a> of The sizes of any outputs besides the data and shortest side desired for image resize Defaults to[-1,-1] or no random resize desired&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;reader&quot;,&quot;The input reader (a <a class="el" href="classcaffe2_1_1db_1_1_d_b_reader.html">db::DBReader</a>)&quot;).Output(0</td></tr>
<tr class="separator:adddbc9ea90ecffa3f431ad2544844c4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abee15142475f6490a021e4f59d3f6386"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abee15142475f6490a021e4f59d3f6386"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to Name of the <a class="el" href="structc10_1_1_type.html">Type</a> of The sizes of any outputs besides the data and shortest side desired for image resize Defaults to[-1,-1] or no random resize desired <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> containing the images&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;label&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> containing the labels&quot;).Output(2</td></tr>
<tr class="separator:abee15142475f6490a021e4f59d3f6386"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42eeee1953b1fa22979df2625afd8f7d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42eeee1953b1fa22979df2625afd8f7d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (ImageInput)</td></tr>
<tr class="separator:a42eeee1953b1fa22979df2625afd8f7d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89ed831fcf3c45cda4c13ca8baf29456"><td class="memTemplParams" colspan="2"><a class="anchor" id="a89ed831fcf3c45cda4c13ca8baf29456"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:a89ed831fcf3c45cda4c13ca8baf29456"><td class="memTemplItemLeft" align="right" valign="top">bool&#160;</td><td class="memTemplItemRight" valign="bottom"><b>RandomSizedCropping</b> (cv::Mat *img, const int crop, std::mt19937 *randgen)</td></tr>
<tr class="separator:a89ed831fcf3c45cda4c13ca8baf29456"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3dfb9938be59968250a613bb0df5dfd"><td class="memTemplParams" colspan="2"><a class="anchor" id="af3dfb9938be59968250a613bb0df5dfd"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:af3dfb9938be59968250a613bb0df5dfd"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Saturation</b> (float *img, const int img_size, const float alpha_rand, std::mt19937 *randgen)</td></tr>
<tr class="separator:af3dfb9938be59968250a613bb0df5dfd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48eca9236fea93a23767520aa5c92d6e"><td class="memTemplParams" colspan="2"><a class="anchor" id="a48eca9236fea93a23767520aa5c92d6e"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:a48eca9236fea93a23767520aa5c92d6e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Brightness</b> (float *img, const int img_size, const float alpha_rand, std::mt19937 *randgen)</td></tr>
<tr class="separator:a48eca9236fea93a23767520aa5c92d6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8f235bf145f6e8fc9b93d9856001e1d"><td class="memTemplParams" colspan="2"><a class="anchor" id="ae8f235bf145f6e8fc9b93d9856001e1d"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:ae8f235bf145f6e8fc9b93d9856001e1d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Contrast</b> (float *img, const int img_size, const float alpha_rand, std::mt19937 *randgen)</td></tr>
<tr class="separator:ae8f235bf145f6e8fc9b93d9856001e1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aacbd0925c4621b7decc472ecf1416797"><td class="memTemplParams" colspan="2"><a class="anchor" id="aacbd0925c4621b7decc472ecf1416797"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:aacbd0925c4621b7decc472ecf1416797"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ColorJitter</b> (float *img, const int img_size, const float saturation, const float brightness, const float contrast, std::mt19937 *randgen)</td></tr>
<tr class="separator:aacbd0925c4621b7decc472ecf1416797"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1a4c3e3844f779fc095a5b90bfebe33"><td class="memTemplParams" colspan="2"><a class="anchor" id="ab1a4c3e3844f779fc095a5b90bfebe33"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:ab1a4c3e3844f779fc095a5b90bfebe33"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ColorLighting</b> (float *img, const int img_size, const float alpha_std, const std::vector&lt; std::vector&lt; float &gt;&gt; &amp;eigvecs, const std::vector&lt; float &gt; &amp;eigvals, std::mt19937 *randgen)</td></tr>
<tr class="separator:ab1a4c3e3844f779fc095a5b90bfebe33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef4838fab94fdeefe86e8c1d4db05557"><td class="memTemplParams" colspan="2"><a class="anchor" id="aef4838fab94fdeefe86e8c1d4db05557"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:aef4838fab94fdeefe86e8c1d4db05557"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ColorNormalization</b> (float *img, const int img_size, const int channels, const std::vector&lt; float &gt; &amp;mean, const std::vector&lt; float &gt; &amp;std)</td></tr>
<tr class="separator:aef4838fab94fdeefe86e8c1d4db05557"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0c8852b2d4c964022bc7b3ff2c71edd"><td class="memTemplParams" colspan="2"><a class="anchor" id="ac0c8852b2d4c964022bc7b3ff2c71edd"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:ac0c8852b2d4c964022bc7b3ff2c71edd"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>TransformImage</b> (const cv::Mat &amp;scaled_img, const int channels, float *image_data, const bool color_jitter, const float saturation, const float brightness, const float contrast, const bool color_lighting, const float color_lighting_std, const std::vector&lt; std::vector&lt; float &gt;&gt; &amp;color_lighting_eigvecs, const std::vector&lt; float &gt; &amp;color_lighting_eigvals, const int crop, const bool mirror, const std::vector&lt; float &gt; &amp;mean, const std::vector&lt; float &gt; &amp;std, std::mt19937 *randgen, std::bernoulli_distribution *mirror_this_image, bool is_test=false)</td></tr>
<tr class="separator:ac0c8852b2d4c964022bc7b3ff2c71edd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54c152792102363f875e27d079a3fdfd"><td class="memTemplParams" colspan="2"><a class="anchor" id="a54c152792102363f875e27d079a3fdfd"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:a54c152792102363f875e27d079a3fdfd"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>CropTransposeImage</b> (const cv::Mat &amp;scaled_img, const int channels, uint8_t *cropped_data, const int crop, const bool mirror, std::mt19937 *randgen, std::bernoulli_distribution *mirror_this_image, bool is_test=false)</td></tr>
<tr class="separator:a54c152792102363f875e27d079a3fdfd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5bf18ece7cf2c9bb50c5cb238f692a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af5bf18ece7cf2c9bb50c5cb238f692a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ImageInput, <a class="el" href="classcaffe2_1_1_image_input_op.html">ImageInputOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:af5bf18ece7cf2c9bb50c5cb238f692a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5051c67772c597281e2b13756b6eac30"><td class="memTemplParams" colspan="2"><a class="anchor" id="a5051c67772c597281e2b13756b6eac30"></a>
template&lt;typename T_IN , typename T_OUT , class Context &gt; </td></tr>
<tr class="memitem:a5051c67772c597281e2b13756b6eac30"><td class="memTemplItemLeft" align="right" valign="top">bool&#160;</td><td class="memTemplItemRight" valign="bottom"><b>TransformOnGPU</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;X, <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *Y, <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;mean, <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;std, Context *context)</td></tr>
<tr class="separator:a5051c67772c597281e2b13756b6eac30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00a56c8772bdd2ef5e10e82e32a2812c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a00a56c8772bdd2ef5e10e82e32a2812c"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>tryConvertToMPSCNN</b> (const NetDef &amp;initNet, const NetDef &amp;predictNet, NetDef *mpscnnPredictNet)</td></tr>
<tr class="separator:a00a56c8772bdd2ef5e10e82e32a2812c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abaf6374034df05c127ea22e3d824285b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abaf6374034df05c127ea22e3d824285b"></a>
NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>annotateDefWithReadCounts</b> (const NetDef &amp;net)</td></tr>
<tr class="separator:abaf6374034df05c127ea22e3d824285b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57a2fbd617c017bb2fd9f8e22b8aaf96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a57a2fbd617c017bb2fd9f8e22b8aaf96"></a>
NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>rewriteForMetal</b> (const NetDef &amp;net)</td></tr>
<tr class="separator:a57a2fbd617c017bb2fd9f8e22b8aaf96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d2ebb0246dd4f78e67f3184b5690b0f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d2ebb0246dd4f78e67f3184b5690b0f"></a>
NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>runMPSCNNFusion</b> (const NetDef &amp;net)</td></tr>
<tr class="separator:a7d2ebb0246dd4f78e67f3184b5690b0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53c02c3cd6007350fa5ba718046d4ecc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a53c02c3cd6007350fa5ba718046d4ecc"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>dumpDef</b> (const NetDef &amp;d)</td></tr>
<tr class="separator:a53c02c3cd6007350fa5ba718046d4ecc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a254d6a74b0298a661e86c225705e39a6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a254d6a74b0298a661e86c225705e39a6"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>mpscnnRecordExecutionFinish</b> ()</td></tr>
<tr class="separator:a254d6a74b0298a661e86c225705e39a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabe607097a57d84acd3ea177a85b7744"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabe607097a57d84acd3ea177a85b7744"></a>
<a class="el" href="structcaffe2_1_1_m_p_s_c_n_n_context.html">MPSCNNContext</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>getMPSCNNContext</b> ()</td></tr>
<tr class="separator:aabe607097a57d84acd3ea177a85b7744"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a8ffd3689386b85c0d49a5200959f96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a8ffd3689386b85c0d49a5200959f96"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>tryConvertToMPSCNNIntermediateCopies</b> (const NetDef &amp;initNet, const NetDef &amp;predictNet, NetDef *mpscnnPredictNet)</td></tr>
<tr class="separator:a9a8ffd3689386b85c0d49a5200959f96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fc4186274961983247e54472fbeed42"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1fc4186274961983247e54472fbeed42"></a>
NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>setSpecialArgs</b> (const NetDef &amp;def)</td></tr>
<tr class="separator:a1fc4186274961983247e54472fbeed42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8da6bdc5a7c0d551de725a92530fd56"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae8da6bdc5a7c0d551de725a92530fd56"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>testMPSCNN</b> ()</td></tr>
<tr class="separator:ae8da6bdc5a7c0d551de725a92530fd56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe7065bb8848760071b8aa75997125eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe7065bb8848760071b8aa75997125eb"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>compareModels</b> (const NetDef &amp;initNet, NetDef predictNet)</td></tr>
<tr class="separator:afe7065bb8848760071b8aa75997125eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca2a0d95be0f12114e4628c99cee76e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca2a0d95be0f12114e4628c99cee76e6"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>verifyRewrite</b> (const NetDef &amp;initNet, const NetDef &amp;net, std::vector&lt; int &gt; inputDims)</td></tr>
<tr class="separator:aca2a0d95be0f12114e4628c99cee76e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2457b3242eeca40cf4f65e6cb0b75d20"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2457b3242eeca40cf4f65e6cb0b75d20"></a>
std::string &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>gSNPELocation</b> ()</td></tr>
<tr class="separator:a2457b3242eeca40cf4f65e6cb0b75d20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade211aa656d7303d830b20fe176f9346"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade211aa656d7303d830b20fe176f9346"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SNPE, <a class="el" href="classcaffe2_1_1_s_n_p_e_op.html">SNPEOp</a>)</td></tr>
<tr class="separator:ade211aa656d7303d830b20fe176f9346"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a858eac856ff7f62c769e23ddb9af406b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a858eac856ff7f62c769e23ddb9af406b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>uniformQuantize2b1b</b> (const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;X, const std::vector&lt; std::unique_ptr&lt; <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &gt;&gt; &amp;XQ, float offset, float inter_center_distance)</td></tr>
<tr class="separator:a858eac856ff7f62c769e23ddb9af406b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1476ad461eaf378d7917e80bce3edb09"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1476ad461eaf378d7917e80bce3edb09"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>qconv</b> (const <a class="el" href="structcaffe2_1_1_conv_args.html">ConvArgs</a> &amp;args, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;X, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;W, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *b, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *Y)</td></tr>
<tr class="separator:a1476ad461eaf378d7917e80bce3edb09"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad17277f2033ff1b4578c1864754c1054"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad17277f2033ff1b4578c1864754c1054"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>qpad_zero</b> (const <a class="el" href="structcaffe2_1_1_conv_args.html">ConvArgs</a> &amp;args, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;X, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *Y)</td></tr>
<tr class="separator:ad17277f2033ff1b4578c1864754c1054"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a708c5c82f39bd355506a0d5e89422bb5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a708c5c82f39bd355506a0d5e89422bb5"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>signQuantize</b> (const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;X, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *XQ)</td></tr>
<tr class="separator:a708c5c82f39bd355506a0d5e89422bb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3400d9dcadd25caed54ad3942ff62493"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3400d9dcadd25caed54ad3942ff62493"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>filterNormalization11</b> (const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;WQ, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *WQN)</td></tr>
<tr class="separator:a3400d9dcadd25caed54ad3942ff62493"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a197ad7509c858d29fc1bf80dc3b9ec92"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a197ad7509c858d29fc1bf80dc3b9ec92"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>filterNormalizationL1</b> (const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;W, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *WL1)</td></tr>
<tr class="separator:a197ad7509c858d29fc1bf80dc3b9ec92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba550b3a9c6fd24a91ad9a114f1bb788"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aba550b3a9c6fd24a91ad9a114f1bb788"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>qim2col</b> (const <a class="el" href="structcaffe2_1_1_conv_args.html">ConvArgs</a> &amp;args, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;XQ, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;WQ, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *XQcol)</td></tr>
<tr class="separator:aba550b3a9c6fd24a91ad9a114f1bb788"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a082c6d0b3cd4fd632e1287358b7d34fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a082c6d0b3cd4fd632e1287358b7d34fe"></a>
std::unique_ptr&lt; <a class="el" href="structcaffe2_1_1_q_conv_state.html">QConvState</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>create2b1bConvState</b> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;W, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *b)</td></tr>
<tr class="separator:a082c6d0b3cd4fd632e1287358b7d34fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94c829fb3b775c8790d3ef0419d6a731"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a94c829fb3b775c8790d3ef0419d6a731"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>run2b1bConvGeneric</b> (<a class="el" href="structcaffe2_1_1_q_conv_state.html">QConvState</a> *state, const <a class="el" href="structcaffe2_1_1_conv_args.html">ConvArgs</a> &amp;args, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;X, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *Y)</td></tr>
<tr class="separator:a94c829fb3b775c8790d3ef0419d6a731"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b77566807b3576fa21053ba071c114a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b77566807b3576fa21053ba071c114a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>run2b1bUnification</b> (<a class="el" href="structcaffe2_1_1_q_conv_state.html">QConvState</a> *state, size_t N, size_t <a class="el" href="struct_c.html">C</a>, const float *WQNVdata, const float *YQs0Vdata, const float *YQs1Vdata, size_t YQstride, float *Ydata, size_t Ystride, const float *bias)</td></tr>
<tr class="separator:a3b77566807b3576fa21053ba071c114a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8246b69b4a3b8c68c512cafd006df397"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8246b69b4a3b8c68c512cafd006df397"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (QConv, <a class="el" href="classcaffe2_1_1_q_conv_op.html">QConvOp</a>)</td></tr>
<tr class="separator:a8246b69b4a3b8c68c512cafd006df397"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac67d9a6a97914fb3a6c54045667b004"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aac67d9a6a97914fb3a6c54045667b004"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><b>divRoundUp</b> (size_t x, size_t d)</td></tr>
<tr class="separator:aac67d9a6a97914fb3a6c54045667b004"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab88af923ed6cef1948561dc4d24d9c9f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab88af923ed6cef1948561dc4d24d9c9f"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>run2b1bConvNeon</b> (<a class="el" href="structcaffe2_1_1_q_conv_state.html">QConvState</a> *state, const <a class="el" href="structcaffe2_1_1_conv_args.html">ConvArgs</a> &amp;args, const <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &amp;X, <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *Y)</td></tr>
<tr class="separator:ab88af923ed6cef1948561dc4d24d9c9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff22675a2de1f5235fc243775d19dbfd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff22675a2de1f5235fc243775d19dbfd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="classcaffe2_1_1_m_p_i_common_world_wrapper.html">MPICommonWorldWrapper</a>)</td></tr>
<tr class="separator:aff22675a2de1f5235fc243775d19dbfd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a606a71d86d33be967f8943fcfd4fcef4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a606a71d86d33be967f8943fcfd4fcef4"></a>
std::mutex &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>MPIMutex</b> ()</td></tr>
<tr class="separator:a606a71d86d33be967f8943fcfd4fcef4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa32a2d15d30c2bff23d742e401ee0841"><td class="memItemLeft" align="right" valign="top">MPI_Comm&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#aa32a2d15d30c2bff23d742e401ee0841">GlobalMPIComm</a> ()</td></tr>
<tr class="memdesc:aa32a2d15d30c2bff23d742e401ee0841"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the global MPI communicator used by Caffe2.  <a href="#aa32a2d15d30c2bff23d742e401ee0841">More...</a><br /></td></tr>
<tr class="separator:aa32a2d15d30c2bff23d742e401ee0841"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a438633cd31c7c1685fcc95cf03a7f7cf"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a438633cd31c7c1685fcc95cf03a7f7cf">SetGlobalMPIComm</a> (MPI_Comm new_comm)</td></tr>
<tr class="memdesc:a438633cd31c7c1685fcc95cf03a7f7cf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the global MPI communicator.  <a href="#a438633cd31c7c1685fcc95cf03a7f7cf">More...</a><br /></td></tr>
<tr class="separator:a438633cd31c7c1685fcc95cf03a7f7cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a652995152af6b9ec5a40f00308568211"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a652995152af6b9ec5a40f00308568211"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a652995152af6b9ec5a40f00308568211">MPICommSize</a> (MPI_Comm comm)</td></tr>
<tr class="memdesc:a652995152af6b9ec5a40f00308568211"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> helper function to return the size of the given communicator. <br /></td></tr>
<tr class="separator:a652995152af6b9ec5a40f00308568211"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad727c228c4acca9113e44f2b1c84a194"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad727c228c4acca9113e44f2b1c84a194"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ad727c228c4acca9113e44f2b1c84a194">MPICommRank</a> (MPI_Comm comm)</td></tr>
<tr class="memdesc:ad727c228c4acca9113e44f2b1c84a194"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> helper function to return the rank of the given communicator. <br /></td></tr>
<tr class="separator:ad727c228c4acca9113e44f2b1c84a194"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4dc2404153d4045abf87562f016a7fa4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a4dc2404153d4045abf87562f016a7fa4">MPISetupPeers</a> (const int replicas, const string &amp;role, const string &amp;job_path)</td></tr>
<tr class="memdesc:a4dc2404153d4045abf87562f016a7fa4"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> function used to perform peer setup so one does not need to use mpirun / mpiexec to run the binary.  <a href="#a4dc2404153d4045abf87562f016a7fa4">More...</a><br /></td></tr>
<tr class="separator:a4dc2404153d4045abf87562f016a7fa4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f3f85d0b09bfde9dc265180f24bf01a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f3f85d0b09bfde9dc265180f24bf01a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>CheckInitializedMPI</b> ()</td></tr>
<tr class="separator:a9f3f85d0b09bfde9dc265180f24bf01a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51ebe7c99de9de6dbfb996980ab3e287"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a51ebe7c99de9de6dbfb996980ab3e287"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Abs, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_abs_functor.html">AbsFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a51ebe7c99de9de6dbfb996980ab3e287"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acff3811d42928bc6109b51619d6ed822"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acff3811d42928bc6109b51619d6ed822"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AbsGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_abs_gradient_functor.html">AbsGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:acff3811d42928bc6109b51619d6ed822"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b503db9e0052571e5b47ea2f9a157ea"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1b503db9e0052571e5b47ea2f9a157ea"></a>
element wise Github workspace FeedBlob(&quot;X&quot;, np.random.randn(5).astype(np.float32)) print(&quot;X&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (AbsGradient).NumInputs(2).NumOutputs(1).IdenticalTypeAndShape()</td></tr>
<tr class="separator:a1b503db9e0052571e5b47ea2f9a157ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bf41d31992d47858547cd42193c8964"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4bf41d31992d47858547cd42193c8964"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Abs, GetAbsGradient)</td></tr>
<tr class="separator:a4bf41d31992d47858547cd42193c8964"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0df747d59995127f18ad03be32131e9d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0df747d59995127f18ad03be32131e9d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Accumulate, <a class="el" href="classcaffe2_1_1_accumulate_op.html">AccumulateOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0df747d59995127f18ad03be32131e9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa99977934dd736d9c2047fe0fbe879af"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa99977934dd736d9c2047fe0fbe879af"></a>
we first initialize the output tensor to all and then do accumulation Any further calls to the&#160;</td><td class="memItemRight" valign="bottom"><b>operator, given that no one else fiddles with the output in the interim, will do simple accumulations.Accumulation is done using Axpby operation as shown:Y=1 *X+gamma *Y where X is the input tensor, Y is the output tensor and gamma is the multiplier argument.) DOC&quot;) .Arg</b> (&quot;gamma&quot;,&quot;(float, default 1.0) Accumulation multiplier&quot;).Input(0</td></tr>
<tr class="separator:aa99977934dd736d9c2047fe0fbe879af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90d5a6ff20e2ced0a7b4f22420527cd8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90d5a6ff20e2ced0a7b4f22420527cd8"></a>
we first initialize the output tensor to all and then do accumulation Any further calls to the The input tensor that has to be accumulated to the output tensor If the output size is not the same as input the output tensor is first reshaped and initialized to and only accumulation is done&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;Accumulated output tensor&quot;)</td></tr>
<tr class="separator:a90d5a6ff20e2ced0a7b4f22420527cd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e78bc14e4f415df7ecbd5dc021f364a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9e78bc14e4f415df7ecbd5dc021f364a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Accumulate)</td></tr>
<tr class="separator:a9e78bc14e4f415df7ecbd5dc021f364a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a226a3949dd6bbe06e017eda3bd9c7871"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a226a3949dd6bbe06e017eda3bd9c7871"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Accuracy, <a class="el" href="classcaffe2_1_1_accuracy_op.html">AccuracyOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a226a3949dd6bbe06e017eda3bd9c7871"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade465a1be9535ecde85ef986fd6433d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade465a1be9535ecde85ef986fd6433d4"></a>
NumInputs(2).NumOutputs(1).ScalarType(TensorProto&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Accuracy)</td></tr>
<tr class="separator:ade465a1be9535ecde85ef986fd6433d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d32f75e5a380425a1e17d615cb9f1ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d32f75e5a380425a1e17d615cb9f1ed"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Acos, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_acos_functor.html">AcosFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a1d32f75e5a380425a1e17d615cb9f1ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad91d314701c55a9de9f6b1205adff793"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad91d314701c55a9de9f6b1205adff793"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AcosGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_acos_gradient_functor.html">AcosGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad91d314701c55a9de9f6b1205adff793"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411386bd927eaf6efde8e598a35a79cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a411386bd927eaf6efde8e598a35a79cb"></a>
element wise DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;input&quot;,&quot;Input tensor&quot;).Output(0</td></tr>
<tr class="separator:a411386bd927eaf6efde8e598a35a79cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a336b4da40391cb74d7fda03c2553dd24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a336b4da40391cb74d7fda03c2553dd24"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Acos, GetAcosGradient)</td></tr>
<tr class="separator:a336b4da40391cb74d7fda03c2553dd24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed9c9ce150c38570f305bb1c7e2e6ea8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed9c9ce150c38570f305bb1c7e2e6ea8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AdjustBatch, <a class="el" href="classcaffe2_1_1_adjust_batch_op.html">AdjustBatchOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aed9c9ce150c38570f305bb1c7e2e6ea8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d188da48705abcf43cb7f5d02c401f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d188da48705abcf43cb7f5d02c401f1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;Input&quot;,&quot;Input data&quot;).Input(1</td></tr>
<tr class="separator:a1d188da48705abcf43cb7f5d02c401f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1ab10f30beaef18092179837fb1b551"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1ab10f30beaef18092179837fb1b551"></a>
Real batch size&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Output&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_data.html">Data</a> with Adjusted batch size&quot;).Output(1</td></tr>
<tr class="separator:ab1ab10f30beaef18092179837fb1b551"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae32c86c292b6e569f0f3638c8d97897c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae32c86c292b6e569f0f3638c8d97897c"></a>
Real batch size Real batah size&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;max_batch_size&quot;,&quot;(*int*): max batch size&quot;).SetDoc(R&quot;DOC( Adjust the batch size of `input` tensor. When we only have 1 input</td></tr>
<tr class="separator:ae32c86c292b6e569f0f3638c8d97897c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aacced94806e0e3664e212f3c1dd6e724"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aacced94806e0e3664e212f3c1dd6e724"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AffineChannel, <a class="el" href="classcaffe2_1_1_affine_channel_op.html">AffineChannelOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aacced94806e0e3664e212f3c1dd6e724"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a138880046ad58ebf127db5b4f2ef6a20"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a138880046ad58ebf127db5b4f2ef6a20"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AffineChannelGradient, <a class="el" href="classcaffe2_1_1_affine_channel_gradient_op.html">AffineChannelGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a138880046ad58ebf127db5b4f2ef6a20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7e075a500fc74f76b041e2f432afafe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad7e075a500fc74f76b041e2f432afafe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (3).NumOutputs(1).AllowInplace(</td></tr>
<tr class="separator:ad7e075a500fc74f76b041e2f432afafe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa79c3a20b5a8076243207b216776525"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa79c3a20b5a8076243207b216776525"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Applies a separate affine transformation to each channel of the input. Useful
for replacing spatial batch norm with its equivalent fixed transformation.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:afa79c3a20b5a8076243207b216776525"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab142ff75605c67e677f6f3a0599b0486"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab142ff75605c67e677f6f3a0599b0486"></a>
Feature map input with order NCHW or NHWC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;scale&quot;,&quot;1D input of shape (C); the c-th element is the scale factor of the &quot;&quot;affine transformation for the c-th channel of the input.&quot;).Input(2</td></tr>
<tr class="separator:ab142ff75605c67e677f6f3a0599b0486"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a808c9f7a9bc8a2717cf5b4e62fdba741"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a808c9f7a9bc8a2717cf5b4e62fdba741"></a>
Feature map input with order NCHW or NHWC input of&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (<a class="el" href="struct_c.html">C</a>)</td></tr>
<tr class="separator:a808c9f7a9bc8a2717cf5b4e62fdba741"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9720e1ad0407baa298c472a794e40871"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9720e1ad0407baa298c472a794e40871"></a>
the c th element is the bias of the affine transformation for the c th channel of the input&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;Output with the same order of Input.&quot;)</td></tr>
<tr class="separator:a9720e1ad0407baa298c472a794e40871"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fb02800eedcc2ffe138e3f33e4cec66"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0fb02800eedcc2ffe138e3f33e4cec66"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> ({2, 3}).NumOutputs(</td></tr>
<tr class="separator:a0fb02800eedcc2ffe138e3f33e4cec66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78ea74c98fdaaa9d2a93e326d3c988fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a78ea74c98fdaaa9d2a93e326d3c988fe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>AllowInplace</b> ({{0, 0}})</td></tr>
<tr class="separator:a78ea74c98fdaaa9d2a93e326d3c988fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a389e705d13db7335cfa69a8a7e106720"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a389e705d13db7335cfa69a8a7e106720"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (AffineChannel, GetAffineChannelGradient)</td></tr>
<tr class="separator:a389e705d13db7335cfa69a8a7e106720"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb83ecccda30ac5eda660ed36f31df39"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adb83ecccda30ac5eda660ed36f31df39"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ArgMax, <a class="el" href="classcaffe2_1_1_arg_op.html">ArgOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_arg_max_reducer.html">ArgMaxReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:adb83ecccda30ac5eda660ed36f31df39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a831934aefbb198e5e194cf4ed6679d15"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a831934aefbb198e5e194cf4ed6679d15"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ArgMin, <a class="el" href="classcaffe2_1_1_arg_op.html">ArgOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_arg_min_reducer.html">ArgMinReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a831934aefbb198e5e194cf4ed6679d15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f052d3bcc423b71530bc2accae13ed0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f052d3bcc423b71530bc2accae13ed0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Asin, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_asin_functor.html">AsinFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a5f052d3bcc423b71530bc2accae13ed0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9148dcf0bb289e8b68e91ddcf5accaa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9148dcf0bb289e8b68e91ddcf5accaa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AsinGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_asin_gradient_functor.html">AsinGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad9148dcf0bb289e8b68e91ddcf5accaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adfb6873d55bcceff9af55c135d7c32ce"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adfb6873d55bcceff9af55c135d7c32ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Asin, GetAsinGradient)</td></tr>
<tr class="separator:adfb6873d55bcceff9af55c135d7c32ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1935fbf87dd5962a9730b559808baa0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1935fbf87dd5962a9730b559808baa0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Assert, <a class="el" href="classcaffe2_1_1_assert_op.html">AssertOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab1935fbf87dd5962a9730b559808baa0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a612960b3119ef74b09f63f88c3ea8059"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a612960b3119ef74b09f63f88c3ea8059"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Atan, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_atan_functor.html">AtanFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a612960b3119ef74b09f63f88c3ea8059"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee51201da77e9a9d9e6a02f588c987b8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aee51201da77e9a9d9e6a02f588c987b8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AtanGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_atan_gradient_functor.html">AtanGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aee51201da77e9a9d9e6a02f588c987b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1418e4bfb72c8332678191c93324ec06"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1418e4bfb72c8332678191c93324ec06"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Atan, GetAtanGradient)</td></tr>
<tr class="separator:a1418e4bfb72c8332678191c93324ec06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3164309da0e94b6370eaa1296d9a191"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab3164309da0e94b6370eaa1296d9a191"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchBucketize, <a class="el" href="classcaffe2_1_1_batch_bucketize_op.html">BatchBucketizeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab3164309da0e94b6370eaa1296d9a191"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0c94dc2ec0920045f3a7eebf4172f92"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af0c94dc2ec0920045f3a7eebf4172f92"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (4).NumOutputs(1).SetDoc(R&quot;DOC( Bucketize the float_features into sparse features. The float_features is a N * <a class="el" href="struct_d.html">D</a> tensor where N is the batch_size</td></tr>
<tr class="separator:af0c94dc2ec0920045f3a7eebf4172f92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f6b3293c9fdceec89c7eacca37b8898"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3f6b3293c9fdceec89c7eacca37b8898"></a>
and <a class="el" href="struct_d.html">D</a> is the feature_dim The indices is a tensor containing the indices of the features that need to be bucketized The lengths is a tensor that splits the following boundaries argument The boundaries is a tensor containing the border list for each feature With in each indices should not have duplicate and the number of elements in indices should be less than or euqal to <a class="el" href="struct_d.html">D</a> Each element in lengths&#160;</td><td class="memItemRight" valign="bottom"><b>vector</b> (lengths[`i`]) represents the number of boundaries in the sub border list.The sum of all elements in`lengths`must be equal to the size of`boundaries`.If lengths[0]</td></tr>
<tr class="separator:a3f6b3293c9fdceec89c7eacca37b8898"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae28b63bd573fb8ac2c243c9f1d158fe9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae28b63bd573fb8ac2c243c9f1d158fe9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchGather, <a class="el" href="classcaffe2_1_1_batch_gather_op.html">BatchGatherOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae28b63bd573fb8ac2c243c9f1d158fe9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aded54ac490ac9528615bf2da79a8a93c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aded54ac490ac9528615bf2da79a8a93c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchGatherGradient, <a class="el" href="classcaffe2_1_1_batch_gather_gradient_op.html">BatchGatherGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aded54ac490ac9528615bf2da79a8a93c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d7ae0dbcf913cf00c9f64eddb8eb3ba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8d7ae0dbcf913cf00c9f64eddb8eb3ba"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Batch gather operation, first dimension in DATA is the batch size.
Given DATA tensor of rank r &gt;= 2, and INDICES tensor of rank q &gt;= 1, gather
entries of the second outer dimension (axis == 1) of DATA indexed by INDICES,
and concatenate them in an output tensor of rank q + (r - 1).

Example:
  DATA  = [
      [1.0, 1.2, 2.4, 4.5],
      [2.3, 3.4, 3.6, 2.3],
      [4.5, 5.7, 1.2, 4.5],
  ]
  INDICES = [0, 2]

  OUTPUT = [
      [1.0, 2.4],
      [2.3, 3.6],
      [4.5, 1.2],
  ]
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a8d7ae0dbcf913cf00c9f64eddb8eb3ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9590799cc93de69c5a33575d93d9e4a7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9590799cc93de69c5a33575d93d9e4a7"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of rank of any rank q&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;OUTPUT&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of rank q + (r - 1).&quot;).InheritOnnxSchema()</td></tr>
<tr class="separator:a9590799cc93de69c5a33575d93d9e4a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a040943feb691c6d2783bfc48d09c4ad6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a040943feb691c6d2783bfc48d09c4ad6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (BatchGatherGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a040943feb691c6d2783bfc48d09c4ad6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c2ab4ef78e8d53533fd78a515f238b3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c2ab4ef78e8d53533fd78a515f238b3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (BatchGather, <a class="el" href="classcaffe2_1_1_get_batch_gather_gradient.html">GetBatchGatherGradient</a>)</td></tr>
<tr class="separator:a3c2ab4ef78e8d53533fd78a515f238b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b50d8d37c31c759a576e1e9dec98a9c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b50d8d37c31c759a576e1e9dec98a9c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchMatMul, <a class="el" href="classcaffe2_1_1_batch_mat_mul_op.html">BatchMatMulOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2b50d8d37c31c759a576e1e9dec98a9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b96df8dd67e4f64e9667e638d405eae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b96df8dd67e4f64e9667e638d405eae"></a>
vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceForBatchMatMul</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a2b96df8dd67e4f64e9667e638d405eae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9918c69fa9b02f835e4c2548d0dcae1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9918c69fa9b02f835e4c2548d0dcae1"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForBatchMatMul</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:ad9918c69fa9b02f835e4c2548d0dcae1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1141b74c0708c627441eec016908db23"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1141b74c0708c627441eec016908db23"></a>
where <a class="el" href="struct_a.html">A</a> has&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (dim0, dim1,...<a class="el" href="struct_m.html">M</a>, K)</td></tr>
<tr class="separator:a1141b74c0708c627441eec016908db23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fbf1fd97d46846af4c0d4415476443f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5fbf1fd97d46846af4c0d4415476443f"></a>
where <a class="el" href="struct_a.html">A</a> has <a class="el" href="struct_b.html">B</a> has&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (dim0, dim1,...K, N)</td></tr>
<tr class="separator:a5fbf1fd97d46846af4c0d4415476443f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a794bb353220a43b6e384befa7f05e35c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a794bb353220a43b6e384befa7f05e35c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchMoments, <a class="el" href="classcaffe2_1_1_batch_moments_op.html">BatchMomentsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a794bb353220a43b6e384befa7f05e35c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a806d5252e13dec295f4d3cf463de2b2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a806d5252e13dec295f4d3cf463de2b2f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchMomentsGradient, <a class="el" href="classcaffe2_1_1_batch_moments_gradient_op.html">BatchMomentsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a806d5252e13dec295f4d3cf463de2b2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29ce949eeee8f6acf204c2db39b48d89"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29ce949eeee8f6acf204c2db39b48d89"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (BatchMoments).NumInputs(1).NumOutputs(2)</td></tr>
<tr class="separator:a29ce949eeee8f6acf204c2db39b48d89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa86ee79023478a3887ba0f6f5c7d6adf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa86ee79023478a3887ba0f6f5c7d6adf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (BatchMomentsGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:aa86ee79023478a3887ba0f6f5c7d6adf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a225624e10d1f6777ea6ae78e78eeaca0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a225624e10d1f6777ea6ae78e78eeaca0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (BatchMoments, GetBatchMomentsGradient)</td></tr>
<tr class="separator:a225624e10d1f6777ea6ae78e78eeaca0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af07d732ffb0cdc05fef37d6e8b8f048c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af07d732ffb0cdc05fef37d6e8b8f048c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchSparseToDense, <a class="el" href="classcaffe2_1_1_batch_sparse_to_dense_op.html">BatchSparseToDenseOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af07d732ffb0cdc05fef37d6e8b8f048c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a441cbca610dea39ea79272ceafd707dd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a441cbca610dea39ea79272ceafd707dd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (3, 4).NumOutputs(1).DisallowInputFillers().SetDoc(R&quot;DOC( Convert sparse matrix representation into dense matrix. <a class="el" href="struct_a.html">A</a> sparse matrix is represented by `lengths` vector</td></tr>
<tr class="separator:a441cbca610dea39ea79272ceafd707dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecf811b86f7ffe9a192a2b133349cf56"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aecf811b86f7ffe9a192a2b133349cf56"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BisectPercentile, <a class="el" href="classcaffe2_1_1_bisect_percentile_op.html">BisectPercentileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aecf811b86f7ffe9a192a2b133349cf56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62234908b599859f7bbba8a0370747a2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62234908b599859f7bbba8a0370747a2"></a>
with the size&#160;</td><td class="memItemRight" valign="bottom"><b>of</b> (batch_size, num_feature)</td></tr>
<tr class="separator:a62234908b599859f7bbba8a0370747a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a99ed7dc601a6897d42f6e539f333f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a99ed7dc601a6897d42f6e539f333f6"></a>
with the size where we also need additional information regarding the feature value distribution There are several vectors to keep data to percentile mappping information as arguments(context) the interpolation is apply&#160;</td><td class="memItemRight" valign="bottom"><b>by</b> (R[t], R[t+1]) and(U[t] and L[t]).As there are F features(F &gt;</td></tr>
<tr class="separator:a3a99ed7dc601a6897d42f6e539f333f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a661de2e8bd57d969076dca9fbbd15c77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a661de2e8bd57d969076dca9fbbd15c77"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BooleanMask, <a class="el" href="classcaffe2_1_1_boolean_mask_op.html">BooleanMaskOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a661de2e8bd57d969076dca9fbbd15c77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6c40f697e54ef82185afeb0d5b9472f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6c40f697e54ef82185afeb0d5b9472f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BooleanMaskLengths, BooleanMaskLengthsOp&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad6c40f697e54ef82185afeb0d5b9472f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c6ed838c14654ec57102ccd17b2c251"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c6ed838c14654ec57102ccd17b2c251"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given a 1D `data` tensor and a boolean `mask` tensor of the same shape, returns a `masked_data` tensor containing only the elements corresponding to positions where the `mask` is True, and a `masked_indices` tensor containing the indices of the True elements.


Github Links:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/boolean_mask_ops.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;BooleanMask&quot;,
    [&quot;data&quot;, &quot;mask&quot;],
    [&quot;masked_data&quot;, &quot;masked_indices&quot;]
)

workspace.FeedBlob(&quot;data&quot;, np.array([1,2,3,4,5,6]))
workspace.FeedBlob(&quot;mask&quot;, np.array([True,False,False,True,True,False]))
print(&quot;data:&quot;, workspace.FetchBlob(&quot;data&quot;))
print(&quot;mask:&quot;, workspace.FetchBlob(&quot;mask&quot;))
workspace.RunOperatorOnce(op)
print(&quot;masked_data:&quot;, workspace.FetchBlob(&quot;masked_data&quot;))
print(&quot;masked_indices:&quot;, workspace.FetchBlob(&quot;masked_indices&quot;))

```

**Result**

```

data: [1 2 3 4 5 6]
mask: [ True False False  True  True False]
masked_data: [1 4 5]
masked_indices: [0 3 4]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a1c6ed838c14654ec57102ccd17b2c251"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af964760d1948a0e497718d520cd020a7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af964760d1948a0e497718d520cd020a7"></a>
same shape as data&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;masked_data&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>*): 1D tensor of same type as `data` input that contains the masked input tensor&quot;).Output(1</td></tr>
<tr class="separator:af964760d1948a0e497718d520cd020a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fdda661bede47c6fd6e8b2d16436459"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1fdda661bede47c6fd6e8b2d16436459"></a>
return the segment lengths of the corresponding segmented tensor after **BooleanMask **is applied If lengths tensor then length of mask tensor must be $a_1 a_2 a_n Github workspace&#160;</td><td class="memItemRight" valign="bottom"><b>FeedBlob</b> (&quot;lengths&quot;, np.array([1, 3, 2], dtype=np.int32)) workspace.FeedBlob(&quot;mask&quot;</td></tr>
<tr class="separator:a1fdda661bede47c6fd6e8b2d16436459"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5361ba15cc4a3015a7b66986eaf9ec38"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5361ba15cc4a3015a7b66986eaf9ec38"></a>
return the segment lengths of the corresponding segmented tensor after **BooleanMask **is applied If lengths tensor then length of mask tensor must be $a_1 a_2 a_n Github workspace np array([False, True, True, False, True, True])) print(&quot;lengths&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (BooleanMaskLengths)</td></tr>
<tr class="separator:a5361ba15cc4a3015a7b66986eaf9ec38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a396cc6a0218fb358da4ef87d070a6b0e"><td class="memTemplParams" colspan="2"><a class="anchor" id="a396cc6a0218fb358da4ef87d070a6b0e"></a>
template&lt;typename Functor &gt; </td></tr>
<tr class="memitem:a396cc6a0218fb358da4ef87d070a6b0e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>MaskWithFunctor</b> (size_t N, size_t <a class="el" href="struct_m.html">M</a>, int <a class="el" href="struct_b.html">B</a>, const float *in, Functor fn, float fill_val, float *out)</td></tr>
<tr class="separator:a396cc6a0218fb358da4ef87d070a6b0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d2dd33050e43e411fc20d2865a804d8"><td class="memTemplParams" colspan="2"><a class="anchor" id="a5d2dd33050e43e411fc20d2865a804d8"></a>
template&lt;typename Functor &gt; </td></tr>
<tr class="memitem:a5d2dd33050e43e411fc20d2865a804d8"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>RepeatedMaskWithFunctor</b> (size_t N, size_t <a class="el" href="struct_m.html">M</a>, int <a class="el" href="struct_d.html">D</a>, const float *in, Functor fn, float fill_val, float *out)</td></tr>
<tr class="separator:a5d2dd33050e43e411fc20d2865a804d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97ac3b44a6339d941867ae3df4f345cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a97ac3b44a6339d941867ae3df4f345cd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SequenceMask, <a class="el" href="classcaffe2_1_1_sequence_mask_op.html">SequenceMaskOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a97ac3b44a6339d941867ae3df4f345cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae052e727bfc0c72e48ddc42578535e54"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae052e727bfc0c72e48ddc42578535e54"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BooleanUnmask, <a class="el" href="classcaffe2_1_1_boolean_unmask_op.html">BooleanUnmaskOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae052e727bfc0c72e48ddc42578535e54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc4a9da9fb1832640970b30cf8839364"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc4a9da9fb1832640970b30cf8839364"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> ([](int n){return n &gt; 0 &amp;&amp;n%2==0;}).NumOutputs(1).SetDoc(R&quot;DOC( Given a series of masks and values</td></tr>
<tr class="separator:abc4a9da9fb1832640970b30cf8839364"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa73d3d18f4fdd57b2c0fd6362f32709f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa73d3d18f4fdd57b2c0fd6362f32709f"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct Note that for all mask there must be at least one True This is not False False we accept the first and no longer expect a value for that False True ***Note that we alternate data and mask inputs Github workspace&#160;</td><td class="memItemRight" valign="bottom"><b>FeedBlob</b> (&quot;mask1&quot;, np.array([True, False, False, True, True, False])) workspace.FeedBlob(&quot;data1&quot;</td></tr>
<tr class="separator:aa73d3d18f4fdd57b2c0fd6362f32709f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3c87d3be73434b46e3cee357b2ec7e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac3c87d3be73434b46e3cee357b2ec7e6"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct Note that for all mask there must be at least one True This is not False False we accept the first and no longer expect a value for that False True ***Note that we alternate data and mask inputs Github workspace np&#160;</td><td class="memItemRight" valign="bottom"><b>array</b> ([1, 4, 5])) workspace.FeedBlob(&quot;mask2&quot;</td></tr>
<tr class="separator:ac3c87d3be73434b46e3cee357b2ec7e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50bd1c4a9c78a89c7ff61776d90c51b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a50bd1c4a9c78a89c7ff61776d90c51b5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ByteWeightDequant, <a class="el" href="classcaffe2_1_1_byte_weight_dequant_op.html">ByteWeightDequantOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a50bd1c4a9c78a89c7ff61776d90c51b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9d04bc184cf56bcb32f74e971bd3c72"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9d04bc184cf56bcb32f74e971bd3c72"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (ByteWeightDequant).NumInputs(1).NumOutputs(1)</td></tr>
<tr class="separator:ad9d04bc184cf56bcb32f74e971bd3c72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e06f847fb5a26f54e6225b3cf9e5c93"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e06f847fb5a26f54e6225b3cf9e5c93"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Cast, <a class="el" href="classcaffe2_1_1_cast_op.html">CastOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6e06f847fb5a26f54e6225b3cf9e5c93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a322565961cb52c6e30b4b0cb280c0b04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a322565961cb52c6e30b4b0cb280c0b04"></a>
out&#160;</td><td class="memItemRight" valign="bottom"><b>push_back</b> (in[0])</td></tr>
<tr class="separator:a322565961cb52c6e30b4b0cb280c0b04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b13bcca4238702e1f3860fb44beecb6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7b13bcca4238702e1f3860fb44beecb6"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>set_data_type</b> (cast::GetCastDataType(helper,&quot;to&quot;))</td></tr>
<tr class="separator:a7b13bcca4238702e1f3860fb44beecb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8726cbe5f09b4c08612d84781d2b9d9b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8726cbe5f09b4c08612d84781d2b9d9b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Casts the elements of a given input tensor to a data type specified by the `to`
argument and returns an output tensor of the same size in the converted type.
The `to` argument must be one of the data types specified in the *DataType*
enum field in the TensorProto message (see below). If the `to` argument is not
provided or is not one of the enumerated types in *DataType*, Caffe2 throws an
Enforce error.

NOTE: Casting from strings is not supported, and casting to strings is only
supported on CPU.

TensorProto *DataType* field:
```
message TensorProto {
  ...
  enum DataType {
    UNDEFINED = 0;
    FLOAT = 1;  // float
    INT32 = 2;  // int
    BYTE = 3;  // BYTE, when deserialized, is going to be restored as uint8.
    STRING = 4;  // string
    BOOL = 5;  // bool
    UINT8 = 6;  // uint8_t
    INT8 = 7;  // int8_t
    UINT16 = 8;  // uint16_t
    INT16 = 9;  // int16_t
    INT64 = 10;  // int64_t
    FLOAT16 = 12;  // <a class="el" href="structc10_1_1_half.html">at::Half</a>
    DOUBLE = 13;  // double
  }
```

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/cast_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Cast&quot;,
    [&quot;X&quot;],
    [&quot;Y&quot;],
    to=2
)

workspace.FeedBlob(&quot;X&quot;, (np.random.rand(3,3)).astype(np.float32)*10)
print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
```

**Result**

```
X: [[9.436466   5.8529844  0.54932857]
 [1.1583444  2.9936118  0.22950427]
 [3.9143739  3.4040766  8.905341  ]]
Y: [[9 5 0]
 [1 2 0]
 [3 3 8]]
```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;to&quot;</td></tr>
<tr class="separator:a8726cbe5f09b4c08612d84781d2b9d9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ca31f20f5f48826244c16253688e969"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8ca31f20f5f48826244c16253688e969"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Cast, <a class="el" href="classcaffe2_1_1_get_cast_gradient.html">GetCastGradient</a>)</td></tr>
<tr class="separator:a8ca31f20f5f48826244c16253688e969"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35697c57448224f7763eb8ed7a977425"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35697c57448224f7763eb8ed7a977425"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Cbrt, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cbrt_functor.html">CbrtFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a35697c57448224f7763eb8ed7a977425"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8476075244f1e8b53fdb8206996f3ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af8476075244f1e8b53fdb8206996f3ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CbrtGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cbrt_gradient_functor.html">CbrtGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:af8476075244f1e8b53fdb8206996f3ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0610e69bcf4c68da9510551055b24a67"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0610e69bcf4c68da9510551055b24a67"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>IdenticalTypeAndShape</b> ().Input(0</td></tr>
<tr class="separator:a0610e69bcf4c68da9510551055b24a67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a193fd9def12bbf14f88df1e133daab4a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a193fd9def12bbf14f88df1e133daab4a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Cbrt, GetCbrtGradient)</td></tr>
<tr class="separator:a193fd9def12bbf14f88df1e133daab4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a674cc31b2aac4d11c3c4c904d500b1bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a674cc31b2aac4d11c3c4c904d500b1bd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Ceil, <a class="el" href="classcaffe2_1_1_ceil_op.html">CeilOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a674cc31b2aac4d11c3c4c904d500b1bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3aa6b1049a63867ea0bcadc14c01cd7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3aa6b1049a63867ea0bcadc14c01cd7f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Element-wise application of the ceil function ($y=ceil(x)$) to the input tensor
`X`. Output tensor shape is the same as the input tensor.

Github Link:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/ceil_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Ceil&quot;,
    [&quot;X&quot;],
    [&quot;X&quot;],
)

workspace.FeedBlob(&quot;X&quot;, (np.random.uniform(-10, 10, (5,5))).astype(np.float32))
print(&quot;X before running op:&quot;, workspace.FetchBlob(&quot;X&quot;))
workspace.RunOperatorOnce(op)
print(&quot;X after running op:&quot;, workspace.FetchBlob(&quot;X&quot;))

```

**Result**

```

X before running op:
[[ 8.44598    -6.5098248  -2.2993476  -7.6859694   0.58566964]
 [-7.846551   -0.03689406  6.9362907  -4.0521703   4.4969673 ]
 [ 0.33355865 -7.895527   -8.393201    9.374202   -2.3930092 ]
 [-6.3061996   3.1403487   3.782099   -8.516556   -2.8387244 ]
 [-2.0164998   4.7663913  -3.422966    0.3636999   8.75713   ]]
X after running op:
[[ 9. -6. -2. -7.  1.]
 [-7. -0.  7. -4.  5.]
 [ 1. -7. -8. 10. -2.]
 [-6.  4.  4. -8. -2.]
 [-2.  5. -3.  1.  9.]]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a3aa6b1049a63867ea0bcadc14c01cd7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44bdb2901e888c0122936d0f7abbc78e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a44bdb2901e888c0122936d0f7abbc78e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>GRADIENT_NOT_IMPLEMENTED_YET</b> (Ceil)</td></tr>
<tr class="separator:a44bdb2901e888c0122936d0f7abbc78e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc1df83ff9b308cd592da73ded0d46cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afc1df83ff9b308cd592da73ded0d46cf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ChannelBackpropStats, <a class="el" href="classcaffe2_1_1_channel_backprop_stats_op.html">ChannelBackpropStatsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afc1df83ff9b308cd592da73ded0d46cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8a94f50e74bbc56721ed4a750faa5bf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa8a94f50e74bbc56721ed4a750faa5bf"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation the results of this op are subsequently reduced over multiple devices to obtain statistics over a larger batch size in cases where the batch size for a single model copy is too low to yield the full benefit of batch normalization The resulting bias and scale can then be plugged back into SpatialBNGradient to get results over the larger batch size DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;The input 4-dimensional tensor of shape NCHW&quot;).Input(1</td></tr>
<tr class="separator:aa8a94f50e74bbc56721ed4a750faa5bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb5e823bd1a5297db0fdd5b420fa89eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afb5e823bd1a5297db0fdd5b420fa89eb"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation the results of this op are subsequently reduced over multiple devices to obtain statistics over a larger batch size in cases where the batch size for a single model copy is too low to yield the full benefit of batch normalization The resulting bias and scale can then be plugged back into SpatialBNGradient to get results over the larger batch size DOC The mean saved from the forward pass as a dimensional tensor of size <a class="el" href="struct_c.html">C</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;inv_std&quot;,&quot;The saved inverse standard deviation as a 1-dimensional tensor &quot;&quot;of size C.&quot;).Input(3</td></tr>
<tr class="separator:afb5e823bd1a5297db0fdd5b420fa89eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac39073bdd0839017842a6ce618c0fcc9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac39073bdd0839017842a6ce618c0fcc9"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation the results of this op are subsequently reduced over multiple devices to obtain statistics over a larger batch size in cases where the batch size for a single model copy is too low to yield the full benefit of batch normalization The resulting bias and scale can then be plugged back into SpatialBNGradient to get results over the larger batch size DOC The mean saved from the forward pass as a dimensional tensor of size <a class="el" href="struct_c.html">C</a> Gradient for the output layer of here used as input because we are on the backward pass&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;scale_grad&quot;,&quot;Gradient for the scale vector&quot;).Output(1</td></tr>
<tr class="separator:ac39073bdd0839017842a6ce618c0fcc9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9cb7dc3fc153a2bcc28ddf48b3981809"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9cb7dc3fc153a2bcc28ddf48b3981809"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (ChannelBackpropStats)</td></tr>
<tr class="separator:a9cb7dc3fc153a2bcc28ddf48b3981809"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5fd5e12bd16695dc92d806b6bd33c8c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae5fd5e12bd16695dc92d806b6bd33c8c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_channel_shuffle.html">ChannelShuffle</a>, <a class="el" href="classcaffe2_1_1_channel_shuffle_op.html">ChannelShuffleOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae5fd5e12bd16695dc92d806b6bd33c8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8fe9a9c691c409365a9e733e9f91580c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8fe9a9c691c409365a9e733e9f91580c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (ChannelShuffleGradient, <a class="el" href="classcaffe2_1_1_channel_shuffle_gradient_op.html">ChannelShuffleGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8fe9a9c691c409365a9e733e9f91580c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1942f40b3c748c8fed39212060a1d1af"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1942f40b3c748c8fed39212060a1d1af"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_channel_shuffle.html">ChannelShuffle</a>, GetChannelShuffleGradient)</td></tr>
<tr class="separator:a1942f40b3c748c8fed39212060a1d1af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8565aab178d2940cf141c30bb3ff7eec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8565aab178d2940cf141c30bb3ff7eec"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ChannelStats, <a class="el" href="classcaffe2_1_1_channel_stats_op.html">ChannelStatsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8565aab178d2940cf141c30bb3ff7eec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a099fb98c647d4c955977cf5b90217e4e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a099fb98c647d4c955977cf5b90217e4e"></a>
computes the sum of all elements per channel and the sum of all elements squared per channel These values can be reduced across multiple batches and used to obtain the mean and variance across the full set of batches Using the new mean and variance as input to SpatialBN has the effect of changing the batch size over which SpatialBN is applied DOC The output dimensional tensor of size <a class="el" href="struct_c.html">C</a> containing the sum of elements of X per channel&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;sumsq&quot;,&quot;The output 1-dimensional tensor of size <a class="el" href="struct_c.html">C</a> containing the sum of &quot;&quot;elements squared per channel.&quot;)</td></tr>
<tr class="separator:a099fb98c647d4c955977cf5b90217e4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a526bfbd0065285dc0b9b45e54fa59228"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a526bfbd0065285dc0b9b45e54fa59228"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (ChannelStats)</td></tr>
<tr class="separator:a526bfbd0065285dc0b9b45e54fa59228"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5193b73ccc1a3de3067c1b65af80f23"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5193b73ccc1a3de3067c1b65af80f23"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_clip.html">Clip</a>, <a class="el" href="classcaffe2_1_1_clip_op.html">ClipOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac5193b73ccc1a3de3067c1b65af80f23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3094a1d4701032391335fe5a5cc13e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3094a1d4701032391335fe5a5cc13e6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (ClipGradient, <a class="el" href="classcaffe2_1_1_clip_gradient_op.html">ClipGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af3094a1d4701032391335fe5a5cc13e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f7126205a3ff8c1be4df06db4fb3888"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f7126205a3ff8c1be4df06db4fb3888"></a>
Key value handler for&#160;</td><td class="memItemRight" valign="bottom"><b>rendezvous</b> (<a class="el" href="classc10_1_1optional.html">optional</a>).&quot;) .Output(0</td></tr>
<tr class="separator:a1f7126205a3ff8c1be4df06db4fb3888"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe63252c455049c7f40f93324a9b05cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe63252c455049c7f40f93324a9b05cf"></a>
Key value handler for <a class="el" href="struct_a.html">A</a> common world for collective operations&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;size&quot;,&quot;(int) size of the common world.&quot;).Arg(&quot;rank&quot;</td></tr>
<tr class="separator:afe63252c455049c7f40f93324a9b05cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a352ced32a1ee4541cf64c748995a1122"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a352ced32a1ee4541cf64c748995a1122"></a>
Existing common world to clone&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;comm_world&quot;,&quot;<a class="el" href="struct_a.html">A</a> common world for collective operations.&quot;)</td></tr>
<tr class="separator:a352ced32a1ee4541cf64c748995a1122"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9010828041090f5fadf2cf3e2074736"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae9010828041090f5fadf2cf3e2074736"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (&quot;Closes all connections managed by a common world.&quot;).Input(0</td></tr>
<tr class="separator:ae9010828041090f5fadf2cf3e2074736"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af03995f4439ef58b918ffe3238b82ab8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af03995f4439ef58b918ffe3238b82ab8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputsOutputs</b> ([](int in, int out){return in &gt;=2 &amp;&amp;out==(in-1);}).EnforceInplace([](int in</td></tr>
<tr class="separator:af03995f4439ef58b918ffe3238b82ab8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3438d55622475b55fb31e6f03f497a94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3438d55622475b55fb31e6f03f497a94"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>InputsCanCrossDevices</b> ().IdenticalTypeAndShapeOfInput(0).SetDoc(R&quot;DOC( Does a broadcast operation from the root node to every other node. The tensor on each node should have been pre-created with the same shape and data type. )DOC&quot;).Input(0</td></tr>
<tr class="separator:a3438d55622475b55fb31e6f03f497a94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9a1d56d6f1999f599063f59417f5ed0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab9a1d56d6f1999f599063f59417f5ed0"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;X&quot;,&quot;<a class="el" href="struct_a.html">A</a> tensor to be broadcasted.&quot;).Output(0</td></tr>
<tr class="separator:ab9a1d56d6f1999f599063f59417f5ed0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af43b93d19f3c2f0a95acb89b83bdf3e2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af43b93d19f3c2f0a95acb89b83bdf3e2"></a>
The common world In place as input&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;root&quot;,&quot;(int, default 0) the root to run broadcast from.&quot;)</td></tr>
<tr class="separator:af43b93d19f3c2f0a95acb89b83bdf3e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13738a8111fabbb2d9af67defb447672"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a13738a8111fabbb2d9af67defb447672"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;X&quot;,&quot;<a class="el" href="struct_a.html">A</a> tensor to be reduced.&quot;).Output(0</td></tr>
<tr class="separator:a13738a8111fabbb2d9af67defb447672"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6bed02a1873b66e7d1e3113b438c8523"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6bed02a1873b66e7d1e3113b438c8523"></a>
The common world The reduced result on not set for other nodes&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;root&quot;,&quot;(int, default 0) the root to run reduce into.&quot;)</td></tr>
<tr class="separator:a6bed02a1873b66e7d1e3113b438c8523"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a0f62d6920884fe591ee7ba9969554f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a0f62d6920884fe591ee7ba9969554f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>IdenticalTypeAndShapeOfInput</b> (0).InputsCanCrossDevices().SetDoc(R&quot;DOC( Does an allreduce operation among the nodes. Currently only <a class="el" href="class_sum.html">Sum</a> is supported. )DOC&quot;).Input(0</td></tr>
<tr class="separator:a0a0f62d6920884fe591ee7ba9969554f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80436037cf60851be3a681f7b6a73b5f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a80436037cf60851be3a681f7b6a73b5f"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;X&quot;,&quot;<a class="el" href="struct_a.html">A</a> tensor to be allreduced.&quot;).Output(0</td></tr>
<tr class="separator:a80436037cf60851be3a681f7b6a73b5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0c4bdf578dafa89c7286ea3dc8f5bec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af0c4bdf578dafa89c7286ea3dc8f5bec"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;X&quot;,&quot;<a class="el" href="struct_a.html">A</a> tensor to be reduce-scattered.&quot;).Output(0</td></tr>
<tr class="separator:af0c4bdf578dafa89c7286ea3dc8f5bec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04940b0368e8abf47fb4ff668c782c73"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04940b0368e8abf47fb4ff668c782c73"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (2, INT_MAX).NumOutputs(1).InputsCanCrossDevices().SetDoc(R&quot;DOC( Does an allgather operation among the nodes. )DOC&quot;).Input(0</td></tr>
<tr class="separator:a04940b0368e8abf47fb4ff668c782c73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad240ba46f9e11ce06726e01a84baaf02"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad240ba46f9e11ce06726e01a84baaf02"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;X&quot;,&quot;<a class="el" href="struct_a.html">A</a> tensor to be allgathered.&quot;).Output(0</td></tr>
<tr class="separator:ad240ba46f9e11ce06726e01a84baaf02"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea90562061faa0f4d3b04d8850fa1f67"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea90562061faa0f4d3b04d8850fa1f67"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> ({2, 4}).NumOutputs(0).SetDoc(R&quot;DOC( Sends the tensor to another node. )DOC&quot;).Input(0</td></tr>
<tr class="separator:aea90562061faa0f4d3b04d8850fa1f67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a326f3fbd7dcbe18be897b2c3630597e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a326f3fbd7dcbe18be897b2c3630597e1"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the to argument of the op&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;tag&quot;,&quot;An int CPUtensor of size 1 specifying the tag to &quot;&quot;send the tensor with. This overrides the 'tag' &quot;&quot;argument of the op.&quot;).Arg(&quot;dst&quot;</td></tr>
<tr class="separator:a326f3fbd7dcbe18be897b2c3630597e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4fe2a8704dc473476b0c22866fb5947"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab4fe2a8704dc473476b0c22866fb5947"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the to argument of the op The rank to send the tensor to&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;tag&quot;,&quot;(int) a tag to send the tensor with.&quot;).Arg(&quot;raw_buffer&quot;</td></tr>
<tr class="separator:ab4fe2a8704dc473476b0c22866fb5947"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10a112d7275e092bef316540a56d4cc3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a10a112d7275e092bef316540a56d4cc3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>AllowInplace</b> ({{2, 1},{3, 2}}).SetDoc(R&quot;DOC( Receives the tensor from another node. )DOC&quot;).Input(0</td></tr>
<tr class="separator:a10a112d7275e092bef316540a56d4cc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a192f36f04e67af2705e1a0035b82fed9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a192f36f04e67af2705e1a0035b82fed9"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;Y&quot;,&quot;In-place output. If raw_buffer is specified, &quot;&quot;Y should have pre-allocated data and type..&quot;).Input(2</td></tr>
<tr class="separator:a192f36f04e67af2705e1a0035b82fed9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0fd97021b8de20cf267d263a5986ba0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae0fd97021b8de20cf267d263a5986ba0"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the from argument of the op The received tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;src&quot;,&quot;The sender that sent the message as a CPUTensor &quot;&quot;of size 1 and of type int.&quot;).Output(2</td></tr>
<tr class="separator:ae0fd97021b8de20cf267d263a5986ba0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32a2a1a6b73ca4c422a472bae0fa6852"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32a2a1a6b73ca4c422a472bae0fa6852"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the from argument of the op The received tensor The tag that the message is sent with as a CPUTensor of size and of type int&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;src&quot;,&quot;(int) he rank to receive the tensor from.&quot;).Arg(&quot;tag&quot;</td></tr>
<tr class="separator:a32a2a1a6b73ca4c422a472bae0fa6852"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2170ab87b7a01bda5058b55cd7a7568"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2170ab87b7a01bda5058b55cd7a7568"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the from argument of the op The received tensor The tag that the message is sent with as a CPUTensor of size and of type int int a tag to receive the tensor with&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;raw_buffer&quot;,&quot;(bool) if set, only send the content and assume that the receiver &quot;&quot;has already known the tensor's shape and information.&quot;)</td></tr>
<tr class="separator:ab2170ab87b7a01bda5058b55cd7a7568"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad49539000e2a5fc0eed28624a67cc016"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad49539000e2a5fc0eed28624a67cc016"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (CreateCommonWorld)</td></tr>
<tr class="separator:ad49539000e2a5fc0eed28624a67cc016"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd80fe8cac2b741aa8fa72047c63e664"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd80fe8cac2b741aa8fa72047c63e664"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (CloneCommonWorld)</td></tr>
<tr class="separator:acd80fe8cac2b741aa8fa72047c63e664"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19ae8b96d0cee85e6a82db74a3618dc2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a19ae8b96d0cee85e6a82db74a3618dc2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (DestroyCommonWorld)</td></tr>
<tr class="separator:a19ae8b96d0cee85e6a82db74a3618dc2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21c8f29f71652e7c3a907d4535eb6159"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a21c8f29f71652e7c3a907d4535eb6159"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Broadcast)</td></tr>
<tr class="separator:a21c8f29f71652e7c3a907d4535eb6159"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48195cc4cdfc484aff4e373cd0648805"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a48195cc4cdfc484aff4e373cd0648805"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Reduce)</td></tr>
<tr class="separator:a48195cc4cdfc484aff4e373cd0648805"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a486e2bba9d4e92afa02816e855cafd6e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a486e2bba9d4e92afa02816e855cafd6e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Allgather)</td></tr>
<tr class="separator:a486e2bba9d4e92afa02816e855cafd6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3650a7bd191ce63b9d6d128755473a84"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3650a7bd191ce63b9d6d128755473a84"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Allreduce)</td></tr>
<tr class="separator:a3650a7bd191ce63b9d6d128755473a84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a850c724e821d0034ae05de7c615c444a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a850c724e821d0034ae05de7c615c444a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (ReduceScatter)</td></tr>
<tr class="separator:a850c724e821d0034ae05de7c615c444a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75ea3114660c16d1481ce94385984ea0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75ea3114660c16d1481ce94385984ea0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (<a class="el" href="struct_barrier.html">Barrier</a>)</td></tr>
<tr class="separator:a75ea3114660c16d1481ce94385984ea0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1af05c9bf4569fc7a1e46136e8662568"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1af05c9bf4569fc7a1e46136e8662568"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (SendTensor)</td></tr>
<tr class="separator:a1af05c9bf4569fc7a1e46136e8662568"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a809d0c77d10a4a63338f8ca0fbc47de3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a809d0c77d10a4a63338f8ca0fbc47de3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (ReceiveTensor)</td></tr>
<tr class="separator:a809d0c77d10a4a63338f8ca0fbc47de3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82ffb04b412a41b84a40a7fd9b6af946"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a82ffb04b412a41b84a40a7fd9b6af946"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CreateCommonWorld, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a82ffb04b412a41b84a40a7fd9b6af946"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01f12b032101d7aa1e795701b551e4b3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01f12b032101d7aa1e795701b551e4b3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CloneCommonWorld, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a01f12b032101d7aa1e795701b551e4b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9201ba82eb22aa93623df5a9fbace5cc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9201ba82eb22aa93623df5a9fbace5cc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DestroyCommonWorld, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9201ba82eb22aa93623df5a9fbace5cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafd7b087b2d8b2dc61f4f112ca50e9a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aafd7b087b2d8b2dc61f4f112ca50e9a1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Broadcast, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aafd7b087b2d8b2dc61f4f112ca50e9a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aacce28a459d4946861f99180a38be193"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aacce28a459d4946861f99180a38be193"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Reduce, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aacce28a459d4946861f99180a38be193"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa19489cdede91acaa8530900fdfae472"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa19489cdede91acaa8530900fdfae472"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Allgather, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa19489cdede91acaa8530900fdfae472"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38bf22b5e8ec68635f0d7351a55d8ea9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38bf22b5e8ec68635f0d7351a55d8ea9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Allreduce, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a38bf22b5e8ec68635f0d7351a55d8ea9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a9fe18433659566bdad6651064056fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8a9fe18433659566bdad6651064056fe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceScatter, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8a9fe18433659566bdad6651064056fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0484a83e1404939b456a983ec76da4b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa0484a83e1404939b456a983ec76da4b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="struct_barrier.html">Barrier</a>, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa0484a83e1404939b456a983ec76da4b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a563f491bf45a8612a48b0f04bfe435"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a563f491bf45a8612a48b0f04bfe435"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SendTensor, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3a563f491bf45a8612a48b0f04bfe435"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26a16bcddd44f6b9d0f58f054404c8be"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a26a16bcddd44f6b9d0f58f054404c8be"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReceiveTensor, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a26a16bcddd44f6b9d0f58f054404c8be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c9536c5e72afa35d3384fcea4e85915"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c9536c5e72afa35d3384fcea4e85915"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CreateCommonWorld, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a3c9536c5e72afa35d3384fcea4e85915"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae687b04805f1b278252e645b04845609"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae687b04805f1b278252e645b04845609"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CloneCommonWorld, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ae687b04805f1b278252e645b04845609"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78998b74f7a886416d7a5cd6c98e1d0d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a78998b74f7a886416d7a5cd6c98e1d0d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Broadcast, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a78998b74f7a886416d7a5cd6c98e1d0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41cf14488f591c1013139b4fb48fcb05"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a41cf14488f591c1013139b4fb48fcb05"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Reduce, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a41cf14488f591c1013139b4fb48fcb05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bb5146bdc443e27be1d0feb34aa305c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8bb5146bdc443e27be1d0feb34aa305c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Allgather, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a8bb5146bdc443e27be1d0feb34aa305c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25e6a068bd3b4a89754a5d5db34d414b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a25e6a068bd3b4a89754a5d5db34d414b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Allreduce, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a25e6a068bd3b4a89754a5d5db34d414b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1514f4ab94c412972f50cc3f9fd2110c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1514f4ab94c412972f50cc3f9fd2110c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (SendTensor, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a1514f4ab94c412972f50cc3f9fd2110c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37e2dadc8ec3fab95bd31ae67f00ac04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a37e2dadc8ec3fab95bd31ae67f00ac04"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ReceiveTensor, <a class="el" href="classcaffe2_1_1_no_default_engine_op.html">NoDefaultEngineOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a37e2dadc8ec3fab95bd31ae67f00ac04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f36c0089fc94b6017420b6e513ea631"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f36c0089fc94b6017420b6e513ea631"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Split, <a class="el" href="classcaffe2_1_1_split_op.html">SplitOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9f36c0089fc94b6017420b6e513ea631"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab089bb69bcb27f5506addabae293b8e9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab089bb69bcb27f5506addabae293b8e9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SplitByLengths, <a class="el" href="classcaffe2_1_1_split_by_lengths_op.html">SplitByLengthsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab089bb69bcb27f5506addabae293b8e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d2b2061d5d62eae72ba640d8db13464"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0d2b2061d5d62eae72ba640d8db13464"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;input&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>*): tensor to split&quot;).Input(1</td></tr>
<tr class="separator:a0d2b2061d5d62eae72ba640d8db13464"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa67ad3559d8eb84f7b226649cbd21003"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa67ad3559d8eb84f7b226649cbd21003"></a>
INT_MAX *&#160;</td><td class="memItemRight" valign="bottom"><b>Tuple</b> (int)*):length of each output&quot;)    .Arg(        &quot;order&quot;,        &quot;(*string *):order of dimensions of input and output blobs;either\&quot;NCHW\&quot; or \&quot;NHWC\&quot;&quot;).Output(0,&quot;[output_0, output_1, ...]&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>*): output tensor&quot;).DeviceInferenceFunction(splitOpDevInfer).SetDoc(R&quot;DOC(Split an `input` tensor into a list of tensors, along the axis specified by the `axis` dimension. The lengths of the split can be specified using argument `split` or <a class="el" href="classc10_1_1optional.html">optional</a> second input blob to the operator. Otherwise, the tensor is split to equal sized parts.Github Links:- https:&lt;details&gt;&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;**Code**```workspace.ResetWorkspace()op = core.CreateOperator(    &quot;Split&quot;,    [&quot;input&quot;],    [&quot;output_0&quot;,&quot;output_1&quot;,&quot;output_2&quot;],    split=(3,2,4),    axis=0)workspace.FeedBlob(&quot;input&quot;, np.random.randint(10, size=(9)))print(&quot;input:&quot;, workspace.FetchBlob(&quot;input&quot;))workspace.RunOperatorOnce(op)print(&quot;output_0:&quot;, workspace.FetchBlob(&quot;output_0&quot;))print(&quot;output_1:&quot;, workspace.FetchBlob(&quot;output_1&quot;))print(&quot;output_2:&quot;, workspace.FetchBlob(&quot;output_2&quot;))```**Result**```input: [2 2 6 6 6 0 5 7 4]output_0: [2 2 6]output_1: [6 6]output_2: [0 5 7 4]```&lt;/details&gt;)DOC&quot;).InheritOnnxSchema(</td></tr>
<tr class="separator:aa67ad3559d8eb84f7b226649cbd21003"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2796d3e2dd75c75b4dcc84d8d912b044"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2796d3e2dd75c75b4dcc84d8d912b044"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;input&quot;,&quot;The tensor to split&quot;).Input(1</td></tr>
<tr class="separator:a2796d3e2dd75c75b4dcc84d8d912b044"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac606be3cd58350baf8770b70a51e3d28"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac606be3cd58350baf8770b70a51e3d28"></a>
INT_MAX The tensor l_i indicates the logic block of input&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;axis&quot;,&quot;Which axis to split on&quot;).Arg(&quot;order&quot;</td></tr>
<tr class="separator:ac606be3cd58350baf8770b70a51e3d28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab71343c807a71597b8ad9ced315c2d05"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab71343c807a71597b8ad9ced315c2d05"></a>
INT_MAX The tensor l_i indicates the logic block of input Either NHWC or will split on <a class="el" href="struct_c.html">C</a> defaults to NCHW&#160;</td><td class="memItemRight" valign="bottom"><b>DeviceInferenceFunction</b> ([](const OperatorDef &amp;def){auto op_device=def.has_device_option()?def.device_option():DeviceOption();vector&lt; DeviceOption &gt; in_dev(def.input_size(), op_device);vector&lt; DeviceOption &gt; out_dev(def.output_size(), op_device);in_dev[1]=DeviceOption();return std::make_pair(in_dev, out_dev);}).SetDoc(R&quot;DOC( Split a tensor into a list of tensors</td></tr>
<tr class="separator:ab71343c807a71597b8ad9ced315c2d05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4d87b96fb7dd715e60f151c567e9b01"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab4d87b96fb7dd715e60f151c567e9b01"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForConcat</b> (const OperatorDef &amp;def, const std::vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:ab4d87b96fb7dd715e60f151c567e9b01"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3da541dfee6f2c34862ebfcdd4af57e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3da541dfee6f2c34862ebfcdd4af57e4"></a>
std::vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceForConcat</b> (const OperatorDef &amp;def, const std::vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a3da541dfee6f2c34862ebfcdd4af57e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbf259b0449f20ec531eca7fab0c7c08"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adbf259b0449f20ec531eca7fab0c7c08"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Split, <a class="el" href="classcaffe2_1_1_split_op.html">SplitOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:adbf259b0449f20ec531eca7fab0c7c08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c0a837afc1d3fc0bb6641916b60d183"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0c0a837afc1d3fc0bb6641916b60d183"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_concat.html">Concat</a>, <a class="el" href="classcaffe2_1_1_concat_op.html">ConcatOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a0c0a837afc1d3fc0bb6641916b60d183"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bf43127339fd7014056ad39fa6ab9a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7bf43127339fd7014056ad39fa6ab9a5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (DepthSplit, <a class="el" href="classcaffe2_1_1_split_op.html">SplitOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a7bf43127339fd7014056ad39fa6ab9a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe48756a227d7227b1c04866552fa49e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe48756a227d7227b1c04866552fa49e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (DepthConcat, <a class="el" href="classcaffe2_1_1_concat_op.html">ConcatOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:abe48756a227d7227b1c04866552fa49e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addf779c704b25000fa588f37590fcc12"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="addf779c704b25000fa588f37590fcc12"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (SplitByLengths, <a class="el" href="classcaffe2_1_1_split_by_lengths_op.html">SplitByLengthsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:addf779c704b25000fa588f37590fcc12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3daa15e8091929ad231fc747b512a49e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3daa15e8091929ad231fc747b512a49e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Conditional, <a class="el" href="classcaffe2_1_1_conditional_op.html">ConditionalOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3daa15e8091929ad231fc747b512a49e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a831a644375c51e977b484f4bb0b3eb42"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a831a644375c51e977b484f4bb0b3eb42"></a>
apply conditional&#160;</td><td class="memItemRight" valign="bottom"><b>operator along the first dimension of DataT and DataF and return DataO.Note, DataT and DataF must have the exact same shape and type.) DOC&quot;) .Input</b> (0,&quot;Condition&quot;,&quot;Boolean tensor to select DataT or DataF&quot;).Input(1</td></tr>
<tr class="separator:a831a644375c51e977b484f4bb0b3eb42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42a0aed8fa5c46c6a597ae99d45d2c81"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42a0aed8fa5c46c6a597ae99d45d2c81"></a>
apply conditional <a class="el" href="classnom_1_1repr_1_1_data.html">Data</a> to use when True&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;DataF&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_data.html">Data</a> to use when False&quot;).Output(0</td></tr>
<tr class="separator:a42a0aed8fa5c46c6a597ae99d45d2c81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6849ec894600bc448cd973150171958"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab6849ec894600bc448cd973150171958"></a>
apply conditional <a class="el" href="classnom_1_1repr_1_1_data.html">Data</a> to use when True Output data after applying <a class="el" href="classcaffe2_1_1_conditional_op.html">ConditionalOp</a>&#160;</td><td class="memItemRight" valign="bottom"><b>IdenticalTypeAndShapeOfInput</b> (1)</td></tr>
<tr class="separator:ab6849ec894600bc448cd973150171958"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a257fa8ed03c06d3e11a454096c47b128"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a257fa8ed03c06d3e11a454096c47b128"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Conditional)</td></tr>
<tr class="separator:a257fa8ed03c06d3e11a454096c47b128"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae169497bf58a97769f50155cfea925e3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae169497bf58a97769f50155cfea925e3"></a>
std::vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceForConvGradient</b> (const OperatorDef &amp;def, const std::vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:ae169497bf58a97769f50155cfea925e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bd72f4e6821b0c8b10c85f8f60d9440"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3bd72f4e6821b0c8b10c85f8f60d9440"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForConvGradient</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;inputs)</td></tr>
<tr class="separator:a3bd72f4e6821b0c8b10c85f8f60d9440"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2de298be2221d805d6cf340faa5c2265"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2de298be2221d805d6cf340faa5c2265"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ConvGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2de298be2221d805d6cf340faa5c2265"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08e3297e8730472e35611b817657a65a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08e3297e8730472e35611b817657a65a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (2, 3).NumOutputs(1</td></tr>
<tr class="separator:a08e3297e8730472e35611b817657a65a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c8cc42dc7617183c1fcc40788281ed5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c8cc42dc7617183c1fcc40788281ed5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> (TensorInferenceForConvGradient).CostInferenceFunction(CostInferenceForConvGradient)</td></tr>
<tr class="separator:a6c8cc42dc7617183c1fcc40788281ed5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0dfdb1488130c01386f73e009ebdea3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0dfdb1488130c01386f73e009ebdea3e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Conv1DGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0dfdb1488130c01386f73e009ebdea3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad62e6db089dfe1d69e2ca5cbf652967f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad62e6db089dfe1d69e2ca5cbf652967f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Conv1DGradient).NumInputs(2</td></tr>
<tr class="separator:ad62e6db089dfe1d69e2ca5cbf652967f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ee0f2953743f1be66bc714e4f62e400"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1ee0f2953743f1be66bc714e4f62e400"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumOutputs</b> (1, 3)</td></tr>
<tr class="separator:a1ee0f2953743f1be66bc714e4f62e400"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac11dcdfa25eba74b23ae88c1f44ba203"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac11dcdfa25eba74b23ae88c1f44ba203"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Conv2DGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac11dcdfa25eba74b23ae88c1f44ba203"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5f149930c99026da1f513db4befb90c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae5f149930c99026da1f513db4befb90c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Conv2DGradient).NumInputs(2</td></tr>
<tr class="separator:ae5f149930c99026da1f513db4befb90c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d87b91c30feba32d163573ad815f0ce"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8d87b91c30feba32d163573ad815f0ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Conv3DGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8d87b91c30feba32d163573ad815f0ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a862914a1ce4ce4da75ad17b8858e55ea"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a862914a1ce4ce4da75ad17b8858e55ea"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Conv3DGradient).NumInputs(2</td></tr>
<tr class="separator:a862914a1ce4ce4da75ad17b8858e55ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0539c8ad037562f59ed975c7ac7f228"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0539c8ad037562f59ed975c7ac7f228"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_conv.html">Conv</a>, <a class="el" href="classcaffe2_1_1_get_conv_gradient.html">GetConvGradient</a>)</td></tr>
<tr class="separator:ab0539c8ad037562f59ed975c7ac7f228"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50e1facdf457ef2f4a647bd0c1ef778c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a50e1facdf457ef2f4a647bd0c1ef778c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Conv1D, <a class="el" href="classcaffe2_1_1_get_conv_gradient.html">GetConvGradient</a>)</td></tr>
<tr class="separator:a50e1facdf457ef2f4a647bd0c1ef778c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ff75df71a3e0f3d4fb9d75cf0482770"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3ff75df71a3e0f3d4fb9d75cf0482770"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Conv2D, <a class="el" href="classcaffe2_1_1_get_conv_gradient.html">GetConvGradient</a>)</td></tr>
<tr class="separator:a3ff75df71a3e0f3d4fb9d75cf0482770"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3d7d7984044891abad49d3f2bb4e5e2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3d7d7984044891abad49d3f2bb4e5e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Conv3D, <a class="el" href="classcaffe2_1_1_get_conv_gradient.html">GetConvGradient</a>)</td></tr>
<tr class="separator:af3d7d7984044891abad49d3f2bb4e5e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cdb4117c1bb618fdcb09cc2ac08a05b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4cdb4117c1bb618fdcb09cc2ac08a05b"></a>
std::function&lt; void(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>ConvDocGenerator</b> (const char *dim)</td></tr>
<tr class="separator:a4cdb4117c1bb618fdcb09cc2ac08a05b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4a8f1035b50560b24e2f5e6abcbd334"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af4a8f1035b50560b24e2f5e6abcbd334"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_conv.html">Conv</a>, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af4a8f1035b50560b24e2f5e6abcbd334"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a035c36ce45aefac076a5c9ac8a7f9c9f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a035c36ce45aefac076a5c9ac8a7f9c9f"></a>
NumInputs(2, 3).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Conv1D, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a035c36ce45aefac076a5c9ac8a7f9c9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e40db5ddd44443696571030136db98e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e40db5ddd44443696571030136db98e"></a>
NumInputs(2, 3).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Conv2D, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4e40db5ddd44443696571030136db98e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e2db24bf5f19e28466d9ae3faa94d10"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e2db24bf5f19e28466d9ae3faa94d10"></a>
NumInputs(2, 3).NumOutputs(1).CostInferenceFunction(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a>&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Conv3D, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0e2db24bf5f19e28466d9ae3faa94d10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a55e76f6280fa3c180bc1c5575d7031"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a55e76f6280fa3c180bc1c5575d7031"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="class_conv.html">Conv</a>, <a class="el" href="classcaffe2_1_1_cudnn_conv_op.html">CudnnConvOp</a>)</td></tr>
<tr class="separator:a3a55e76f6280fa3c180bc1c5575d7031"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ababe80cf5ad02fd87783df2f3bd68913"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ababe80cf5ad02fd87783df2f3bd68913"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (ConvGradient, <a class="el" href="classcaffe2_1_1_cudnn_conv_gradient_op.html">CudnnConvGradientOp</a>)</td></tr>
<tr class="separator:ababe80cf5ad02fd87783df2f3bd68913"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abef673b86ba934e008ccb3d8ef8fe6b8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abef673b86ba934e008ccb3d8ef8fe6b8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Conv1D, <a class="el" href="classcaffe2_1_1_cudnn_conv_op.html">CudnnConvOp</a>)</td></tr>
<tr class="separator:abef673b86ba934e008ccb3d8ef8fe6b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedf00e30165169fd98a32db8725a60ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aedf00e30165169fd98a32db8725a60ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Conv1DGradient, <a class="el" href="classcaffe2_1_1_cudnn_conv_gradient_op.html">CudnnConvGradientOp</a>)</td></tr>
<tr class="separator:aedf00e30165169fd98a32db8725a60ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1008188d46c33ac672d2716970e9b529"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1008188d46c33ac672d2716970e9b529"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Conv2D, <a class="el" href="classcaffe2_1_1_cudnn_conv_op.html">CudnnConvOp</a>)</td></tr>
<tr class="separator:a1008188d46c33ac672d2716970e9b529"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a65994e157c44fc7c7b2fc88bb67d08"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a65994e157c44fc7c7b2fc88bb67d08"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Conv2DGradient, <a class="el" href="classcaffe2_1_1_cudnn_conv_gradient_op.html">CudnnConvGradientOp</a>)</td></tr>
<tr class="separator:a5a65994e157c44fc7c7b2fc88bb67d08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79c17613f95bd532fba0b3e9b8e91fe8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79c17613f95bd532fba0b3e9b8e91fe8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Conv3D, <a class="el" href="classcaffe2_1_1_cudnn_conv_op.html">CudnnConvOp</a>)</td></tr>
<tr class="separator:a79c17613f95bd532fba0b3e9b8e91fe8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6728f13e1f07639c0a4064b50cc7487"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab6728f13e1f07639c0a4064b50cc7487"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Conv3DGradient, <a class="el" href="classcaffe2_1_1_cudnn_conv_gradient_op.html">CudnnConvGradientOp</a>)</td></tr>
<tr class="separator:ab6728f13e1f07639c0a4064b50cc7487"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0080513a31b41074defde34c59a7631d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0080513a31b41074defde34c59a7631d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_conv.html">Conv</a>, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a0080513a31b41074defde34c59a7631d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4d484f11ab3fc6b654748ee90835d42"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4d484f11ab3fc6b654748ee90835d42"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ConvGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aa4d484f11ab3fc6b654748ee90835d42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2670912f01d9b13ad0c7f051fb231eaa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2670912f01d9b13ad0c7f051fb231eaa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Conv1D, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a2670912f01d9b13ad0c7f051fb231eaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f8b3d9c6aa7dbcd9e4e1778bd7eb761"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2f8b3d9c6aa7dbcd9e4e1778bd7eb761"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Conv1DGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a2f8b3d9c6aa7dbcd9e4e1778bd7eb761"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e3c0504914ea9f630a02b80e96233c0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e3c0504914ea9f630a02b80e96233c0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Conv2D, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a6e3c0504914ea9f630a02b80e96233c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7e4417c57afc2b9d325a88e9ce1f47c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad7e4417c57afc2b9d325a88e9ce1f47c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Conv2DGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ad7e4417c57afc2b9d325a88e9ce1f47c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad747122b1d6b00d39fb715796975f6f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aad747122b1d6b00d39fb715796975f6f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Conv3D, <a class="el" href="classcaffe2_1_1_conv_op.html">ConvOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aad747122b1d6b00d39fb715796975f6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c75eedba15c075b77730337efc10e59"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c75eedba15c075b77730337efc10e59"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Conv3DGradient, <a class="el" href="classcaffe2_1_1_conv_gradient_op.html">ConvGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a3c75eedba15c075b77730337efc10e59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f88a107a6c3915d6363926a599dca0c"><td class="memTemplParams" colspan="2"><a class="anchor" id="a9f88a107a6c3915d6363926a599dca0c"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a9f88a107a6c3915d6363926a599dca0c"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>createSharedBuffer&lt; CPUContext &gt;</b> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws)</td></tr>
<tr class="separator:a9f88a107a6c3915d6363926a599dca0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a228e35fc9b7851bc398a5e9b5ff2b1de"><td class="memTemplParams" colspan="2"><a class="anchor" id="a228e35fc9b7851bc398a5e9b5ff2b1de"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a228e35fc9b7851bc398a5e9b5ff2b1de"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>runWithSharedBuffer&lt; CPUContext &gt;</b> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws, std::function&lt; void(<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *buffer)&gt; f)</td></tr>
<tr class="separator:a228e35fc9b7851bc398a5e9b5ff2b1de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bab26d8f00817d54cb0d975ea633123"><td class="memTemplParams" colspan="2">template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a5bab26d8f00817d54cb0d975ea633123"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a5bab26d8f00817d54cb0d975ea633123">createSharedBuffer</a> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws)</td></tr>
<tr class="memdesc:a5bab26d8f00817d54cb0d975ea633123"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a mutex and shared buffer in the workspace.  <a href="#a5bab26d8f00817d54cb0d975ea633123">More...</a><br /></td></tr>
<tr class="separator:a5bab26d8f00817d54cb0d975ea633123"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7325af6c5155b94ed4fdae09adc8f614"><td class="memTemplParams" colspan="2"><a class="anchor" id="a7325af6c5155b94ed4fdae09adc8f614"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a7325af6c5155b94ed4fdae09adc8f614"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a7325af6c5155b94ed4fdae09adc8f614">runWithSharedBuffer</a> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws, std::function&lt; void(<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *buffer)&gt; f)</td></tr>
<tr class="memdesc:a7325af6c5155b94ed4fdae09adc8f614"><td class="mdescLeft">&#160;</td><td class="mdescRight">Thread-safe, can be invoked from RunOnDevice() to serialize access to shared buffer. <br /></td></tr>
<tr class="separator:a7325af6c5155b94ed4fdae09adc8f614"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a498e06540c78d810ee1f4ab906a41bd8"><td class="memTemplParams" colspan="2"><a class="anchor" id="a498e06540c78d810ee1f4ab906a41bd8"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a498e06540c78d810ee1f4ab906a41bd8"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>createSharedBuffer&lt; CUDAContext &gt;</b> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws)</td></tr>
<tr class="separator:a498e06540c78d810ee1f4ab906a41bd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04f5692aa93a637ab5b28a1d8fe573ed"><td class="memTemplParams" colspan="2"><a class="anchor" id="a04f5692aa93a637ab5b28a1d8fe573ed"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a04f5692aa93a637ab5b28a1d8fe573ed"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>runWithSharedBuffer&lt; CUDAContext &gt;</b> (<a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws, std::function&lt; void(<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *buffer)&gt; f)</td></tr>
<tr class="separator:a04f5692aa93a637ab5b28a1d8fe573ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e5d3e1f4bf2fcdd3da3e4c9866dd6b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e5d3e1f4bf2fcdd3da3e4c9866dd6b5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ConvTransposeGradient, <a class="el" href="classcaffe2_1_1_conv_transpose_gradient_op.html">ConvTransposeGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6e5d3e1f4bf2fcdd3da3e4c9866dd6b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2886c6933fd6befaa73b27927d1c6b8c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2886c6933fd6befaa73b27927d1c6b8c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (ConvTransposeGradient).NumInputs(3).NumOutputs(1</td></tr>
<tr class="separator:a2886c6933fd6befaa73b27927d1c6b8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3809c4b5ea9c977ed42d9fbb0b8e704e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3809c4b5ea9c977ed42d9fbb0b8e704e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_conv_transpose.html">ConvTranspose</a>, <a class="el" href="classcaffe2_1_1_get_conv_transpose_gradient.html">GetConvTransposeGradient</a>)</td></tr>
<tr class="separator:a3809c4b5ea9c977ed42d9fbb0b8e704e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c7221ade0eb07cf5a7cce0a034c34e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c7221ade0eb07cf5a7cce0a034c34e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_conv_transpose.html">ConvTranspose</a>, <a class="el" href="classcaffe2_1_1_conv_transpose_op.html">ConvTransposeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3c7221ade0eb07cf5a7cce0a034c34e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87c1312c8ac58863a2e8dcceb7a2ce77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87c1312c8ac58863a2e8dcceb7a2ce77"></a>
an input weight tensor and optionally an input bias tensor $bias It then computes the transposed sometimes referred to as and produces a single output tensor $Y The hyperparameters of the op such as kernel and padding are specified as args At each the filter is deconvolved with a subset of $X and the $bias is added This is done throughout the input data until the output computation is complete The output shapes are computed as follows The number of channels in the output feature map is the number of kernels specified in the filter blob The spatial height and width are computed which is why they are separate files in the implementation this&#160;</td><td class="memItemRight" valign="bottom"><b>operator inherits from the *ConvTransposeUnpoolOpBase *operator.Github Links:-https:-https:-https:&lt; details &gt;&lt; summary &gt;&lt; b &gt;Example&lt;/b &gt;&lt;/summary &gt; **Code **```workspace.ResetWorkspace</b> () op</td></tr>
<tr class="separator:a87c1312c8ac58863a2e8dcceb7a2ce77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f8e8432ee0a969ed41eecea44dd07a3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f8e8432ee0a969ed41eecea44dd07a3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="class_conv_transpose.html">ConvTranspose</a>, <a class="el" href="classcaffe2_1_1_cudnn_conv_transpose_op.html">CudnnConvTransposeOp</a>&lt; float &gt;)</td></tr>
<tr class="separator:a1f8e8432ee0a969ed41eecea44dd07a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b5c15ee4460f36e2d806f31ad868a19"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b5c15ee4460f36e2d806f31ad868a19"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (ConvTransposeGradient, <a class="el" href="classcaffe2_1_1_cudnn_conv_transpose_gradient_op.html">CudnnConvTransposeGradientOp</a>&lt; float &gt;)</td></tr>
<tr class="separator:a0b5c15ee4460f36e2d806f31ad868a19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a467c89d9a81c34c23afc470ad0f46355"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a467c89d9a81c34c23afc470ad0f46355"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_conv_transpose.html">ConvTranspose</a>, <a class="el" href="classcaffe2_1_1_conv_transpose_op.html">ConvTransposeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a467c89d9a81c34c23afc470ad0f46355"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9257b79fa1cebcfe21372c7b61c2b182"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9257b79fa1cebcfe21372c7b61c2b182"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ConvTransposeGradient, <a class="el" href="classcaffe2_1_1_conv_transpose_gradient_op.html">ConvTransposeGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a9257b79fa1cebcfe21372c7b61c2b182"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af31f258716b43bd475dc13f904120f9f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af31f258716b43bd475dc13f904120f9f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CopyFromCPUInput, <a class="el" href="classcaffe2_1_1_copy_op.html">CopyOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af31f258716b43bd475dc13f904120f9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f6d36b3549f883e3cd6e53b36ba1a94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f6d36b3549f883e3cd6e53b36ba1a94"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CopyOnDeviceLike, <a class="el" href="classcaffe2_1_1_copy_on_device_like_op.html">CopyOnDeviceLikeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a5f6d36b3549f883e3cd6e53b36ba1a94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8819d12f475637364ebbe942e8a3e1bf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8819d12f475637364ebbe942e8a3e1bf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Copy, <a class="el" href="classcaffe2_1_1_copy_op.html">CopyOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8819d12f475637364ebbe942e8a3e1bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4524c8fa6cea5b7c91c8dd8dd80efd70"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4524c8fa6cea5b7c91c8dd8dd80efd70"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Copy tensor for GPU to CPU context. Must be run under GPU device option.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a4524c8fa6cea5b7c91c8dd8dd80efd70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3549fb415d74c607849da1b252e7ac75"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3549fb415d74c607849da1b252e7ac75"></a>
The input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> that will contain a copy of the input.&quot;)</td></tr>
<tr class="separator:a3549fb415d74c607849da1b252e7ac75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a687f0d8f43654a9029e352c6cf4e64f7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a687f0d8f43654a9029e352c6cf4e64f7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Copy tensor for CPU to GPU context. Must be run under GPU device option.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a687f0d8f43654a9029e352c6cf4e64f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b9bf0a7f89a097285ab4dff6953c24e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b9bf0a7f89a097285ab4dff6953c24e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Take a CPU input tensor and copy it to an output in the current
Context (GPU or CPU). This may involves cross-device MemCpy.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a0b9bf0a7f89a097285ab4dff6953c24e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9b2143d37855d1e6fd3706f7863203c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac9b2143d37855d1e6fd3706f7863203c"></a>
The input CPU tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;either a <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCUDA</a> or a <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a>&quot;)</td></tr>
<tr class="separator:ac9b2143d37855d1e6fd3706f7863203c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a155f3eb38cb765b1fa42222285eec1c2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a155f3eb38cb765b1fa42222285eec1c2"></a>
The input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;dst&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>, on which device the copy will be performed.&quot;).Output(0</td></tr>
<tr class="separator:a155f3eb38cb765b1fa42222285eec1c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a968df189e1c2daab8793e0c015d79b56"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a968df189e1c2daab8793e0c015d79b56"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Copy, <a class="el" href="structcaffe2_1_1_get_copy_gradient.html">GetCopyGradient</a>)</td></tr>
<tr class="separator:a968df189e1c2daab8793e0c015d79b56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a807eb4562ba6c809422a6f04cf9698f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a807eb4562ba6c809422a6f04cf9698f3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (CopyGPUToCPU, <a class="el" href="structcaffe2_1_1_get_g_p_u_to_c_p_u_gradient.html">GetGPUToCPUGradient</a>)</td></tr>
<tr class="separator:a807eb4562ba6c809422a6f04cf9698f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa143b478aff90a4cdfc8274c6ad18d2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa143b478aff90a4cdfc8274c6ad18d2f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (CopyCPUToGPU, <a class="el" href="structcaffe2_1_1_get_c_p_u_to_g_p_u_gradient.html">GetCPUToGPUGradient</a>)</td></tr>
<tr class="separator:aa143b478aff90a4cdfc8274c6ad18d2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3302a436feb107c7b02e21c35de3ebec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3302a436feb107c7b02e21c35de3ebec"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Cos, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cos_functor.html">CosFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a3302a436feb107c7b02e21c35de3ebec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60683fce1af24a5e2d62cc5d147869cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a60683fce1af24a5e2d62cc5d147869cd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CosGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cos_gradient_functor.html">CosGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a60683fce1af24a5e2d62cc5d147869cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecbeb423c4fa4df2a180832a75007ade"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aecbeb423c4fa4df2a180832a75007ade"></a>
element wise Github workspace FeedBlob(&quot;X&quot;, np.random.rand(5).astype(np.float32)) print(&quot;X&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (CosGradient).NumInputs(2).NumOutputs(1).IdenticalTypeAndShape()</td></tr>
<tr class="separator:aecbeb423c4fa4df2a180832a75007ade"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fc548c2c8f9a883536882f1ba0860f2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5fc548c2c8f9a883536882f1ba0860f2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Cos, GetCosGradient)</td></tr>
<tr class="separator:a5fc548c2c8f9a883536882f1ba0860f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b8e8bdafc4e8e8e3535bd8611888e2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8b8e8bdafc4e8e8e3535bd8611888e2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Cosh, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cosh_functor.html">CoshFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a8b8e8bdafc4e8e8e3535bd8611888e2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56f39c10119d6680ea2e2226e2e8ec35"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a56f39c10119d6680ea2e2226e2e8ec35"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CoshGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cosh_gradient_functor.html">CoshGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a56f39c10119d6680ea2e2226e2e8ec35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09529c731f559652271603a2325e0155"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09529c731f559652271603a2325e0155"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Cosh, GetCoshGradient)</td></tr>
<tr class="separator:a09529c731f559652271603a2325e0155"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefa7665df55970fa98126428f43a61fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aefa7665df55970fa98126428f43a61fd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CosineEmbeddingCriterion, <a class="el" href="classcaffe2_1_1_cosine_embedding_criterion_op.html">CosineEmbeddingCriterionOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aefa7665df55970fa98126428f43a61fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6eb38b712b2fff805f5b7eea6dd4f4f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac6eb38b712b2fff805f5b7eea6dd4f4f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CosineEmbeddingCriterionGradient, <a class="el" href="classcaffe2_1_1_cosine_embedding_criterion_gradient_op.html">CosineEmbeddingCriterionGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac6eb38b712b2fff805f5b7eea6dd4f4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ed8fef54afee9a213146e58071ff945"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7ed8fef54afee9a213146e58071ff945"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CreateCounter, <a class="el" href="classcaffe2_1_1_create_counter_op.html">CreateCounterOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7ed8fef54afee9a213146e58071ff945"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14ce03ab286c508bef6e2f333f7ba209"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a14ce03ab286c508bef6e2f333f7ba209"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ResetCounter, <a class="el" href="classcaffe2_1_1_reset_counter_op.html">ResetCounterOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a14ce03ab286c508bef6e2f333f7ba209"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a2cc9daa694e95b811d5b931601eb59"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a2cc9daa694e95b811d5b931601eb59"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CountDown, <a class="el" href="classcaffe2_1_1_count_down_op.html">CountDownOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7a2cc9daa694e95b811d5b931601eb59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ce152bf1ed15524a042b3be386d9171"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2ce152bf1ed15524a042b3be386d9171"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CheckCounterDone, <a class="el" href="classcaffe2_1_1_check_counter_done_op.html">CheckCounterDoneOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2ce152bf1ed15524a042b3be386d9171"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af776edd8c4b941a72a3f1c2f0a7b038f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af776edd8c4b941a72a3f1c2f0a7b038f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CountUp, <a class="el" href="classcaffe2_1_1_count_up_op.html">CountUpOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af776edd8c4b941a72a3f1c2f0a7b038f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7eed2de4731cd839dc300a62974cbcde"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7eed2de4731cd839dc300a62974cbcde"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RetrieveCount, <a class="el" href="classcaffe2_1_1_retrieve_count_op.html">RetrieveCountOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7eed2de4731cd839dc300a62974cbcde"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff69a71fe0ab60a87ade7188a55bb3b1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff69a71fe0ab60a87ade7188a55bb3b1"></a>
NumInputs(1).NumOutputs(1).ScalarType(TensorProto&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (CreateCounter)</td></tr>
<tr class="separator:aff69a71fe0ab60a87ade7188a55bb3b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a686b2db0137d53f760269e2592609faf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a686b2db0137d53f760269e2592609faf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (ResetCounter)</td></tr>
<tr class="separator:a686b2db0137d53f760269e2592609faf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac103cc3aff03a96285ef79d457b07bc3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac103cc3aff03a96285ef79d457b07bc3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (CountDown)</td></tr>
<tr class="separator:ac103cc3aff03a96285ef79d457b07bc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d71ec0631b4cdecc1b917b17f0be1c6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5d71ec0631b4cdecc1b917b17f0be1c6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (CountUp)</td></tr>
<tr class="separator:a5d71ec0631b4cdecc1b917b17f0be1c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a948f382242c395442ebabbde308aa463"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a948f382242c395442ebabbde308aa463"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (RetrieveCount)</td></tr>
<tr class="separator:a948f382242c395442ebabbde308aa463"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfeb8ca2d13305c0ce3d3f5f78648a83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abfeb8ca2d13305c0ce3d3f5f78648a83"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_counter.html">Counter</a>&lt; int64_t &gt;&gt;)</td></tr>
<tr class="separator:abfeb8ca2d13305c0ce3d3f5f78648a83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab18bb186479318c9aa01ce97e602b667"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab18bb186479318c9aa01ce97e602b667"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_BLOB_SERIALIZER</b> ((TypeMeta::Id&lt; std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_counter.html">Counter</a>&lt; int64_t &gt;&gt;&gt;()), CounterSerializer)</td></tr>
<tr class="separator:ab18bb186479318c9aa01ce97e602b667"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a378132f2239970fbee7eae92c3837f0d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a378132f2239970fbee7eae92c3837f0d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_BLOB_DESERIALIZER</b> (std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_counter.html">Counter</a>&lt; int64_t &gt;&gt;, CounterDeserializer)</td></tr>
<tr class="separator:a378132f2239970fbee7eae92c3837f0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a045b0015362f294d90b189d378ee448b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a045b0015362f294d90b189d378ee448b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CreateCounter, <a class="el" href="classcaffe2_1_1_create_counter_op.html">CreateCounterOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a045b0015362f294d90b189d378ee448b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb4aaff7be981c8f50228bf65129fe16"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeb4aaff7be981c8f50228bf65129fe16"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ResetCounter, <a class="el" href="classcaffe2_1_1_reset_counter_op.html">ResetCounterOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aeb4aaff7be981c8f50228bf65129fe16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a092617e34390d060ade14cf0f428b7e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a092617e34390d060ade14cf0f428b7e4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CountDown, <a class="el" href="classcaffe2_1_1_count_down_op.html">CountDownOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a092617e34390d060ade14cf0f428b7e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5414b411f8598bdcf7a5759273f5dbc0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5414b411f8598bdcf7a5759273f5dbc0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CheckCounterDone, <a class="el" href="classcaffe2_1_1_check_counter_done_op.html">CheckCounterDoneOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a5414b411f8598bdcf7a5759273f5dbc0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67e2919309940df0230167b891aa4460"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67e2919309940df0230167b891aa4460"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CountUp, <a class="el" href="classcaffe2_1_1_count_up_op.html">CountUpOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a67e2919309940df0230167b891aa4460"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfd301bfab132a9b2529d1e05a6185f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abfd301bfab132a9b2529d1e05a6185f5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (RetrieveCount, <a class="el" href="classcaffe2_1_1_retrieve_count_op.html">RetrieveCountOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:abfd301bfab132a9b2529d1e05a6185f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af06db80a0517868754937406c34a8544"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af06db80a0517868754937406c34a8544"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="classcaffe2_1_1detail_1_1_workspace_stack.html">detail::WorkspaceStack</a>)</td></tr>
<tr class="separator:af06db80a0517868754937406c34a8544"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca8604e71023fd1d73c9c4940e3ee41b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca8604e71023fd1d73c9c4940e3ee41b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CreateScope, <a class="el" href="classcaffe2_1_1_create_scope_op.html">CreateScopeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aca8604e71023fd1d73c9c4940e3ee41b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa57ae8ea03d63bc92f1be201ecc25eef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa57ae8ea03d63bc92f1be201ecc25eef"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (CreateScope)</td></tr>
<tr class="separator:aa57ae8ea03d63bc92f1be201ecc25eef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabb85c896ba4e9c67180b6a2dd5ab282"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabb85c896ba4e9c67180b6a2dd5ab282"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (CreateScope).NumInputs(0).NumOutputs(1).SetDoc(R&quot;DOC( 'CreateScope' operator initializes and outputs empty scope that is used by Do operator to store local blobs )DOC&quot;)</td></tr>
<tr class="separator:aabb85c896ba4e9c67180b6a2dd5ab282"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a4c0f2068c0ef86c22c5deb60c8130d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2a4c0f2068c0ef86c22c5deb60c8130d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (HasScope, <a class="el" href="classcaffe2_1_1_has_scope_op.html">HasScopeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2a4c0f2068c0ef86c22c5deb60c8130d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae33ddc7882e5c7d177c933870427f0d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae33ddc7882e5c7d177c933870427f0d7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (HasScope)</td></tr>
<tr class="separator:ae33ddc7882e5c7d177c933870427f0d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8ec89b16557060167a914f41aae3b95"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad8ec89b16557060167a914f41aae3b95"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (HasScope).NumInputs(1).NumOutputs(1).SetDoc(R&quot;DOC( Checks whether scope blob has any saved scopes left )DOC&quot;)</td></tr>
<tr class="separator:ad8ec89b16557060167a914f41aae3b95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c4396fc145639b103c925214fbc6303"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7c4396fc145639b103c925214fbc6303"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LabelCrossEntropy, <a class="el" href="classcaffe2_1_1_label_cross_entropy_op.html">LabelCrossEntropyOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7c4396fc145639b103c925214fbc6303"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a312a993638b53afa2e9a3c6d3a0972e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a312a993638b53afa2e9a3c6d3a0972e6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LabelCrossEntropyGradient, <a class="el" href="classcaffe2_1_1_label_cross_entropy_gradient_op.html">LabelCrossEntropyGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a312a993638b53afa2e9a3c6d3a0972e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51433626e5e6e0c52fec227715091aa5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a51433626e5e6e0c52fec227715091aa5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
This operator computes the cross entropy between a $NxD$ dimensional input data tensor $X$  and a one dimensional input label tensor $label$. The op produces a single length $N$ output tensor $Y$. Here, $N$ is considered the batch size and $D$ is the size of each element in the batch. In practice, it is most commonly used at the end of models as a part of the loss computation, after the SoftMax operator and before the <a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a> operator. The cross entropy operation is defined as follows

$$Y_i = -log(X_{ij})$$

where ($i$, $j$) is the classifier's prediction of the $j$th class (the correct one), and $i$ is the batch size. Each log has a lower limit for numerical stability.

The difference between *LabelCrossEntropy* and *CrossEntropy* is how the labels are specified. Here, the labels are a length $N$ list of integers, whereas in CrossEntropy the labels are a $NxD$ dimensional matrix of one hot label vectors. However, the results of computation should be the same, as shown in the two examples where ($i$, $j$) is the classifier's prediction of the $j$th class (the correct one), and $i$ is the batch size. Each log has a lower limit for numerical stability.

Github Links:
- https://github.com/caffe2/caffe2/blob/master/caffe2/operators/cross_entropy_op.h
- https://github.com/caffe2/caffe2/blob/master/caffe2/operators/cross_entropy_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;LabelCrossEntropy&quot;,
    [&quot;X&quot;, &quot;label&quot;],
    [&quot;Y&quot;]
)

// Create X: Sample softmax output for 5-class model
X = np.array([[.01, .05, .02, .02, .9],[.03, .1, .42, .05, .4]])
print(&quot;X:\n&quot;,X)

// Create label: Sample 1-hot ground truth label vectors
label = np.array([4,2])
print(&quot;label:\n&quot;,label)

// Feed X &amp; label into workspace
workspace.FeedBlob(&quot;X&quot;, X.astype(np.float32))
workspace.FeedBlob(&quot;label&quot;, label.astype(np.int32))

// Run op
workspace.RunOperatorOnce(op)

// Collect Output
print(&quot;Y:\n&quot;, workspace.FetchBlob(&quot;Y&quot;))

```

**Result**

```

X:
 [[0.01 0.05 0.02 0.02 0.9 ]
 [0.03 0.1  0.42 0.05 0.4 ]]
label:
 [4 2]
Y:
 [0.10536055 0.8675006 ]

```

&lt;/details&gt;


)DOC&quot;).Input(0</td></tr>
<tr class="separator:a51433626e5e6e0c52fec227715091aa5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25ec5a2f132762a2955f1efa619a0ed3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a25ec5a2f132762a2955f1efa619a0ed3"></a>
Input tensor which is almost always the result of a softmax operation $X is a array of size where $N is the batch size and $<a class="el" href="struct_d.html">D</a> is the number of classes&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;label&quot;,&quot;<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> containing the labels used to compare the input. $label$ is a length $N$ list of integers, where each element is the integer label for the $n$th element of the batch.&quot;).Output(0</td></tr>
<tr class="separator:a25ec5a2f132762a2955f1efa619a0ed3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a042db7e40bc940d4c8621a642a4001"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8a042db7e40bc940d4c8621a642a4001"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LabelCrossEntropy, <a class="el" href="classcaffe2_1_1_get_label_cross_entropy_gradient.html">GetLabelCrossEntropyGradient</a>)</td></tr>
<tr class="separator:a8a042db7e40bc940d4c8621a642a4001"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a465467c9f5367cc0dad262ca2185848c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a465467c9f5367cc0dad262ca2185848c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MakeTwoClass, <a class="el" href="classcaffe2_1_1_make_two_class_op.html">MakeTwoClassOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a465467c9f5367cc0dad262ca2185848c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaafe7fba6fa17a784791c76c60c4a28c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaafe7fba6fa17a784791c76c60c4a28c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MakeTwoClassGradient, <a class="el" href="classcaffe2_1_1_make_two_class_gradient_op.html">MakeTwoClassGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aaafe7fba6fa17a784791c76c60c4a28c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab292b58d85aeff0ac8d19e47458baaad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab292b58d85aeff0ac8d19e47458baaad"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SigmoidCrossEntropyWithLogits, <a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_with_logits_op.html">SigmoidCrossEntropyWithLogitsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab292b58d85aeff0ac8d19e47458baaad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4fd06f57da40b896837de2110f2898e9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4fd06f57da40b896837de2110f2898e9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SigmoidCrossEntropyWithLogitsGradient, <a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_with_logits_gradient_op.html">SigmoidCrossEntropyWithLogitsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4fd06f57da40b896837de2110f2898e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0335af892586700897d690af0cf6ffc6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0335af892586700897d690af0cf6ffc6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WeightedSigmoidCrossEntropyWithLogits, <a class="el" href="classcaffe2_1_1_weighted_sigmoid_cross_entropy_with_logits_op.html">WeightedSigmoidCrossEntropyWithLogitsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0335af892586700897d690af0cf6ffc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aceca955ee067384ace9f0c1d1676f3cc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aceca955ee067384ace9f0c1d1676f3cc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WeightedSigmoidCrossEntropyWithLogitsGradient, <a class="el" href="classcaffe2_1_1_weighted_sigmoid_cross_entropy_with_logits_gradient_op.html">WeightedSigmoidCrossEntropyWithLogitsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aceca955ee067384ace9f0c1d1676f3cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a278002796a245b82d2176c6d3af198dd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a278002796a245b82d2176c6d3af198dd"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (in[0].dims(0))</td></tr>
<tr class="separator:a278002796a245b82d2176c6d3af198dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30e47da95b0cd124065dfa39a4aaa991"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a30e47da95b0cd124065dfa39a4aaa991"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (2)</td></tr>
<tr class="separator:a30e47da95b0cd124065dfa39a4aaa991"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef6c712ec8feccd09fc63df4d2f9bc03"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef6c712ec8feccd09fc63df4d2f9bc03"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given a vector of probabilities, this operator transforms this into a 2-column
 matrix with complimentary probabilities for binary classification. In explicit
 terms, given the vector X, the output Y is vstack(1 - X, X).
  )DOC&quot;).Input(0</td></tr>
<tr class="separator:aef6c712ec8feccd09fc63df4d2f9bc03"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ed7348963c27c26bd5ddce57dc801d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6ed7348963c27c26bd5ddce57dc801d5"></a>
Input vector of probabilities&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;2-column matrix with complimentary probabilities of X for &quot;&quot;binary classification&quot;)</td></tr>
<tr class="separator:a6ed7348963c27c26bd5ddce57dc801d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bba3ab728b3d543880c2567f7f1d533"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9bba3ab728b3d543880c2567f7f1d533"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;log_D_trick&quot;, R&quot;DOC(
default is false; if enabled, will use the log d trick to avoid the vanishing
gradients early on; see Goodfellow et. al (2014)
)DOC&quot;).Arg(&quot;unjoined_lr_loss&quot;</td></tr>
<tr class="separator:a9bba3ab728b3d543880c2567f7f1d533"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b3c9bda2dc1656e464085c8bceb8209"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5b3c9bda2dc1656e464085c8bceb8209"></a>
R&#160;</td><td class="memItemRight" valign="bottom"><b>DOC</b> (default is false;if enabled, the model will be allowed to train on an unjoined dataset, where some examples might be false negative and might appear in the dataset later as(true) positive example.) DOC&quot;) .NumInputs(2) .NumOutputs(1) .IdenticalTypeAndShapeOfInputDim(0</td></tr>
<tr class="separator:a5b3c9bda2dc1656e464085c8bceb8209"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4734b5a0e63a2af17787b2f07fd108e3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4734b5a0e63a2af17787b2f07fd108e3"></a>
R&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given two matrices logits and targets, of same shape,
(batch_size, num_classes), computes the sigmoid cross entropy between the two.
Returns a tensor of shape (batch_size,) of losses for each example.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a4734b5a0e63a2af17787b2f07fd108e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63ae0598dd7b87f227ddfb5b9939c3dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a63ae0598dd7b87f227ddfb5b9939c3dc"></a>
R matrix of logits for each example and class&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;targets&quot;,&quot;matrix of targets, same shape as logits.&quot;).Output(0</td></tr>
<tr class="separator:a63ae0598dd7b87f227ddfb5b9939c3dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1f8efe40905d6e30a920d6002b0f6eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac1f8efe40905d6e30a920d6002b0f6eb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given three matrices: logits, targets, weights, all of the same shape,
(batch_size, num_classes), computes the weighted sigmoid cross entropy between
logits and targets. Specifically, at each position r,c, this computes
weights[r, c] * crossentropy(sigmoid(logits[r, c]), targets[r, c]), and then
averages over each row.
Returns a tensor of shape (batch_size,) of losses for each example.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:ac1f8efe40905d6e30a920d6002b0f6eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa12cba80072c4e774c5937c17a2688c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa12cba80072c4e774c5937c17a2688c1"></a>
matrix of logits for each example and class matrix of same shape as logits&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;xentropy&quot;,&quot;Vector with the total xentropy for each example.&quot;)</td></tr>
<tr class="separator:aa12cba80072c4e774c5937c17a2688c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47a3b8b865de49c0da833bddb86fc6e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a47a3b8b865de49c0da833bddb86fc6e1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (MakeTwoClass, <a class="el" href="structcaffe2_1_1_get_make_two_class_gradient.html">GetMakeTwoClassGradient</a>)</td></tr>
<tr class="separator:a47a3b8b865de49c0da833bddb86fc6e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e7429af1d9a8a5bc5bf0eb3c9642248"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e7429af1d9a8a5bc5bf0eb3c9642248"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SigmoidCrossEntropyWithLogits, <a class="el" href="structcaffe2_1_1_get_sigmoid_cross_entropy_with_logits_gradient.html">GetSigmoidCrossEntropyWithLogitsGradient</a>)</td></tr>
<tr class="separator:a0e7429af1d9a8a5bc5bf0eb3c9642248"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae26b537f56129874abbc9a77b8db4662"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae26b537f56129874abbc9a77b8db4662"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (WeightedSigmoidCrossEntropyWithLogits, <a class="el" href="structcaffe2_1_1_get_weighted_sigmoid_cross_entropy_with_logits_gradient.html">GetWeightedSigmoidCrossEntropyWithLogitsGradient</a>)</td></tr>
<tr class="separator:ae26b537f56129874abbc9a77b8db4662"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af09c375cd2a4f9d14a61ce1935028f47"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af09c375cd2a4f9d14a61ce1935028f47"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CrossEntropy, <a class="el" href="classcaffe2_1_1_cross_entropy_op.html">CrossEntropyOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af09c375cd2a4f9d14a61ce1935028f47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac84c43849ee5c2af009b8f64b665020b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac84c43849ee5c2af009b8f64b665020b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CrossEntropyGradient, <a class="el" href="classcaffe2_1_1_cross_entropy_gradient_op.html">CrossEntropyGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac84c43849ee5c2af009b8f64b665020b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff131733622603fa6a37fb44bcd99b25"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff131733622603fa6a37fb44bcd99b25"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
This operator computes the cross entropy between a $NxD$ dimensional input data tensor $X$  and a $NxD$ dimensional input label tensor $label$. The op produces a single length $N$ output tensor $Y$. Here, $N$ is considered the batch size and $D$ is the size of each element in the batch. In practice, it is most commonly used at the end of models as a part of the loss computation, after the SoftMax operator and before the <a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a> operator. The cross entropy operation is defined as follows

$$Y_i = \sum_j (label_{ij} * log(X_{ij}))$$

where ($i$, $j$) is the classifier's prediction of the $j$th class (the correct one), and $i$ is the batch size. Each log has a lower limit for numerical stability.

Github Links:
- https://github.com/caffe2/caffe2/blob/master/caffe2/operators/cross_entropy_op.h
- https://github.com/caffe2/caffe2/blob/master/caffe2/operators/cross_entropy_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;CrossEntropy&quot;,
    [&quot;X&quot;, &quot;label&quot;],
    [&quot;Y&quot;]
)

// Create X: Sample softmax output for 5-class model
X = np.array([[.01, .05, .02, .02, .9],[.03, .1, .42, .05, .4]])
print(&quot;X:\n&quot;,X)

// Create label: Sample 1-hot ground truth label vectors
label = np.array([[0.,0.,0.,0.,1.],[0.,0.,1.,0.,0.]])
print(&quot;label:\n&quot;,label)

// Feed X &amp; label into workspace
workspace.FeedBlob(&quot;X&quot;, X.astype(np.float32))
workspace.FeedBlob(&quot;label&quot;, label.astype(np.float32))

// Run op
workspace.RunOperatorOnce(op)

// Collect Output
print(&quot;Y:\n&quot;, workspace.FetchBlob(&quot;Y&quot;))

```

**Result**

```

X:
 [[0.01 0.05 0.02 0.02 0.9 ]
 [0.03 0.1  0.42 0.05 0.4 ]]
label:
 [[0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0.]]
Y:
 [0.10536055 0.8675006 ]

```

&lt;/details&gt;


)DOC&quot;).Input(0</td></tr>
<tr class="separator:aff131733622603fa6a37fb44bcd99b25"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1eea4698f527a791034ab245c5446a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa1eea4698f527a791034ab245c5446a0"></a>
Input tensor which is almost always the result of a softmax operation $X is a array of size where $N is the batch size and $<a class="el" href="struct_d.html">D</a> is the number of classes&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;label&quot;,&quot;<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> containing the labels used to compare the input. $label$ is the same shape as $X$.&quot;).Output(0</td></tr>
<tr class="separator:aa1eea4698f527a791034ab245c5446a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83144fc9b38a5895eaf15458e5ef170a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a83144fc9b38a5895eaf15458e5ef170a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (CrossEntropy, <a class="el" href="classcaffe2_1_1_get_cross_entropy_gradient.html">GetCrossEntropyGradient</a>)</td></tr>
<tr class="separator:a83144fc9b38a5895eaf15458e5ef170a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a727b18e8c44a6ffe82aeea2aa8ccb870"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a727b18e8c44a6ffe82aeea2aa8ccb870"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CTCBeamSearchDecoder, <a class="el" href="classcaffe2_1_1_c_t_c_beam_search_decoder_op.html">CTCBeamSearchDecoderOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a727b18e8c44a6ffe82aeea2aa8ccb870"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a5e04a9e6a672ddd6285f071c3fb08a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8a5e04a9e6a672ddd6285f071c3fb08a"></a>
Maximum number of candidates to carry over to next activation step&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;prune_threshold&quot;,&quot;Probability threshold below which outputs are ignored.&quot;).Input(0</td></tr>
<tr class="separator:a8a5e04a9e6a672ddd6285f071c3fb08a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a0669766a9ccd83f8249f42cc944afa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a0669766a9ccd83f8249f42cc944afa"></a>
Maximum number of candidates to carry over to next activation step float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_activation_length, batch_size, alphabet_size] of network&#160;</td><td class="memItemRight" valign="bottom"><b>logits</b> (before softmax application).&quot;) .Input( 1</td></tr>
<tr class="separator:a7a0669766a9ccd83f8249f42cc944afa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3027754af03cb71f3ba2f66740777012"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3027754af03cb71f3ba2f66740777012"></a>
Maximum number of candidates to carry over to next activation step float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_activation_length, batch_size, alphabet_size] of network <a class="el" href="classc10_1_1optional.html">optional</a> int vector containing sequence having size[batch_size] seq_len will be set to max_time if not provided&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;OUTPUT_LEN&quot;,&quot;Output_len matrix size (batch_size). &quot;&quot;Each index stores final output length of its corresponding batch item.&quot;).Output(1</td></tr>
<tr class="separator:a3027754af03cb71f3ba2f66740777012"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a909717c5ca387053cd4c7fda046e24cc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a909717c5ca387053cd4c7fda046e24cc"></a>
Maximum number of candidates to carry over to next activation step float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_activation_length, batch_size, alphabet_size] of network <a class="el" href="classc10_1_1optional.html">optional</a> int vector containing sequence having size[batch_size] seq_len will be set to max_time if not provided Values&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (total_decoded_outputs).&quot; &quot;The flattened vector of final output sequences</td></tr>
<tr class="separator:a909717c5ca387053cd4c7fda046e24cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3412e333f5bd08424fff36b46b023409"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3412e333f5bd08424fff36b46b023409"></a>
Maximum number of candidates to carry over to next activation step float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_activation_length, batch_size, alphabet_size] of network <a class="el" href="classc10_1_1optional.html">optional</a> int vector containing sequence having size[batch_size] seq_len will be set to max_time if not provided Values in batch order&#160;</td><td class="memItemRight" valign="bottom"><b>InheritOnnxSchema</b> ()</td></tr>
<tr class="separator:a3412e333f5bd08424fff36b46b023409"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39cd8d5c41801dbfe39e358e01858939"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39cd8d5c41801dbfe39e358e01858939"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (CTCBeamSearchDecoder)</td></tr>
<tr class="separator:a39cd8d5c41801dbfe39e358e01858939"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7426f7c3a76183e03298267365cfcaa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad7426f7c3a76183e03298267365cfcaa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CTCGreedyDecoder, <a class="el" href="classcaffe2_1_1_c_t_c_greedy_decoder_op.html">CTCGreedyDecoderOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad7426f7c3a76183e03298267365cfcaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad29a0ccc3a88f459c32e3306e2f47533"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad29a0ccc3a88f459c32e3306e2f47533"></a>
When merge_repeated is merge repeated classes in output&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (&quot;Greedy decoder for connectionist temporal classification.&quot;).Input(0</td></tr>
<tr class="separator:ad29a0ccc3a88f459c32e3306e2f47533"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd6a3b74727f64b426b00ef451105fdb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd6a3b74727f64b426b00ef451105fdb"></a>
When merge_repeated is merge repeated classes in output float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_time, batch_size, num_classes]&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;SEQ_LEN&quot;,&quot;(<a class="el" href="classc10_1_1optional.html">optional</a>) 1D int vector containing sequence lengths, &quot;&quot;having size [batch_size]&quot;&quot;seq_len will be set to max_time if not provided&quot;).Output(0</td></tr>
<tr class="separator:acd6a3b74727f64b426b00ef451105fdb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1063281e038a7d2d9a38f8af856ccaa5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1063281e038a7d2d9a38f8af856ccaa5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Cube, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cube_functor.html">CubeFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a1063281e038a7d2d9a38f8af856ccaa5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86c0f13af3546587053f69dd5cf20ecd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86c0f13af3546587053f69dd5cf20ecd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CubeGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_cube_gradient_functor.html">CubeGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a86c0f13af3546587053f69dd5cf20ecd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd33c58824f8b1208371408b91526540"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd33c58824f8b1208371408b91526540"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Cube, GetCubeGradient)</td></tr>
<tr class="separator:afd33c58824f8b1208371408b91526540"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c3f2bcf45422dfc3d70914ba61f9b91"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c3f2bcf45422dfc3d70914ba61f9b91"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DataCouple, <a class="el" href="classcaffe2_1_1_data_couple_op.html">DataCoupleOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1c3f2bcf45422dfc3d70914ba61f9b91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a992911c8e79cb27a305c1ad867db887f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a992911c8e79cb27a305c1ad867db887f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EnforceOneToOneInplace</b> ().SetDoc(R&quot;DOC( <a class="el" href="struct_a.html">A</a> one to one operator that takes an arbitrary number of input and output blobs such that each input blob is inplace with it's matching output blob. It then proceedes to do nothing with each of these operators. This serves two purposes. It can make it appear as if a blob has been written to</td></tr>
<tr class="separator:a992911c8e79cb27a305c1ad867db887f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc919c49f725b3492fe44ef3536aa3af"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc919c49f725b3492fe44ef3536aa3af"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1dataset__ops_1_1_tree_cursor.html">dataset_ops::TreeCursor</a> &gt;)</td></tr>
<tr class="separator:abc919c49f725b3492fe44ef3536aa3af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca53cc14edd289837b600f597983199b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca53cc14edd289837b600f597983199b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (dataset_ops::TensorVectorPtr)</td></tr>
<tr class="separator:aca53cc14edd289837b600f597983199b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19caef35d3f96aa748efe387890d0985"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a19caef35d3f96aa748efe387890d0985"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (dataset_ops::SharedTensorVectorPtr)</td></tr>
<tr class="separator:a19caef35d3f96aa748efe387890d0985"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af300ffee8007add914d05020c1a4fb1a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af300ffee8007add914d05020c1a4fb1a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (DeformConvGradient).NumInputs(4</td></tr>
<tr class="separator:af300ffee8007add914d05020c1a4fb1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc270ee9705bfa4ee30f052e337f7350"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acc270ee9705bfa4ee30f052e337f7350"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumOutputs</b> (2, 4)</td></tr>
<tr class="separator:acc270ee9705bfa4ee30f052e337f7350"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf97f160d57d7bda74144301846abc2e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaf97f160d57d7bda74144301846abc2e"></a>
vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceForDotProduct</b> (const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:aaf97f160d57d7bda74144301846abc2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5debb703fbd7fecf713a187dc4dbecd0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5debb703fbd7fecf713a187dc4dbecd0"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForDotProduct</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a5debb703fbd7fecf713a187dc4dbecd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a759c87f7659eb48d10d55307e0434848"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a759c87f7659eb48d10d55307e0434848"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SquaredL2Distance, <a class="el" href="classcaffe2_1_1_squared_l2_distance_op.html">SquaredL2DistanceOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a759c87f7659eb48d10d55307e0434848"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a193ee1375b1ba85a1cd7a766ea6ae047"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a193ee1375b1ba85a1cd7a766ea6ae047"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SquaredL2DistanceGradient, <a class="el" href="classcaffe2_1_1_squared_l2_distance_gradient_op.html">SquaredL2DistanceGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a193ee1375b1ba85a1cd7a766ea6ae047"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82136e05b09fbfa006d612ec955fc70d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a82136e05b09fbfa006d612ec955fc70d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given two input float tensors X, Y, and produces one output float tensor
of the L2 difference between X and Y that is computed as ||(X - Y)^2 / 2||.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a82136e05b09fbfa006d612ec955fc70d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea308eb3099e114845e74fe035573d05"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea308eb3099e114845e74fe035573d05"></a>
or input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;Y&quot;,&quot;1D or 2D input tensor (must have the same shape as X)&quot;).Output(0</td></tr>
<tr class="separator:aea308eb3099e114845e74fe035573d05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9535174dd8f5bea5c9f4d729a323bd04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9535174dd8f5bea5c9f4d729a323bd04"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (SquaredL2DistanceGradient).NumInputs(3).NumOutputs(2)</td></tr>
<tr class="separator:a9535174dd8f5bea5c9f4d729a323bd04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58166fd9b119bfdcd330b7ca74bc1f0c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a58166fd9b119bfdcd330b7ca74bc1f0c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SquaredL2Distance, <a class="el" href="classcaffe2_1_1_get_squared_l2_distance_gradient.html">GetSquaredL2DistanceGradient</a>)</td></tr>
<tr class="separator:a58166fd9b119bfdcd330b7ca74bc1f0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66d4093899c29097437b6d788a182f4f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a66d4093899c29097437b6d788a182f4f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (L1Distance, <a class="el" href="classcaffe2_1_1_l1_distance_op.html">L1DistanceOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a66d4093899c29097437b6d788a182f4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e7868e35ea4a154b4ef0846da048a1a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9e7868e35ea4a154b4ef0846da048a1a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (L1DistanceGradient, <a class="el" href="classcaffe2_1_1_l1_distance_gradient_op.html">L1DistanceGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9e7868e35ea4a154b4ef0846da048a1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af02673780e929facf0ceeb7bbb3bac4f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af02673780e929facf0ceeb7bbb3bac4f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Computes the row-wise L1 Distance between the two input tensors $X$ and $Y$, which is defined as

$$L1Distance(\mathbf{x},\mathbf{y}) = \sum_{i}\mid x_i - y_i\mid$$

Note, both inputs must either be 1-dimensional or 2-dimensional and both must have the same shape. The output $Z$ will be 1-dimensional regardless and its length will equal the number of rows in the inputs.

Github Links:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/distance_op.h
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/distance_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;L1Distance&quot;,
    [&quot;X&quot;, &quot;Y&quot;],
    [&quot;Z&quot;]
)

// Create X
X = 5*np.ones((1, 4))
print(&quot;X:\n&quot;,X)

// Create Y
Y = np.ones((1, 4))
print(&quot;Y:\n&quot;,Y)

// Feed X &amp; Y into workspace
workspace.FeedBlob(&quot;X&quot;, X.astype(np.float32))
workspace.FeedBlob(&quot;Y&quot;, Y.astype(np.float32))

// Run op
workspace.RunOperatorOnce(op)

// Collect Output
print(&quot;Z:\n&quot;, workspace.FetchBlob(&quot;Z&quot;))

```

**Result**

```

X:
 [[5. 5. 5. 5.]]
Y:
 [[1. 1. 1. 1.]]
Z:
 [16.]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:af02673780e929facf0ceeb7bbb3bac4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee3b9f21b7d6557b413396a3ec5f099d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aee3b9f21b7d6557b413396a3ec5f099d"></a>
First input&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (1D or 2D)&quot;) .Input(1</td></tr>
<tr class="separator:aee3b9f21b7d6557b413396a3ec5f099d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace005a4f165bf7c3d001a26654915a0e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ace005a4f165bf7c3d001a26654915a0e"></a>
First input Second input&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (must have the same shape as $X $)&quot;) .Output(0</td></tr>
<tr class="separator:ace005a4f165bf7c3d001a26654915a0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03dba067dd6ecf88e697a9134cc8f03a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a03dba067dd6ecf88e697a9134cc8f03a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (L1DistanceGradient).NumInputs(3).NumOutputs(2)</td></tr>
<tr class="separator:a03dba067dd6ecf88e697a9134cc8f03a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4eb2394c679844ae159d8b01ce847c6c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4eb2394c679844ae159d8b01ce847c6c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (L1Distance, <a class="el" href="classcaffe2_1_1_get_l1_distance_gradient.html">GetL1DistanceGradient</a>)</td></tr>
<tr class="separator:a4eb2394c679844ae159d8b01ce847c6c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4adc5be29a915c4fd711df9ec1005176"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4adc5be29a915c4fd711df9ec1005176"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DotProduct, <a class="el" href="classcaffe2_1_1_dot_product_op.html">DotProductOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4adc5be29a915c4fd711df9ec1005176"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa88847c6a3482af154ce49fa4e5b8708"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa88847c6a3482af154ce49fa4e5b8708"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DotProductGradient, <a class="el" href="classcaffe2_1_1_dot_product_gradient_op.html">DotProductGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa88847c6a3482af154ce49fa4e5b8708"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a427e566d99186a304ea3dc520dd8cd06"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a427e566d99186a304ea3dc520dd8cd06"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Computes and outputs the dot product of the two input float tensors `X` and `Y`.
Note that `X` and `Y` must be either 1D or 2D, and they must be the same shape.
The output tensor is 1D, which represents either the product of each element in
a respective dimension if the inputs are 1D, or the sum of the products in a
given dimension if the inputs are 2D matrices. Note that the actual dot product
is a scalar value, which is effectively the sum of the elements in the 1D
output tensor.

For 1D inputs:
Given two vectors $X = [x_0, x_1, x_2]$ and $Y = [y_0, y_1, y_2]$; $Z = [x_0 * y_0, x_1 * y_1, x_2 * y_2]$

For 2D inputs:
Given two matrices:
$$X = [[x_0^0, x_1^0, x_2^0], \\ [x_0^1, x_1^1, x_2^1], \\ [x_0^2, x_1^2, x_2^2], \\ ..., \\ [x_0^n, x_1^n, x_2^n]]$$

and

$$Y = [[y_0^0, y_1^0, y_2^0], \\ [y_0^1, y_1^1, y_2^1], \\ [y_0^2, y_1^2, y_2^2], \\ ..., \\ [y_0^n, y_1^n, y_2^n]]$$

then

$$Z =  \biggl[\Big((x_0^0 * y_0^0) + (x_1^0 * y_1^0) + (x_2^0 * y_2^0)\Big), \\ \Big((x_0^1 * y_0^1) + (x_1^1 * y_1^1) + (x_2^1 * y_2^1)\Big), \\ \Big((x_0^2 * y_0^2) + (x_1^2 * y_1^2) + (x_2^2 * y_2^2)\Big), \\ ..., \\ \Big((x_0^n * y_0^n) + (x_1^n * y_1^n) + (x_2^n * y_2^n)\Big)\biggr]$$

Github Link:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/distance_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;DotProduct&quot;,
    [&quot;X&quot;,  &quot;Y&quot;],
    [&quot;Z&quot;]
)

workspace.FeedBlob(&quot;X&quot;, np.random.randint(20, size=(5)).astype(np.float32))
workspace.FeedBlob(&quot;Y&quot;, np.random.randint(20, size=(5)).astype(np.float32))
print(&quot;X:\n&quot;, workspace.FetchBlob(&quot;X&quot;))
print(&quot;Y:\n&quot;, workspace.FetchBlob(&quot;Y&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Z:\n&quot;, workspace.FetchBlob(&quot;X&quot;))


workspace.ResetWorkspace()
workspace.FeedBlob(&quot;X&quot;, np.random.randint(10, size=(3,3)).astype(np.float32))
workspace.FeedBlob(&quot;Y&quot;, np.random.randint(10, size=(3,3)).astype(np.float32))
print(&quot;X:\n&quot;, workspace.FetchBlob(&quot;X&quot;))
print(&quot;Y:\n&quot;, workspace.FetchBlob(&quot;Y&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Z:\n&quot;, workspace.FetchBlob(&quot;Z&quot;))

```

**Result**

```

X:
 [ 2. 15.  2.  7. 12.]
Y:
 [ 3. 12.  9.  3. 18.]
Z:
 [ 2. 15.  2.  7. 12.]
X:
 [[2. 0. 4.]
 [7. 7. 4.]
 [7. 9. 9.]]
Y:
 [[2. 0. 8.]
 [9. 6. 1.]
 [7. 8. 0.]]
Z:
 [ 36. 109. 121.]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a427e566d99186a304ea3dc520dd8cd06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6abb0efe4e8e91bb3f21451535faa3bc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6abb0efe4e8e91bb3f21451535faa3bc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (DotProductGradient).NumInputs(3).NumOutputs(2)</td></tr>
<tr class="separator:a6abb0efe4e8e91bb3f21451535faa3bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d5192fbaddd9a460e2984464339f9fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d5192fbaddd9a460e2984464339f9fd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (DotProduct, <a class="el" href="classcaffe2_1_1_get_dot_product_gradient.html">GetDotProductGradient</a>)</td></tr>
<tr class="separator:a4d5192fbaddd9a460e2984464339f9fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abea4509a408b06d3e69d2764b4223462"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abea4509a408b06d3e69d2764b4223462"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CosineSimilarity, <a class="el" href="classcaffe2_1_1_cosine_similarity_op.html">CosineSimilarityOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:abea4509a408b06d3e69d2764b4223462"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5de21b7a7a3425f67a507a140c15c17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae5de21b7a7a3425f67a507a140c15c17"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CosineSimilarityGradient, <a class="el" href="classcaffe2_1_1_cosine_similarity_gradient_op.html">CosineSimilarityGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae5de21b7a7a3425f67a507a140c15c17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09f44c3897d9d52ccb0da4fb93b2bfb8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09f44c3897d9d52ccb0da4fb93b2bfb8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
This op takes two input float tensors of the same size, $X$ and $Y$, and produces one output float tensor , $Z$, calculated as the cosine similarity between $X$ and $Y$. Recall, the cosine similarity between two tensors $X$ and $Y$ is defined as:

$$\mathbf{Z}=CosineSimilarity(\mathbf{X},\mathbf{Y}) = \frac{\mathbf{X}\cdot\mathbf{Y}}{\|\mathbf{X}\|\|\mathbf{Y}\|} = \frac{\sum_n^{i=1}X_iY_i}{\sqrt{\sum_n^{i=1}X_i^2}\sqrt{\sum_n^{i=1}Y_i^2}}$$

Github Links:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/distance_op.h
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/distance_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;CosineSimilarity&quot;,
    [&quot;X&quot;, &quot;Y&quot;],
    [&quot;Z&quot;]
)

// Create X
X = np.random.randn(3, 3)
print(&quot;X:\n&quot;,X)

// Create Y
Y = np.random.randn(3, 3)
print(&quot;Y:\n&quot;,Y)

// Feed X &amp; Y into workspace
workspace.FeedBlob(&quot;X&quot;, X.astype(np.float32))
workspace.FeedBlob(&quot;Y&quot;, Y.astype(np.float32))

// Run op
workspace.RunOperatorOnce(op)

// Collect Output
print(&quot;Z:\n&quot;, workspace.FetchBlob(&quot;Z&quot;))

```

**Result**

```

X:
 [[-0.42635564 -0.23831588 -0.25515547]
 [ 1.43914719 -1.05613228  1.01717373]
 [ 0.06883105  0.33386519 -1.46648334]]
Y:
 [[-0.90648691 -0.14241514 -1.1070837 ]
 [ 0.92152729 -0.28115511 -0.17756722]
 [-0.88394254  1.34654037 -0.80080998]]
Z:
 [-1.7849885e-23  1.7849885e-23 -1.0842022e-07]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a09f44c3897d9d52ccb0da4fb93b2bfb8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e95453ffd4f09215d3d7b74b3c9ecfe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e95453ffd4f09215d3d7b74b3c9ecfe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (CosineSimilarityGradient).NumInputs(3).NumOutputs(2)</td></tr>
<tr class="separator:a8e95453ffd4f09215d3d7b74b3c9ecfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46c057b06a1c2bf40ad0ca6b9e0a03ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46c057b06a1c2bf40ad0ca6b9e0a03ad"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (CosineSimilarity, <a class="el" href="classcaffe2_1_1_get_cosine_similarity_gradient.html">GetCosineSimilarityGradient</a>)</td></tr>
<tr class="separator:a46c057b06a1c2bf40ad0ca6b9e0a03ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77b1efc8b1c93d426c7a5db470afbe3f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a77b1efc8b1c93d426c7a5db470afbe3f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DotProductWithPadding, <a class="el" href="classcaffe2_1_1_dot_product_with_padding_op.html">DotProductWithPaddingOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a77b1efc8b1c93d426c7a5db470afbe3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61e3a56d9650d88c824460e5458bf063"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a61e3a56d9650d88c824460e5458bf063"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DotProductWithPaddingGradient, <a class="el" href="classcaffe2_1_1_dot_product_with_padding_gradient_op.html">DotProductWithPaddingGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a61e3a56d9650d88c824460e5458bf063"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cdbb01665a04f6bfc9aeca0d67452f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1cdbb01665a04f6bfc9aeca0d67452f6"></a>
Y with different shapes and produces one output float tensor of the dot product between X and Y We currently support two kinds of strategies to achieve this Before doing normal dot_product pad the smaller&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (using pad_value) to the same shape as the other one.2) replicate the smaller tensor to the same shape as the other one.Note the first dimension of X</td></tr>
<tr class="separator:a1cdbb01665a04f6bfc9aeca0d67452f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5978f310e365d165d09a177968fe6cbd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5978f310e365d165d09a177968fe6cbd"></a>
Y with different shapes and produces one output float tensor of the dot product between X and Y We currently support two kinds of strategies to achieve this Before doing normal dot_product pad the smaller Y must be equal Only the second dimension of X or Y can be padded DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;1D or 2D input tensor&quot;).Input(1</td></tr>
<tr class="separator:a5978f310e365d165d09a177968fe6cbd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0834b37715cc0792963bea40709636c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0834b37715cc0792963bea40709636c"></a>
Y with different shapes and produces one output float tensor of the dot product between X and Y We currently support two kinds of strategies to achieve this Before doing normal dot_product pad the smaller Y must be equal Only the second dimension of X or Y can be padded DOC or input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Z&quot;,&quot;1D output tensor&quot;).IdenticalTypeAndShapeOfInputDim(0</td></tr>
<tr class="separator:ac0834b37715cc0792963bea40709636c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a517526992ab52ba7b03a788f13a77e03"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a517526992ab52ba7b03a788f13a77e03"></a>
Y with different shapes and produces one output float tensor of the dot product between X and Y We currently support two kinds of strategies to achieve this Before doing normal dot_product pad the smaller Y must be equal Only the second dimension of X or Y can be padded DOC or input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;pad_value&quot;,&quot;the padding value for tensors with smaller dimension&quot;).Arg(&quot;replicate&quot;</td></tr>
<tr class="separator:a517526992ab52ba7b03a788f13a77e03"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab57062b2d63a516028d03c3aa970c564"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab57062b2d63a516028d03c3aa970c564"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (DotProductWithPaddingGradient).NumInputs(3).NumOutputs(2)</td></tr>
<tr class="separator:ab57062b2d63a516028d03c3aa970c564"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afece1925a65deee851a9905ba4ef0eda"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afece1925a65deee851a9905ba4ef0eda"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (DotProductWithPadding, <a class="el" href="classcaffe2_1_1_get_dot_product_with_padding_gradient.html">GetDotProductWithPaddingGradient</a>)</td></tr>
<tr class="separator:afece1925a65deee851a9905ba4ef0eda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a120c315e80b7dd994deb27c6de2731f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a120c315e80b7dd994deb27c6de2731f5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Do, <a class="el" href="classcaffe2_1_1_do_op.html">DoOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a120c315e80b7dd994deb27c6de2731f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a918a1385c170b684f446724efd2e4457"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a918a1385c170b684f446724efd2e4457"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (1, INT_MAX).NumOutputs(1</td></tr>
<tr class="separator:a918a1385c170b684f446724efd2e4457"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c07db97daf382528ab784ac1c650715"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0c07db97daf382528ab784ac1c650715"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
'Do' control operator, executes a subnet in a separate workspace.
Last blobs in the input and output lists should be the same blob created with
CreateScope op. Arguments 'inner_blobs' and 'outer_blobs_idx' provide a mapping
between selected inner blob names and corresponding outer blob indices.
    )DOC&quot;).Arg(&quot;net&quot;</td></tr>
<tr class="separator:a0c07db97daf382528ab784ac1c650715"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a139f31d457029fdf5bf87beec6af448b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a139f31d457029fdf5bf87beec6af448b"></a>
INT_MAX Subnet with blob bindings&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;inner_blobs&quot;,&quot;List of inner net blob names to bind to outer workspace&quot;).Arg(&quot;outer_blobs_idx&quot;</td></tr>
<tr class="separator:a139f31d457029fdf5bf87beec6af448b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9918233cb5a585cbc9c9cfd7ecd7975"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab9918233cb5a585cbc9c9cfd7ecd7975"></a>
INT_MAX Subnet with blob bindings Indices of corresponding outer workspace in&#160;</td><td class="memItemRight" valign="bottom"><b>operator outputs</b> (skipping workspace blobs)&quot;) .Arg( &quot;saved_fwd_blobs&quot;</td></tr>
<tr class="separator:ab9918233cb5a585cbc9c9cfd7ecd7975"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61023ad7af7d38a277e79cce170b557b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a61023ad7af7d38a277e79cce170b557b"></a>
INT_MAX Subnet with blob bindings Indices of corresponding outer workspace in List of blobs from the forward Do&#160;</td><td class="memItemRight" valign="bottom"><b>operator workspace needed&quot; &quot;in backward pass, used in gradient Do operator&quot;) .Arg</b> (&quot;reuse_workspace&quot;,&quot;Whether to reuse workspace or create a new one in a given scope&quot;).AllowInplace([](int in</td></tr>
<tr class="separator:a61023ad7af7d38a277e79cce170b557b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c9aec77b9877ad602837148d5dff1f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c9aec77b9877ad602837148d5dff1f6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Do, <a class="el" href="classcaffe2_1_1_do_op.html">DoOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a3c9aec77b9877ad602837148d5dff1f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dff897b9581cf290790faf38553b148"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dff897b9581cf290790faf38553b148"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Dropout, <a class="el" href="classcaffe2_1_1_dropout_op.html">DropoutOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3dff897b9581cf290790faf38553b148"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5fba04361c3efc8e7a8e59f9ecaec39"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5fba04361c3efc8e7a8e59f9ecaec39"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (DropoutGrad, <a class="el" href="classcaffe2_1_1_dropout_gradient_op.html">DropoutGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac5fba04361c3efc8e7a8e59f9ecaec39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8418272a90cc7223a92f2660ad6d2c00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8418272a90cc7223a92f2660ad6d2c00"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (def.output().size()==2)</td></tr>
<tr class="separator:a8418272a90cc7223a92f2660ad6d2c00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8474f5d46936f2c0bd370f5bc9df02d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8474f5d46936f2c0bd370f5bc9df02d5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(

`Dropout` takes one input data tensor (`X`) and produces two tensor outputs, `Y` and
`mask`. If the `is_test` argument is zero (default=0), the output `Y` will be the input
with random elements zeroed. The probability that a given element is zeroed is
determined by the `ratio` argument.

If the `is_test` argument is set to non-zero, the output `Y` is exactly the same as the
input `X`. Note that outputs are scaled by a factor of $\frac{1}{1-ratio}$ during
training, so that during test time, we can simply compute an identity function. This
scaling is important because we want the output at test time to equal the expected value
at training time. Dropout has been proven to be an effective regularization technique to
prevent overfitting during training.


Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/dropout_op.h
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/dropout_op.cc


&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Dropout&quot;,
    [&quot;X&quot;],
    [&quot;Y&quot;] + [&quot;mask&quot;],
    ratio=0.5,
    is_test=0
)

workspace.FeedBlob(&quot;X&quot;, np.random.randint(10, size=(5, 5)).astype(np.float32))
print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
print(&quot;mask:&quot;, workspace.FetchBlob(&quot;mask&quot;))
```

**Result**

```
X: [[5. 4. 3. 6. 9.]
 [2. 1. 8. 0. 9.]
 [7. 3. 0. 6. 3.]
 [1. 8. 2. 6. 4.]
 [6. 2. 6. 4. 0.]]
Y: [[ 0.  0.  0. 12. 18.]
 [ 0.  0. 16.  0.  0.]
 [ 0.  0.  0. 12.  6.]
 [ 0.  0.  4.  0.  0.]
 [12.  0.  0.  0.  0.]]
mask: [[False False False  True  True]
 [False False  True  True False]
 [False False  True  True  True]
 [False False  True False False]
 [ True False False False False]]
```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;ratio&quot;</td></tr>
<tr class="separator:a8474f5d46936f2c0bd370f5bc9df02d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7cba4f4dee9d0bef0751b881395dec64"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7cba4f4dee9d0bef0751b881395dec64"></a>
default perform dropout If non&#160;</td><td class="memItemRight" valign="bottom"><b>zero</b> (test mode)</td></tr>
<tr class="separator:a7cba4f4dee9d0bef0751b881395dec64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ee809be80b8cc87ce4358d03159b43a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8ee809be80b8cc87ce4358d03159b43a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Dropout, <a class="el" href="classcaffe2_1_1_get_dropout_gradient.html">GetDropoutGradient</a>)</td></tr>
<tr class="separator:a8ee809be80b8cc87ce4358d03159b43a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57de362d6e039b8cc7d7d0e3c08f86fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a57de362d6e039b8cc7d7d0e3c08f86fd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AddGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_add_functor.html">AddFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a57de362d6e039b8cc7d7d0e3c08f86fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a961b76c39f2fdcfb2b9a1a9702ac1e0c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a961b76c39f2fdcfb2b9a1a9702ac1e0c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_add.html">Add</a>, GetAddGradient)</td></tr>
<tr class="separator:a961b76c39f2fdcfb2b9a1a9702ac1e0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bc96057f9c1cf3491a2ca08bfb97ff7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3bc96057f9c1cf3491a2ca08bfb97ff7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_add.html">Add</a>, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_add_functor.html">AddFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a3bc96057f9c1cf3491a2ca08bfb97ff7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6cdb1170d8a3fdd26b8e956b0eff099"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6cdb1170d8a3fdd26b8e956b0eff099"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_add.html">Add</a>, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_add_functor.html">AddFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad6cdb1170d8a3fdd26b8e956b0eff099"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65e8de6f3dfac0b386a3e7288c186d73"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a65e8de6f3dfac0b386a3e7288c186d73"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (AddGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_add_functor.html">AddFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a65e8de6f3dfac0b386a3e7288c186d73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae96339ba7b692e882a7ec6bf24127d41"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae96339ba7b692e882a7ec6bf24127d41"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DivGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_div_functor.html">DivFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ae96339ba7b692e882a7ec6bf24127d41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefc52bb39342ddc784595be98d60bebb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aefc52bb39342ddc784595be98d60bebb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Div, GetDivGradient)</td></tr>
<tr class="separator:aefc52bb39342ddc784595be98d60bebb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a622b9e4368eb13b9c2fd7fef6f4188df"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a622b9e4368eb13b9c2fd7fef6f4188df"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Div, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_div_functor.html">DivFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a622b9e4368eb13b9c2fd7fef6f4188df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4696f995a2d3eda5ff8ae4ae89f967c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af4696f995a2d3eda5ff8ae4ae89f967c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ElementwiseLinear, <a class="el" href="classcaffe2_1_1_elementwise_linear_op.html">ElementwiseLinearOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af4696f995a2d3eda5ff8ae4ae89f967c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a825114a76adc85d79bd206213e1c002a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a825114a76adc85d79bd206213e1c002a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ElementwiseLinearGradient, <a class="el" href="classcaffe2_1_1_elementwise_linear_gradient_op.html">ElementwiseLinearGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a825114a76adc85d79bd206213e1c002a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab36cb19298d392bfba498e3ea64f14c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab36cb19298d392bfba498e3ea64f14c3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ElementwiseLinear, <a class="el" href="structcaffe2_1_1_get_elementwise_linear_gradient.html">GetElementwiseLinearGradient</a>)</td></tr>
<tr class="separator:ab36cb19298d392bfba498e3ea64f14c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3176f7623972f962effa9f82af1e1e6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3176f7623972f962effa9f82af1e1e6d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MulGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_mul_functor.html">MulFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a3176f7623972f962effa9f82af1e1e6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b63c1357e1ee64093941cfc4ce9bf97"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1b63c1357e1ee64093941cfc4ce9bf97"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Mul, GetMulGradient)</td></tr>
<tr class="separator:a1b63c1357e1ee64093941cfc4ce9bf97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a20ebc7136eacbbea4841e05afc0058"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a20ebc7136eacbbea4841e05afc0058"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Mul, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_mul_functor.html">MulFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0a20ebc7136eacbbea4841e05afc0058"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad557e4af760ed42725ed6e8632f72e8c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad557e4af760ed42725ed6e8632f72e8c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Not, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">BoolTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_not_functor.html">NotFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad557e4af760ed42725ed6e8632f72e8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc748e55408447ad0b6eff3b14d82791"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc748e55408447ad0b6eff3b14d82791"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Sign, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sign_functor.html">SignFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:adc748e55408447ad0b6eff3b14d82791"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd7b63941e59a63a1976d2078e756715"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd7b63941e59a63a1976d2078e756715"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_COMPARE_OPERATOR</b> (EQ)</td></tr>
<tr class="separator:afd7b63941e59a63a1976d2078e756715"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83af9b8558a9bdfa751782e40de05cd4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a83af9b8558a9bdfa751782e40de05cd4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_COMPARE_OPERATOR</b> (NE)</td></tr>
<tr class="separator:a83af9b8558a9bdfa751782e40de05cd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad470bbd146f0e6c4132ed0e378a50173"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad470bbd146f0e6c4132ed0e378a50173"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_COMPARE_OPERATOR</b> (LT)</td></tr>
<tr class="separator:ad470bbd146f0e6c4132ed0e378a50173"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d48ca6b517ca1faaf7dc55731ef154c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8d48ca6b517ca1faaf7dc55731ef154c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_COMPARE_OPERATOR</b> (LE)</td></tr>
<tr class="separator:a8d48ca6b517ca1faaf7dc55731ef154c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae24c997478c3436d19ca52ccbf0b9370"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae24c997478c3436d19ca52ccbf0b9370"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_COMPARE_OPERATOR</b> (GT)</td></tr>
<tr class="separator:ae24c997478c3436d19ca52ccbf0b9370"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c4f32f375626bc8bc48130301b7beae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2c4f32f375626bc8bc48130301b7beae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_COMPARE_OPERATOR</b> (GE)</td></tr>
<tr class="separator:a2c4f32f375626bc8bc48130301b7beae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae30e12d42bf4d6848f759e5c809bd151"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae30e12d42bf4d6848f759e5c809bd151"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_LOGICAL_BINARY_OPERATOR</b> (And)</td></tr>
<tr class="separator:ae30e12d42bf4d6848f759e5c809bd151"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade569fbf61eaf74a2ea03ca638837044"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade569fbf61eaf74a2ea03ca638837044"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_LOGICAL_BINARY_OPERATOR</b> (Or)</td></tr>
<tr class="separator:ade569fbf61eaf74a2ea03ca638837044"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a026f488647a10ff41eecb948a24e6b50"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a026f488647a10ff41eecb948a24e6b50"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_LOGICAL_BINARY_OPERATOR</b> (Xor)</td></tr>
<tr class="separator:a026f488647a10ff41eecb948a24e6b50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cb63c851006e8c1ffa7b1134e68eb3f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0cb63c851006e8c1ffa7b1134e68eb3f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_BITWISE_BINARY_OPERATOR</b> (BitwiseAnd)</td></tr>
<tr class="separator:a0cb63c851006e8c1ffa7b1134e68eb3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a575a60ca168fd1592058af53963dbdf9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a575a60ca168fd1592058af53963dbdf9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_BITWISE_BINARY_OPERATOR</b> (BitwiseOr)</td></tr>
<tr class="separator:a575a60ca168fd1592058af53963dbdf9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f21af8d2ed4d57bcb760d2a8e896e10"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f21af8d2ed4d57bcb760d2a8e896e10"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_BITWISE_BINARY_OPERATOR</b> (BitwiseXor)</td></tr>
<tr class="separator:a1f21af8d2ed4d57bcb760d2a8e896e10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5090bd618e12592070b3ac536c5a052"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad5090bd618e12592070b3ac536c5a052"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SumReduceLike, <a class="el" href="classcaffe2_1_1_sum_reduce_like_op.html">SumReduceLikeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad5090bd618e12592070b3ac536c5a052"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a589f797f5c81ecddc5cf911ebd86ca07"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a589f797f5c81ecddc5cf911ebd86ca07"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (EQ)</td></tr>
<tr class="separator:a589f797f5c81ecddc5cf911ebd86ca07"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cc60c839d0a558ac2370f04cb5e447a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6cc60c839d0a558ac2370f04cb5e447a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (NE)</td></tr>
<tr class="separator:a6cc60c839d0a558ac2370f04cb5e447a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07f4ea7c6ee0927218802fd7401f72d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a07f4ea7c6ee0927218802fd7401f72d0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (LT)</td></tr>
<tr class="separator:a07f4ea7c6ee0927218802fd7401f72d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ae59831200b36577e94b3c0758447f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6ae59831200b36577e94b3c0758447f4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (LE)</td></tr>
<tr class="separator:a6ae59831200b36577e94b3c0758447f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2965d64f6f49c6e55d9ccb7ee2ba7892"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2965d64f6f49c6e55d9ccb7ee2ba7892"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (GT)</td></tr>
<tr class="separator:a2965d64f6f49c6e55d9ccb7ee2ba7892"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab058b2ce3935356375e282e6456c9458"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab058b2ce3935356375e282e6456c9458"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (GE)</td></tr>
<tr class="separator:ab058b2ce3935356375e282e6456c9458"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff21364c380dda3ddc68146ced268c25"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff21364c380dda3ddc68146ced268c25"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (And)</td></tr>
<tr class="separator:aff21364c380dda3ddc68146ced268c25"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ddbd48e07e409dbb10252d535f6c518"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3ddbd48e07e409dbb10252d535f6c518"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (Or)</td></tr>
<tr class="separator:a3ddbd48e07e409dbb10252d535f6c518"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70257a3f898d442960cea8a10fdc8433"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a70257a3f898d442960cea8a10fdc8433"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (Xor)</td></tr>
<tr class="separator:a70257a3f898d442960cea8a10fdc8433"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4372feaaf6139eca3c4d54c2f6cdde6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad4372feaaf6139eca3c4d54c2f6cdde6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (BitwiseAnd)</td></tr>
<tr class="separator:ad4372feaaf6139eca3c4d54c2f6cdde6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5e3bfa26d36c0afbcf0b8d15cd93921"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad5e3bfa26d36c0afbcf0b8d15cd93921"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (BitwiseOr)</td></tr>
<tr class="separator:ad5e3bfa26d36c0afbcf0b8d15cd93921"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdcecc21c0a75b1b5b4f249472917b17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acdcecc21c0a75b1b5b4f249472917b17"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_FOWARD_ONLY_BINARY_FUNCTOR</b> (BitwiseXor)</td></tr>
<tr class="separator:acdcecc21c0a75b1b5b4f249472917b17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a031465b6431c8f4717f46a25db8a9c28"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a031465b6431c8f4717f46a25db8a9c28"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceFunction</b> (PointwiseCostInference&lt; 1 &gt;).TensorInferenceFunction(ElementwiseOpShapeInference).FillUsing(MathDocGenerator(&quot;addition&quot;</td></tr>
<tr class="separator:a031465b6431c8f4717f46a25db8a9c28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3338f28d9f20274ff81e6356759decd1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3338f28d9f20274ff81e6356759decd1"></a>
and the dimensions of the second input is the contiguous subset of the dimensions of the first For the following tensor shapes are&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (<a class="el" href="struct_b.html">B</a>)</td></tr>
<tr class="separator:a3338f28d9f20274ff81e6356759decd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3bf4918b3309dec0d3e0f99e4913e84"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab3bf4918b3309dec0d3e0f99e4913e84"></a>
and the dimensions of the second input is the contiguous subset of the dimensions of the first For the following tensor shapes are i e <a class="el" href="struct_b.html">B</a> is a scalar&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (<a class="el" href="struct_a.html">A</a>)</td></tr>
<tr class="separator:ab3bf4918b3309dec0d3e0f99e4913e84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adaab7e6b9241ca90f51f3b9cf1adc8c4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adaab7e6b9241ca90f51f3b9cf1adc8c4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SubGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sub_functor.html">SubFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:adaab7e6b9241ca90f51f3b9cf1adc8c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecc060ecefb6d663cebc3b6235aead3d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aecc060ecefb6d663cebc3b6235aead3d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Sub, GetSubGradient)</td></tr>
<tr class="separator:aecc060ecefb6d663cebc3b6235aead3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa37ec87bb36a4f81d44dc30ba91a0a40"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa37ec87bb36a4f81d44dc30ba91a0a40"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Sub, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sub_functor.html">SubFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aa37ec87bb36a4f81d44dc30ba91a0a40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a637969c14e27bf0cd1b4d92abf697a03"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a637969c14e27bf0cd1b4d92abf697a03"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Sub, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_sub_functor.html">SubFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a637969c14e27bf0cd1b4d92abf697a03"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac606c161a7208dbdeff9ee12337a6c65"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac606c161a7208dbdeff9ee12337a6c65"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (SubGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_gradient_op.html">BinaryElementwiseGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_sub_functor.html">SubFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ac606c161a7208dbdeff9ee12337a6c65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9b718bd1d99ccaa1b0629a7f1fc6d00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9b718bd1d99ccaa1b0629a7f1fc6d00"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_sum.html">Sum</a>, <a class="el" href="classcaffe2_1_1_sum_op.html">SumOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad9b718bd1d99ccaa1b0629a7f1fc6d00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b1f5fb42a66bc0f72de579b62a4db1c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1b1f5fb42a66bc0f72de579b62a4db1c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceFunction</b> (CostInferenceForSum).InputsCanCrossDevices().IdenticalTypeAndShapeOfInput(0).SetDoc(R&quot;DOC( Element-wise sum of each of the input tensors. The first input tensor can be used in-place as the output tensor</td></tr>
<tr class="separator:a1b1f5fb42a66bc0f72de579b62a4db1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35c06ab5650f38a8e2be26011253ad00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35c06ab5650f38a8e2be26011253ad00"></a>
in which case the sum will be done in place and results will be accumulated the first input tensor All inputs and outputs must have the same shape and data type Github workspace&#160;</td><td class="memItemRight" valign="bottom"><b>FeedBlob</b> (&quot;A&quot;, np.array([[1, 2],[3, 4]]).astype(np.float32)) workspace.FeedBlob(&quot;B&quot;</td></tr>
<tr class="separator:a35c06ab5650f38a8e2be26011253ad00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a529b1b2343a0d432705c94993162bca3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a529b1b2343a0d432705c94993162bca3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Elu, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_elu_functor.html">EluFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a529b1b2343a0d432705c94993162bca3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8708578ecbc65ee98d5043d9269ace33"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8708578ecbc65ee98d5043d9269ace33"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (EluGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_elu_gradient_functor.html">EluGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a8708578ecbc65ee98d5043d9269ace33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e5a05b09105f42b5f8b316cf0ec95c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e5a05b09105f42b5f8b316cf0ec95c9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Elu, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_op.html">CuDNNActivationOp</a>&lt; CUDNN_ACTIVATION_ELU &gt;)</td></tr>
<tr class="separator:a1e5a05b09105f42b5f8b316cf0ec95c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9614b2ed5a5bdf26f2b4b9b06bfe1fcb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9614b2ed5a5bdf26f2b4b9b06bfe1fcb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (EluGradient, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_gradient_op.html">CuDNNActivationGradientOp</a>&lt; CUDNN_ACTIVATION_ELU &gt;)</td></tr>
<tr class="separator:a9614b2ed5a5bdf26f2b4b9b06bfe1fcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7418d503891e8e514fc516a98991e17a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7418d503891e8e514fc516a98991e17a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (EnforceFinite, <a class="el" href="classcaffe2_1_1_enforce_finite_op.html">EnforceFiniteOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7418d503891e8e514fc516a98991e17a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a553418ca50fd6b3359b93cace07840bc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a553418ca50fd6b3359b93cace07840bc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (EnforceFinite)</td></tr>
<tr class="separator:a553418ca50fd6b3359b93cace07840bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62643622fd0dbb57f1e76818c4871f88"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62643622fd0dbb57f1e76818c4871f88"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (EnsureClipped, <a class="el" href="classcaffe2_1_1_ensure_clipped_op.html">EnsureClippedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a62643622fd0dbb57f1e76818c4871f88"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafa222e16214cf5377e161d298c85aaa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aafa222e16214cf5377e161d298c85aaa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (1, 3).NumOutputs(1).Input(0</td></tr>
<tr class="separator:aafa222e16214cf5377e161d298c85aaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad147356e6c85447cec332ff4d8989dc2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad147356e6c85447cec332ff4d8989dc2"></a>
Parameters to be normalized&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;indices&quot;,&quot;Sparse indices, only needed for sparse param&quot;).Input(2</td></tr>
<tr class="separator:ad147356e6c85447cec332ff4d8989dc2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9aa771f16ac45bb6bb976195a9b7b47e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9aa771f16ac45bb6bb976195a9b7b47e"></a>
Parameters to be normalized Gradient only needed for sparse param&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output_param&quot;,&quot;param ensured to be clipped within range&quot;).AllowInplace(</td></tr>
<tr class="separator:a9aa771f16ac45bb6bb976195a9b7b47e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3fd4115551ed44fcfcf43874ccced1f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae3fd4115551ed44fcfcf43874ccced1f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given a tensor, apply clip after gradient is applied; when the param is sparse as
indicated by valid indices and grad, in-place is required
)DOC&quot;)</td></tr>
<tr class="separator:ae3fd4115551ed44fcfcf43874ccced1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4db464743225460d9e4b2b8a57ea2965"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4db464743225460d9e4b2b8a57ea2965"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (EnsureClipped)</td></tr>
<tr class="separator:a4db464743225460d9e4b2b8a57ea2965"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30ccf943e94745d76ff62ebffadf70d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a30ccf943e94745d76ff62ebffadf70d9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (EnsureCPUOutput, <a class="el" href="classcaffe2_1_1_ensure_c_p_u_output_op.html">EnsureCPUOutputOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a30ccf943e94745d76ff62ebffadf70d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cf21e0c4328e6bdff3a116f7b3b93d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1cf21e0c4328e6bdff3a116f7b3b93d6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
This Op always create <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> output, and may involves cross-device MemCpy.
Under CPU Context, this Op takes <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> as input. Under the CUDA Context,
this Op accepts either CUDA or CPU <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> input.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a1cf21e0c4328e6bdff3a116f7b3b93d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74a7866c4896ba4a33435f9fae6a807b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a74a7866c4896ba4a33435f9fae6a807b"></a>
The input CUDA or CPU tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> that is a copy of the input.&quot;)</td></tr>
<tr class="separator:a74a7866c4896ba4a33435f9fae6a807b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2a1fb3e97c2ec1f87409047f81d4948"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae2a1fb3e97c2ec1f87409047f81d4948"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (EnsureCPUOutput)</td></tr>
<tr class="separator:ae2a1fb3e97c2ec1f87409047f81d4948"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f0e69950debd04c142afa43462392d8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0f0e69950debd04c142afa43462392d8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Erf, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_erf_functor.html">ErfFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0f0e69950debd04c142afa43462392d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a644783055b17753bc52520368c2e964e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a644783055b17753bc52520368c2e964e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ErfGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_erf_gradient_functor.html">ErfGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a644783055b17753bc52520368c2e964e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bb6b2670a2f1e8e2b4d006a617234c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7bb6b2670a2f1e8e2b4d006a617234c5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Erf, GetErfGradient)</td></tr>
<tr class="separator:a7bb6b2670a2f1e8e2b4d006a617234c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ad8706464f66fd9f17179ea408ad12a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7ad8706464f66fd9f17179ea408ad12a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Exp, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_exp_functor.html">ExpFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a7ad8706464f66fd9f17179ea408ad12a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace21a98aaf448ca86e2f57c4467765e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ace21a98aaf448ca86e2f57c4467765e6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Exp, GetExpGradient)</td></tr>
<tr class="separator:ace21a98aaf448ca86e2f57c4467765e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a770355fdf509712b0730f0cb66d2a9fa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a770355fdf509712b0730f0cb66d2a9fa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Exp, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_exp_functor.html">ExpFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a770355fdf509712b0730f0cb66d2a9fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77bcc8bfbcfe4685d6ab4b4703eff997"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a77bcc8bfbcfe4685d6ab4b4703eff997"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Expand, <a class="el" href="classcaffe2_1_1_expand_op.html">ExpandOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a77bcc8bfbcfe4685d6ab4b4703eff997"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1c40c7f1edc7f55801a2c0eecfe88bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac1c40c7f1edc7f55801a2c0eecfe88bb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ExpandGradient, <a class="el" href="classcaffe2_1_1_expand_gradient_op.html">ExpandGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac1c40c7f1edc7f55801a2c0eecfe88bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5614cdacaee9175458c3412749b5fab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5614cdacaee9175458c3412749b5fab"></a>
NumInputs(2).NumOutputs(1).SetDoc(R&quot;DOC( Broadcast the input tensor to a materialized new tensor using given shape. Broadcast rule is similar to &quot;numpy.array(input)*numpy.ones(shape)&quot; Two corresponding dimensions must have the same or one of them equals to In order to align with PyTorch s shape is allowed to have entries equal which means to preserve the size of the corresponding dimension in&#160;</td><td class="memItemRight" valign="bottom"><b>X</b> (so it's actually equivalent to equal to 1).) DOC&quot;) .Input(0</td></tr>
<tr class="separator:ac5614cdacaee9175458c3412749b5fab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55028ca61c6d3e562980e1701cb8a0b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55028ca61c6d3e562980e1701cb8a0b4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (ExpandGradient).NumInputs(2).NumOutputs(1)</td></tr>
<tr class="separator:a55028ca61c6d3e562980e1701cb8a0b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a985d0ab4f02ac684dc9039f9539100b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a985d0ab4f02ac684dc9039f9539100b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Expand, GetExpandGradient)</td></tr>
<tr class="separator:a985d0ab4f02ac684dc9039f9539100b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b7e15479f5e792c97de4a91b09b3fb7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5b7e15479f5e792c97de4a91b09b3fb7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Expand, <a class="el" href="classcaffe2_1_1_expand_op.html">ExpandOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a5b7e15479f5e792c97de4a91b09b3fb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad822924b22e7744b10c783e0b9b0e1d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad822924b22e7744b10c783e0b9b0e1d5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ExpandGradient, <a class="el" href="classcaffe2_1_1_expand_gradient_op.html">ExpandGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ad822924b22e7744b10c783e0b9b0e1d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a639f59d659fed5f5788ff8d2444070"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a639f59d659fed5f5788ff8d2444070"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ExpandDims, <a class="el" href="classcaffe2_1_1_expand_dims_op.html">ExpandDimsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9a639f59d659fed5f5788ff8d2444070"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1df341a5f4674d17842a1b3e77366edd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1df341a5f4674d17842a1b3e77366edd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Squeeze, <a class="el" href="classcaffe2_1_1_squeeze_op.html">SqueezeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1df341a5f4674d17842a1b3e77366edd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afbada4967ee5bc7650321707601788e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afbada4967ee5bc7650321707601788e5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in){<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> helper(def);auto dims=helper.template GetRepeatedArgument&lt; int &gt;(&quot;dims&quot;);auto originalSize=dims.size();CAFFE_ENFORCE(originalSize &gt; 0,&quot;Parameter `dims` must be provided.&quot;);std::sort(dims.begin(), dims.end());dims.erase(std::unique(dims.begin(), dims.end()), dims.end());if(dims.size()&lt; originalSize){LOG(WARNING)&lt;&lt; &quot;Parameter `dims` has repeated dimensions.&quot;;}CAFFE_ENFORCE(dims.front() &gt;=0,&quot;Dimension ids must be non-negative.&quot;);CAFFE_ENFORCE_GE(in[0].dims_size()+dims.size(), dims.back()+1,&quot;Input needs at least &quot;,(1+dims.back()-dims.size()),&quot; dimensions given `dims`.&quot;);vector&lt; TensorShape &gt; out(1);int cur_pos=0;int idx=0;for(const auto new_dim:dims){for(int i=cur_pos;i&lt; new_dim;i++){out[0].add_dims(in[0].dims(idx++));}out[0].add_dims(1);cur_pos=new_dim+1;}for(;idx&lt; in[0].dims_size();idx++){out[0].add_dims(in[0].dims(idx));}out[0].set_data_type(in[0].data_type());return out;}).SetDoc(R&quot;DOC( The *ExpandDims* op inserts single-dimensional entries into the shape of the input tensor *data</td></tr>
<tr class="separator:afbada4967ee5bc7650321707601788e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb54da6115ccb4df3786967a3bad329e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afb54da6115ccb4df3786967a3bad329e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
The *Squeeze* op removes single-dimensional entries from the shape of the input tensor *data,* and produces a single output tensor *squeezed*. The op also takes an argument *dims* with a list of dimensions to squeeze. If the same blob is provided as input and output, the operation is copy-free. This is the exact inverse operation of *ExpandDims* given the same *dims* argument.

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/expand_squeeze_dims_op.h
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/expand_squeeze_dims_op.cc


&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Squeeze&quot;,
    [&quot;data&quot;],
    [&quot;squeezed&quot;],
    dims=[0,1],
)

workspace.FeedBlob(&quot;data&quot;, np.zeros((1,1,100,100)).astype(np.float32))
print(&quot;data.shape:&quot;, workspace.FetchBlob(&quot;data&quot;).shape)

workspace.RunOperatorOnce(op)
print(&quot;squeezed.shape:&quot;, workspace.FetchBlob(&quot;squeezed&quot;).shape)

```

**Result**

```

data.shape: (1, 1, 100, 100)
squeezed.shape: (100, 100)

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:afb54da6115ccb4df3786967a3bad329e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9172e566a10c2889598d55714786c7b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9172e566a10c2889598d55714786c7b9"></a>
Input tensor of data to be operated on&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;squeezed&quot;,&quot;Reshaped tensor with same data as input.&quot;).Arg(&quot;dims&quot;</td></tr>
<tr class="separator:a9172e566a10c2889598d55714786c7b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae75479f04ec0d0503f861905ffa60700"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae75479f04ec0d0503f861905ffa60700"></a>
dims&#160;</td><td class="memItemRight" valign="bottom"><b>erase</b> (std::unique(dims.begin(), dims.end()), dims.end())</td></tr>
<tr class="separator:ae75479f04ec0d0503f861905ffa60700"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48a5af17a543ced8c4da8772906557f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a48a5af17a543ced8c4da8772906557f1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (dims.size()&lt; originalSize)</td></tr>
<tr class="separator:a48a5af17a543ced8c4da8772906557f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf07617f49465d46542ecabb78ad4c35"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf07617f49465d46542ecabb78ad4c35"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE</b> (dims.front() &gt;=0,&quot;Dimension ids must be non-negative.&quot;)</td></tr>
<tr class="separator:adf07617f49465d46542ecabb78ad4c35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab04c03a72626c14843c248829f802c50"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab04c03a72626c14843c248829f802c50"></a>
vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>out</b> (1)</td></tr>
<tr class="separator:ab04c03a72626c14843c248829f802c50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b60a58e1c5dae6975675d435545f8e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b60a58e1c5dae6975675d435545f8e6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Squeeze, <a class="el" href="classcaffe2_1_1_get_squeeze_gradient.html">GetSqueezeGradient</a>)</td></tr>
<tr class="separator:a0b60a58e1c5dae6975675d435545f8e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9835756d2b6eba7fea41ab82a4660567"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9835756d2b6eba7fea41ab82a4660567"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ExpandDims, <a class="el" href="classcaffe2_1_1_get_expand_dims_gradient.html">GetExpandDimsGradient</a>)</td></tr>
<tr class="separator:a9835756d2b6eba7fea41ab82a4660567"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b27586c43651c1c73785db21657ddfc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b27586c43651c1c73785db21657ddfc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Squeeze, <a class="el" href="classcaffe2_1_1_squeeze_op.html">SqueezeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a0b27586c43651c1c73785db21657ddfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ba9712992902de52a0c864a424d4a93"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3ba9712992902de52a0c864a424d4a93"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ExpandDims, <a class="el" href="classcaffe2_1_1_expand_dims_op.html">ExpandDimsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a3ba9712992902de52a0c864a424d4a93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3a63ed1c95e5afbf97b991613cb7ee8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3a63ed1c95e5afbf97b991613cb7ee8"></a>
std::vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>FCShapeInference</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in, bool pretransposed_weight)</td></tr>
<tr class="separator:af3a63ed1c95e5afbf97b991613cb7ee8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08efd21a1586572085a5cb5f80adff82"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08efd21a1586572085a5cb5f80adff82"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForFC</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in, bool pretransposed_weight)</td></tr>
<tr class="separator:a08efd21a1586572085a5cb5f80adff82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9b6dc5a6a52e2c93b44713b7133578d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9b6dc5a6a52e2c93b44713b7133578d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FeedBlob, <a class="el" href="classcaffe2_1_1_feed_blob_op.html">FeedBlobOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa9b6dc5a6a52e2c93b44713b7133578d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8351e03fb859b3632d11f62ad1d8950c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8351e03fb859b3632d11f62ad1d8950c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (FeedBlob)</td></tr>
<tr class="separator:a8351e03fb859b3632d11f62ad1d8950c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72a4dfd4bf8a7ea0f46944463a766650"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a72a4dfd4bf8a7ea0f46944463a766650"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (0, 0).NumOutputs(1</td></tr>
<tr class="separator:a72a4dfd4bf8a7ea0f46944463a766650"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a340fab007e3db9818f9b88d2bb195134"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a340fab007e3db9818f9b88d2bb195134"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
FeedBlobs the content of the blobs. The input and output blobs should be
one-to-one inplace.)DOC&quot;).Arg(&quot;value&quot;</td></tr>
<tr class="separator:a340fab007e3db9818f9b88d2bb195134"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27f639e28601da3c07ac8e237b3572c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a27f639e28601da3c07ac8e237b3572c3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UniformFill, <a class="el" href="classcaffe2_1_1_uniform_fill_op.html">UniformFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a27f639e28601da3c07ac8e237b3572c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1974816c7e4b3740e96cc2f940a90af"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa1974816c7e4b3740e96cc2f940a90af"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UniformIntFill, <a class="el" href="classcaffe2_1_1_uniform_fill_op.html">UniformFillOp</a>&lt; int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa1974816c7e4b3740e96cc2f940a90af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac81b63ebab12452f6f8e8d57980dd1f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aac81b63ebab12452f6f8e8d57980dd1f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UniqueUniformFill, <a class="el" href="classcaffe2_1_1_unique_uniform_fill_op.html">UniqueUniformFillOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aac81b63ebab12452f6f8e8d57980dd1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a1e9f65068d0fcb55d3699c00559e46"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a1e9f65068d0fcb55d3699c00559e46"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ConstantFill, <a class="el" href="classcaffe2_1_1_constant_fill_op.html">ConstantFillOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9a1e9f65068d0fcb55d3699c00559e46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a210f156a8503d60d2a32394a8656458b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a210f156a8503d60d2a32394a8656458b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DiagonalFill, <a class="el" href="classcaffe2_1_1_diagonal_fill_op.html">DiagonalFillOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a210f156a8503d60d2a32394a8656458b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5041564a2c1bb5307576f93e6b2ee2e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af5041564a2c1bb5307576f93e6b2ee2e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GaussianFill, <a class="el" href="classcaffe2_1_1_gaussian_fill_op.html">GaussianFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af5041564a2c1bb5307576f93e6b2ee2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af52c5c69d3eff8b8997ddd2d0321db30"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af52c5c69d3eff8b8997ddd2d0321db30"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (XavierFill, <a class="el" href="classcaffe2_1_1_xavier_fill_op.html">XavierFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af52c5c69d3eff8b8997ddd2d0321db30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa8a118c7c04bd6a44970b938c397c18"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa8a118c7c04bd6a44970b938c397c18"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MSRAFill, <a class="el" href="classcaffe2_1_1_m_s_r_a_fill_op.html">MSRAFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afa8a118c7c04bd6a44970b938c397c18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a212da7c76bc28aaf943d4814799b0c83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a212da7c76bc28aaf943d4814799b0c83"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RangeFill, <a class="el" href="classcaffe2_1_1_range_fill_op.html">RangeFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a212da7c76bc28aaf943d4814799b0c83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a85b6d6e73a4c5ed6acdf7c5d81357f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a85b6d6e73a4c5ed6acdf7c5d81357f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsRangeFill, <a class="el" href="classcaffe2_1_1_lengths_range_fill_op.html">LengthsRangeFillOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7a85b6d6e73a4c5ed6acdf7c5d81357f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab90ceace9aa6733418c5e0b28bd5df32"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab90ceace9aa6733418c5e0b28bd5df32"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> (FillerTensorInference&lt;&gt;).SetDoc(R&quot;DOC( This operator fills the elements of the output tensor with a const ant value specified by the `value` argument. - The data type is specified by the `dtype` argument - Currently</td></tr>
<tr class="separator:ab90ceace9aa6733418c5e0b28bd5df32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a6ff25f05cade0376d7c733fb59d193"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a6ff25f05cade0376d7c733fb59d193"></a>
the data types supported are *float *int32 *int64 and *bool *If the dtype argument is not the data type of value is used The output tensor shape is either specified by the shape argument or will match the shape of the input tensor if one is&#160;</td><td class="memItemRight" valign="bottom"><b>provided</b> (if an input tensor is provided, a shape argument should not be set)-Optional additional dimensions can be appended at the end as specified by`extra_shape`argument-If`input_as_shape`is set to True</td></tr>
<tr class="separator:a5a6ff25f05cade0376d7c733fb59d193"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad093e7e58af86a531730e6de392f7a7e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad093e7e58af86a531730e6de392f7a7e"></a>
the data types supported are *float *int32 *int64 and *bool *If the dtype argument is not the data type of value is used The output tensor shape is either specified by the shape argument or will match the shape of the input tensor if one is the input should be a tensor containing the desired output&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (the dimensions specified in`extra_shape`will also be appended) When specifying`dtype`argument</td></tr>
<tr class="separator:ad093e7e58af86a531730e6de392f7a7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bd86da25b1d52453ac9f0286be5b9c2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9bd86da25b1d52453ac9f0286be5b9c2"></a>
shape input must be in CPU context&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;shape&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;int&gt;`*): 1-<a class="el" href="struct_d.html">D</a> tensor of the shape of the output, must be used with `input_as_shape` argument&quot;).Input(1</td></tr>
<tr class="separator:a9bd86da25b1d52453ac9f0286be5b9c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef9e77c63d126ee189ef8705b25fde44"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef9e77c63d126ee189ef8705b25fde44"></a>
shape input must be in CPU context inclusive&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;max&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;float&gt;`*): scalar tensor containing maximum value, inclusive&quot;).Output(0</td></tr>
<tr class="separator:aef9e77c63d126ee189ef8705b25fde44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a1c14e437fa277de9fefbfd2e1dd2e7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6a1c14e437fa277de9fefbfd2e1dd2e7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> ({0, 1, 3}).NumOutputs(1).AllowInplace(</td></tr>
<tr class="separator:a6a1c14e437fa277de9fefbfd2e1dd2e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3234efc5d564075d42a04cde856c97d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae3234efc5d564075d42a04cde856c97d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> (FillerTensorInference&lt; TensorProto_DataType_INT32 &gt;).SetDoc(R&quot;DOC( Fill the output tensor with int32 samples from uniform distribution [`min`</td></tr>
<tr class="separator:ae3234efc5d564075d42a04cde856c97d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f1f3d8acaccd5c5f8a56afa4e29b70d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f1f3d8acaccd5c5f8a56afa4e29b70d"></a>
max The range can be defined either by arguments or input blobs min and max are inclusive If the range is given by input you also need to give the shape as input When the range is given as this&#160;</td><td class="memItemRight" valign="bottom"><b>operator enforces min&lt;=max.When the range is given as inputs, the constraint is not enforced.-When the range is given as inputs and max&lt; min, the first dimension of the output is set to 0.This behavior is allowed so that dynamically sampling indices into a dynamically sized tensor is possible.-The shape of the output can be given as argument or input.Github Links:-https:-https:&lt; details &gt;&lt; summary &gt;&lt; b &gt;Example&lt;/b &gt;&lt;/summary &gt; **Code **```workspace.ResetWorkspace</b> () op_1</td></tr>
<tr class="separator:a9f1f3d8acaccd5c5f8a56afa4e29b70d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad57478d3c2975b81bf1b38c48fa0c271"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad57478d3c2975b81bf1b38c48fa0c271"></a>
shape input must be in CPU context inclusive&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;max&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;int&gt;`*): scalar tensor containing maximum value, inclusive&quot;).Output(0</td></tr>
<tr class="separator:ad57478d3c2975b81bf1b38c48fa0c271"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6a9b216be18f2d9ef2adf1c79b29f5d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab6a9b216be18f2d9ef2adf1c79b29f5d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (0, 2).NumOutputs(1).AllowInplace(</td></tr>
<tr class="separator:ab6a9b216be18f2d9ef2adf1c79b29f5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5657c28c184ec81d936c87d4998068df"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5657c28c184ec81d936c87d4998068df"></a>
its elements will be excluded from uniform sampling Using the second input will require you to provide shape via the first input DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;min&quot;,&quot;Minimum value, inclusive&quot;).Arg(&quot;max&quot;</td></tr>
<tr class="separator:a5657c28c184ec81d936c87d4998068df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afcb5743daa7de23f552e8780616a369b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afcb5743daa7de23f552e8780616a369b"></a>
its elements will be excluded from uniform sampling Using the second input will require you to provide shape via the first input DOC Maximum inclusive&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;dtype&quot;,&quot;The data type for the elements of the output tensor.&quot;&quot;Strictly must be one of the types from DataType enum in TensorProto.&quot;&quot;This only supports INT32 and INT64 now. If not set, assume INT32&quot;).Arg(&quot;shape&quot;</td></tr>
<tr class="separator:afcb5743daa7de23f552e8780616a369b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0d91d1b3323cbf0b236e89e40d21a14"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad0d91d1b3323cbf0b236e89e40d21a14"></a>
its elements will be excluded from uniform sampling Using the second input will require you to provide shape via the first input DOC Maximum inclusive The shape of the output tensor Cannot set the shape argument and pass in an input at the same time&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;extra_shape&quot;,&quot;The additional dimensions appended at the end of the shape indicated&quot;&quot;by the input blob. &quot;&quot;Cannot set the extra_shape argument when there is no input blob.&quot;).Arg(&quot;input_as_shape&quot;</td></tr>
<tr class="separator:ad0d91d1b3323cbf0b236e89e40d21a14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9c462c83de0724ae87c4113b36bdef3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9c462c83de0724ae87c4113b36bdef3"></a>
its elements will be excluded from uniform sampling Using the second input will require you to provide shape via the first input DOC Maximum inclusive The shape of the output tensor Cannot set the shape argument and pass in an input at the same time tensor containing the desired output shape First input must be in CPU context&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;input&quot;,&quot;Input tensor to provide shape information&quot;).Input(1</td></tr>
<tr class="separator:aa9c462c83de0724ae87c4113b36bdef3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9434b5eb21be0e67738b7b7eb340c5e0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9434b5eb21be0e67738b7b7eb340c5e0"></a>
its elements will be excluded from uniform sampling Using the second input will require you to provide shape via the first input DOC Maximum inclusive The shape of the output tensor Cannot set the shape argument and pass in an input at the same time tensor containing the desired output shape First input must be in CPU context <a class="el" href="classc10_1_1optional.html">optional</a> Avoid elements in this tensor Elements must be unique&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;Output tensor of unique uniform samples&quot;)</td></tr>
<tr class="separator:a9434b5eb21be0e67738b7b7eb340c5e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f6b63b5943d4ef1b2c3d7f1de01050f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f6b63b5943d4ef1b2c3d7f1de01050f"></a>
if *input_as_shape *is set to *true then the *input *should be a tensor containing the desired output&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (the dimensions specified in *extra_shape *will also be appended).In this case</td></tr>
<tr class="separator:a7f6b63b5943d4ef1b2c3d7f1de01050f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affef2c8d5e428a73b191483d03642ab2"><td class="memTemplParams" colspan="2"><a class="anchor" id="affef2c8d5e428a73b191483d03642ab2"></a>
template&lt;int VALUE_TYPE = TensorProto_DataType_FLOAT&gt; </td></tr>
<tr class="memitem:affef2c8d5e428a73b191483d03642ab2"><td class="memTemplItemLeft" align="right" valign="top">std::vector&lt; TensorShape &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>FillerTensorInference</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:affef2c8d5e428a73b191483d03642ab2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab07a696b96099f051dc3ea125aa64e04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab07a696b96099f051dc3ea125aa64e04"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Index</b> (integers)&quot;) .Input(1</td></tr>
<tr class="separator:ab07a696b96099f051dc3ea125aa64e04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a776e20a70e6f034b0ab99c8cbb0e440d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a776e20a70e6f034b0ab99c8cbb0e440d"></a>
Needles query&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;query_indices&quot;,&quot;Indices of the needles in index or 'missing value'&quot;).Arg(&quot;missing_value&quot;</td></tr>
<tr class="separator:a776e20a70e6f034b0ab99c8cbb0e440d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2f8acbf738bbcfb85fa22285b787061"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af2f8acbf738bbcfb85fa22285b787061"></a>
Needles query Placeholder for items that are not found&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Finds elements of second input from first input,
outputting the last (max) index for each query.
If query not find, inserts missing_value.
See IndexGet() for a version that modifies the index when
values are not found.
)DOC&quot;)</td></tr>
<tr class="separator:af2f8acbf738bbcfb85fa22285b787061"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1755f5007b5525661e297ac95b85289d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1755f5007b5525661e297ac95b85289d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_flatten.html">Flatten</a>, <a class="el" href="classcaffe2_1_1_flatten_op.html">FlattenOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1755f5007b5525661e297ac95b85289d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84c2b2f4c470a2d8cbb8262f4295b60e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a84c2b2f4c470a2d8cbb8262f4295b60e"></a>
std::vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceForFlatten</b> (const OperatorDef &amp;def, const std::vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a84c2b2f4c470a2d8cbb8262f4295b60e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2fcd71de627b3a4c418c6ee15896cb72"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2fcd71de627b3a4c418c6ee15896cb72"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FlexibleTopK, <a class="el" href="classcaffe2_1_1_flexible_top_k_op.html">FlexibleTopKOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2fcd71de627b3a4c418c6ee15896cb72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a381f774a585fae067302931bb7c00542"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a381f774a585fae067302931bb7c00542"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FlexibleTopKGradient, <a class="el" href="classcaffe2_1_1_flexible_top_k_gradient_op.html">FlexibleTopKGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a381f774a585fae067302931bb7c00542"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae28839e5aacd40cdf93789551f87c1f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae28839e5aacd40cdf93789551f87c1f1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Floor, <a class="el" href="classcaffe2_1_1_floor_op.html">FloorOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae28839e5aacd40cdf93789551f87c1f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b8d7bdf8e132b4ec27aabf47d85e573"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8b8d7bdf8e132b4ec27aabf47d85e573"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Element-wise application of the floor function ($y=floor(x)$) to the input
tensor `X`. Output tensor shape is the same as the input tensor. This
operator can be used in an in-place fashion by using the same input blob as the
output blob.

Github Link:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/floor_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Floor&quot;,
    [&quot;X&quot;],
    [&quot;X&quot;],
)

workspace.FeedBlob(&quot;X&quot;, (np.random.uniform(-10, 10, (5,5))).astype(np.float32))
print(&quot;X before running op:&quot;, workspace.FetchBlob(&quot;X&quot;))
workspace.RunOperatorOnce(op)
print(&quot;X after running op:&quot;, workspace.FetchBlob(&quot;X&quot;))

```

**Result**

```

X before running op:
[[ 3.813361   -1.319647    5.2089314  -4.931328    0.6218652 ]
 [ 7.2757645   5.5552588   5.785643   -2.4790506  -0.41400087]
 [ 1.1541046  -6.933266    3.3754056   1.6569928  -1.7670316 ]
 [-3.4932013   4.891472    1.5530115  -3.2443287  -4.605099  ]
 [-4.574543   -7.360948    5.91305    -8.196495   -5.357458  ]]
X after running op:
[[ 3. -2.  5. -5.  0.]
 [ 7.  5.  5. -3. -1.]
 [ 1. -7.  3.  1. -2.]
 [-4.  4.  1. -4. -5.]
 [-5. -8.  5. -9. -6.]]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a8b8d7bdf8e132b4ec27aabf47d85e573"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a062dec729017bbf1bfb05a496e0b73cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a062dec729017bbf1bfb05a496e0b73cd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>GRADIENT_NOT_IMPLEMENTED_YET</b> (Floor)</td></tr>
<tr class="separator:a062dec729017bbf1bfb05a496e0b73cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace44a6fcfc0ff135335e8fbe29ce87b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ace44a6fcfc0ff135335e8fbe29ce87b2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Free, <a class="el" href="classcaffe2_1_1_free_op.html">FreeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ace44a6fcfc0ff135335e8fbe29ce87b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a069d91af285b8d6101007750937f5512"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a069d91af285b8d6101007750937f5512"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Free)</td></tr>
<tr class="separator:a069d91af285b8d6101007750937f5512"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b40bfc2fcecb522a8a90bbd063df1dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b40bfc2fcecb522a8a90bbd063df1dc"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SameNumberOfOutput</b> ().EnforceOneToOneInplace().SetDoc(R&quot;DOC( Frees the content of the blobs. The input and output blobs should be one-to-one inplace.)DOC&quot;)</td></tr>
<tr class="separator:a0b40bfc2fcecb522a8a90bbd063df1dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4f9797224aef8884a1cb233c0ffbe82"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad4f9797224aef8884a1cb233c0ffbe82"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Free, <a class="el" href="classcaffe2_1_1_free_op.html">FreeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ad4f9797224aef8884a1cb233c0ffbe82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dc120235d53fe0a733a44a98b42ab17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dc120235d53fe0a733a44a98b42ab17"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_f_c.html">FC</a>, <a class="el" href="classcaffe2_1_1_fully_connected_op.html">FullyConnectedOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3dc120235d53fe0a733a44a98b42ab17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5e5933ada17bcd8d413857a176472f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5e5933ada17bcd8d413857a176472f8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (FCGradient, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_op.html">FullyConnectedGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa5e5933ada17bcd8d413857a176472f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af71d158abf61ab81c2b0c5543a1be3f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af71d158abf61ab81c2b0c5543a1be3f9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FCTransposed, <a class="el" href="classcaffe2_1_1_fully_connected_op.html">FullyConnectedOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_default_engine.html">DefaultEngine</a>, false &gt;)</td></tr>
<tr class="separator:af71d158abf61ab81c2b0c5543a1be3f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abca3f6d4425d153cc62d7c9ca3484eac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abca3f6d4425d153cc62d7c9ca3484eac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (FCTransposedGradient, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_op.html">FullyConnectedGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="classcaffe2_1_1_default_engine.html">DefaultEngine</a>, false &gt;)</td></tr>
<tr class="separator:abca3f6d4425d153cc62d7c9ca3484eac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44555fbef3acb1dfc26cfdc9037b74be"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a44555fbef3acb1dfc26cfdc9037b74be"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_f_c.html">FC</a>, <a class="el" href="classcaffe2_1_1_fully_connected_op.html">FullyConnectedOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a44555fbef3acb1dfc26cfdc9037b74be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21cc15980ac98f61c26ba6772cb26f1a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a21cc15980ac98f61c26ba6772cb26f1a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (FCGradient, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_op.html">FullyConnectedGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a21cc15980ac98f61c26ba6772cb26f1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4aa7282aa4ed23e9f10a6ae3f021345"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad4aa7282aa4ed23e9f10a6ae3f021345"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (FCTransposed, <a class="el" href="classcaffe2_1_1_fully_connected_op.html">FullyConnectedOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="classcaffe2_1_1_default_engine.html">DefaultEngine</a>, false &gt;)</td></tr>
<tr class="separator:ad4aa7282aa4ed23e9f10a6ae3f021345"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c7cc869429fbba5869a831a6bc177a3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c7cc869429fbba5869a831a6bc177a3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (FCTransposedGradient, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_op.html">FullyConnectedGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="classcaffe2_1_1_default_engine.html">DefaultEngine</a>, false &gt;)</td></tr>
<tr class="separator:a9c7cc869429fbba5869a831a6bc177a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab195ed3ca451ff118079c3ce5b746e54"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab195ed3ca451ff118079c3ce5b746e54"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FloatToFused8BitRowwiseQuantized, <a class="el" href="classcaffe2_1_1_float_to_fused8_bit_rowwise_quantized_op.html">FloatToFused8BitRowwiseQuantizedOp</a>&lt; float, convertfp32fp32, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab195ed3ca451ff118079c3ce5b746e54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0cf9be0d724bfb17049ba6f4c8b5fef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0cf9be0d724bfb17049ba6f4c8b5fef"></a>
X&#160;</td><td class="memItemRight" valign="bottom"><b>set_dims</b> (1, X.dims(1)+8)</td></tr>
<tr class="separator:ab0cf9be0d724bfb17049ba6f4c8b5fef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab05b2e2defd481fec56b30eb1ca3894c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab05b2e2defd481fec56b30eb1ca3894c"></a>
out&#160;</td><td class="memItemRight" valign="bottom"><b>push_back</b> (std::move(X))</td></tr>
<tr class="separator:ab05b2e2defd481fec56b30eb1ca3894c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab256347686947278155efa7a54920b10"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab256347686947278155efa7a54920b10"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>set_data_type</b> (TensorProto_DataType_UINT8)</td></tr>
<tr class="separator:ab256347686947278155efa7a54920b10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf919b200358ff464b420b45a892950f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaf919b200358ff464b420b45a892950f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Applies 8-bit row-wise quantization by determining the range
(maximum - minimum) and offset (minimum value) of each row in the input
matrix, and then scaling each element to an 8-bit number between 0 and
255. To later de-quantize values, the scale (range / 255) and offset
(bias) are stored alongside the data. More precisely, the first 4 bytes
of each row in the output matrix are a 32-bit float storing the scale,
the next 4 bytes store the bias as a 32-bit float, and all remaining
bytes in the row encode single quantized values.)
)DOC&quot;).Input(0</td></tr>
<tr class="separator:aaf919b200358ff464b420b45a892950f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f1f89fe4bfd3182da651ab0c18508d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f1f89fe4bfd3182da651ab0c18508d7"></a>
Float32 input data&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;Fused scale, bias and quantized data&quot;)</td></tr>
<tr class="separator:a5f1f89fe4bfd3182da651ab0c18508d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a010084a6ee5b808fd7a27fb58b72cb6a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a010084a6ee5b808fd7a27fb58b72cb6a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (FloatToFused8BitRowwiseQuantized)</td></tr>
<tr class="separator:a010084a6ee5b808fd7a27fb58b72cb6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0ab805f3a2ded5fd7f91fd0e7f1adb7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae0ab805f3a2ded5fd7f91fd0e7f1adb7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (HalfFloatToFused8BitRowwiseQuantized, <a class="el" href="classcaffe2_1_1_float_to_fused8_bit_rowwise_quantized_op.html">FloatToFused8BitRowwiseQuantizedOp</a>&lt; <a class="el" href="structc10_1_1_half.html">at::Half</a>, convertfp16fp32, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae0ab805f3a2ded5fd7f91fd0e7f1adb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78f5679a0f638b4bf3873cc16385bc9b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a78f5679a0f638b4bf3873cc16385bc9b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (HalfFloatToFused8BitRowwiseQuantized)</td></tr>
<tr class="separator:a78f5679a0f638b4bf3873cc16385bc9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4865b70f82b735307fe681fdd41dc994"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4865b70f82b735307fe681fdd41dc994"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Fused8BitRowwiseQuantizedToFloat, <a class="el" href="classcaffe2_1_1_fused8_bit_rowwise_quantized_to_float_op.html">Fused8BitRowwiseQuantizedToFloatOp</a>&lt; float, convertfp32fp32, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4865b70f82b735307fe681fdd41dc994"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6430b732c9cdd1ba3936626f7f9a7a2b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6430b732c9cdd1ba3936626f7f9a7a2b"></a>
X&#160;</td><td class="memItemRight" valign="bottom"><b>set_dims</b> (1, X.dims(1)-8)</td></tr>
<tr class="separator:a6430b732c9cdd1ba3936626f7f9a7a2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae1bd2ffab8464109c668b45df6591f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aae1bd2ffab8464109c668b45df6591f8"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>set_data_type</b> (TensorProto_DataType_FLOAT)</td></tr>
<tr class="separator:aae1bd2ffab8464109c668b45df6591f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3a6afeaa0996763499cdb2fda4204a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa3a6afeaa0996763499cdb2fda4204a0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
De-quantizes the result of the
FloatToFused8BitRowwiseQuantized operator. The input is expected to
encode the scale as a 32-bit float in the second to the last 4 bytes of each
row, followed by the bias as a 32-bit float in the next 4 bytes, and the
quantized values in the preceding bytes of the row. The output is a
matrix containing only the values, but de-quantized. De-quantization is
performed by multiplying each value by its row's scale and bias
parameters. The de-quantized values will thus not be exactly equal to
the original, un-quantized floating point values.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:aa3a6afeaa0996763499cdb2fda4204a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a041b0b4c83ffc9470f24b2b3c14bb5e7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a041b0b4c83ffc9470f24b2b3c14bb5e7"></a>
Fused bias and quantized data&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;float_output&quot;,&quot;Float32 data&quot;)</td></tr>
<tr class="separator:a041b0b4c83ffc9470f24b2b3c14bb5e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8052dfa230a77350a00706311fea6754"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8052dfa230a77350a00706311fea6754"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Fused8BitRowwiseQuantizedToFloat)</td></tr>
<tr class="separator:a8052dfa230a77350a00706311fea6754"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d91fb0026df8d82c465b3ce386f4f5a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3d91fb0026df8d82c465b3ce386f4f5a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Fused8BitRowwiseQuantizedToHalfFloat, <a class="el" href="classcaffe2_1_1_fused8_bit_rowwise_quantized_to_float_op.html">Fused8BitRowwiseQuantizedToFloatOp</a>&lt; <a class="el" href="structc10_1_1_half.html">at::Half</a>, convertfp32fp16, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3d91fb0026df8d82c465b3ce386f4f5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba527b99c7e1b69a8258cf418920c0d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aba527b99c7e1b69a8258cf418920c0d4"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>set_data_type</b> (TensorProto_DataType_FLOAT16)</td></tr>
<tr class="separator:aba527b99c7e1b69a8258cf418920c0d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39e03b654141020fcbed08bc341d5530"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39e03b654141020fcbed08bc341d5530"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
De-quantizes the result of the
HalfFloatToFused8BitRowwiseQuantized operator. The input is expected to
encode the scale as a 32-bit float in the second to the last 4 bytes of each
row, followed by the bias as a 32-bit float in the next 4 bytes, and the
quantized values in the preceding bytes of the row. The output is a
matrix containing only the values, but de-quantized. De-quantization is
performed by multiplying each value by its row's scale and bias
parameters. The de-quantized values will thus not be exactly equal to
the original, un-quantized floating point values.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a39e03b654141020fcbed08bc341d5530"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adeef8ba2d5e87a789e4c9b81baf09605"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adeef8ba2d5e87a789e4c9b81baf09605"></a>
Fused bias and quantized data&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;float16_output&quot;,&quot;Float16 data&quot;)</td></tr>
<tr class="separator:adeef8ba2d5e87a789e4c9b81baf09605"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86428cc2ab1654b90bdade43320090b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86428cc2ab1654b90bdade43320090b2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Fused8BitRowwiseQuantizedToHalfFloat)</td></tr>
<tr class="separator:a86428cc2ab1654b90bdade43320090b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb6c9d430fee7fe344919f877dd10aa8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abb6c9d430fee7fe344919f877dd10aa8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FloatToFusedRandRowwiseQuantized, <a class="el" href="classcaffe2_1_1_float_to_fused_rand_rowwise_quantized_op.html">FloatToFusedRandRowwiseQuantizedOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:abb6c9d430fee7fe344919f877dd10aa8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b4b92b93b0bb99a70dd556ca5ad970a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1b4b92b93b0bb99a70dd556ca5ad970a"></a>
X&#160;</td><td class="memItemRight" valign="bottom"><b>set_dims</b> (1, 10+(X.dims(1)+data_per_byte-1)/data_per_byte)</td></tr>
<tr class="separator:a1b4b92b93b0bb99a70dd556ca5ad970a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9611aee1b95e6aa890c7be58ff50877"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae9611aee1b95e6aa890c7be58ff50877"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Applies row-wise stochastic/random quantization by determining the range of
each row in the input matrix, and then quantize each element to one of two
closest discrete levels by randomly drawing Bernoulli distribution.
The method is extended from TernGrad [1],
which randomly quantizes gradients to three levels to reduce communication in distributed training.
The format of each row (x) in the output matrix is [bitwidth][tail][min][max][data]:
bitwidth[1 Byte]: bitwidth per data [1, 2, 4 or 8];
tail[1 Byte]: the number of unused buckets [1-8] (One byte is split to 8/bitwidth buckets and each bucket stores one low-precision data in bitwidth bits);
min[4 Bytes]: the minimum floating value min(x);
max[4 Bytes]: the maximum floating value max(x);
data: quantized data.
The quantization is uniform with levels q = min + (max-min)/(2^bitwidth - 1)*[0:1:2^bitwidth].
During stochastic/random quantization x'=Quantize(x), for q_j &lt; x_i &lt;= q_{j+1}, we draw quantization x'_i from Bernoulli distributions with
P(x'_i = q_{j+1}) = (x_i - q_j)/(q_{j+1} - q_j), and
P(x'_i = q_j) = (q_{j+1} - x_i)/(q_{j+1} - q_j) where x'_i is the quantized value of x_i.
[1] proved <a class="el" href="struct_e.html">E</a>{x'_i}=x_i, which is an unbiased approximation. More details are in the paper.
For example, suppose targeted bitwidth = 2 and x = [0.3, -1.4, -0.6, 0.9, 1.0],
then tail = 3, min = -1.4, max = 1.0 and q = [-1.4, -0.6, 0.2, 1.0].
x_1 = 0.3 will be quantized to x'_1 = 0.2 with probability 7/8 and to x'_1 = 1.0 with probability 1/8.
The storage format of quantized data is: [x'_1|x'_3|x'_5|xxx]-[x'_2|x'_4|xxx|xxx].
In general, a input row is split to multiple segments. One segment is a continuous subarray of the row,
and its length is the number of bytes storing quantized data in the output matrix.
The b-th bucket of the i-th byte stores the i-th data of the b-th segment of input row.

[1] Wen, Wei, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li.
&quot;Terngrad:Ternary gradients to reduce communication in distributed deep learning.&quot;
In Advances in Neural Information Processing Systems, pp. 1508-1518. 2017.

)DOC&quot;).Input(0</td></tr>
<tr class="separator:ae9611aee1b95e6aa890c7be58ff50877"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50977d478ad0b31b51f58db6f8322329"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a50977d478ad0b31b51f58db6f8322329"></a>
Float32 input data&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;Fused bitwidth, tail, min, max and quantized data&quot;).Arg(&quot;bitwidth&quot;</td></tr>
<tr class="separator:a50977d478ad0b31b51f58db6f8322329"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae97d56b6891ba49188213b1ce4897e67"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae97d56b6891ba49188213b1ce4897e67"></a>
Float32 input data How many bits to quantiz per&#160;</td><td class="memItemRight" valign="bottom"><b>data</b> (defaults to 8).&quot;) .Arg(&quot;random&quot;</td></tr>
<tr class="separator:ae97d56b6891ba49188213b1ce4897e67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a006b2ca4402ae251f79d53ee99672b73"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a006b2ca4402ae251f79d53ee99672b73"></a>
Float32 input data How many bits to quantiz per random or&#160;</td><td class="memItemRight" valign="bottom"><b>not</b> (True).False is set up for unittest.&quot;)</td></tr>
<tr class="separator:a006b2ca4402ae251f79d53ee99672b73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a814411380cfa2395351549089fb85d3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a814411380cfa2395351549089fb85d3e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (FloatToFusedRandRowwiseQuantized)</td></tr>
<tr class="separator:a814411380cfa2395351549089fb85d3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbf003dbeea0e0ad56c4e57730b91c8e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adbf003dbeea0e0ad56c4e57730b91c8e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FusedRandRowwiseQuantizedToFloat, <a class="el" href="classcaffe2_1_1_fused_rand_rowwise_quantized_to_float_op.html">FusedRandRowwiseQuantizedToFloatOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:adbf003dbeea0e0ad56c4e57730b91c8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af208393f38c365f09b5293a199ef8cdb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af208393f38c365f09b5293a199ef8cdb"></a>
const vector&lt; TensorShape &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>for</b> (int i=0;i&lt; def.output_size();i++)</td></tr>
<tr class="separator:af208393f38c365f09b5293a199ef8cdb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3773eaf142b59152b869d7a1c6cad11"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3773eaf142b59152b869d7a1c6cad11"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
De-quantizes the result of the FloatToFusedRandRowwiseQuantized operator.
Refer FloatToFusedRandRowwiseQuantized operator for details.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:ad3773eaf142b59152b869d7a1c6cad11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a010792fb6fd576e8a0c09f02b1b6340d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a010792fb6fd576e8a0c09f02b1b6340d"></a>
Fused max and quantized data&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;float_input&quot;,&quot;Float32 data&quot;)</td></tr>
<tr class="separator:a010792fb6fd576e8a0c09f02b1b6340d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27eeadc8ca1e6337627c27fdec74b3a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a27eeadc8ca1e6337627c27fdec74b3a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (FusedRandRowwiseQuantizedToFloat)</td></tr>
<tr class="separator:a27eeadc8ca1e6337627c27fdec74b3a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a40c8ce51b9de6c5ad61dc047b829e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1a40c8ce51b9de6c5ad61dc047b829e6"></a>
but operating on bit rowwise quantized matrices with fused&#160;</td><td class="memItemRight" valign="bottom"><b>storage</b> (where each row stores quantized values, and then the scale and offset).DATA needs to have rank 2 and INDICES needs to have rank 1.) DOC&quot;) .Input( 0</td></tr>
<tr class="separator:a1a40c8ce51b9de6c5ad61dc047b829e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf8d016e6881e2c8aba2c83145db0608"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abf8d016e6881e2c8aba2c83145db0608"></a>
but operating on bit rowwise quantized matrices with fused uint8 tensor with rank obtained with&#160;</td><td class="memItemRight" valign="bottom"><b>operator FloatToFused8BitRowwiseQuantized&quot;) .Input</b> (1,&quot;INDICES&quot;,&quot;Integer vector containing indices of the first dimension of DATA for&quot;&quot;the rows that are being gathered&quot;).Output(0</td></tr>
<tr class="separator:abf8d016e6881e2c8aba2c83145db0608"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7e5fb4372ed6660a3a98ea0690043ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af7e5fb4372ed6660a3a98ea0690043ff"></a>
but operating on bit rowwise quantized matrices with fused uint8 tensor with rank obtained with output&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in){vector&lt; TensorShape &gt; out(1);for(auto d:in[1].dims()){out[0].add_dims(d);}for(int i=1;i&lt; in[0].dims_size();++i){out[0].add_dims(in[0].dims(i));}out[0].set_data_type(in[0].data_type());return out;})</td></tr>
<tr class="separator:af7e5fb4372ed6660a3a98ea0690043ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac60efa88d8e5c2b93818ae8da725a4db"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac60efa88d8e5c2b93818ae8da725a4db"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GatherFused8BitRowwise, <a class="el" href="classcaffe2_1_1_gather_fused8_bit_rowwise_op.html">GatherFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac60efa88d8e5c2b93818ae8da725a4db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3e76112be57bae9b1bd0c999bce8b18"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3e76112be57bae9b1bd0c999bce8b18"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Gather, <a class="el" href="classcaffe2_1_1_gather_op.html">GatherOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af3e76112be57bae9b1bd0c999bce8b18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1671a0024cacfc8e7a478fd036746bdf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1671a0024cacfc8e7a478fd036746bdf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GenerateProposals, <a class="el" href="classcaffe2_1_1_generate_proposals_op.html">GenerateProposalsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1671a0024cacfc8e7a478fd036746bdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade126cdaac305d8372151d36b776d610"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade126cdaac305d8372151d36b776d610"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GenerateProposalsCPP, <a class="el" href="classcaffe2_1_1_generate_proposals_op.html">GenerateProposalsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ade126cdaac305d8372151d36b776d610"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35a9f10d1736f5c803ee2d4a013b2bd5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35a9f10d1736f5c803ee2d4a013b2bd5"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;spatial_scale&quot;,&quot;(float) spatial scale&quot;).Arg(&quot;pre_nms_topN&quot;</td></tr>
<tr class="separator:a35a9f10d1736f5c803ee2d4a013b2bd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84beef2f068194665626513d137fc8e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a84beef2f068194665626513d137fc8e6"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;post_nms_topN&quot;,&quot;(int) RPN_POST_NMS_TOP_N&quot;).Arg(&quot;nms_thresh&quot;</td></tr>
<tr class="separator:a84beef2f068194665626513d137fc8e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a639cc355096f75fba90ac2704902555c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a639cc355096f75fba90ac2704902555c"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;min_size&quot;,&quot;(float) RPN_MIN_SIZE&quot;).Arg(&quot;angle_bound_on&quot;</td></tr>
<tr class="separator:a639cc355096f75fba90ac2704902555c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea836a1f6bbb9cb098de81ff84099a57"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea836a1f6bbb9cb098de81ff84099a57"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH&#160;</td><td class="memItemRight" valign="bottom"><b>bool</b> (default true).If set</td></tr>
<tr class="separator:aea836a1f6bbb9cb098de81ff84099a57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa15362723adc48bcfca6f9ea5c501a77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa15362723adc48bcfca6f9ea5c501a77"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi]&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;angle_bound_lo&quot;,&quot;int (default -90 degrees). If set, for rotated boxes, angle is &quot;&quot;normalized to be within [angle_bound_lo, angle_bound_hi].&quot;).Arg(&quot;angle_bound_hi&quot;</td></tr>
<tr class="separator:aa15362723adc48bcfca6f9ea5c501a77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0847585e2a775644db17d10ad2302698"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0847585e2a775644db17d10ad2302698"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi]&#160;</td><td class="memItemRight" valign="bottom"><b>int</b> (default 90 degrees).If set</td></tr>
<tr class="separator:a0847585e2a775644db17d10ad2302698"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4435672dc6c10d245b7c907e4ae920d3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4435672dc6c10d245b7c907e4ae920d3"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi]&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;clip_angle_thresh&quot;,&quot;float (default 1.0 degrees). For RRPN, clip almost horizontal boxes &quot;&quot;within this threshold of tolerance for backward compatibility. &quot;&quot;Set to negative value for no clipping.&quot;).Input(0</td></tr>
<tr class="separator:a4435672dc6c10d245b7c907e4ae920d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23b9af797d7c03b15ca4303794456986"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a23b9af797d7c03b15ca4303794456986"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (img_count, <a class="el" href="struct_a.html">A</a>, H, W)&quot;) .Input( 1</td></tr>
<tr class="separator:a23b9af797d7c03b15ca4303794456986"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c8bd17148835089d180f53127648cdf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4c8bd17148835089d180f53127648cdf"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (img_count, 4 *<a class="el" href="struct_a.html">A</a>, H, W)&quot;) .Input( 2</td></tr>
<tr class="separator:a4c8bd17148835089d180f53127648cdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa252ebd43d802290cfc8574fd419f1f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa252ebd43d802290cfc8574fd419f1f9"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (img_count, 3)</td></tr>
<tr class="separator:aa252ebd43d802290cfc8574fd419f1f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af61561d02f2bd5adefd22ee96e77a188"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af61561d02f2bd5adefd22ee96e77a188"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image&#160;</td><td class="memItemRight" valign="bottom"><b>format</b> (height, width, scale)&quot;) .Input(3</td></tr>
<tr class="separator:af61561d02f2bd5adefd22ee96e77a188"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaad745676e2ca008978e2305a4f4f65b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaad745676e2ca008978e2305a4f4f65b"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (<a class="el" href="struct_a.html">A</a>, 4)&quot;) .Output( 0</td></tr>
<tr class="separator:aaad745676e2ca008978e2305a4f4f65b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc63c189776c156ad68cede6686eca96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc63c189776c156ad68cede6686eca96"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (n x 5)</td></tr>
<tr class="separator:abc63c189776c156ad68cede6686eca96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aece68c49dac69e7afc1d53e2b9df987d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aece68c49dac69e7afc1d53e2b9df987d"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box&#160;</td><td class="memItemRight" valign="bottom"><b>format</b> (image_index, x1, y1, x2, y2)&quot;) .Output(1</td></tr>
<tr class="separator:aece68c49dac69e7afc1d53e2b9df987d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa10ab43885954217a553f5b02c5661b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa10ab43885954217a553f5b02c5661b9"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box scores of&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (n)&quot;)</td></tr>
<tr class="separator:aa10ab43885954217a553f5b02c5661b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7906a9fd6c5ec0d46783277b4931ed92"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7906a9fd6c5ec0d46783277b4931ed92"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (GenerateProposalsCPP).NumInputs(4).NumOutputs(2)</td></tr>
<tr class="separator:a7906a9fd6c5ec0d46783277b4931ed92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9f3e5bd5ea1b98c0d776181236df790"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9f3e5bd5ea1b98c0d776181236df790"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (GenerateProposals)</td></tr>
<tr class="separator:ad9f3e5bd5ea1b98c0d776181236df790"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb52b72a217f72c28763306a12b08c04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abb52b72a217f72c28763306a12b08c04"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (GenerateProposalsCPP)</td></tr>
<tr class="separator:abb52b72a217f72c28763306a12b08c04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f5fb85280c30059b6e234d8722bc5ac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4f5fb85280c30059b6e234d8722bc5ac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GivenTensorByteStringToUInt8Fill, <a class="el" href="classcaffe2_1_1_given_tensor_byte_string_to_u_int8_fill_op.html">GivenTensorByteStringToUInt8FillOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4f5fb85280c30059b6e234d8722bc5ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b2be1631a30b535894108a82b59cb4f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6b2be1631a30b535894108a82b59cb4f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (GivenTensorByteStringToUInt8Fill)</td></tr>
<tr class="separator:a6b2be1631a30b535894108a82b59cb4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add475f78b4a16d8824abe6ab299d420b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="add475f78b4a16d8824abe6ab299d420b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
This op fills a uint8 output tensor with the data specified by the *value* argument. The data must previously be serialized as a byte string. The output tensor shape is specified by the *shape* argument. Beware, when using this argument *value* should have a value for every element of the *output*, as missing values will not be initialized automatically. If *input_as_shape* is set to *true*, then the *input* should be a 1D tensor containing the desired output shape (the dimensions specified in *extra_shape* will also be appended). In this case, the *shape* argument should **not** be set.

This op allows us to write uint8 tensors to Protobuf as byte strings and read them back as uint8 tensors in order to avoid the Protobuf uint32_t varint encoding size penalty.

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

val = np.array([1, 2, 3], dtype=np.uint8)
op = core.CreateOperator(
    &quot;GivenTensorByteStringToUInt8Fill&quot;,
    [],
    [&quot;out&quot;],
    values=[val.tobytes()],
    shape=val.shape,
)

workspace.RunOperatorOnce(op)
print(&quot;Out:\n&quot;, workspace.FetchBlob(&quot;out&quot;))

```

**Result**

```

Out:
 [1 2 3]

```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;values&quot;</td></tr>
<tr class="separator:add475f78b4a16d8824abe6ab299d420b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33f1ea09ef914e93bda6794cd87e081f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a33f1ea09ef914e93bda6794cd87e081f"></a>
The value for the elements of the output true&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;shape&quot;,&quot;The shape of the output tensor.&quot;&quot;Cannot set the shape argument and pass in an input at the same time.&quot;).Arg(&quot;extra_shape&quot;</td></tr>
<tr class="separator:a33f1ea09ef914e93bda6794cd87e081f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e225f47e3656a2cfc628661e0a66cba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e225f47e3656a2cfc628661e0a66cba"></a>
The value for the elements of the output true The additional dimensions appended at the end of the shape indicated by the input blob Cannot set the extra_shape argument when there is no input blob&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;input_as_shape&quot;,&quot;1D tensor containing the desired output shape. First input must be in CPU context.&quot;).TensorInferenceFunction(FillerTensorInference&lt; TensorProto_DataType_STRING &gt;)</td></tr>
<tr class="separator:a1e225f47e3656a2cfc628661e0a66cba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f785a1ae552fd2ae17d62a2820a585d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f785a1ae552fd2ae17d62a2820a585d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_given_tensor_fill.html">GivenTensorFill</a>, <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7f785a1ae552fd2ae17d62a2820a585d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a228f3cb8714bb1747b0d7ea286f19c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6a228f3cb8714bb1747b0d7ea286f19c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GivenTensorDoubleFill, <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; double, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6a228f3cb8714bb1747b0d7ea286f19c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6793798d6aa4a28518481f72b5dffe0e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6793798d6aa4a28518481f72b5dffe0e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GivenTensorBoolFill, <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; bool, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6793798d6aa4a28518481f72b5dffe0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe3ee829a67c1ff79abe416528c41f30"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe3ee829a67c1ff79abe416528c41f30"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GivenTensorIntFill, <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afe3ee829a67c1ff79abe416528c41f30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1be5a6969ca8de5d902a53309df0c27"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1be5a6969ca8de5d902a53309df0c27"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GivenTensorInt64Fill, <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab1be5a6969ca8de5d902a53309df0c27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25c1bf149a69798586ca44a0f7a11d39"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a25c1bf149a69798586ca44a0f7a11d39"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GivenTensorStringFill, <a class="el" href="classcaffe2_1_1_given_tensor_fill_op.html">GivenTensorFillOp</a>&lt; std::string, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a25c1bf149a69798586ca44a0f7a11d39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27b7a04b92c4d0c7e688cbd5d9b92453"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a27b7a04b92c4d0c7e688cbd5d9b92453"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (<a class="el" href="class_given_tensor_fill.html">GivenTensorFill</a>)</td></tr>
<tr class="separator:a27b7a04b92c4d0c7e688cbd5d9b92453"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a776f57c3c36d1ca80e440a9731910326"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a776f57c3c36d1ca80e440a9731910326"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (GivenTensorDoubleFill)</td></tr>
<tr class="separator:a776f57c3c36d1ca80e440a9731910326"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16de4c54a6bcb97507e49a946bedd6f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a16de4c54a6bcb97507e49a946bedd6f8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (GivenTensorBoolFill)</td></tr>
<tr class="separator:a16de4c54a6bcb97507e49a946bedd6f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d4f5291476fc8ac4db53c1b88e506b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d4f5291476fc8ac4db53c1b88e506b2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (GivenTensorIntFill)</td></tr>
<tr class="separator:a7d4f5291476fc8ac4db53c1b88e506b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4182e9d6ba8afaf3e24478479e6350de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4182e9d6ba8afaf3e24478479e6350de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (GivenTensorInt64Fill)</td></tr>
<tr class="separator:a4182e9d6ba8afaf3e24478479e6350de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09357b5c1748c66e24ce0b4495e02c9e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09357b5c1748c66e24ce0b4495e02c9e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (GivenTensorStringFill)</td></tr>
<tr class="separator:a09357b5c1748c66e24ce0b4495e02c9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd344b623672f40fa17cd4e7c0f27dc9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd344b623672f40fa17cd4e7c0f27dc9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
This op fills an output tensor with the data specified by the *value* and *dtype* arguments.  The output tensor shape is specified by the *shape* argument. Beware, when using this argument *value* should have a value for every element of the *output*, as missing values will not be initialized automatically. If *input_as_shape* is set to *true*, then the *input* should be a 1D tensor containing the desired output shape (the dimensions specified in *extra_shape* will also be appended). In this case, the *shape* argument should **not** be set.

*Note: Do not set the shape argument and pass in an input at the same time.*

Github Links:
- https://github.com/caffe2/caffe2/blob/master/caffe2/operators/given_tensor_fill_op.h
- https://github.com/caffe2/caffe2/blob/master/caffe2/operators/given_tensor_fill_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;GivenTensorFill&quot;,
    [],
    [&quot;out&quot;],
    values=[1., 2., 3.],
    shape=[3],
)

workspace.RunOperatorOnce(op)
print(&quot;Out:\n&quot;, workspace.FetchBlob(&quot;out&quot;))

```

**Result**

```

Out:
 [1. 2. 3.]

```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;values&quot;</td></tr>
<tr class="separator:afd344b623672f40fa17cd4e7c0f27dc9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cc44b5939fc8534ca17c794fcb0f428"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8cc44b5939fc8534ca17c794fcb0f428"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GroupNorm, <a class="el" href="classcaffe2_1_1_group_norm_op.html">GroupNormOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8cc44b5939fc8534ca17c794fcb0f428"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf48f1ffb568b8960fbbaa9392e520a7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaf48f1ffb568b8960fbbaa9392e520a7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GroupNormGradient, <a class="el" href="classcaffe2_1_1_group_norm_gradient_op.html">GroupNormGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aaf48f1ffb568b8960fbbaa9392e520a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8718cf578124512ca7dced4d45064317"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8718cf578124512ca7dced4d45064317"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Group Normalization (GN) operation: https://arxiv.org/abs/1803.08494
)DOC&quot;).Arg(&quot;num_groups&quot;</td></tr>
<tr class="separator:a8718cf578124512ca7dced4d45064317"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e0811378233cfc41da920b7e5ab23b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e0811378233cfc41da920b7e5ab23b9"></a>
number of groups used by GN&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;epsilon&quot;,&quot;(float) default 1e-5; small constant added to var.&quot;).Input(0</td></tr>
<tr class="separator:a0e0811378233cfc41da920b7e5ab23b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b1441fb45c62829835f5df2c664f9b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7b1441fb45c62829835f5df2c664f9b5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GRUUnit, <a class="el" href="classcaffe2_1_1_g_r_u_unit_op.html">GRUUnitOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7b1441fb45c62829835f5df2c664f9b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a275ad44c1cbd4a64ee957dfd6ff9fa52"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a275ad44c1cbd4a64ee957dfd6ff9fa52"></a>
in a sequence length aware fashion given&#160;</td><td class="memItemRight" valign="bottom"><b>the</b> (fused) inputs X(TxNxD)</td></tr>
<tr class="separator:a275ad44c1cbd4a64ee957dfd6ff9fa52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a959bdd2f18bcf6ed779e4edb688429c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a959bdd2f18bcf6ed779e4edb688429c7"></a>
in a sequence length aware fashion given the previous hidden&#160;</td><td class="memItemRight" valign="bottom"><b>state</b> (NxD)</td></tr>
<tr class="separator:a959bdd2f18bcf6ed779e4edb688429c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5785a0265bb5a49fe563576a5856bffb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5785a0265bb5a49fe563576a5856bffb"></a>
in a sequence length aware fashion given the previous hidden and the sequence&#160;</td><td class="memItemRight" valign="bottom"><b>lengths</b> (N)</td></tr>
<tr class="separator:a5785a0265bb5a49fe563576a5856bffb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bded13860e75746552c5f62698996f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0bded13860e75746552c5f62698996f3"></a>
in a sequence length aware fashion given the previous hidden and the sequence computes the GRU avoiding computation if the input is&#160;</td><td class="memItemRight" valign="bottom"><b>invalid</b> (as in, the value at X[t][n] &gt;=seqLengths[n].) DOC&quot;) .Arg( &quot;drop_states&quot;</td></tr>
<tr class="separator:a0bded13860e75746552c5f62698996f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab42f64f71fed13909e998bfb422051df"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab42f64f71fed13909e998bfb422051df"></a>
in a sequence length aware fashion given the previous hidden and the sequence computes the GRU avoiding computation if the input is Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;sequence_lengths&quot;,&quot;When false, the sequence lengths input is left out, &quot;&quot;and all following inputs are shifted left by one.&quot;).Output(0</td></tr>
<tr class="separator:ab42f64f71fed13909e998bfb422051df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65219a73c9faa974635939b186318b75"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a65219a73c9faa974635939b186318b75"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GRUUnitGradient, <a class="el" href="classcaffe2_1_1_g_r_u_unit_gradient_op.html">GRUUnitGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a65219a73c9faa974635939b186318b75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af75c99c5b2b78b982546af2552826ac8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af75c99c5b2b78b982546af2552826ac8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (5, 6).NumOutputs(2).Arg(&quot;sequence_lengths&quot;</td></tr>
<tr class="separator:af75c99c5b2b78b982546af2552826ac8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67ded52bdd945fab308b19d3d7eb1c42"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67ded52bdd945fab308b19d3d7eb1c42"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (GRUUnit, <a class="el" href="classcaffe2_1_1_get_g_r_u_unit_gradient.html">GetGRUUnitGradient</a>)</td></tr>
<tr class="separator:a67ded52bdd945fab308b19d3d7eb1c42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ad5fc7c557ca1f8407ddbae483d1613"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2ad5fc7c557ca1f8407ddbae483d1613"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FloatToHalf, <a class="el" href="classcaffe2_1_1_float_to_half_op.html">FloatToHalfOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2ad5fc7c557ca1f8407ddbae483d1613"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae20872077df86deee2cef4061d0aef5c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae20872077df86deee2cef4061d0aef5c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (HalfToFloat, <a class="el" href="classcaffe2_1_1_half_to_float_op.html">HalfToFloatOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae20872077df86deee2cef4061d0aef5c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20e1b3d007135b6e2591f5e23e11e1a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a20e1b3d007135b6e2591f5e23e11e1a5"></a>
out&#160;</td><td class="memItemRight" valign="bottom"><b>push_back</b> (X)</td></tr>
<tr class="separator:a20e1b3d007135b6e2591f5e23e11e1a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7080085d4d91d88173227b3d571ef432"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7080085d4d91d88173227b3d571ef432"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Float16ConstantFill, <a class="el" href="classcaffe2_1_1_float16_constant_fill_op.html">Float16ConstantFillOp</a>)</td></tr>
<tr class="separator:a7080085d4d91d88173227b3d571ef432"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59f3e70f4501b0add82896a006359dcc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a59f3e70f4501b0add82896a006359dcc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Float16UniformFill, <a class="el" href="classcaffe2_1_1_float16_uniform_fill_op.html">Float16UniformFillOp</a>)</td></tr>
<tr class="separator:a59f3e70f4501b0add82896a006359dcc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4cccd2f897e0abaff87620c8a766b80"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad4cccd2f897e0abaff87620c8a766b80"></a>
max&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;shape&quot;,&quot;Shape of the tensor&quot;).Arg(&quot;min&quot;</td></tr>
<tr class="separator:ad4cccd2f897e0abaff87620c8a766b80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5074cd5f3127bd02d59ee7937d45e52"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad5074cd5f3127bd02d59ee7937d45e52"></a>
max Minimim value to generate&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;max&quot;,&quot;Maximum value to generate&quot;)</td></tr>
<tr class="separator:ad5074cd5f3127bd02d59ee7937d45e52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6025871d7c65aeafb3f208070496cb9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6025871d7c65aeafb3f208070496cb9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Float16UniformFill)</td></tr>
<tr class="separator:aa6025871d7c65aeafb3f208070496cb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14bcdb257c86dc846180e777357f208c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a14bcdb257c86dc846180e777357f208c"></a>
The value for the elements of the output tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;shape&quot;,&quot;The shape of the output tensor.&quot;).Output(0</td></tr>
<tr class="separator:a14bcdb257c86dc846180e777357f208c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a36696199136eaf34faac441f46efca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a36696199136eaf34faac441f46efca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (FloatToHalf, <a class="el" href="classcaffe2_1_1_get_float_to_half_gradient.html">GetFloatToHalfGradient</a>)</td></tr>
<tr class="separator:a3a36696199136eaf34faac441f46efca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa81004f1ab8baad6daa1fe974ee060f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa81004f1ab8baad6daa1fe974ee060f6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (HalfToFloat, <a class="el" href="classcaffe2_1_1_get_half_to_float_gradient.html">GetHalfToFloatGradient</a>)</td></tr>
<tr class="separator:aa81004f1ab8baad6daa1fe974ee060f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45e3494b799b136a2787912c5c8c200d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a45e3494b799b136a2787912c5c8c200d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Float16ConstantFill)</td></tr>
<tr class="separator:a45e3494b799b136a2787912c5c8c200d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e52c366909d9e9723388425b3bf7b72"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e52c366909d9e9723388425b3bf7b72"></a>
std::vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Float16FillerTensorInference</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a8e52c366909d9e9723388425b3bf7b72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af205ee22e69ef82aabf74acaa8bc7dd0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af205ee22e69ef82aabf74acaa8bc7dd0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (HardSigmoid, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_hard_sigmoid_functor.html">HardSigmoidFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:af205ee22e69ef82aabf74acaa8bc7dd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a097f19c4c9de483f5d1725b0eb0814f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a097f19c4c9de483f5d1725b0eb0814f9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (HardSigmoidGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_hard_sigmoid_gradient_functor.html">HardSigmoidGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a097f19c4c9de483f5d1725b0eb0814f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bfe793aab3068e149ad61194b47a171"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4bfe793aab3068e149ad61194b47a171"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceFunction</b> (CostInferenceForHardSigmoid).IdenticalTypeAndShape().SetDoc(R&quot;DOC( Applies hard sigmoid operation to the input data element-wise. The HardSigmoid operation takes one input $X$</td></tr>
<tr class="separator:a4bfe793aab3068e149ad61194b47a171"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28c28ce5d8a0bae091163f9342c38542"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28c28ce5d8a0bae091163f9342c38542"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (If, <a class="el" href="classcaffe2_1_1_if_op.html">IfOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a28c28ce5d8a0bae091163f9342c38542"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca7eb7bdae983a0dc2bc94104175bae8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca7eb7bdae983a0dc2bc94104175bae8"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
'If' control operator, first input is a scalar boolean blob that stores condition
value. Accepts 'then_net' (required) and 'else_net' (<a class="el" href="classc10_1_1optional.html">optional</a>) arguments for 'then' and
'else' subnets respectively. Subnets are executed in the same workspace as 'If'.
    )DOC&quot;).Arg(&quot;then_net&quot;</td></tr>
<tr class="separator:aca7eb7bdae983a0dc2bc94104175bae8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adddbde416cf87af0dee9cdddc0fa191f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adddbde416cf87af0dee9cdddc0fa191f"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed when condition is true&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;else_net&quot;,&quot;<a class="el" href="struct_net.html">Net</a> executed when condition is false (<a class="el" href="classc10_1_1optional.html">optional</a>)&quot;).Input(0</td></tr>
<tr class="separator:adddbde416cf87af0dee9cdddc0fa191f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a144a71879072634a064d5e6bccf62bfa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a144a71879072634a064d5e6bccf62bfa"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed when condition is true <a class="el" href="classc10_1_1_scalar.html">Scalar</a> boolean condition&#160;</td><td class="memItemRight" valign="bottom"><b>AllowInplace</b> ([](int in, int out) -&gt; bool{return true;})</td></tr>
<tr class="separator:a144a71879072634a064d5e6bccf62bfa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84b5ff154ad3fd3019cb05de7283925d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a84b5ff154ad3fd3019cb05de7283925d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (If, <a class="el" href="classcaffe2_1_1_if_op.html">IfOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a84b5ff154ad3fd3019cb05de7283925d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a113cc01301d21f478188b3f0e3c6f4ac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a113cc01301d21f478188b3f0e3c6f4ac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Im2Col, <a class="el" href="classcaffe2_1_1_im2_col_op.html">Im2ColOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a113cc01301d21f478188b3f0e3c6f4ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ca353312069267046d35ab8c4f4e97d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7ca353312069267046d35ab8c4f4e97d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Col2Im, <a class="el" href="classcaffe2_1_1_col2_im_op.html">Col2ImOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7ca353312069267046d35ab8c4f4e97d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a135134482622f6a9688744822b69c691"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a135134482622f6a9688744822b69c691"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Im2Col, <a class="el" href="classcaffe2_1_1_get_im2_col_gradient.html">GetIm2ColGradient</a>)</td></tr>
<tr class="separator:a135134482622f6a9688744822b69c691"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50b102883b9a724576888fd933fdafca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a50b102883b9a724576888fd933fdafca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Col2Im, <a class="el" href="classcaffe2_1_1_get_col2_im_gradient.html">GetCol2ImGradient</a>)</td></tr>
<tr class="separator:a50b102883b9a724576888fd933fdafca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2f2e4aa5de48764929b5f3893550af7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad2f2e4aa5de48764929b5f3893550af7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>switch</b> (order)</td></tr>
<tr class="separator:ad2f2e4aa5de48764929b5f3893550af7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa282b23c9194e9f55b8c0a2d1791049e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa282b23c9194e9f55b8c0a2d1791049e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE</b> (H &gt;=dkernel_h)</td></tr>
<tr class="separator:aa282b23c9194e9f55b8c0a2d1791049e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94afdbc207e805298189c5d2c8136241"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a94afdbc207e805298189c5d2c8136241"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE</b> (W &gt;=dkernel_w)</td></tr>
<tr class="separator:a94afdbc207e805298189c5d2c8136241"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afeb03e731553bf866806e3951e4724da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afeb03e731553bf866806e3951e4724da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;4-tensor in NCHW or NHWC.&quot;).Output(0</td></tr>
<tr class="separator:afeb03e731553bf866806e3951e4724da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30c75a39c612a14c09ac8802acf988be"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a30c75a39c612a14c09ac8802acf988be"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Col2Im).NumInputs(2).NumOutputs(1)</td></tr>
<tr class="separator:a30c75a39c612a14c09ac8802acf988be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a192b899b8c03924960fa28167a035b53"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a192b899b8c03924960fa28167a035b53"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Im2Col, <a class="el" href="classcaffe2_1_1_im2_col_op.html">Im2ColOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a192b899b8c03924960fa28167a035b53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f0e66a1d9d8b0b02508c9e1919676d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f0e66a1d9d8b0b02508c9e1919676d7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Col2Im, <a class="el" href="classcaffe2_1_1_col2_im_op.html">Col2ImOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a9f0e66a1d9d8b0b02508c9e1919676d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bbadabea450b6aaf36301ddc2c56458"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1bbadabea450b6aaf36301ddc2c56458"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IntIndexCreate, <a class="el" href="classcaffe2_1_1_index_create_op.html">IndexCreateOp</a>&lt; int32_t &gt;)</td></tr>
<tr class="separator:a1bbadabea450b6aaf36301ddc2c56458"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77f5f565be1a53b7165de223af1d7d77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a77f5f565be1a53b7165de223af1d7d77"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LongIndexCreate, <a class="el" href="classcaffe2_1_1_index_create_op.html">IndexCreateOp</a>&lt; int64_t &gt;)</td></tr>
<tr class="separator:a77f5f565be1a53b7165de223af1d7d77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3334f788f88b77115926011ee2a9d65"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3334f788f88b77115926011ee2a9d65"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StringIndexCreate, <a class="el" href="classcaffe2_1_1_index_create_op.html">IndexCreateOp</a>&lt; std::string &gt;)</td></tr>
<tr class="separator:af3334f788f88b77115926011ee2a9d65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3b1c1b091ac2f07f1a447e86200813f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa3b1c1b091ac2f07f1a447e86200813f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IndexGet, <a class="el" href="classcaffe2_1_1_index_get_op.html">IndexGetOp</a>)</td></tr>
<tr class="separator:aa3b1c1b091ac2f07f1a447e86200813f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8b20d47b4f18396c328b6630866612e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad8b20d47b4f18396c328b6630866612e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IndexLoad, <a class="el" href="classcaffe2_1_1_index_load_op.html">IndexLoadOp</a>)</td></tr>
<tr class="separator:ad8b20d47b4f18396c328b6630866612e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a826a240fc30821040510877689d2f9e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a826a240fc30821040510877689d2f9e5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IndexStore, <a class="el" href="classcaffe2_1_1_index_store_op.html">IndexStoreOp</a>)</td></tr>
<tr class="separator:a826a240fc30821040510877689d2f9e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a524999b8c59758427ba16492de3e9c8d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a524999b8c59758427ba16492de3e9c8d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IndexFreeze, <a class="el" href="classcaffe2_1_1_index_freeze_op.html">IndexFreezeOp</a>)</td></tr>
<tr class="separator:a524999b8c59758427ba16492de3e9c8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed210c9226ce7a92cd93a8d8c71bc011"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed210c9226ce7a92cd93a8d8c71bc011"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IndexSize, <a class="el" href="classcaffe2_1_1_index_size_op.html">IndexSizeOp</a>)</td></tr>
<tr class="separator:aed210c9226ce7a92cd93a8d8c71bc011"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc36c82256dd6dfaff86181d28e5c351"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc36c82256dd6dfaff86181d28e5c351"></a>
Max number of including the zero entry&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;handler&quot;,&quot;Pointer to an <a class="el" href="structcaffe2_1_1_index.html">Index</a> instance.&quot;).ScalarType(TensorProto_DataType_UNDEFINED)</td></tr>
<tr class="separator:abc36c82256dd6dfaff86181d28e5c351"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86f4ff6cceadcf54a9cc50ccaacaad20"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86f4ff6cceadcf54a9cc50ccaacaad20"></a>
Max number of including the zero entry&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;handle&quot;,&quot;Pointer to an <a class="el" href="structcaffe2_1_1_index.html">Index</a> instance.&quot;).ScalarType(TensorProto_DataType_UNDEFINED)</td></tr>
<tr class="separator:a86f4ff6cceadcf54a9cc50ccaacaad20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab47c8a672f7da0f868371750c74316b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab47c8a672f7da0f868371750c74316b0"></a>
return an Int tensor of same shape containing the indices for each of the keys If the index is unknown entries are given index new entries are added into the index If an insert is necessary but max_elements has been fail DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;handle&quot;,&quot;Pointer to an <a class="el" href="structcaffe2_1_1_index.html">Index</a> instance.&quot;).Input(1</td></tr>
<tr class="separator:ab47c8a672f7da0f868371750c74316b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b0f83b0647e6a7908b30cc473ec8ccf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b0f83b0647e6a7908b30cc473ec8ccf"></a>
return an Int tensor of same shape containing the indices for each of the keys If the index is unknown entries are given index new entries are added into the index If an insert is necessary but max_elements has been fail DOC <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of keys to be looked up Output(0,&quot;indices&quot;,&quot;Indices for each of the keys.&quot;).ScalarType(TensorProto disallowing creation of new index entries Should not be called concurrently with IndexGet DOC The input handle&#160;</td><td class="memItemRight" valign="bottom"><b>EnforceInplace</b> ({{0, 0}}).ScalarType(TensorProto_DataType_UNDEFINED)</td></tr>
<tr class="separator:a3b0f83b0647e6a7908b30cc473ec8ccf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeaf47500482f6aaa857f23f89e269d52"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeaf47500482f6aaa857f23f89e269d52"></a>
Pointer to an <a class="el" href="structcaffe2_1_1_index.html">Index</a> instance&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;items&quot;,&quot;1-<a class="el" href="struct_d.html">D</a> tensor with elements starting with index 1.&quot;).Output(0</td></tr>
<tr class="separator:aeaf47500482f6aaa857f23f89e269d52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65be859c5254a6d78ce7ff969fe9d134"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a65be859c5254a6d78ce7ff969fe9d134"></a>
Pointer to an <a class="el" href="structcaffe2_1_1_index.html">Index</a> instance The input handle If skips the first entry of the tensor This allows to load tensors that are aligned with an where the first entry corresponds to the default index entry&#160;</td><td class="memItemRight" valign="bottom"><b>ScalarType</b> (TensorProto_DataType_UNDEFINED)</td></tr>
<tr class="separator:a65be859c5254a6d78ce7ff969fe9d134"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a047fd3902fe90af881533489cffc43b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a047fd3902fe90af881533489cffc43b5"></a>
Pointer to an <a class="el" href="structcaffe2_1_1_index.html">Index</a> instance&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;items&quot;,&quot;<a class="el" href="classc10_1_1_scalar.html">Scalar</a> int64 tensor with number of entries.&quot;)</td></tr>
<tr class="separator:a047fd3902fe90af881533489cffc43b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f281293d10a867072b740077d058270"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0f281293d10a867072b740077d058270"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_index_get_op.html">IndexGetOp</a>)</td></tr>
<tr class="separator:a0f281293d10a867072b740077d058270"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18aef91c7d93e6997aa19e28d3246fbf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a18aef91c7d93e6997aa19e28d3246fbf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (IntIndexCreate)</td></tr>
<tr class="separator:a18aef91c7d93e6997aa19e28d3246fbf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e94b1d33c7c70b44de59c6276ba264d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e94b1d33c7c70b44de59c6276ba264d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (LongIndexCreate)</td></tr>
<tr class="separator:a8e94b1d33c7c70b44de59c6276ba264d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab929f3d0e43c56b474afc25a53141a26"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab929f3d0e43c56b474afc25a53141a26"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (StringIndexCreate)</td></tr>
<tr class="separator:ab929f3d0e43c56b474afc25a53141a26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a690f6626f025edb1699495d2aa157112"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a690f6626f025edb1699495d2aa157112"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (IndexFreeze)</td></tr>
<tr class="separator:a690f6626f025edb1699495d2aa157112"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62d7bffcc3c74b78c3c3fc67b42d76df"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62d7bffcc3c74b78c3c3fc67b42d76df"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (IndexLoad)</td></tr>
<tr class="separator:a62d7bffcc3c74b78c3c3fc67b42d76df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36f2e92a711580482a684080e4c08922"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a36f2e92a711580482a684080e4c08922"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (IndexStore)</td></tr>
<tr class="separator:a36f2e92a711580482a684080e4c08922"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f15843d09e06554084a8116b544d8e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2f15843d09e06554084a8116b544d8e5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (IndexSize)</td></tr>
<tr class="separator:a2f15843d09e06554084a8116b544d8e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2431e6b523ecc2eb8aced116bac416d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2431e6b523ecc2eb8aced116bac416d1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (std::unique_ptr&lt; <a class="el" href="structcaffe2_1_1_index_base.html">caffe2::IndexBase</a> &gt;)</td></tr>
<tr class="separator:a2431e6b523ecc2eb8aced116bac416d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a498534efc64526508676a9fa17b443bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a498534efc64526508676a9fa17b443bd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_BLOB_SERIALIZER</b> ((TypeMeta::Id&lt; std::unique_ptr&lt; <a class="el" href="structcaffe2_1_1_index_base.html">caffe2::IndexBase</a> &gt;&gt;()), <a class="el" href="classcaffe2_1_1_index_serializer.html">IndexSerializer</a>)</td></tr>
<tr class="separator:a498534efc64526508676a9fa17b443bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b6bfcb6492d0e7044d8b2461f108e6c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b6bfcb6492d0e7044d8b2461f108e6c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_BLOB_DESERIALIZER</b> (std::unique_ptr&lt; <a class="el" href="structcaffe2_1_1_index_base.html">caffe2::IndexBase</a> &gt;, <a class="el" href="classcaffe2_1_1_index_deserializer.html">IndexDeserializer</a>)</td></tr>
<tr class="separator:a0b6bfcb6492d0e7044d8b2461f108e6c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e2f4ceb2b6a85106b4378bee04a8b5c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9e2f4ceb2b6a85106b4378bee04a8b5c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (InstanceNormGradient, <a class="el" href="classcaffe2_1_1_instance_norm_gradient_op.html">InstanceNormGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9e2f4ceb2b6a85106b4378bee04a8b5c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3c347803669d9cf2910272708ab0907"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac3c347803669d9cf2910272708ab0907"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (InstanceNormGradient).NumInputs(4</td></tr>
<tr class="separator:ac3c347803669d9cf2910272708ab0907"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a612b4e4d17f9e8d6c40579ec84b60e3b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a612b4e4d17f9e8d6c40579ec84b60e3b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumOutputs</b> (3)</td></tr>
<tr class="separator:a612b4e4d17f9e8d6c40579ec84b60e3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af81aee449bf149a09a82ec31f4882a63"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af81aee449bf149a09a82ec31f4882a63"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (InstanceNorm, <a class="el" href="classcaffe2_1_1_get_instance_norm_gradient.html">GetInstanceNormGradient</a>)</td></tr>
<tr class="separator:af81aee449bf149a09a82ec31f4882a63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef0af483cee269a5f5ff6b50caff6943"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef0af483cee269a5f5ff6b50caff6943"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (InstanceNorm, <a class="el" href="classcaffe2_1_1_instance_norm_op.html">InstanceNormOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aef0af483cee269a5f5ff6b50caff6943"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f8411297da1e2c6e65b5635133fc3a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6f8411297da1e2c6e65b5635133fc3a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IntegralImage, <a class="el" href="classcaffe2_1_1_integral_image_op.html">IntegralImageOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6f8411297da1e2c6e65b5635133fc3a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6446ebb224371b7275d9731e4c565cd1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6446ebb224371b7275d9731e4c565cd1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IntegralImageGradient, <a class="el" href="classcaffe2_1_1_integral_image_gradient_op.html">IntegralImageGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6446ebb224371b7275d9731e4c565cd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bec9a95a5bcbee45a8c642fbdf00bc1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5bec9a95a5bcbee45a8c642fbdf00bc1"></a>
which contains the sum of pixel values within an image vertically and horizontally This integral image can then be used with other detection and tracking techniques DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;Images tensor of the form (N, <a class="el" href="struct_c.html">C</a>, H, W)&quot;).Output(0</td></tr>
<tr class="separator:a5bec9a95a5bcbee45a8c642fbdf00bc1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e79945d183253c3630a3b86664a4e48"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e79945d183253c3630a3b86664a4e48"></a>
which contains the sum of pixel values within an image vertically and horizontally This integral image can then be used with other detection and tracking techniques DOC Integrated image of the&#160;</td><td class="memItemRight" valign="bottom"><b>form</b> (N, <a class="el" href="struct_c.html">C</a>, H+1, W+1)&quot;)</td></tr>
<tr class="separator:a8e79945d183253c3630a3b86664a4e48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4765e79eb057df5d187b3ee9d0fe6ee9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4765e79eb057df5d187b3ee9d0fe6ee9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (IntegralImageGradient).NumInputs(2).NumOutputs(1)</td></tr>
<tr class="separator:a4765e79eb057df5d187b3ee9d0fe6ee9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e52b54a702af92d1a5d2685e34a663f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e52b54a702af92d1a5d2685e34a663f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (IntegralImage, <a class="el" href="classcaffe2_1_1_get_integral_image_gradient.html">GetIntegralImageGradient</a>)</td></tr>
<tr class="separator:a6e52b54a702af92d1a5d2685e34a663f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c4b03b3eeecbe0cc9e4804846d8a691"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c4b03b3eeecbe0cc9e4804846d8a691"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (IsEmpty, <a class="el" href="classcaffe2_1_1_is_empty_op.html">IsEmptyOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3c4b03b3eeecbe0cc9e4804846d8a691"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bffc30682c0843d52223564efd877d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0bffc30682c0843d52223564efd877d5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BernoulliJSD, <a class="el" href="classcaffe2_1_1_bernoulli_j_s_d_op.html">BernoulliJSDOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0bffc30682c0843d52223564efd877d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad22303aabd08a7b7706a69d39d0ba4ba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad22303aabd08a7b7706a69d39d0ba4ba"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BernoulliJSDGradient, <a class="el" href="classcaffe2_1_1_bernoulli_j_s_d_gradient_op.html">BernoulliJSDGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad22303aabd08a7b7706a69d39d0ba4ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a858776ce1f1216c2df4ec19bc9e893fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a858776ce1f1216c2df4ec19bc9e893fe"></a>
array of probabilities for prediction&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;T&quot;,&quot;array of probabilities for target&quot;).Output(0</td></tr>
<tr class="separator:a858776ce1f1216c2df4ec19bc9e893fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06016ba6fc7a7bf51db1eb204a5da628"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a06016ba6fc7a7bf51db1eb204a5da628"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (BernoulliJSDGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a06016ba6fc7a7bf51db1eb204a5da628"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82708cc86adbd368c6a760f95f786292"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a82708cc86adbd368c6a760f95f786292"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (BernoulliJSD, <a class="el" href="classcaffe2_1_1_get_bernoulli_j_s_d_gradient.html">GetBernoulliJSDGradient</a>)</td></tr>
<tr class="separator:a82708cc86adbd368c6a760f95f786292"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12265f745d3c059e7cfe2869bf6ac786"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a12265f745d3c059e7cfe2869bf6ac786"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (KeySplit, <a class="el" href="classcaffe2_1_1_key_split_op.html">KeySplitOp</a>&lt; int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a12265f745d3c059e7cfe2869bf6ac786"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaedecb2914782e4628fe842b5415e682"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaedecb2914782e4628fe842b5415e682"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_key_split_op.html">KeySplitOp</a>)</td></tr>
<tr class="separator:aaedecb2914782e4628fe842b5415e682"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b0866b7d590af1e53d29378bcc31b9b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b0866b7d590af1e53d29378bcc31b9b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (KeySplit).NumInputs(1).NumOutputs(1</td></tr>
<tr class="separator:a0b0866b7d590af1e53d29378bcc31b9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a327c089dfb7d86f6ea01447865c945cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a327c089dfb7d86f6ea01447865c945cf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LayerNorm, <a class="el" href="classcaffe2_1_1_layer_norm_op.html">LayerNormOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a327c089dfb7d86f6ea01447865c945cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a8a78f0c564ee8f85feb8334b45944d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a8a78f0c564ee8f85feb8334b45944d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LayerNormGradient).NumInputs(5).NumOutputs(1)</td></tr>
<tr class="separator:a0a8a78f0c564ee8f85feb8334b45944d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6e01bb0ae44a6c2b47a44852cc72ff2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6e01bb0ae44a6c2b47a44852cc72ff2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LayerNormGradient, <a class="el" href="classcaffe2_1_1_layer_norm_gradient_op.html">LayerNormGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa6e01bb0ae44a6c2b47a44852cc72ff2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea8528c57a6e4c9f15081661271e9411"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea8528c57a6e4c9f15081661271e9411"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LayerNorm, GetLayerNormGradient)</td></tr>
<tr class="separator:aea8528c57a6e4c9f15081661271e9411"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85b031020b594a1fc2472f642593ff33"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a85b031020b594a1fc2472f642593ff33"></a>
std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>input_dims</b> (input_dims_long.begin(), input_dims_long.end())</td></tr>
<tr class="separator:a85b031020b594a1fc2472f642593ff33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a361340ae951d832bd229b551db6d686c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a361340ae951d832bd229b551db6d686c"></a>
<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a>&#160;</td><td class="memItemRight" valign="bottom"><b>helper</b> (def)</td></tr>
<tr class="separator:a361340ae951d832bd229b551db6d686c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b896aa28455a7f33ba3d7f55d0b7e00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b896aa28455a7f33ba3d7f55d0b7e00"></a>
std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>stat_dims</b> (input_dims.begin(), input_dims.begin()+canonical_axis)</td></tr>
<tr class="separator:a3b896aa28455a7f33ba3d7f55d0b7e00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe470c342523160213450ac5708d0041"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe470c342523160213450ac5708d0041"></a>
stat_dims&#160;</td><td class="memItemRight" valign="bottom"><b>push_back</b> (1)</td></tr>
<tr class="separator:afe470c342523160213450ac5708d0041"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae02daba3b6c74564217fa93817a1f29b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae02daba3b6c74564217fa93817a1f29b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Computes layer normalization as described in https://arxiv.org/pdf/1607.06450.pdf.
Given an input vector x \in [a_0, a_1, ...,a_{k-1}, a_k, ..., a_{n-1}],
this op treats dimensions a_k through a_{n-1} as feature vectors. For each
feature vector, the op contains the mean and standard deviation. Then,
it returns the normalized values (with respect to the feature vector).

Note that this op does not contain the scale an bias terms described in the
paper. Simply follow this op with an <a class="el" href="class_f_c.html">FC</a> op to add those. Concretely, this op
implements:

h = \frac{1}{\sigma}(a - \mu)
where \mu = \frac{1}{H}\sum_{i=1}^{H} a_i
and \sigma = \sqrt{\frac{1}{H}\sum_{i=1}^{H}(a_i - \mu)^2}
where H is the number of hidden units (i.e. product of dimensions from 'axis'
to the end.)
)DOC&quot;).Arg(&quot;axis&quot;</td></tr>
<tr class="separator:ae02daba3b6c74564217fa93817a1f29b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adefe70ce6e423ae38bdddb07fe367510"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adefe70ce6e423ae38bdddb07fe367510"></a>
Describes axis of the inputs Defaults to one because the axis most likely describes the batch size&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;epsilon&quot;,&quot;(float) default to 0.001. Small value to be added to the stdev when&quot;&quot; dividing out by that value. This prevents division by zero.&quot;).Input(0</td></tr>
<tr class="separator:adefe70ce6e423ae38bdddb07fe367510"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef802f512ba74c2bce30b8fd96a0dc7a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef802f512ba74c2bce30b8fd96a0dc7a"></a>
Describes axis of the inputs Defaults to one because the axis most likely describes the batch size Input tensor which layer normalization will be applied to&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;Normalized values&quot;).Output(1</td></tr>
<tr class="separator:aef802f512ba74c2bce30b8fd96a0dc7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4de415e963632e7285ce3db115f92c06"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4de415e963632e7285ce3db115f92c06"></a>
Describes axis of the inputs Defaults to one because the axis most likely describes the batch size Input tensor which layer normalization will be applied to Mean values for each feature vector&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (2,&quot;stddev&quot;,&quot;Standard deviations for each feature vector&quot;)</td></tr>
<tr class="separator:a4de415e963632e7285ce3db115f92c06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2263206a567cd499e2088b447264c4cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2263206a567cd499e2088b447264c4cb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LeakyRelu, <a class="el" href="classcaffe2_1_1_leaky_relu_op.html">LeakyReluOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2263206a567cd499e2088b447264c4cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411c5b13234bf990c1555a10fb09b95d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a411c5b13234bf990c1555a10fb09b95d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LeakyReluGradient, <a class="el" href="classcaffe2_1_1_leaky_relu_gradient_op.html">LeakyReluGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a411c5b13234bf990c1555a10fb09b95d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af34b4982cdc580bc7bb3d26cab5ed9f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af34b4982cdc580bc7bb3d26cab5ed9f6"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceFunction</b> (PointwiseCostInference&lt; 2 &gt;).IdenticalTypeAndShape().SetDoc(R&quot;DOC( The *LeakyRelu* op takes one input tensor $X$ and an argument $alpha$</td></tr>
<tr class="separator:af34b4982cdc580bc7bb3d26cab5ed9f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf2add143a99429dd891c4961bbedea7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf2add143a99429dd891c4961bbedea7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;alpha&quot;,&quot;Coefficient of leakage&quot;).InheritOnnxSchema()</td></tr>
<tr class="separator:adf2add143a99429dd891c4961bbedea7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ae6b082c1a7064c4fc73157bc41643f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1ae6b082c1a7064c4fc73157bc41643f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LeakyRelu, <a class="el" href="classcaffe2_1_1_get_leaky_relu_gradient.html">GetLeakyReluGradient</a>)</td></tr>
<tr class="separator:a1ae6b082c1a7064c4fc73157bc41643f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86a6cb36d16a1c2d5c6265d5efd001bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86a6cb36d16a1c2d5c6265d5efd001bb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsSplit, <a class="el" href="classcaffe2_1_1_lengths_split_op.html">LengthsSplitOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a86a6cb36d16a1c2d5c6265d5efd001bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6d453d0ceccdc3b7482f4ad55f82210"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6d453d0ceccdc3b7482f4ad55f82210"></a>
NumInputs(1, 2).NumOutputs(1).ScalarType(TensorProto&#160;</td><td class="memItemRight" valign="bottom"><b>GRADIENT_NOT_IMPLEMENTED_YET</b> (LengthsSplit)</td></tr>
<tr class="separator:ad6d453d0ceccdc3b7482f4ad55f82210"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a168583fdd220fc8554a554a4feb1edf7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a168583fdd220fc8554a554a4feb1edf7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsPad, <a class="el" href="classcaffe2_1_1_lengths_pad_op.html">LengthsPadOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a168583fdd220fc8554a554a4feb1edf7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91d8b5ff322dc32ea156dd89fbd0218c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a91d8b5ff322dc32ea156dd89fbd0218c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsSumFused8BitRowwise, <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a91d8b5ff322dc32ea156dd89fbd0218c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a036e35e7f6d29522f158d997ff02955a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a036e35e7f6d29522f158d997ff02955a"></a>
NumInputs(3).NumOutputs(1).ValueKeyLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SparseLengthsSumFused8BitRowwise)</td></tr>
<tr class="separator:a036e35e7f6d29522f158d997ff02955a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7eb6fcabe3dd05328ef202600210f9b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af7eb6fcabe3dd05328ef202600210f9b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsWeightedSumFused8BitRowwise, <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;)</td></tr>
<tr class="separator:af7eb6fcabe3dd05328ef202600210f9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d086556ece72a8c5578ef764b5a1abc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d086556ece72a8c5578ef764b5a1abc"></a>
true <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;::WEIGHTS&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Performs the same operation as SparseLengthsWeightedSum,
but operating on 8-bit rowwise quantized matrices with fused storage
(where each row stores quantized values, and then 4-byte scale and 4-byte bias).
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a9d086556ece72a8c5578ef764b5a1abc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2694649d78a99b062223eb09145c860"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad2694649d78a99b062223eb09145c860"></a>
true <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;::WEIGHTS uint8 tensor obtained with&#160;</td><td class="memItemRight" valign="bottom"><b>operator FloatToFused8BitRowwiseQuantized&quot;) .Input</b> (1,&quot;INDICES&quot;,&quot;Integer vector containing indices of the first &quot;&quot;dimension of DATA for the slices that are being aggregated&quot;).Input(2</td></tr>
<tr class="separator:ad2694649d78a99b062223eb09145c860"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33ceff4580c033cee82f78e0847b097b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a33ceff4580c033cee82f78e0847b097b"></a>
true <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;::WEIGHTS uint8 tensor obtained with Vector with the same sum of elements as the first dimension of DATA&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;WEIGHTS&quot;,&quot;Vector of weights to scale rows of DATA with before reduction&quot;).Output(0</td></tr>
<tr class="separator:a33ceff4580c033cee82f78e0847b097b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0626ce66b6efc80ad54f6fb4b35faed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa0626ce66b6efc80ad54f6fb4b35faed"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SparseLengthsWeightedSumFused8BitRowwise)</td></tr>
<tr class="separator:aa0626ce66b6efc80ad54f6fb4b35faed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0bf9d89c75d5d1709dc47165ff2cec7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af0bf9d89c75d5d1709dc47165ff2cec7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsMeanFused8BitRowwise, <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false, true &gt;)</td></tr>
<tr class="separator:af0bf9d89c75d5d1709dc47165ff2cec7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae80b9561c7a1343ee05aefb81970acc9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae80b9561c7a1343ee05aefb81970acc9"></a>
true <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false, true &gt;::LENGTHS&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Performs the same operation as SparseLengthsMean, but
operating on 8-bit rowwise quantized matrices with fused storage
(where each row stores quantized values, and then 4-byte scale and 4-byte bias).
)DOC&quot;).Input(0</td></tr>
<tr class="separator:ae80b9561c7a1343ee05aefb81970acc9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa7afda2926c1208f5cda8f95bfbf20b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa7afda2926c1208f5cda8f95bfbf20b"></a>
true <a class="el" href="classcaffe2_1_1_sparse_lengths_fused8_bit_rowwise_op.html">SparseLengthsFused8BitRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false, true &gt;::LENGTHS uint8 tensor obtained with Vector with the same sum of elements as the first dimension of DATA&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;output&quot;)</td></tr>
<tr class="separator:afa7afda2926c1208f5cda8f95bfbf20b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4de7891a5a0d69774139573cd45a1f64"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4de7891a5a0d69774139573cd45a1f64"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SparseLengthsMeanFused8BitRowwise)</td></tr>
<tr class="separator:a4de7891a5a0d69774139573cd45a1f64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b181cbe588ad5724df31fcf87b70f2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6b181cbe588ad5724df31fcf87b70f2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsSum, <a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">SparseLengthsSumOp</a>)</td></tr>
<tr class="separator:a6b181cbe588ad5724df31fcf87b70f2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a696633b671c4f99864477a7a4ae36e00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a696633b671c4f99864477a7a4ae36e00"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsWeightedSum, <a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">SparseLengthsWeightedSumOp</a>)</td></tr>
<tr class="separator:a696633b671c4f99864477a7a4ae36e00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabefeeac8f745d36b630da4ee96fb40b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabefeeac8f745d36b630da4ee96fb40b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsMean, <a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">SparseLengthsMeanOp</a>)</td></tr>
<tr class="separator:aabefeeac8f745d36b630da4ee96fb40b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab52c0864f43d3cdd85a76610a16bdebe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab52c0864f43d3cdd85a76610a16bdebe"></a>
for each weights are accessed by where L is the length of given row This is basically a fused&#160;</td><td class="memItemRight" valign="bottom"><b>operator of LengthsRangeFill+Gather+SparseWeightedSum) DOC&quot;) .Input</b> (0,&quot;DATA&quot;,&quot;uint8 tensor obtained with &quot;&quot;operator FloatToRowwiseQuantized8Bits&quot;).Input(1</td></tr>
<tr class="separator:ab52c0864f43d3cdd85a76610a16bdebe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a6ab43873e2156e9ee99cb24b67c4f2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a6ab43873e2156e9ee99cb24b67c4f2"></a>
for each weights are accessed by where L is the length of given row This is basically a fused <a class="el" href="classc10_1_1_scalar.html">Scalar</a> multipliers for the input slices Must be a vector with the length matching the length of DATA&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;INDICES&quot;,&quot;Integer vector containing indices of the first &quot;&quot;dimension of DATA for the slices that are being aggregated&quot;).Input(3</td></tr>
<tr class="separator:a4a6ab43873e2156e9ee99cb24b67c4f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe6e9d2f5e8a969fa963ba87b13be3af"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe6e9d2f5e8a969fa963ba87b13be3af"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_STR</b> (&quot;SparseLengthsPositionalWeightedSum&quot;, CPUSparseLengthsReductionOp&lt; float, <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float, <a class="el" href="structc10_1_1_half.html">at::Half</a> &gt;, 1, 0, 1 &gt;)</td></tr>
<tr class="separator:afe6e9d2f5e8a969fa963ba87b13be3af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a095a49b74f0abb4a00a927a23f5d2db6"><td class="memTemplParams" colspan="2"><a class="anchor" id="a095a49b74f0abb4a00a927a23f5d2db6"></a>
template&lt;typename Def &gt; </td></tr>
<tr class="memitem:a095a49b74f0abb4a00a927a23f5d2db6"><td class="memTemplItemLeft" align="right" valign="top">string&#160;</td><td class="memTemplItemRight" valign="bottom"><b>FormatDoc</b> ()</td></tr>
<tr class="separator:a095a49b74f0abb4a00a927a23f5d2db6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8611a0034b8b5876c4e12a05aebab43c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8611a0034b8b5876c4e12a05aebab43c"></a>
NumInputs(SparseLengthsSumDef::ForwardOp::kNumInputs).NumOutputs(1).ValueKeyLengthInputFillers(<a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">SparseLengthsSumOp</a>&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsSumGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">SparseLengthsSumDef::BackwardOp</a>)</td></tr>
<tr class="separator:a8611a0034b8b5876c4e12a05aebab43c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c3f1c62f23f75414930c2cb7e32754c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5c3f1c62f23f75414930c2cb7e32754c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (SparseLengthsSumDef::BackwardOp::kNumInputs).NumOutputs(1).DisallowInputFillers()</td></tr>
<tr class="separator:a5c3f1c62f23f75414930c2cb7e32754c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f5673f296f494a999b464838bd01607"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f5673f296f494a999b464838bd01607"></a>
NumInputs(SparseLengthsWeightedSumDef::ForwardOp::kNumInputs).NumOutputs(1).WeightedValueKeyLengthInputFillers(<a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">SparseLengthsWeightedSumOp</a>&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsWeightedSumGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">SparseLengthsWeightedSumDef::BackwardOp</a>)</td></tr>
<tr class="separator:a7f5673f296f494a999b464838bd01607"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fb70a8cbdb4acc3effb3f181fc10d83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7fb70a8cbdb4acc3effb3f181fc10d83"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (SparseLengthsWeightedSumDef::BackwardOp::kNumInputs).NumOutputs(1).DisallowInputFillers()</td></tr>
<tr class="separator:a7fb70a8cbdb4acc3effb3f181fc10d83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cf81f3a40c55499d8156bfb52380157"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0cf81f3a40c55499d8156bfb52380157"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SparseLengthsWeightedSum, <a class="el" href="structcaffe2_1_1_lengths_op_get_gradient.html">SparseLengthsWeightedSumDef::GetGradient</a>) using SparseLengthsMeanDef</td></tr>
<tr class="separator:a0cf81f3a40c55499d8156bfb52380157"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f9cf2236d8a67f8c12ad29a37ee1b2a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4f9cf2236d8a67f8c12ad29a37ee1b2a"></a>
NumInputs(SparseLengthsMeanDef::ForwardOp::kNumInputs).NumOutputs(1).ValueKeyLengthInputFillers(<a class="el" href="classcaffe2_1_1_c_p_u_sparse_lengths_reduction_op.html">SparseLengthsMeanOp</a>&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsMeanGradient, SparseLengthsMeanDef::BackwardOp)</td></tr>
<tr class="separator:a4f9cf2236d8a67f8c12ad29a37ee1b2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38ebc27fc9e242c28bf13be6e36f4e92"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38ebc27fc9e242c28bf13be6e36f4e92"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (SparseLengthsMeanDef::BackwardOp::kNumInputs).NumOutputs(1).DisallowInputFillers()</td></tr>
<tr class="separator:a38ebc27fc9e242c28bf13be6e36f4e92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afafe488e6db7646a9d15aec155a0fc04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afafe488e6db7646a9d15aec155a0fc04"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Rowwise8BitQuantizedToFloat, <a class="el" href="classcaffe2_1_1_rowwise8_bit_quantized_to_float_op.html">Rowwise8BitQuantizedToFloatOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afafe488e6db7646a9d15aec155a0fc04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a75b30a0c88ed4f390bf2e445d68311"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1a75b30a0c88ed4f390bf2e445d68311"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FloatToRowwiseQuantized8Bits, <a class="el" href="classcaffe2_1_1_float_to_rowwise_quantized8_bits_op.html">FloatToRowwiseQuantized8BitsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1a75b30a0c88ed4f390bf2e445d68311"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e9bc5b0516a81f46642c5c36d55f4c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e9bc5b0516a81f46642c5c36d55f4c9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsSum8BitsRowwise, <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8e9bc5b0516a81f46642c5c36d55f4c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5a52395c5f3f9c00284b61da06cadc8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab5a52395c5f3f9c00284b61da06cadc8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsWeightedSum8BitsRowwise, <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;)</td></tr>
<tr class="separator:ab5a52395c5f3f9c00284b61da06cadc8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e5ca5d3b1682fd375392731ad2ebfae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e5ca5d3b1682fd375392731ad2ebfae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsMean8BitsRowwise, <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 0, 1 &gt;)</td></tr>
<tr class="separator:a4e5ca5d3b1682fd375392731ad2ebfae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a906c1b465e20295abe7d0a644ba260f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a906c1b465e20295abe7d0a644ba260f4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsWeightedMean8BitsRowwise, <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1, 1 &gt;)</td></tr>
<tr class="separator:a906c1b465e20295abe7d0a644ba260f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ab87e01676d9fb7d47bf3554de00f24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7ab87e01676d9fb7d47bf3554de00f24"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (5).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a></td></tr>
<tr class="separator:a7ab87e01676d9fb7d47bf3554de00f24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a519e2f475b37c955ff7323ce1278a6a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a519e2f475b37c955ff7323ce1278a6a4"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;::LENGTHS&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Variation of SparseLengthsWeightedSum operator, where
DATA is stored using 8bits. DATA was quantized with 8Bit row-wise
quantization (see doc to FloatToRowwiseQuantized8Bits operator). To
restore DATA from 8Bit, we use additional input that stores scales
and biases.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a519e2f475b37c955ff7323ce1278a6a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa82815e2efd96d514f35cf803fe76390"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa82815e2efd96d514f35cf803fe76390"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;::LENGTHS uint8 tensor obtained with&#160;</td><td class="memItemRight" valign="bottom"><b>operator FloatToRowwiseQuantized8Bits&quot;) .Input</b> (1,&quot;SCALARS&quot;,&quot;<a class="el" href="classc10_1_1_scalar.html">Scalar</a> multipliers for the input slices. Must &quot;&quot;be a vector with the length matching the length of INDICES&quot;).Input(2</td></tr>
<tr class="separator:aa82815e2efd96d514f35cf803fe76390"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f39fbf619ddf40926a0e83919a51ae1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f39fbf619ddf40926a0e83919a51ae1"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;::LENGTHS uint8 tensor obtained with Integer vector containing indices of the first dimension of DATA for the slices that are being aggregated&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;LENGTHS&quot;,&quot;Vector with the same sum of elements as the first dimension of DATA&quot;).Input(4</td></tr>
<tr class="separator:a1f39fbf619ddf40926a0e83919a51ae1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a897a5004c7fe9b3550c9aa1657889d9d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a897a5004c7fe9b3550c9aa1657889d9d"></a>
<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1, 1 &gt;::LENGTHS&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Variation of SparseLengthsWeightedMean operator, where
DATA is stored using 8bits. DATA was quantized with 8Bit row-wise
quantization (see doc to FloatToRowwiseQuantized8Bits operator). To
restore DATA from 8Bit, we use additional input that stores scales
and biases.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a897a5004c7fe9b3550c9aa1657889d9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bb8c06d8c466b1445ca915bd25218bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0bb8c06d8c466b1445ca915bd25218bd"></a>
NumInputs(1).NumOutputs(2).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; NumInputs(2).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Rowwise8BitQuantizedToFloat)</td></tr>
<tr class="separator:a0bb8c06d8c466b1445ca915bd25218bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab955b674bc3eef5b4e11be15854f4a58"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab955b674bc3eef5b4e11be15854f4a58"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (FloatToRowwiseQuantized8Bits)</td></tr>
<tr class="separator:ab955b674bc3eef5b4e11be15854f4a58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31761fa6a21e4722cad8b5b8336433f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a31761fa6a21e4722cad8b5b8336433f0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SparseLengthsSum8BitsRowwise)</td></tr>
<tr class="separator:a31761fa6a21e4722cad8b5b8336433f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd6e17cd7f773983c7ff8958cfbe1a6e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd6e17cd7f773983c7ff8958cfbe1a6e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SparseLengthsWeightedSum8BitsRowwise)</td></tr>
<tr class="separator:acd6e17cd7f773983c7ff8958cfbe1a6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af28abebee9dcb7db4b73ea9a334981e2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af28abebee9dcb7db4b73ea9a334981e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SparseLengthsMean8BitsRowwise)</td></tr>
<tr class="separator:af28abebee9dcb7db4b73ea9a334981e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae338e633b6c9b6d53aa17d141c2173d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae338e633b6c9b6d53aa17d141c2173d1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SparseLengthsWeightedMean8BitsRowwise)</td></tr>
<tr class="separator:ae338e633b6c9b6d53aa17d141c2173d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38ba780c03088ffdf5e3d08f6d274a4e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38ba780c03088ffdf5e3d08f6d274a4e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsTile, <a class="el" href="classcaffe2_1_1_lengths_tile_op.html">LengthsTileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a38ba780c03088ffdf5e3d08f6d274a4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1706e4dfb2e27ede3b5f7690d961ad2d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1706e4dfb2e27ede3b5f7690d961ad2d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsTopK, <a class="el" href="classcaffe2_1_1_lengths_top_k_op.html">LengthsTopKOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1706e4dfb2e27ede3b5f7690d961ad2d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a580d523aaa232eb0d30a9e9c1d0ae8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a580d523aaa232eb0d30a9e9c1d0ae8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsTopKGradient, <a class="el" href="classcaffe2_1_1_lengths_top_k_gradient_op.html">LengthsTopKGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9a580d523aaa232eb0d30a9e9c1d0ae8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec4405504dd7c0aa41a0aa7a184148b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec4405504dd7c0aa41a0aa7a184148b0"></a>
where segments are defined by their and concatenate them in an output tensor of the output value will be padded and the corresponding output indices will be padded by DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;DATA&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of rank 1. First dimension must be equal to the sum of &quot;&quot;lengths&quot;).Input(1</td></tr>
<tr class="separator:aec4405504dd7c0aa41a0aa7a184148b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafe2cde672489d8ce983c5eda0bbfbe4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aafe2cde672489d8ce983c5eda0bbfbe4"></a>
where segments are defined by their and concatenate them in an output tensor of the output value will be padded and the corresponding output indices will be padded by DOC <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of int32 lengths of rank&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;TopKValue&quot;,&quot;Output top k elements for each segment, with&quot;&quot;shape=(SIZE(lengths), k)&quot;).Output(1</td></tr>
<tr class="separator:aafe2cde672489d8ce983c5eda0bbfbe4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab549efed88fc7cc80733e3b07ca9a4ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab549efed88fc7cc80733e3b07ca9a4ed"></a>
where segments are defined by their and concatenate them in an output tensor of the output value will be padded and the corresponding output indices will be padded by DOC <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of int32 lengths of rank Output indices in DATA corresponding to value in TopKValue&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;k&quot;,&quot;the number of top values to return for each segment, if the number &quot;&quot;of values is smaller than k, the values would be padded with 0 and &quot;&quot;indices would be padded with -1.&quot;)</td></tr>
<tr class="separator:ab549efed88fc7cc80733e3b07ca9a4ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9882aad183ec1a93cbdef02f529bdbb4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9882aad183ec1a93cbdef02f529bdbb4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LengthsTopKGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a9882aad183ec1a93cbdef02f529bdbb4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a103f939c0cd701c1548e4d7a8ca1b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a103f939c0cd701c1548e4d7a8ca1b9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LengthsTopK, GetLengthsTopKGradient)</td></tr>
<tr class="separator:a3a103f939c0cd701c1548e4d7a8ca1b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9327141f225d709f7ffc9c4049768167"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9327141f225d709f7ffc9c4049768167"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DBExists, <a class="el" href="classcaffe2_1_1_d_b_exists_op.html">DBExistsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9327141f225d709f7ffc9c4049768167"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83a3c43568d2c93a45f3cf3313bfa02f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a83a3c43568d2c93a45f3cf3313bfa02f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Load, <a class="el" href="classcaffe2_1_1_load_op.html">LoadOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a83a3c43568d2c93a45f3cf3313bfa02f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4857a64f8d05730bf604eb9b6f789da8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4857a64f8d05730bf604eb9b6f789da8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Save, <a class="el" href="classcaffe2_1_1_save_op.html">SaveOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4857a64f8d05730bf604eb9b6f789da8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89777888c5fe5010a5db2e9fa335fae6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a89777888c5fe5010a5db2e9fa335fae6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Checkpoint, <a class="el" href="classcaffe2_1_1_checkpoint_op.html">CheckpointOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a89777888c5fe5010a5db2e9fa335fae6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34354f11cf682249cc1ce24a8114cd1e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a34354f11cf682249cc1ce24a8114cd1e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Snapshot, <a class="el" href="classcaffe2_1_1_checkpoint_op.html">CheckpointOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a34354f11cf682249cc1ce24a8114cd1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85c2521adbee241d8cebeef1ab224e3b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a85c2521adbee241d8cebeef1ab224e3b"></a>
NumInputs(0).NumOutputs(1).SetDoc(R&quot;DOC( Checks if the db described by the arguments exists. Github Links see the absolute_path arg details for options regarding the current root folder of the workspace&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;db_type&quot;,&quot;*(type: string)* <a class="el" href="structc10_1_1_type.html">Type</a> of db to save (options: \&quot;lmdb\&quot;, &quot;&quot;\&quot;leveldb\&quot;, \&quot;minidb\&quot;).&quot;)</td></tr>
<tr class="separator:a85c2521adbee241d8cebeef1ab224e3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab08b4dcb85e6a72c5f1636e692bf7b9a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab08b4dcb85e6a72c5f1636e692bf7b9a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (0, INT_MAX).NumOutputs(0</td></tr>
<tr class="separator:ab08b4dcb85e6a72c5f1636e692bf7b9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a330e8e35144fab7e8d79e7de58de6a2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a330e8e35144fab7e8d79e7de58de6a2f"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
The Load operator loads a set of serialized blobs from a db or multiple dbs. It
takes $[0, \infty)$ number of inputs and $[0, \infty)$ number of outputs, using
the db keys to match the db entries with the outputs.

If at least one input is passed, then it is assumed that that input blobs are a
set of DBReaders to load from. Otherwise the `db` or `dbs` argument is used to load
blobs from one single db or multiple dbs respectively. `db_type` argument is used
to specify the type of the input db/dbs.

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/load_save_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Load&quot;,
    [],
    [&quot;X&quot;, &quot;Y&quot;],
    db=&quot;test_db&quot;,
    db_type=&quot;lmdb&quot;
)

workspace.RunOperatorOnce(op)
print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a330e8e35144fab7e8d79e7de58de6a2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeef981a52a8d0c08d793d5497c1fe3ac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeef981a52a8d0c08d793d5497c1fe3ac"></a>
default save the db directly to the path specified by the db arg If not&#160;</td><td class="memItemRight" valign="bottom"><b>set</b> (default)</td></tr>
<tr class="separator:aeef981a52a8d0c08d793d5497c1fe3ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a22b1e8f380ebf24c269c337fee4b89"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1a22b1e8f380ebf24c269c337fee4b89"></a>
default save the db directly to the path specified by the db arg If not prepend the path of the current root folder of the workspace to the path specified by the db arg&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;add_prefix&quot;,&quot;*(type: string, default: \&quot;\&quot;)* Blobs will be prefixed with this when &quot;&quot;loading. Useful for avoiding collisions with blobs existing in the &quot;&quot;workspace. The output blob names specified to this op should include &quot;&quot;this prefix.&quot;).Arg(&quot;strip_prefix&quot;</td></tr>
<tr class="separator:a1a22b1e8f380ebf24c269c337fee4b89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1158082d0060cc3a510643075910910d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1158082d0060cc3a510643075910910d"></a>
default save the db directly to the path specified by the db arg If not prepend the path of the current root folder of the workspace to the path specified by the db arg characters that precede strip_prefix will be removed Useful for removing device scope from blob names&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;db&quot;,&quot;*(type: string)* The output path of the db. See the &quot;&quot;`absolute_path` arg details for options regarding the current root folder &quot;&quot;of the workspace.&quot;).Arg(&quot;dbs&quot;</td></tr>
<tr class="separator:a1158082d0060cc3a510643075910910d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6028e03168fa61ce1e277d10b7756c2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac6028e03168fa61ce1e277d10b7756c2"></a>
default save the db directly to the path specified by the db arg If not prepend the path of the current root folder of the workspace to the path specified by the db arg characters that precede strip_prefix will be removed Useful for removing device scope from blob names minidb&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;keep_device&quot;,&quot;*(type: int; default: 0)* If nonzero, the blobs are loaded into the &quot;&quot;device that is specified in the serialized `BlobProto`. Otherwise, &quot;&quot;the device will be set as the one that the `Load` operator is being &quot;&quot;run under.&quot;).Arg(&quot;load_all&quot;</td></tr>
<tr class="separator:ac6028e03168fa61ce1e277d10b7756c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7a8b96d8be989f5b9c20dfd924c101e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af7a8b96d8be989f5b9c20dfd924c101e"></a>
default will load all blobs pointed to by the db to the workspace overwriting creating blobs as needed&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;allow_incomplete&quot;,&quot;*(type: bool; default: False)* If True, will allow not loading all &quot;&quot;the output blobs specified in the outputs.&quot;).Arg(&quot;source_blob_names&quot;</td></tr>
<tr class="separator:af7a8b96d8be989f5b9c20dfd924c101e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad153f4894c27d93a9eb7b138e8de6336"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad153f4894c27d93a9eb7b138e8de6336"></a>
default save the db directly to the path specified by the db arg If not prepend the path of the current root folder of the workspace to the path specified by the db arg&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;strip_prefix&quot;,&quot;*(type: string, default: \&quot;\&quot;)* Characters in the provided blob names &quot;&quot;that match `strip_prefix` will be removed prior to saving. Also, &quot;&quot;characters that precede `strip_prefix` will be removed. Useful for &quot;&quot;removing device scope from blob names.&quot;).Arg(&quot;blob_name_overrides&quot;</td></tr>
<tr class="separator:ad153f4894c27d93a9eb7b138e8de6336"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad270fed1b901374937528bc7723b401f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad270fed1b901374937528bc7723b401f"></a>
default save the db directly to the path specified by the db arg If not prepend the path of the current root folder of the workspace to the path specified by the db arg *&#160;</td><td class="memItemRight" valign="bottom"><b>List</b> (string))*If set</td></tr>
<tr class="separator:ad270fed1b901374937528bc7723b401f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad443d465a473d642c70b2813317e39bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad443d465a473d642c70b2813317e39bd"></a>
default save the db directly to the path specified by the db arg If not prepend the path of the current root folder of the workspace to the path specified by the db arg used as blob names instead of original blob names Must be same length as number of blobs minidb&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;chunk_size&quot;,&quot;*(type: string; default: kDefaultChunkSize)* The chunk &quot;&quot;size to split tensor data into. If not set, caffe2_tensor_chunk_size will &quot;&quot;be used&quot;).Input(0</td></tr>
<tr class="separator:ad443d465a473d642c70b2813317e39bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42aaf8a2f399dcee5aa8594756992b3a"><td class="memTemplParams" colspan="2"><a class="anchor" id="a42aaf8a2f399dcee5aa8594756992b3a"></a>
template&lt;typename... Ts&gt; </td></tr>
<tr class="memitem:a42aaf8a2f399dcee5aa8594756992b3a"><td class="memTemplItemLeft" align="right" valign="top">string&#160;</td><td class="memTemplItemRight" valign="bottom"><b>FormatString</b> (const string &amp;pattern, Ts...values)</td></tr>
<tr class="separator:a42aaf8a2f399dcee5aa8594756992b3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab8186606e8b24d29010b076a7c9ccc9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aab8186606e8b24d29010b076a7c9ccc9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Load, <a class="el" href="classcaffe2_1_1_load_op.html">LoadOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aab8186606e8b24d29010b076a7c9ccc9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af101d9b19521d084f15edd39e20c43e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af101d9b19521d084f15edd39e20c43e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Save, <a class="el" href="classcaffe2_1_1_save_op.html">SaveOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:af101d9b19521d084f15edd39e20c43e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8145f81bb04342575425becdd999e2f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8145f81bb04342575425becdd999e2f3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Checkpoint, <a class="el" href="classcaffe2_1_1_checkpoint_op.html">CheckpointOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a8145f81bb04342575425becdd999e2f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7702dd289068377c4356b52ee90b74ec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7702dd289068377c4356b52ee90b74ec"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LRN, <a class="el" href="classcaffe2_1_1_l_r_n_op.html">LRNOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7702dd289068377c4356b52ee90b74ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05dbd0b26aaca2fac07d5191c2ffb419"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a05dbd0b26aaca2fac07d5191c2ffb419"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LRNGradient, <a class="el" href="classcaffe2_1_1_l_r_n_gradient_op.html">LRNGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a05dbd0b26aaca2fac07d5191c2ffb419"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc00bca59a2adc368cbbe0833c076b1d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc00bca59a2adc368cbbe0833c076b1d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(

`LRN` applies Local Response Normalization to an input blob. This operation performs
a kind of &quot;lateral inhibition&quot; by normalizing over local input regions, where
normalization is applied across channels. This operator is typically used to
normalize an unbounded activation (such as ReLU). The output shape is the same as
the input shape. The `brew` module has a wrapper for this operator for use in a
`ModelHelper` object.

The formula for LRN is as follows:

$$b_{c} = a_{c}(bias + \frac{\alpha}{n}\sum_{c'=max(0,c-n/2)}^{min(N-1,c+n/2)} a_{c'}^2 )^{-\beta}$$


Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/local_response_normalization_op.h
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/local_response_normalization_op.cc


&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

op = core.CreateOperator(&quot;LRN&quot;,
     [&quot;X&quot;],
     [&quot;Y&quot;, &quot;Y_scale&quot;],
     size=11,
     alpha=0.001,
     beta=0.5,
     bias=2.0,
     order=&quot;NHWC&quot;
)

workspace.FeedBlob(&quot;X&quot;, np.random.randn(1, 6, 6, 1).astype(np.float32)) // NCHW
print(&quot;X:\n&quot;, workspace.FetchBlob(&quot;X&quot;), &quot;\n&quot;)
workspace.RunOperatorOnce(op)
print(&quot;Y:\n&quot;, workspace.FetchBlob(&quot;Y&quot;))
print(&quot;Y_scale:\n&quot;, workspace.FetchBlob(&quot;Y_scale&quot;))
```

**Result**

```
X:
 [[[[ 0.72985137]
   [-0.3753357 ]
   [ 2.7344604 ]
   [-0.5937792 ]
   [ 0.38440478]
   [-2.1659644 ]]

  [[-0.92846817]
   [-0.9996144 ]
   [ 0.212943  ]
   [-1.968045  ]
   [-0.77839696]
   [ 0.45492038]]

  [[-0.11263168]
   [ 1.9901097 ]
   [ 0.19275683]
   [ 0.15630436]
   [ 0.7536298 ]
   [-0.77339894]]

  [[ 0.8353551 ]
   [-0.7784452 ]
   [ 1.779317  ]
   [ 0.22421335]
   [ 1.3846219 ]
   [-3.0546608 ]]

  [[ 0.09977621]
   [ 2.2071757 ]
   [ 0.79971045]
   [ 3.563886  ]
   [-0.7169287 ]
   [ 0.77170426]]

  [[-1.4296649 ]
   [ 0.19181213]
   [ 0.45961624]
   [-1.0201577 ]
   [ 0.62854475]
   [-0.6395456 ]]]]

Y:
 [[[[ 0.5160766 ]
   [-0.26540157]
   [ 1.9332271 ]
   [-0.41986194]
   [ 0.27181432]
   [-1.5314047 ]]

  [[-0.6565133 ]
   [-0.7068181 ]
   [ 0.15057328]
   [-1.3914955 ]
   [-0.5504022 ]
   [ 0.32167578]]

  [[-0.0796426 ]
   [ 1.4070934 ]
   [ 0.13629955]
   [ 0.11052381]
   [ 0.53288984]
   [-0.5468682 ]]

  [[ 0.5906759 ]
   [-0.5504363 ]
   [ 1.2580767 ]
   [ 0.1585426 ]
   [ 0.9790328 ]
   [-2.1595135 ]]

  [[ 0.07055242]
   [ 1.5605361 ]
   [ 0.5654725 ]
   [ 2.5193207 ]
   [-0.50693923]
   [ 0.54567   ]]

  [[-1.0108787 ]
   [ 0.13563155]
   [ 0.3249962 ]
   [-0.72134334]
   [ 0.44444424]
   [-0.45222285]]]]
Y_scale:
 [[[[2.0000484]
   [2.0000129]
   [2.0006797]
   [2.000032 ]
   [2.0000134]
   [2.0004265]]

  [[2.0000784]
   [2.0000908]
   [2.000004 ]
   [2.0003521]
   [2.000055 ]
   [2.0000188]]

  [[2.0000012]
   [2.00036  ]
   [2.0000033]
   [2.0000021]
   [2.0000517]
   [2.0000544]]

  [[2.0000634]
   [2.000055 ]
   [2.0002878]
   [2.0000045]
   [2.0001743]
   [2.0008483]]

  [[2.000001 ]
   [2.000443 ]
   [2.0000582]
   [2.0011547]
   [2.0000467]
   [2.0000541]]

  [[2.0001857]
   [2.0000033]
   [2.0000193]
   [2.0000947]
   [2.000036 ]
   [2.0000372]]]]
```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;size&quot;</td></tr>
<tr class="separator:abc00bca59a2adc368cbbe0833c076b1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a887777439f2aa62e31317e81d3ebf359"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a887777439f2aa62e31317e81d3ebf359"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LRNGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a887777439f2aa62e31317e81d3ebf359"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3c499f29f00ec4a299b806f50d19b83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3c499f29f00ec4a299b806f50d19b83"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LRN, <a class="el" href="classcaffe2_1_1_get_l_r_n_gradient.html">GetLRNGradient</a>)</td></tr>
<tr class="separator:af3c499f29f00ec4a299b806f50d19b83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a1b86cbff4a05b3c01cdb4c9f045fe4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6a1b86cbff4a05b3c01cdb4c9f045fe4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LC, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6a1b86cbff4a05b3c01cdb4c9f045fe4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ae234337a0f5b723601a468cc35d61e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ae234337a0f5b723601a468cc35d61e"></a>
NumInputs(2, 3).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LC1D, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4ae234337a0f5b723601a468cc35d61e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ecaff2efc994a1396203c6d75cff4a6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3ecaff2efc994a1396203c6d75cff4a6"></a>
NumInputs(2, 3).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LC2D, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3ecaff2efc994a1396203c6d75cff4a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac32e2253300a3fd1b58d636a7d9bacd4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac32e2253300a3fd1b58d636a7d9bacd4"></a>
NumInputs(2, 3).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LC3D, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac32e2253300a3fd1b58d636a7d9bacd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3691743e6c1b60e8bf613c05ab0c125"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab3691743e6c1b60e8bf613c05ab0c125"></a>
NumInputs(2, 3).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LCGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab3691743e6c1b60e8bf613c05ab0c125"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8426a407adb929ab24a730ff53fee83a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8426a407adb929ab24a730ff53fee83a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LCGradient).NumInputs(2</td></tr>
<tr class="separator:a8426a407adb929ab24a730ff53fee83a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a164978d7deef2ba12deb94e1f0be5380"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a164978d7deef2ba12deb94e1f0be5380"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LC1DGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a164978d7deef2ba12deb94e1f0be5380"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9828214ab329c658ea2dec0557ae20f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae9828214ab329c658ea2dec0557ae20f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LC1DGradient).NumInputs(2</td></tr>
<tr class="separator:ae9828214ab329c658ea2dec0557ae20f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c7be3ac8dd05e2696316efb5b3c2e6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c7be3ac8dd05e2696316efb5b3c2e6d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LC2DGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6c7be3ac8dd05e2696316efb5b3c2e6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a922e5441460996843774046bb54f1b41"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a922e5441460996843774046bb54f1b41"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LC2DGradient).NumInputs(2</td></tr>
<tr class="separator:a922e5441460996843774046bb54f1b41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab92c83d050f7aa5379fa4a80aefa102d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab92c83d050f7aa5379fa4a80aefa102d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LC3DGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab92c83d050f7aa5379fa4a80aefa102d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb2ff6d35b42931a85ace3074ac3de8b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adb2ff6d35b42931a85ace3074ac3de8b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LC3DGradient).NumInputs(2</td></tr>
<tr class="separator:adb2ff6d35b42931a85ace3074ac3de8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afeea10cda4338df72063c16742af28a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afeea10cda4338df72063c16742af28a4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LC, GetLocallyConnectedGradient)</td></tr>
<tr class="separator:afeea10cda4338df72063c16742af28a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a492be997ec6d0e35a30d2183d6e664a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a492be997ec6d0e35a30d2183d6e664a1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LC1D, GetLocallyConnectedGradient)</td></tr>
<tr class="separator:a492be997ec6d0e35a30d2183d6e664a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3769e348f517d725c973cfb5f52a6a7b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3769e348f517d725c973cfb5f52a6a7b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LC2D, GetLocallyConnectedGradient)</td></tr>
<tr class="separator:a3769e348f517d725c973cfb5f52a6a7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63f8bf91a78f04b115ddddfc2175d2a7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a63f8bf91a78f04b115ddddfc2175d2a7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LC3D, GetLocallyConnectedGradient)</td></tr>
<tr class="separator:a63f8bf91a78f04b115ddddfc2175d2a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf90cd104587ffd347097e80454527f7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acf90cd104587ffd347097e80454527f7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LC, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:acf90cd104587ffd347097e80454527f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7eaea276dbc3b70723aef025f48070ac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7eaea276dbc3b70723aef025f48070ac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LCGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a7eaea276dbc3b70723aef025f48070ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2754d35f306a7cc7f5155d9c085da7b3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2754d35f306a7cc7f5155d9c085da7b3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LC1D, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a2754d35f306a7cc7f5155d9c085da7b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94c984f58b64f42af2c571b84bcc4147"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a94c984f58b64f42af2c571b84bcc4147"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LC1DGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a94c984f58b64f42af2c571b84bcc4147"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65346e779cc27df7c07a1cb3c389c19e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a65346e779cc27df7c07a1cb3c389c19e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LC2D, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a65346e779cc27df7c07a1cb3c389c19e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8723c1666cf781d42fb3ad667465c8f7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8723c1666cf781d42fb3ad667465c8f7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LC2DGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a8723c1666cf781d42fb3ad667465c8f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a802124c6027b6873fb8c424d2ceb8a45"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a802124c6027b6873fb8c424d2ceb8a45"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LC3D, <a class="el" href="classcaffe2_1_1_locally_connected_op.html">LocallyConnectedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a802124c6027b6873fb8c424d2ceb8a45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41c09c3d303e397f74050b8cb5d1c587"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a41c09c3d303e397f74050b8cb5d1c587"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LC3DGradient, <a class="el" href="classcaffe2_1_1_locally_connected_gradient_op.html">LocallyConnectedGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a41c09c3d303e397f74050b8cb5d1c587"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02d52253a4fe15c2b67d6af4ab0d1dd7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02d52253a4fe15c2b67d6af4ab0d1dd7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Log, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_log_functor.html">LogFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a02d52253a4fe15c2b67d6af4ab0d1dd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58f7b405b7c8bab8fb79c8174334e6b7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a58f7b405b7c8bab8fb79c8174334e6b7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Log, GetLogGradient)</td></tr>
<tr class="separator:a58f7b405b7c8bab8fb79c8174334e6b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a567f8a47c0361f726464644a9bb2d79f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a567f8a47c0361f726464644a9bb2d79f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Log, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_log_functor.html">LogFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a567f8a47c0361f726464644a9bb2d79f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf60f1c50aa61c7ff18451ac4fa573c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf60f1c50aa61c7ff18451ac4fa573c1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Logit, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_logit_functor.html">LogitFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:adf60f1c50aa61c7ff18451ac4fa573c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7f92115b6b354c26c521c337d50f02d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae7f92115b6b354c26c521c337d50f02d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LogitGradient, <a class="el" href="classcaffe2_1_1_logit_gradient_op.html">LogitGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae7f92115b6b354c26c521c337d50f02d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b6a546b2bb8f24d41dc111c6b57f08d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9b6a546b2bb8f24d41dc111c6b57f08d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a>, <a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9b6a546b2bb8f24d41dc111c6b57f08d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75e97ffdbe98d84cba77c1e2ea9bd950"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75e97ffdbe98d84cba77c1e2ea9bd950"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_averaged_loss_gradient.html">AveragedLossGradient</a>, <a class="el" href="classcaffe2_1_1_averaged_loss_gradient.html">AveragedLossGradient</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a75e97ffdbe98d84cba77c1e2ea9bd950"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44131466951f0c7f19ca61bbd332e921"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a44131466951f0c7f19ca61bbd332e921"></a>
NumInputs(1).NumOutputs(1).ScalarType(TensorProto&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (<a class="el" href="classcaffe2_1_1_averaged_loss_gradient.html">AveragedLossGradient</a>).NumInputs(2).NumOutputs(1)</td></tr>
<tr class="separator:a44131466951f0c7f19ca61bbd332e921"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae70fd91f38572036a41ec4bec609a830"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae70fd91f38572036a41ec4bec609a830"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_averaged_loss.html">AveragedLoss</a>, <a class="el" href="classcaffe2_1_1_get_averaged_loss_gradient.html">GetAveragedLossGradient</a>)</td></tr>
<tr class="separator:ae70fd91f38572036a41ec4bec609a830"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9857bddde22a3dd1c6f9846653de2226"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9857bddde22a3dd1c6f9846653de2226"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LpPool, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_lp_pool_functor.html">LpPoolFunctor</a> &gt;)</td></tr>
<tr class="separator:a9857bddde22a3dd1c6f9846653de2226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac036739eaa0e4cc33f1d67358bbf1a05"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac036739eaa0e4cc33f1d67358bbf1a05"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LpPoolGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_lp_pool_functor.html">LpPoolFunctor</a> &gt;)</td></tr>
<tr class="separator:ac036739eaa0e4cc33f1d67358bbf1a05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab436155bdeca962ec444820f3aa30b7d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab436155bdeca962ec444820f3aa30b7d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LpPoolGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:ab436155bdeca962ec444820f3aa30b7d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae41bcbb51139cc41b96eaae6c31182a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae41bcbb51139cc41b96eaae6c31182a5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LpPool, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:ae41bcbb51139cc41b96eaae6c31182a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4233cbd96ab2aa3f1dac368f5af4776a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4233cbd96ab2aa3f1dac368f5af4776a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LSTMUnit, <a class="el" href="classcaffe2_1_1_l_s_t_m_unit_op.html">LSTMUnitOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4233cbd96ab2aa3f1dac368f5af4776a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81b805b430b58da15a61e93b165a723a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a81b805b430b58da15a61e93b165a723a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (4, 5).NumOutputs(2).SetDoc(R&quot;DOC( LSTMUnit computes the activations of a standard LSTM (without peephole connections)</td></tr>
<tr class="separator:a81b805b430b58da15a61e93b165a723a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae556702783a95dfa3475ae030ec0fa82"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae556702783a95dfa3475ae030ec0fa82"></a>
in a sequence length aware fashion given the previous cell and the sequence computes the LSTM avoiding computation if the input is&#160;</td><td class="memItemRight" valign="bottom"><b>invalid</b> (as in, the value at X{t][n] &gt;=seqLengths[n].) DOC&quot;) .Arg(&quot;forget_bias&quot;</td></tr>
<tr class="separator:ae556702783a95dfa3475ae030ec0fa82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4d1a5de72aa682f38ea6ba570466b89"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab4d1a5de72aa682f38ea6ba570466b89"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LSTMUnitGradient, <a class="el" href="classcaffe2_1_1_l_s_t_m_unit_gradient_op.html">LSTMUnitGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab4d1a5de72aa682f38ea6ba570466b89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef1b7a763f73632a332d11ed579f7361"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef1b7a763f73632a332d11ed579f7361"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (8, 9).NumOutputs(3).Arg(&quot;sequence_lengths&quot;</td></tr>
<tr class="separator:aef1b7a763f73632a332d11ed579f7361"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a077ac830f10218a734569cd51deb4410"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a077ac830f10218a734569cd51deb4410"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (LSTMUnit, <a class="el" href="classcaffe2_1_1_get_l_s_t_m_unit_gradient.html">GetLSTMUnitGradient</a>)</td></tr>
<tr class="separator:a077ac830f10218a734569cd51deb4410"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a935a0791880f503ec8ee08fa44991230"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a935a0791880f503ec8ee08fa44991230"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (MapType64To64)</td></tr>
<tr class="separator:a935a0791880f503ec8ee08fa44991230"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d3a404643b4e355cd537ac2b294511e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6d3a404643b4e355cd537ac2b294511e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MarginRankingCriterion, <a class="el" href="classcaffe2_1_1_margin_ranking_criterion_op.html">MarginRankingCriterionOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6d3a404643b4e355cd537ac2b294511e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fb68f6a378891063c08d234a8677c18"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1fb68f6a378891063c08d234a8677c18"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MarginRankingCriterionGradient, <a class="el" href="classcaffe2_1_1_margin_ranking_criterion_gradient_op.html">MarginRankingCriterionGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1fb68f6a378891063c08d234a8677c18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f2bc9c420fbbde79e54da670db919cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0f2bc9c420fbbde79e54da670db919cb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>X2</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>)</td></tr>
<tr class="separator:a0f2bc9c420fbbde79e54da670db919cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fea6a12827905ff05711c465362b147"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7fea6a12827905ff05711c465362b147"></a>
and label&#160;</td><td class="memItemRight" valign="bottom"><b>Y</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>) to produce the loss(<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>) where the loss function</td></tr>
<tr class="separator:a7fea6a12827905ff05711c465362b147"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c96e20a3a753848fc97b32479cf08fc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c96e20a3a753848fc97b32479cf08fc"></a>
and label&#160;</td><td class="memItemRight" valign="bottom"><b>loss</b> (X1, X2, Y)</td></tr>
<tr class="separator:a1c96e20a3a753848fc97b32479cf08fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71862c888d76ce10dd13ba7f842c8662"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a71862c888d76ce10dd13ba7f842c8662"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MatMul, <a class="el" href="classcaffe2_1_1_mat_mul_op.html">MatMulOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a71862c888d76ce10dd13ba7f842c8662"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2aa42a78dbd98b1b5fa034551023585"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa2aa42a78dbd98b1b5fa034551023585"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>set_data_type</b> (in[0].data_type())</td></tr>
<tr class="separator:aa2aa42a78dbd98b1b5fa034551023585"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4798b759aa7e727e9dba79fa8442be63"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4798b759aa7e727e9dba79fa8442be63"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (trans_a)</td></tr>
<tr class="separator:a4798b759aa7e727e9dba79fa8442be63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a56694d062fe35e23b4e0066303e67b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a56694d062fe35e23b4e0066303e67b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (trans_b)</td></tr>
<tr class="separator:a0a56694d062fe35e23b4e0066303e67b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a802ebf379af3fc6d0a7a0546550717ee"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a802ebf379af3fc6d0a7a0546550717ee"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (<a class="el" href="struct_m.html">M</a>)</td></tr>
<tr class="separator:a802ebf379af3fc6d0a7a0546550717ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2021ee2afe42aa981c2e83b89b685d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2021ee2afe42aa981c2e83b89b685d4"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (N)</td></tr>
<tr class="separator:ac2021ee2afe42aa981c2e83b89b685d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79f50282f1219161fbc74a606d08c549"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79f50282f1219161fbc74a606d08c549"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Matrix multiplication $Y = <a class="el" href="struct_a.html">A</a> * B$, where `<a class="el" href="struct_a.html">A</a>` has size (<a class="el" href="struct_m.html">M</a> x K), `<a class="el" href="struct_b.html">B</a>` has size
(K x N), and `Y` will have a size (<a class="el" href="struct_m.html">M</a> x N). To transpose `<a class="el" href="struct_a.html">A</a>` or `<a class="el" href="struct_b.html">B</a>` before
multiplication, pass 1 to the `trans_a` and/or `trans_b` arguments, which
separate the first and second dimensions of the respective matrices using
`axis_a` and `axis_b`.

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/matmul_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;MatMul&quot;,
    [&quot;<a class="el" href="struct_a.html">A</a>&quot;, &quot;<a class="el" href="struct_b.html">B</a>&quot;],
    [&quot;Y&quot;],
)

workspace.FeedBlob(&quot;A&quot;, np.random.randint(10, size=(3,3)).astype(np.float32))
workspace.FeedBlob(&quot;B&quot;, np.random.randint(10, size=(3,3)).astype(np.float32))
print(&quot;A:&quot;, workspace.FetchBlob(&quot;A&quot;))
print(&quot;B:&quot;, workspace.FetchBlob(&quot;B&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
```

**Result**

```
A: [[1. 8. 3.]
 [6. 4. 4.]
 [5. 4. 7.]]
B: [[4. 0. 3.]
 [3. 1. 1.]
 [8. 5. 8.]]
Y: [[52. 23. 35.]
 [68. 24. 54.]
 [88. 39. 75.]]
```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a79f50282f1219161fbc74a606d08c549"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a452acecd416b0c04009c4590da881cd1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a452acecd416b0c04009c4590da881cd1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (MatMul, <a class="el" href="classcaffe2_1_1_get_mat_mul_gradient.html">GetMatMulGradient</a>)</td></tr>
<tr class="separator:a452acecd416b0c04009c4590da881cd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3ab02d720682a23fd6585d9b0ac6194"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3ab02d720682a23fd6585d9b0ac6194"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (MatMul, <a class="el" href="classcaffe2_1_1_mat_mul_op.html">MatMulOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ad3ab02d720682a23fd6585d9b0ac6194"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f39d90a6f6e5308b985741ecff82c7b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f39d90a6f6e5308b985741ecff82c7b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Mean, <a class="el" href="classcaffe2_1_1_mean_op.html">MeanOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7f39d90a6f6e5308b985741ecff82c7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8de6e3acf48f74383904f288fbd5fe16"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8de6e3acf48f74383904f288fbd5fe16"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MeanGradient, <a class="el" href="classcaffe2_1_1_mean_gradient_op.html">MeanGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8de6e3acf48f74383904f288fbd5fe16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e42e95caafd0f2608973a69412901e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2e42e95caafd0f2608973a69412901e1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Element-wise mean of an arbitrary number of input tensors. This operation can be
performed in-place, by using the first input blob as the output blob. All inputs
must have the same shape and data type, and the output will have the same shape
as the inputs.

Github Link:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/mean_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Mean&quot;,
    [&quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;],
    [&quot;X&quot;],
)

workspace.FeedBlob(&quot;X&quot;, (np.random.rand(3,3)).astype(np.float32))
workspace.FeedBlob(&quot;Y&quot;, (np.random.rand(3,3)).astype(np.float32))
workspace.FeedBlob(&quot;Z&quot;, (np.random.rand(3,3)).astype(np.float32))
print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
print(&quot;Z:&quot;, workspace.FetchBlob(&quot;Z&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Mean:&quot;, workspace.FetchBlob(&quot;X&quot;))

```

**Result**

```

X:
[[0.6035237  0.5305746  0.6298913 ]
 [0.9169737  0.01280353 0.16286302]
 [0.6017664  0.9946255  0.05128575]]
Y:
[[0.07544111 0.45371833 0.08460239]
 [0.9708728  0.7422064  0.7933344 ]
 [0.97671497 0.3411384  0.73818344]]
Z:
[[0.08837954 0.90187573 0.46734726]
 [0.6308827  0.8719029  0.39888734]
 [0.90059936 0.92883426 0.5695987 ]]
Mean:
[[0.25578147 0.6287229  0.39394698]
 [0.8395764  0.5423043  0.45169494]
 [0.8263602  0.75486606 0.45302266]]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a2e42e95caafd0f2608973a69412901e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e0745ab798aa53d54518fe141dcc313"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3e0745ab798aa53d54518fe141dcc313"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Mean, <a class="el" href="classcaffe2_1_1_get_mean_gradient.html">GetMeanGradient</a>)</td></tr>
<tr class="separator:a3e0745ab798aa53d54518fe141dcc313"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42b700ff5275b79e6ee47b1c9d533e1b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42b700ff5275b79e6ee47b1c9d533e1b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxGradient, <a class="el" href="classcaffe2_1_1_max_gradient_op.html">MaxGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a42b700ff5275b79e6ee47b1c9d533e1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55a3d39eed02e48d9f7f4be7f6b0771e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55a3d39eed02e48d9f7f4be7f6b0771e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MinGradient, <a class="el" href="classcaffe2_1_1_min_gradient_op.html">MinGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a55a3d39eed02e48d9f7f4be7f6b0771e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c1f67d0b6b7956e78665e29187905aa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0c1f67d0b6b7956e78665e29187905aa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (MaxGradient).NumInputs(3</td></tr>
<tr class="separator:a0c1f67d0b6b7956e78665e29187905aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15a43f44a3cd087418865a013a312ee7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a15a43f44a3cd087418865a013a312ee7"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>NumOutputs</b> (1, INT_MAX)</td></tr>
<tr class="separator:a15a43f44a3cd087418865a013a312ee7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74f31a858fc0d60a2b0d78c52d121ff5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a74f31a858fc0d60a2b0d78c52d121ff5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (MinGradient).NumInputs(3</td></tr>
<tr class="separator:a74f31a858fc0d60a2b0d78c52d121ff5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c226db9d74ed03cb6b85db10f4519c4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c226db9d74ed03cb6b85db10f4519c4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Max, GetMaxGradient)</td></tr>
<tr class="separator:a9c226db9d74ed03cb6b85db10f4519c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d532ada2a3b864a2b6183c87f507861"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d532ada2a3b864a2b6183c87f507861"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Min, GetMinGradient)</td></tr>
<tr class="separator:a7d532ada2a3b864a2b6183c87f507861"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc565a8b3aff1ff2ea7e134c2a744f8a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acc565a8b3aff1ff2ea7e134c2a744f8a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Min, <a class="el" href="classcaffe2_1_1_min_op.html">MinOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:acc565a8b3aff1ff2ea7e134c2a744f8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebc233420d643a3a47c38bea14d6f90a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aebc233420d643a3a47c38bea14d6f90a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Max, <a class="el" href="classcaffe2_1_1_max_op.html">MaxOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aebc233420d643a3a47c38bea14d6f90a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87cd32a345ac0ee02cb0b65e8e121671"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87cd32a345ac0ee02cb0b65e8e121671"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Element-wise max of an arbitrary number of input tensors. This operation can be
performed in-place, by using the first input blob as the output blob. All inputs
must have the same shape and data type, and the output will have the same shape
as the inputs.

Github Link:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/minmax_ops.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Max&quot;,
    [&quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;],
    [&quot;X&quot;],
)

workspace.FeedBlob(&quot;X&quot;, (np.random.rand(3,3)).astype(np.float32))
workspace.FeedBlob(&quot;Y&quot;, (np.random.rand(3,3)).astype(np.float32))
workspace.FeedBlob(&quot;Z&quot;, (np.random.rand(3,3)).astype(np.float32))
print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
print(&quot;Z:&quot;, workspace.FetchBlob(&quot;Z&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Max:&quot;, workspace.FetchBlob(&quot;X&quot;))

```

**Result**

```

X:
[[0.4496477  0.07061381 0.7139333 ]
 [0.83203    0.05970785 0.72786295]
 [0.75988126 0.04601283 0.32820013]]
Y:
[[0.05683139 0.16872478 0.671098  ]
 [0.70739156 0.09878621 0.03416285]
 [0.34087983 0.94986707 0.67263436]]
Z:
[[0.48051122 0.07141234 0.85264146]
 [0.77086854 0.22082241 0.13154659]
 [0.42401117 0.995431   0.4263775 ]]
Max:
[[0.48051122 0.16872478 0.85264146]
 [0.83203    0.22082241 0.72786295]
 [0.75988126 0.995431   0.67263436]]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a87cd32a345ac0ee02cb0b65e8e121671"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a335cf7e61e69a1004a8a56c89f7a3438"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a335cf7e61e69a1004a8a56c89f7a3438"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Element-wise min of an arbitrary number of input tensors. This operation can be performed in-place, by using the first input blob as the output blob. All inputs must have the same shape and data type, and the output will have the same shape as the inputs.

Github Link:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/minmax_ops.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Min&quot;,
    [&quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;],
    [&quot;X&quot;],
)

workspace.FeedBlob(&quot;X&quot;, (np.random.rand(2,2)).astype(np.float32))
workspace.FeedBlob(&quot;Y&quot;, (np.random.rand(2,2)).astype(np.float32))
workspace.FeedBlob(&quot;Z&quot;, (np.random.rand(2,2)).astype(np.float32))
print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
print(&quot;Z:&quot;, workspace.FetchBlob(&quot;Z&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Min:&quot;, workspace.FetchBlob(&quot;X&quot;))

```

**Result**

```

X:
[[0.32731926 0.4939747 ]
 [0.29242373 0.43460014]]
Y:
[[0.40928316 0.916115  ]
 [0.77526504 0.29339448]]
Z:
[[0.7899794  0.90335774]
 [0.82599413 0.2843068 ]]
Min:
[[0.32731926 0.4939747 ]
 [0.29242373 0.2843068 ]]

```

&lt;/details&gt;

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a335cf7e61e69a1004a8a56c89f7a3438"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62c8f22ebacceb915a50a98d8e3e12aa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62c8f22ebacceb915a50a98d8e3e12aa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Moments, <a class="el" href="classcaffe2_1_1_moments_op.html">MomentsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a62c8f22ebacceb915a50a98d8e3e12aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae016fdeebb11f304254e3b9c9e1d559d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae016fdeebb11f304254e3b9c9e1d559d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MomentsGradient, <a class="el" href="classcaffe2_1_1_moments_gradient_op.html">MomentsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae016fdeebb11f304254e3b9c9e1d559d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1c2ac4d0222e70dc7b1d8c483b61312"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1c2ac4d0222e70dc7b1d8c483b61312"></a>
then the resulted tensor have the reduced dimension pruned DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;axes&quot;,&quot;<a class="el" href="struct_a.html">A</a> list of integers, along which to reduce. If axes is not provided, &quot;&quot;the op computes the element-wise mean and variance.&quot;).Arg(&quot;keepdims&quot;</td></tr>
<tr class="separator:ab1c2ac4d0222e70dc7b1d8c483b61312"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02df73a82b0964121f23fb3edcbbefa2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02df73a82b0964121f23fb3edcbbefa2"></a>
then the resulted tensor have the reduced dimension pruned DOC Keep the reduced&#160;</td><td class="memItemRight" valign="bottom"><b>dimension</b> (s) or not</td></tr>
<tr class="separator:a02df73a82b0964121f23fb3edcbbefa2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa601bf2c793498c05ed78d0ebf329fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa601bf2c793498c05ed78d0ebf329fe"></a>
then the resulted tensor have the reduced dimension pruned DOC Keep the reduced default True keeps the reduced An input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;mean&quot;,&quot;Reduced mean tensor.&quot;).Output(1</td></tr>
<tr class="separator:afa601bf2c793498c05ed78d0ebf329fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38c4453ef7ea85de966963d268e709d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38c4453ef7ea85de966963d268e709d1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (MomentsGradient).NumInputs(4).NumOutputs(1)</td></tr>
<tr class="separator:a38c4453ef7ea85de966963d268e709d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84fa6b7ba4b3a6e2d3ba2c86f9d0a95a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a84fa6b7ba4b3a6e2d3ba2c86f9d0a95a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Moments, GetMomentsGradient)</td></tr>
<tr class="separator:a84fa6b7ba4b3a6e2d3ba2c86f9d0a95a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae73741e5100acaea710d5a2f66a282df"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae73741e5100acaea710d5a2f66a282df"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MultiClassAccuracy, <a class="el" href="classcaffe2_1_1_multi_class_accuracy_op.html">MultiClassAccuracyOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae73741e5100acaea710d5a2f66a282df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6dbc859825b4614b5341b5846a4e8890"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6dbc859825b4614b5341b5846a4e8890"></a>
<a class="el" href="struct_d.html">D</a> float&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (N, <a class="el" href="struct_d.html">D</a>,) of predicted scores of each class for&quot; &quot;each data.N is the number of instances</td></tr>
<tr class="separator:a6dbc859825b4614b5341b5846a4e8890"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03fcbc04ff2ed71d5734afe16528b213"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a03fcbc04ff2ed71d5734afe16528b213"></a>
<a class="el" href="struct_d.html">D</a> float i batch size <a class="el" href="struct_d.html">D</a> is number of possible classes labels&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;labels&quot;,&quot;1-<a class="el" href="struct_d.html">D</a> int tensor (N,) of labels for each instance.&quot;).Output(0</td></tr>
<tr class="separator:a03fcbc04ff2ed71d5734afe16528b213"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98cc69aebdb2b17b6c067c22978a4f43"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a98cc69aebdb2b17b6c067c22978a4f43"></a>
<a class="el" href="struct_d.html">D</a> float i batch size <a class="el" href="struct_d.html">D</a> is number of possible classes labels <a class="el" href="struct_d.html">D</a> float&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (<a class="el" href="struct_d.html">D</a>,) of accuracy for each class.If a class has no&quot; &quot;instance in the batch</td></tr>
<tr class="separator:a98cc69aebdb2b17b6c067c22978a4f43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07bebaeff9482820483a8f59d2ce20a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a07bebaeff9482820483a8f59d2ce20a4"></a>
<a class="el" href="struct_d.html">D</a> float i batch size <a class="el" href="struct_d.html">D</a> is number of possible classes labels <a class="el" href="struct_d.html">D</a> float its accuracy score is set to zero&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;amounts&quot;,&quot;1-<a class="el" href="struct_d.html">D</a> int tensor (<a class="el" href="struct_d.html">D</a>,) of number of instances for each class in the batch.&quot;)</td></tr>
<tr class="separator:a07bebaeff9482820483a8f59d2ce20a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9fc2bd7525f78337eed917c64c744995"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9fc2bd7525f78337eed917c64c744995"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (MultiClassAccuracy)</td></tr>
<tr class="separator:a9fc2bd7525f78337eed917c64c744995"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a74d9ce08d54b01200e60d08738f416"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a74d9ce08d54b01200e60d08738f416"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (NegateGradient, <a class="el" href="classcaffe2_1_1_negate_gradient_op.html">NegateGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7a74d9ce08d54b01200e60d08738f416"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca61e8187d209a1b44b9b69bb0f92b73"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca61e8187d209a1b44b9b69bb0f92b73"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
NegagteGradient operator in forward pass simply copies input to the
output, and in backward pass, flips the sign of the output gradient
)DOC&quot;)</td></tr>
<tr class="separator:aca61e8187d209a1b44b9b69bb0f92b73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a308242536221240cfb3c23408915176e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a308242536221240cfb3c23408915176e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (NegateGradient, <a class="el" href="structcaffe2_1_1_get_negate_gradient_gradient.html">GetNegateGradientGradient</a>)</td></tr>
<tr class="separator:a308242536221240cfb3c23408915176e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6aad1a27593e957cf4a6c36f712cf15c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6aad1a27593e957cf4a6c36f712cf15c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Negative, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_negative_functor.html">NegativeFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a6aad1a27593e957cf4a6c36f712cf15c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5c62b18b09ec13278186947e4b4679b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae5c62b18b09ec13278186947e4b4679b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Negative, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">NumericTypes</a>, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_negative_functor.html">NegativeFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ae5c62b18b09ec13278186947e4b4679b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57bf32e1267f4b6f436f3c01f51b1752"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a57bf32e1267f4b6f436f3c01f51b1752"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (NGramFromCategorical, <a class="el" href="classcaffe2_1_1_n_gram_from_categorical_op.html">NGramFromCategoricalOp</a>&lt; float, int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a57bf32e1267f4b6f436f3c01f51b1752"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72c58fd6a8fa1ebee21fca0a8ebe3c8d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a72c58fd6a8fa1ebee21fca0a8ebe3c8d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (NGramFromCategorical)</td></tr>
<tr class="separator:a72c58fd6a8fa1ebee21fca0a8ebe3c8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac714bb28e95b298bd3f501a148bd6896"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac714bb28e95b298bd3f501a148bd6896"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (NGramFromCategorical).NumInputs(1).NumOutputs(1)</td></tr>
<tr class="separator:ac714bb28e95b298bd3f501a148bd6896"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7bda0e37849040ded81e611019e5b21"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7bda0e37849040ded81e611019e5b21"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (NormalizeL1, <a class="el" href="classcaffe2_1_1_normalize_l1_op.html">NormalizeL1Op</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac7bda0e37849040ded81e611019e5b21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a996da1960a88803183debe3c722f25dd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a996da1960a88803183debe3c722f25dd"></a>
axis to normalize&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given a matrix, apply L1-normalization along the specified axis.
)DOC&quot;)</td></tr>
<tr class="separator:a996da1960a88803183debe3c722f25dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bd9d79e49c3a5064c3ee6f99033f3cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7bd9d79e49c3a5064c3ee6f99033f3cf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Normalize, <a class="el" href="classcaffe2_1_1_normalize_op.html">NormalizeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7bd9d79e49c3a5064c3ee6f99033f3cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15e55345465d459ec697cbaff5bd0110"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a15e55345465d459ec697cbaff5bd0110"></a>
axis to normalize&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given a matrix, apply L2-normalization along the specified dimension.
)DOC&quot;).IdenticalTypeAndShape()</td></tr>
<tr class="separator:a15e55345465d459ec697cbaff5bd0110"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf52dbf4a63403e9b0b1564d78de3940"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acf52dbf4a63403e9b0b1564d78de3940"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (NormalizeGradient, <a class="el" href="classcaffe2_1_1_normalize_gradient_op.html">NormalizeGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:acf52dbf4a63403e9b0b1564d78de3940"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeadc0f1046ef0f5ef46728f3fe5d5621"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeadc0f1046ef0f5ef46728f3fe5d5621"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Normalize, <a class="el" href="classcaffe2_1_1_get_normalize_gradient.html">GetNormalizeGradient</a>)</td></tr>
<tr class="separator:aeadc0f1046ef0f5ef46728f3fe5d5621"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cee9c1564a19e2a443abf434f52d6b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8cee9c1564a19e2a443abf434f52d6b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (NumpyTile, <a class="el" href="classcaffe2_1_1_numpy_tile_op.html">NumpyTileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8cee9c1564a19e2a443abf434f52d6b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e334709f27d0d4e7b6181f060ea910e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e334709f27d0d4e7b6181f060ea910e"></a>
The input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;repeats&quot;,&quot;1-<a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> specifying how many times to repeat&quot;&quot; each axis.&quot;).Output(0</td></tr>
<tr class="separator:a1e334709f27d0d4e7b6181f060ea910e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c241c83af379b9aa104d970b26a91c8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c241c83af379b9aa104d970b26a91c8"></a>
The input tensor <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> that will contain input replicated along the given axis&#160;</td><td class="memItemRight" valign="bottom"><b>InheritOnnxSchema</b> (&quot;Tile&quot;)</td></tr>
<tr class="separator:a1c241c83af379b9aa104d970b26a91c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab42c103d7d2b2996c3d2b2c3e21bcb00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab42c103d7d2b2996c3d2b2c3e21bcb00"></a>
vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceForBatchOneHot</b> (const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:ab42c103d7d2b2996c3d2b2c3e21bcb00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a182d6c2820918ce5b245571e01bb70d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a182d6c2820918ce5b245571e01bb70d6"></a>
vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceForBucketBatchOneHot</b> (const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a182d6c2820918ce5b245571e01bb70d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f7a75d2551b6a7dcf5f9a4321b9546b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6f7a75d2551b6a7dcf5f9a4321b9546b"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForBatchOneHot</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a6f7a75d2551b6a7dcf5f9a4321b9546b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6e0c977e2e446394bd48ca32da569f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6e0c977e2e446394bd48ca32da569f8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchBucketOneHot, <a class="el" href="classcaffe2_1_1_batch_bucket_one_hot_op.html">BatchBucketOneHotOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa6e0c977e2e446394bd48ca32da569f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5581ceb6d55bc4b925d4a76f6abed791"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5581ceb6d55bc4b925d4a76f6abed791"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchOneHot, <a class="el" href="classcaffe2_1_1_batch_one_hot_op.html">BatchOneHotOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a5581ceb6d55bc4b925d4a76f6abed791"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2b518ed406ae2a637c91866b35b949a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af2b518ed406ae2a637c91866b35b949a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (OneHot, <a class="el" href="classcaffe2_1_1_one_hot_op.html">OneHotOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af2b518ed406ae2a637c91866b35b949a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87576f4d67a3c7ce8a0c13a06a869231"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87576f4d67a3c7ce8a0c13a06a869231"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SegmentOneHot, <a class="el" href="classcaffe2_1_1_segment_one_hot_op.html">SegmentOneHotOp</a>)</td></tr>
<tr class="separator:a87576f4d67a3c7ce8a0c13a06a869231"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0966ddf36b0cdaaec4a3f9fb19f01baf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0966ddf36b0cdaaec4a3f9fb19f01baf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ONNXWhile, <a class="el" href="classcaffe2_1_1_o_n_n_x_while_op.html">ONNXWhileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0966ddf36b0cdaaec4a3f9fb19f01baf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a4371161736adb351153809453016ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a4371161736adb351153809453016ff"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
*** EXPERIMENTAL. This operator is a work-in-progress. No assumption should be
made about the stability or correctness of this op. ***

Generic Looping construct confirming to the ONNX Loop operator spec. This loop
has multiple termination conditions:

1. Trip count. Iteration count specified at runtime. Set by specifying the
    input M. Optional. Set to empty string to omit. Note that a static trip
    count (specified at graph construction time) can be specified by passing
    in a constant node for input M.
2. Loop termination condition. This is an input to the op that determines
    whether to run the first interation and also a loop-carried dependency for
    the body graph. The body graph must yield a value for the condition
    variable, whether this input is provided or not.

This table summarizes the operating modes of this operator with equivalent
<a class="el" href="struct_c.html">C</a>-style code:

<a class="el" href="classcaffe2_1_1_operator.html">Operator</a> inputs defined as (max_trip_count, condition_var). Omitted <a class="el" href="classc10_1_1optional.html">optional</a>
inputs are represented as empty string. Concretely, in this caffe2 op an input
is marked as omitted by setting its 'has_{name}' argument to False.

    input (&quot;&quot;, &quot;&quot;):
        for (int i=0; ; ++i) {
          cond = ... // Note this value is ignored, but is required in the body
        }

    input (&quot;&quot;, cond) // Note this is analogous to a while loop
        bool cond = ...;
        for (int i=0; cond; ++i) {
          cond = ...;
        }

    input (&quot;&quot;, 1) // Note this is analogous to a do-while loop
        bool cond = true
        for (int i=0; cond; ++i) {
          cond = ...;
        }

    input (trip_count, &quot;&quot;) // Note this is analogous to a for loop
        int trip_count = ...
        for (int i=0; i &lt; trip_count; ++i) {
          cond = ...; // ignored
        }

    input (trip_count, cond)
        int trip_count = ...;
        bool cond = ...;
        for (int i=0; i &lt; trip_count &amp;&amp; cond; ++i) {
          cond = ...;
        }
    )DOC&quot;).Arg(&quot;body&quot;</td></tr>
<tr class="separator:a9a4371161736adb351153809453016ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a064ae0e7277188eda50ad11a97a3f9f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a064ae0e7277188eda50ad11a97a3f9f4"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed on each iteration&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;has_trip_count&quot;,&quot;Whether to use the trip count input&quot;).Arg(&quot;has_cond&quot;</td></tr>
<tr class="separator:a064ae0e7277188eda50ad11a97a3f9f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9daf47c7a130aca486c4b57ddbd003a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af9daf47c7a130aca486c4b57ddbd003a"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed on each iteration Whether to use the condition input&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;save_scopes&quot;,&quot;Whether to save the scopes across iterations, as in &quot;&quot;for backprop&quot;).Arg(&quot;disable_scopes&quot;</td></tr>
<tr class="separator:af9daf47c7a130aca486c4b57ddbd003a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a4bb6e81c2d3e0d779a3645d7459dde"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2a4bb6e81c2d3e0d779a3645d7459dde"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed on each iteration Whether to use the condition input Do not create new scopes Use this only if you re certain there will be no name for example if you re converting from a fully SSA IR Number of iterations to go out to Used if the flag has_trip_count is True&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;first_iter_condition&quot;,&quot;Dynamic condition value for the first &quot;&quot;iteration. For all subsequent iterations,&quot;&quot; the condition from the body graph is &quot;&quot;used. This input is used if the flag &quot;&quot;has_cond is true.&quot;).NumOutputs(0</td></tr>
<tr class="separator:a2a4bb6e81c2d3e0d779a3645d7459dde"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5b9047f94b208091f1d3614a83fc99c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5b9047f94b208091f1d3614a83fc99c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Onnxifi, <a class="el" href="classcaffe2_1_1_onnxifi_op.html">OnnxifiOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa5b9047f94b208091f1d3614a83fc99c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8d53fc5ee992bb12af1a1f550834d81"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad8d53fc5ee992bb12af1a1f550834d81"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
    The Onnxifi operator is a black-box operator to lower the computation to Onnxifi backend
    )DOC&quot;).Arg(&quot;onnx_model&quot;</td></tr>
<tr class="separator:ad8d53fc5ee992bb12af1a1f550834d81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92947fc7103428f88eb5f1462c6c1c88"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92947fc7103428f88eb5f1462c6c1c88"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_n_h_w_c2_n_c_h_w.html">NHWC2NCHW</a>, <a class="el" href="classcaffe2_1_1_n_h_w_c2_n_c_h_w_op.html">NHWC2NCHWOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a92947fc7103428f88eb5f1462c6c1c88"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08b43075b2d68e8b1b43712e35b9e6ac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08b43075b2d68e8b1b43712e35b9e6ac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_n_c_h_w2_n_h_w_c.html">NCHW2NHWC</a>, <a class="el" href="classcaffe2_1_1_n_c_h_w2_n_h_w_c_op.html">NCHW2NHWCOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a08b43075b2d68e8b1b43712e35b9e6ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9b1b46024b7c5a4ea46461a42d91f09"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9b1b46024b7c5a4ea46461a42d91f09"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (in[0].dims(in[0].dims_size()-1))</td></tr>
<tr class="separator:aa9b1b46024b7c5a4ea46461a42d91f09"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7d52a7e136514ed2bee8380bf18c85b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab7d52a7e136514ed2bee8380bf18c85b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
The operator switches the order of data in a tensor from NHWC- sample index N,
height H, width H and channels <a class="el" href="struct_c.html">C</a>, to the NCHW order (this is for 2D images).
In general, this operator switches the order of data in a tensor from N H_1 ...
H_k C to N C H_1 ... H_k for k-dimensional features, and currently supports
k=1, 2, and 3.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:ab7d52a7e136514ed2bee8380bf18c85b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af44fc1e4c297c6bd4e4d4bffe37cfafe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af44fc1e4c297c6bd4e4d4bffe37cfafe"></a>
The input&#160;</td><td class="memItemRight" valign="bottom"><b>data</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>) in the NHWC order.&quot;) .Output(0</td></tr>
<tr class="separator:af44fc1e4c297c6bd4e4d4bffe37cfafe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c2a191aa433753e04db8d73d10852bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c2a191aa433753e04db8d73d10852bd"></a>
The input The output&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>) in the NCHW order.&quot;)</td></tr>
<tr class="separator:a6c2a191aa433753e04db8d73d10852bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3906a56bf1823905ea60c8a63bda92ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3906a56bf1823905ea60c8a63bda92ca"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (in[0].dims(1))</td></tr>
<tr class="separator:a3906a56bf1823905ea60c8a63bda92ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af36a92d66e2ad916b0f8c1101ffb6bee"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af36a92d66e2ad916b0f8c1101ffb6bee"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
The operator switches the order of data in a tensor from NCHW- sample index N,
channels <a class="el" href="struct_c.html">C</a>, height H and width W, to the NHWC order (this is for 2D images).
In general, this operator switches the order of data in a tensor from N C H_1
... H_k to N H_1 ... H_k C for k-dimensional features, and currently supports
k=1, 2, and 3.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:af36a92d66e2ad916b0f8c1101ffb6bee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa46ec495208cca7f46a3a7cf2fe65c74"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa46ec495208cca7f46a3a7cf2fe65c74"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_n_h_w_c2_n_c_h_w.html">NHWC2NCHW</a>, GetNHWC2NCHWGradient)</td></tr>
<tr class="separator:aa46ec495208cca7f46a3a7cf2fe65c74"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6473f8847c5a73688ae867f99668fb04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6473f8847c5a73688ae867f99668fb04"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_n_c_h_w2_n_h_w_c.html">NCHW2NHWC</a>, GetNCHW2NHWCGradient)</td></tr>
<tr class="separator:a6473f8847c5a73688ae867f99668fb04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0df89d706ae96615a75fde2b86bd93cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0df89d706ae96615a75fde2b86bd93cf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="class_n_h_w_c2_n_c_h_w.html">NHWC2NCHW</a>, CuDNNNHWC2NCHWOp)</td></tr>
<tr class="separator:a0df89d706ae96615a75fde2b86bd93cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac23495a0883b0a0942c6aab5647536a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac23495a0883b0a0942c6aab5647536a5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="class_n_c_h_w2_n_h_w_c.html">NCHW2NHWC</a>, CuDNNNCHW2NHWCOp)</td></tr>
<tr class="separator:ac23495a0883b0a0942c6aab5647536a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1efc2c5364d07a541c154f14dfd3765f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1efc2c5364d07a541c154f14dfd3765f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_n_h_w_c2_n_c_h_w.html">NHWC2NCHW</a>, <a class="el" href="classcaffe2_1_1_n_h_w_c2_n_c_h_w_op.html">NHWC2NCHWOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a1efc2c5364d07a541c154f14dfd3765f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1dfb839b4cda5802e93e7e0607dd9689"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1dfb839b4cda5802e93e7e0607dd9689"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_n_c_h_w2_n_h_w_c.html">NCHW2NHWC</a>, <a class="el" href="classcaffe2_1_1_n_c_h_w2_n_h_w_c_op.html">NCHW2NHWCOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a1dfb839b4cda5802e93e7e0607dd9689"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76f6874cc7bae3a02ea9fe8496b0d840"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a76f6874cc7bae3a02ea9fe8496b0d840"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PackSegments, <a class="el" href="classcaffe2_1_1_pack_segments_op.html">PackSegmentsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a76f6874cc7bae3a02ea9fe8496b0d840"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af875c2b05a6e7c2c3a5f81b8efe3178f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af875c2b05a6e7c2c3a5f81b8efe3178f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UnpackSegments, <a class="el" href="classcaffe2_1_1_unpack_segments_op.html">UnpackSegmentsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af875c2b05a6e7c2c3a5f81b8efe3178f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefcb07318d67d9a7270c277820cd9df1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aefcb07318d67d9a7270c277820cd9df1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (&quot;Map N dim tensor to N+1 dim based on length blob. Sequences that \
    are shorter than the longest sequence are padded with zeros.&quot;).Input(0</td></tr>
<tr class="separator:aefcb07318d67d9a7270c277820cd9df1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13ddbdf2041b52ac4fad644d8a84c142"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a13ddbdf2041b52ac4fad644d8a84c142"></a>
d int long tensor contains the length in each of the output&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;tensor&quot;,&quot;N dim Tensor.&quot;).Output(0</td></tr>
<tr class="separator:a13ddbdf2041b52ac4fad644d8a84c142"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bfc46a1c3f583346191918e4e2292a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9bfc46a1c3f583346191918e4e2292a1"></a>
d int long tensor contains the length in each of the output N dim <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> where&#160;</td><td class="memItemRight" valign="bottom"><b>dim</b> (1) is the max length&quot; &quot;</td></tr>
<tr class="separator:a9bfc46a1c3f583346191918e4e2292a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0090655e96781383f208c797375a048f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0090655e96781383f208c797375a048f"></a>
d int long tensor contains the length in each of the output N dim <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> where&#160;</td><td class="memItemRight" valign="bottom"><b>dim</b> (0) is the batch size.&quot;) .Output( 1</td></tr>
<tr class="separator:a0090655e96781383f208c797375a048f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04309588633353f61ae89cc11b8217f2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04309588633353f61ae89cc11b8217f2"></a>
d int long tensor contains the length in each of the output N dim <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> where dim boolean false where packed_tensor is true otherwise&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;max_length&quot;,&quot;The pre-defined max_length for the packed segments&quot;).Arg(&quot;pad_minf&quot;</td></tr>
<tr class="separator:a04309588633353f61ae89cc11b8217f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a797de50869417c41e385c5668a89c327"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a797de50869417c41e385c5668a89c327"></a>
d int long tensor contains the length in each of the output N dim <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> where dim boolean false where packed_tensor is true otherwise Padding number in the packed segments Use true to pad otherwise pad zeros&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;return_presence_mask&quot;,&quot;bool whether to return presence mask, false by default&quot;)</td></tr>
<tr class="separator:a797de50869417c41e385c5668a89c327"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c3ae04b0399d6d7e3386f3630724690"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c3ae04b0399d6d7e3386f3630724690"></a>
d int long tensor contains the length in each of the input&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;tensor&quot;,&quot;N+1 dim Tensor.&quot;).Output(0</td></tr>
<tr class="separator:a9c3ae04b0399d6d7e3386f3630724690"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9cdfabeddd0d829f0988af5af2da65c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9cdfabeddd0d829f0988af5af2da65c9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (PackSegments, <a class="el" href="classcaffe2_1_1_get_pack_segments_gradient.html">GetPackSegmentsGradient</a>)</td></tr>
<tr class="separator:a9cdfabeddd0d829f0988af5af2da65c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aceb4b8eaf7a8b51e5332b0dc8ceadaff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aceb4b8eaf7a8b51e5332b0dc8ceadaff"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (UnpackSegments, <a class="el" href="classcaffe2_1_1_get_unpack_segments_gradient.html">GetUnpackSegmentsGradient</a>)</td></tr>
<tr class="separator:aceb4b8eaf7a8b51e5332b0dc8ceadaff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac225ab26d9752cfb215cc4b2167851a3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac225ab26d9752cfb215cc4b2167851a3"></a>
PadMode&#160;</td><td class="memItemRight" valign="bottom"><b>StringToPadMode</b> (const string &amp;mode)</td></tr>
<tr class="separator:ac225ab26d9752cfb215cc4b2167851a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15517e7b5a1a5ebd97ed7196fb69f94f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a15517e7b5a1a5ebd97ed7196fb69f94f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PadImage, <a class="el" href="classcaffe2_1_1_pad_image_op.html">PadImageOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a15517e7b5a1a5ebd97ed7196fb69f94f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb953e35bd6500b4a823231a9162f7b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abb953e35bd6500b4a823231a9162f7b6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (PadImageGradient, <a class="el" href="classcaffe2_1_1_pad_image_gradient_op.html">PadImageGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:abb953e35bd6500b4a823231a9162f7b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a370b1ef2396b1ff2c5721ab0de1c48"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a370b1ef2396b1ff2c5721ab0de1c48"></a>
CPUContext::PadTensorInference&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
PadImage pads values around the boundary of an image according to the pad
values and stride sizes defined by the <a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a> operator.
  )DOC&quot;).Input(0</td></tr>
<tr class="separator:a3a370b1ef2396b1ff2c5721ab0de1c48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04f84b5447012247667b8f1414bee805"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04f84b5447012247667b8f1414bee805"></a>
dimensions depend on whether the NCHW or NHWC operators are being used For in the the input has&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (N x <a class="el" href="struct_c.html">C</a> x H x W)</td></tr>
<tr class="separator:a04f84b5447012247667b8f1414bee805"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58770cbe28c91a680894739ac8b1527f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a58770cbe28c91a680894739ac8b1527f"></a>
dimensions depend on whether the NCHW or NHWC operators are being used For in the the input has where N is the batch <a class="el" href="struct_c.html">C</a> is the number of and H and W are the height and the width of the data The corresponding permutation of dimensions is used in the latter case&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;Output data tensor from padding the H and W dimensions on &quot;&quot;the tensor. Dimensions will vary based on various pad and stride &quot;&quot;sizes.&quot;)</td></tr>
<tr class="separator:a58770cbe28c91a680894739ac8b1527f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5d6b28fd314b0b40cdee17adb6d2d09"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae5d6b28fd314b0b40cdee17adb6d2d09"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>GRADIENT_OPERATOR_SCHEMA</b> (PadImageGradient).NumInputs(1).NumOutputs(1)</td></tr>
<tr class="separator:ae5d6b28fd314b0b40cdee17adb6d2d09"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afabfd45bcf5afac18be7162dfa9d0ac3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afabfd45bcf5afac18be7162dfa9d0ac3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (PadImage, <a class="el" href="classcaffe2_1_1_get_pad_image_gradient.html">GetPadImageGradient</a>)</td></tr>
<tr class="separator:afabfd45bcf5afac18be7162dfa9d0ac3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b411f3767afb32fffa1080f9b38afa3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b411f3767afb32fffa1080f9b38afa3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Percentile, <a class="el" href="classcaffe2_1_1_percentile_op.html">PercentileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a0b411f3767afb32fffa1080f9b38afa3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12a3eef2f3efde81d2b994fb30ad93b7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a12a3eef2f3efde81d2b994fb30ad93b7"></a>
given a sample set of raw labeled with their corresponding percentiles from the same distribution In this&#160;</td><td class="memItemRight" valign="bottom"><b>operator takes as input a tensor of floats to find the percentile values for, a 2D tensor of floats, where the first column of the tensor represents sampled values, and the second column represents the percentile labels, and a tensor of integers lengths.This lengths tensor is used because the operator works on multiple sets of raw values at the same time.For example, for an input:original_values=[[3, 5, 3], [5, 1, 6]], lengths=[2, 1, 1], value_to_pct=[[3, 0.2],[5, 0.5],[1, 0.3],[3.0.6]] Our operator expects that each column i of the input tensor is sampled from distribution i.Lengths tells us that the first two elements in value_to_pct are sampled from distribution 1, the next is from distribution two, and the last is from distribution 3.We expect the output of our operator to give us[[0.2, 1.0, 0.6],[0.5, 0.3, 1.0]].To calculate the percentile of an element, we check to see if its value is already mapped to a percentile in value_to_pct.If so, we return that value.If not, we linearly interpolate between the two closest values in value_to_pct.If the value is larger than all values in value_to_pct, we return 1.If it's smaller than all the values, we return 0.) DOC&quot;) .Input</b> (0,&quot;original_values&quot;,&quot;Input 2D tensor of floats, representing the original, raw data to calculate percentiles for.&quot;).Input(1</td></tr>
<tr class="separator:a12a3eef2f3efde81d2b994fb30ad93b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b343b9a0305d399016cd967c1a92125"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b343b9a0305d399016cd967c1a92125"></a>
given a sample set of raw labeled with their corresponding percentiles from the same distribution In this Sorted with columns Each element in the first column is a float representing the raw value of a sample Its corresponding element in the next column represents the percentile it maps to&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;lengths&quot;,&quot;1D tensor, representing the length of each distribution. We expect that the sum of elements of this tensor&quot;&quot; is equal to the total length of value_to_pct.&quot;).Output(0</td></tr>
<tr class="separator:a2b343b9a0305d399016cd967c1a92125"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad42ee021aa8e4e81fb4f2289192b2754"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad42ee021aa8e4e81fb4f2289192b2754"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Percentile)</td></tr>
<tr class="separator:ad42ee021aa8e4e81fb4f2289192b2754"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b4cdcbfd982aeba7cdf0893b2f1f5a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b4cdcbfd982aeba7cdf0893b2f1f5a1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Perplexity, <a class="el" href="classcaffe2_1_1_perplexity_op.html">PerplexityOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3b4cdcbfd982aeba7cdf0893b2f1f5a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17b91551137ecac7ce6feb33a25fe23c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17b91551137ecac7ce6feb33a25fe23c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Perplexity).NumInputs(1).NumOutputs(1).SetDoc(R&quot;DOC( Perplexity calculates how well a probability distribution predicts a sample. Perplexity takes a 1-<a class="el" href="struct_d.html">D</a> tensor containing a batch of probabilities. Each value in the tensor belongs to a different sample and represents the probability of the model predicting the true label for that sample. The operator returns a single (float) perplexity value for the batch. )DOC&quot;).Input(0</td></tr>
<tr class="separator:a17b91551137ecac7ce6feb33a25fe23c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3959e5f76637c01917e37772b41bef30"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3959e5f76637c01917e37772b41bef30"></a>
The input data as <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> It contains a batch of true label or target probabilities&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;The output- a single (float) perplexity value for the &quot;&quot;batch&quot;)</td></tr>
<tr class="separator:a3959e5f76637c01917e37772b41bef30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63d654419d43877e9d2478f97c220819"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a63d654419d43877e9d2478f97c220819"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Perplexity)</td></tr>
<tr class="separator:a63d654419d43877e9d2478f97c220819"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc450c1226f6ce99e5e46134b2442379"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc450c1226f6ce99e5e46134b2442379"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PiecewiseLinearTransform, <a class="el" href="classcaffe2_1_1_piecewise_linear_transform_op.html">PiecewiseLinearTransformOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:adc450c1226f6ce99e5e46134b2442379"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a233a73e145bfe9731125ef6a3290b9c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a233a73e145bfe9731125ef6a3290b9c5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (1, 4).NumOutputs(1).SetDoc(R&quot;DOC( PiecewiseLinearTransform takes inputs -- predictions</td></tr>
<tr class="separator:a233a73e145bfe9731125ef6a3290b9c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a132380591116ed2ac218a3ad71a05f58"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a132380591116ed2ac218a3ad71a05f58"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each low bound is excluded while high bound is included Also the piecewise linear function must be continuous Notes If the input is binary&#160;</td><td class="memItemRight" valign="bottom"><b>predictions</b> (Nx2 or Nx1 tensor)</td></tr>
<tr class="separator:a132380591116ed2ac218a3ad71a05f58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae2ee1504b7b5da2d7275c3001ed0281"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aae2ee1504b7b5da2d7275c3001ed0281"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each low bound is excluded while high bound is included Also the piecewise linear function must be continuous Notes If the input is binary set the binary arg to true so that one group of piecewise linear functions is&#160;</td><td class="memItemRight" valign="bottom"><b>needed</b> (see details below).-The transform parameters(bounds</td></tr>
<tr class="separator:aae2ee1504b7b5da2d7275c3001ed0281"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa839f9409e00ca93677063adb8da95d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa839f9409e00ca93677063adb8da95d0"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each low bound is excluded while high bound is included Also the piecewise linear function must be continuous Notes If the input is binary set the binary arg to true so that one group of piecewise linear functions is intercepts can be passed either through args or through input blobs If we have multiple groups of piecewise linear each group has the same number of pieces If a prediction is out of the it is capped to the smallest or largest bound DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;bounds&quot;,&quot;1-<a class="el" href="struct_d.html">D</a> vector of size (prediction_dimensions x (pieces+1)) contain the &quot;&quot;upper bounds of each piece of linear function. One special case is &quot;&quot;the first bound is the lower bound of whole piecewise function and we &quot;&quot;treat it the same as the left most functions. (bounds, slopes, &quot;&quot;intercepts) can be passed through either arg or input blobs.&quot;).Arg(&quot;slopes&quot;</td></tr>
<tr class="separator:aa839f9409e00ca93677063adb8da95d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1e648ed7306bd3b0b9611bccbc63655"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1e648ed7306bd3b0b9611bccbc63655"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each low bound is excluded while high bound is included Also the piecewise linear function must be continuous Notes If the input is binary set the binary arg to true so that one group of piecewise linear functions is intercepts can be passed either through args or through input blobs If we have multiple groups of piecewise linear each group has the same number of pieces If a prediction is out of the it is capped to the smallest or largest bound DOC <a class="el" href="struct_d.html">D</a> vector of&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (prediction_dimensions x pieces) containing the&quot; &quot;slopes of linear function&quot;) .Arg( &quot;intercepts&quot;</td></tr>
<tr class="separator:ab1e648ed7306bd3b0b9611bccbc63655"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7731669ae130b2ddb91293c8d103abab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7731669ae130b2ddb91293c8d103abab"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AveragePoolGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a7731669ae130b2ddb91293c8d103abab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a588e2194022fa086582f7482cf90be08"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a588e2194022fa086582f7482cf90be08"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (AveragePoolGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a588e2194022fa086582f7482cf90be08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedcc0cf561ec94f73500fad875f4bc1d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aedcc0cf561ec94f73500fad875f4bc1d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AveragePool1DGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aedcc0cf561ec94f73500fad875f4bc1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7f77a2198a9ab1eb4502ef3d16c2f40"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae7f77a2198a9ab1eb4502ef3d16c2f40"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (AveragePool1DGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:ae7f77a2198a9ab1eb4502ef3d16c2f40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56e0e37fb57a221958004459845a864d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a56e0e37fb57a221958004459845a864d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AveragePool2DGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a56e0e37fb57a221958004459845a864d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2168d639116e0d1649c1ef157cb2418f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2168d639116e0d1649c1ef157cb2418f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (AveragePool2DGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a2168d639116e0d1649c1ef157cb2418f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29f77538b42e5a5c84fc180aed329552"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29f77538b42e5a5c84fc180aed329552"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AveragePool3DGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a29f77538b42e5a5c84fc180aed329552"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0ea9ef7f8abe4a1e39be24269257ccb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0ea9ef7f8abe4a1e39be24269257ccb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (AveragePool3DGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:ab0ea9ef7f8abe4a1e39be24269257ccb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf282826aa25c6e2efe6b0976c559cfe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abf282826aa25c6e2efe6b0976c559cfe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxPoolGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:abf282826aa25c6e2efe6b0976c559cfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af51c26b383feb3ebd03cf5e4e8ab379d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af51c26b383feb3ebd03cf5e4e8ab379d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (MaxPoolGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:af51c26b383feb3ebd03cf5e4e8ab379d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0dc6f318adf4ae2a2461844a4252cdae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0dc6f318adf4ae2a2461844a4252cdae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxPool1DGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0dc6f318adf4ae2a2461844a4252cdae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67bf8ecae4818d45fc794429c8e34b93"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67bf8ecae4818d45fc794429c8e34b93"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (MaxPool1DGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a67bf8ecae4818d45fc794429c8e34b93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7f0067669ddeecda335e374e6243d75"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad7f0067669ddeecda335e374e6243d75"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxPool2DGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ad7f0067669ddeecda335e374e6243d75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bdef69d939d16f9337ca4cf1f106bbb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1bdef69d939d16f9337ca4cf1f106bbb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (MaxPool2DGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a1bdef69d939d16f9337ca4cf1f106bbb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d379dfc9890cc71e3b06f29e6047fac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0d379dfc9890cc71e3b06f29e6047fac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxPool3DGradient, <a class="el" href="classcaffe2_1_1_pool_gradient_op.html">PoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0d379dfc9890cc71e3b06f29e6047fac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae93ac8a4382768cc2511c81344854d02"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae93ac8a4382768cc2511c81344854d02"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (MaxPool3DGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:ae93ac8a4382768cc2511c81344854d02"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc4226d56a6213572c7988e55cd1f6de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc4226d56a6213572c7988e55cd1f6de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_average_pool.html">AveragePool</a>, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:adc4226d56a6213572c7988e55cd1f6de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97aae647d6c84627cc840be61fdf823b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a97aae647d6c84627cc840be61fdf823b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (AveragePool1D, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:a97aae647d6c84627cc840be61fdf823b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1a554f3ca4d4714256f3c373af1e11f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af1a554f3ca4d4714256f3c373af1e11f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (AveragePool2D, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:af1a554f3ca4d4714256f3c373af1e11f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5bb76fffa78fd438c0fe1af0e0176d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab5bb76fffa78fd438c0fe1af0e0176d6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (AveragePool3D, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:ab5bb76fffa78fd438c0fe1af0e0176d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e163b376d2fb7de32f7da191e3ab229"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7e163b376d2fb7de32f7da191e3ab229"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_max_pool.html">MaxPool</a>, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:a7e163b376d2fb7de32f7da191e3ab229"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17fc4a60c9bf1d52880be12e2ecc2509"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17fc4a60c9bf1d52880be12e2ecc2509"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (MaxPool1D, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:a17fc4a60c9bf1d52880be12e2ecc2509"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0a1aaa9d4ff6886c2071b36f7b73841"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0a1aaa9d4ff6886c2071b36f7b73841"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (MaxPool2D, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:ac0a1aaa9d4ff6886c2071b36f7b73841"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af10c955e7d5d7c2869698bdcc7e0a141"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af10c955e7d5d7c2869698bdcc7e0a141"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (MaxPool3D, <a class="el" href="classcaffe2_1_1_get_pool_gradient.html">GetPoolGradient</a>)</td></tr>
<tr class="separator:af10c955e7d5d7c2869698bdcc7e0a141"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c465b386eeb12caabd612a2f3da9b81"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c465b386eeb12caabd612a2f3da9b81"></a>
std::function&lt; void(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>AveragePoolDocGenerator</b> (const char *dim)</td></tr>
<tr class="separator:a1c465b386eeb12caabd612a2f3da9b81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5813eb9fe43aa4c9ba4d319da95805ef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5813eb9fe43aa4c9ba4d319da95805ef"></a>
std::function&lt; void(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>MaxPoolDocGenerator</b> (const char *dim)</td></tr>
<tr class="separator:a5813eb9fe43aa4c9ba4d319da95805ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75223bcc3bb738afea24c09557e5b1d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75223bcc3bb738afea24c09557e5b1d9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_average_pool.html">AveragePool</a>, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a75223bcc3bb738afea24c09557e5b1d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1312bb34fae53af57f210084d789db2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1312bb34fae53af57f210084d789db2f"></a>
NumInputs(1).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AveragePool1D, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a1312bb34fae53af57f210084d789db2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2f55614cedb0253cb7d4f4345db6002"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2f55614cedb0253cb7d4f4345db6002"></a>
NumInputs(1).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AveragePool2D, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ab2f55614cedb0253cb7d4f4345db6002"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0885b0822450898f718e2ea9e738a7dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0885b0822450898f718e2ea9e738a7dc"></a>
NumInputs(1).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AveragePool3D, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_average_pool_functor.html">AveragePoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0885b0822450898f718e2ea9e738a7dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01a013912e8b85906ce2bd5b3d97a456"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01a013912e8b85906ce2bd5b3d97a456"></a>
NumInputs(1).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_max_pool.html">MaxPool</a>, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a01a013912e8b85906ce2bd5b3d97a456"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adec27ea2b6dbfa7eab36c7eb0273062f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adec27ea2b6dbfa7eab36c7eb0273062f"></a>
NumInputs(1).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxPool1D, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:adec27ea2b6dbfa7eab36c7eb0273062f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a059eb94ba572c3aafe59a37329f51eec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a059eb94ba572c3aafe59a37329f51eec"></a>
NumInputs(1).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxPool2D, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a059eb94ba572c3aafe59a37329f51eec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72741793a31357f6dae74eef533443aa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a72741793a31357f6dae74eef533443aa"></a>
NumInputs(1).NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MaxPool3D, <a class="el" href="classcaffe2_1_1_pool_op.html">PoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_pool_functor.html">MaxPoolFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a72741793a31357f6dae74eef533443aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d22089922f227d342a39745fccad826"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3d22089922f227d342a39745fccad826"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="class_average_pool.html">AveragePool</a>, CuDNNPoolOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:a3d22089922f227d342a39745fccad826"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a799d783f2615bf503da6a6d454fd84a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a799d783f2615bf503da6a6d454fd84a1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (AveragePoolGradient, CuDNNPoolGradientOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:a799d783f2615bf503da6a6d454fd84a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84febfab353e1f8b795d2e210bb27333"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a84febfab353e1f8b795d2e210bb27333"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (AveragePool1D, CuDNNPoolOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:a84febfab353e1f8b795d2e210bb27333"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af65b3f2aeb2d66cfde6fa1008d47c1dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af65b3f2aeb2d66cfde6fa1008d47c1dc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (AveragePool1DGradient, CuDNNPoolGradientOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:af65b3f2aeb2d66cfde6fa1008d47c1dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a773cabd59ae12c25298d2118c70a4ac6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a773cabd59ae12c25298d2118c70a4ac6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (AveragePool2D, CuDNNPoolOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:a773cabd59ae12c25298d2118c70a4ac6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899256d3dbeaa6412cdaabb89696fe0f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a899256d3dbeaa6412cdaabb89696fe0f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (AveragePool2DGradient, CuDNNPoolGradientOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:a899256d3dbeaa6412cdaabb89696fe0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a661473a49746f8816622a9e9fa447fb4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a661473a49746f8816622a9e9fa447fb4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (AveragePool3D, CuDNNPoolOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:a661473a49746f8816622a9e9fa447fb4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acacab71168face53f6b2b4b62623aff7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acacab71168face53f6b2b4b62623aff7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (AveragePool3DGradient, CuDNNPoolGradientOp&lt; CuDNNAveragePoolFunctor &gt;)</td></tr>
<tr class="separator:acacab71168face53f6b2b4b62623aff7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46bfafb53bd312740d4500d0c08ee41f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46bfafb53bd312740d4500d0c08ee41f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="class_max_pool.html">MaxPool</a>, CuDNNPoolOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:a46bfafb53bd312740d4500d0c08ee41f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2cdd116076f7ad4fc923bb58f9de8a77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2cdd116076f7ad4fc923bb58f9de8a77"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (MaxPoolGradient, CuDNNPoolGradientOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:a2cdd116076f7ad4fc923bb58f9de8a77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40bfaa5e1094d9f560442859b032b3ae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a40bfaa5e1094d9f560442859b032b3ae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (MaxPool1D, CuDNNPoolOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:a40bfaa5e1094d9f560442859b032b3ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77eac3336cbe36cddd951e653161f534"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a77eac3336cbe36cddd951e653161f534"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (MaxPool1DGradient, CuDNNPoolGradientOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:a77eac3336cbe36cddd951e653161f534"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabc4dee357045725fd88576e39c48da6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabc4dee357045725fd88576e39c48da6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (MaxPool2D, CuDNNPoolOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:aabc4dee357045725fd88576e39c48da6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25b4feac691438c1678333ea650af80a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a25b4feac691438c1678333ea650af80a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (MaxPool2DGradient, CuDNNPoolGradientOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:a25b4feac691438c1678333ea650af80a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61214e890d4d13c7b789a7b7f247c159"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a61214e890d4d13c7b789a7b7f247c159"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (MaxPool3D, CuDNNPoolOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:a61214e890d4d13c7b789a7b7f247c159"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada9179341d086bd85b5a374fee808b3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada9179341d086bd85b5a374fee808b3e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (MaxPool3DGradient, CuDNNPoolGradientOp&lt; CuDNNMaxPoolFunctor &gt;)</td></tr>
<tr class="separator:ada9179341d086bd85b5a374fee808b3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a675895d042aa981cffa018ac9ccf519b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a675895d042aa981cffa018ac9ccf519b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Pow, <a class="el" href="classcaffe2_1_1_pow_op.html">PowOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_eigen_pow_functor.html">EigenPowFunctor</a>, <a class="el" href="structcaffe2_1_1_same_type_as_input.html">SameTypeAsInput</a> &gt;).NumInputs(1</td></tr>
<tr class="separator:a675895d042aa981cffa018ac9ccf519b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a390c221c10e9eaa52c8d036a3263279b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a390c221c10e9eaa52c8d036a3263279b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumOutputs</b> (1).AllowInplace(</td></tr>
<tr class="separator:a390c221c10e9eaa52c8d036a3263279b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae519015529c49ba9edba9b9afcf109a6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae519015529c49ba9edba9b9afcf109a6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PRelu, <a class="el" href="classcaffe2_1_1_p_relu_op.html">PReluOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae519015529c49ba9edba9b9afcf109a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd74c19e358135e16c75becb20816c85"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd74c19e358135e16c75becb20816c85"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (PReluGradient, <a class="el" href="classcaffe2_1_1_p_relu_gradient_op.html">PReluGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:acd74c19e358135e16c75becb20816c85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a172cf6c8bb4ccdab15e468b80388fc38"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a172cf6c8bb4ccdab15e468b80388fc38"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PrependDim, <a class="el" href="classcaffe2_1_1_prepend_dim_op.html">PrependDimOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a172cf6c8bb4ccdab15e468b80388fc38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7888791d15ee3ce8aa591ef922e8e05b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7888791d15ee3ce8aa591ef922e8e05b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MergeDim, <a class="el" href="classcaffe2_1_1_merge_dim_op.html">MergeDimOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7888791d15ee3ce8aa591ef922e8e05b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a552edd379cd773b36d42607c8c1184d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a552edd379cd773b36d42607c8c1184d7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
<a class="el" href="class_reshape.html">Reshape</a> the tensor by prepending a dimension of fixed size and dividing the
size of the next dimension by that amount.
)DOC&quot;).Arg(&quot;dim_size&quot;</td></tr>
<tr class="separator:a552edd379cd773b36d42607c8c1184d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d202ef89f58740ea92731f6ed86cd7e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d202ef89f58740ea92731f6ed86cd7e"></a>
Size of the dimension to prepend&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;data&quot;,&quot;An input tensor.&quot;).Output(0</td></tr>
<tr class="separator:a1d202ef89f58740ea92731f6ed86cd7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa39b62274ae8c5eecc075b2d29b82c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa39b62274ae8c5eecc075b2d29b82c7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Merge first two dimensions in a single dimension with size dim(0) * dim(1).
)DOC&quot;).Input(0</td></tr>
<tr class="separator:aaa39b62274ae8c5eecc075b2d29b82c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fc05dc2cbae64c70a191e9c90030be0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3fc05dc2cbae64c70a191e9c90030be0"></a>
An input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;reshaped&quot;,&quot;Reshaped tensor.&quot;).InheritOnnxSchema(&quot;Reshape&quot;)</td></tr>
<tr class="separator:a3fc05dc2cbae64c70a191e9c90030be0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac36531a3054c60c1b16fc40150b08aae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac36531a3054c60c1b16fc40150b08aae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (PrependDim, <a class="el" href="classcaffe2_1_1_get_prepend_dim_gradient.html">GetPrependDimGradient</a>)</td></tr>
<tr class="separator:ac36531a3054c60c1b16fc40150b08aae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3258a81ad064d50d0deda05b001a002"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3258a81ad064d50d0deda05b001a002"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (PrependDim, <a class="el" href="classcaffe2_1_1_prepend_dim_op.html">PrependDimOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ad3258a81ad064d50d0deda05b001a002"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc671ac6dd953c08ba8a1020b119753b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc671ac6dd953c08ba8a1020b119753b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (MergeDim, <a class="el" href="classcaffe2_1_1_merge_dim_op.html">MergeDimOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:adc671ac6dd953c08ba8a1020b119753b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58f06fe45c8edaeaf575855649fe12d3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a58f06fe45c8edaeaf575855649fe12d3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (QuantDecode, <a class="el" href="classcaffe2_1_1_quant_decode_op.html">QuantDecodeOp</a>&lt; QuantDecodeRunTy::RUN_ALWAYS &gt;)</td></tr>
<tr class="separator:a58f06fe45c8edaeaf575855649fe12d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dcfdffcb657bdd6f536fcc8d808b097"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dcfdffcb657bdd6f536fcc8d808b097"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (QuantDecodeGradient, <a class="el" href="classcaffe2_1_1_quant_decode_gradient_op.html">QuantDecodeGradientOp</a>)</td></tr>
<tr class="separator:a3dcfdffcb657bdd6f536fcc8d808b097"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac22cb664805064aa5429881155f32723"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac22cb664805064aa5429881155f32723"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>initQNNPACK</b> ()</td></tr>
<tr class="separator:ac22cb664805064aa5429881155f32723"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc743e73e576d22dbe32481a2fade70f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afc743e73e576d22dbe32481a2fade70f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Add, <a class="el" href="classcaffe2_1_1int8_1_1_int8_add_op.html">int8::Int8AddOp</a>&lt; int8::Activation::NONE &gt;)</td></tr>
<tr class="separator:afc743e73e576d22dbe32481a2fade70f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d72c1664bc05e7917c5f8237f926ce2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d72c1664bc05e7917c5f8237f926ce2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8AddRelu, <a class="el" href="classcaffe2_1_1int8_1_1_int8_add_op.html">int8::Int8AddOp</a>&lt; int8::Activation::RELU &gt;)</td></tr>
<tr class="separator:a4d72c1664bc05e7917c5f8237f926ce2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a111d3975e66d4e164d2dd63e37deab68"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a111d3975e66d4e164d2dd63e37deab68"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Sum, <a class="el" href="classcaffe2_1_1int8_1_1_int8_add_op.html">int8::Int8AddOp</a>&lt; int8::Activation::NONE &gt;)</td></tr>
<tr class="separator:a111d3975e66d4e164d2dd63e37deab68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96d5d9fad258008471f40c0808b4c74e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96d5d9fad258008471f40c0808b4c74e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8SumRelu, <a class="el" href="classcaffe2_1_1int8_1_1_int8_add_op.html">int8::Int8AddOp</a>&lt; int8::Activation::RELU &gt;)</td></tr>
<tr class="separator:a96d5d9fad258008471f40c0808b4c74e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1011ca0e012f017821004b4c839c8e8f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1011ca0e012f017821004b4c839c8e8f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;Y_scale&quot;,&quot;Output tensor quantization scale&quot;).Arg(&quot;Y_zero_point&quot;</td></tr>
<tr class="separator:a1011ca0e012f017821004b4c839c8e8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae725534548ef73b38d9bc4ad8939e6f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae725534548ef73b38d9bc4ad8939e6f8"></a>
Output tensor quantization offset&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
    Performs element-wise binary <a class="el" href="class_add.html">Add</a> (with no broadcast support).
)DOC&quot;).Input(0</td></tr>
<tr class="separator:ae725534548ef73b38d9bc4ad8939e6f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c569b740d6d9f6ba10a13817f26201b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5c569b740d6d9f6ba10a13817f26201b"></a>
Output tensor quantization offset First should share the type with the second operand&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;B&quot;,&quot;Second operand. It should be of the same size as A.&quot;).Output(0</td></tr>
<tr class="separator:a5c569b740d6d9f6ba10a13817f26201b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a222e29b843b2ba6d16cba7e5c24ccce8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a222e29b843b2ba6d16cba7e5c24ccce8"></a>
Output tensor quantization offset&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
    Performs element-wise binary <a class="el" href="class_add.html">Add</a> (with no broadcast support). &quot;&quot;Output will go through rectified linear &quot;&quot;function, where y = max(0, x).
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a222e29b843b2ba6d16cba7e5c24ccce8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a3432afc02c3022fe8d77b77efb9cfb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a3432afc02c3022fe8d77b77efb9cfb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (1, std::numeric_limits&lt; int &gt;::max()).NumOutputs(1).AllowInplace(</td></tr>
<tr class="separator:a7a3432afc02c3022fe8d77b77efb9cfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0603dafef82b4fcb6a0f6615d1114f37"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0603dafef82b4fcb6a0f6615d1114f37"></a>
Output tensor quantization scale&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;Y_zero_point&quot;,&quot;Output tensor quantization offset&quot;)</td></tr>
<tr class="separator:a0603dafef82b4fcb6a0f6615d1114f37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8323c8cc0a34d8a2ca1600bd8e4dcc6e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8323c8cc0a34d8a2ca1600bd8e4dcc6e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8AveragePool, <a class="el" href="classcaffe2_1_1int8_1_1_int8_average_pool_op.html">int8::Int8AveragePoolOp</a>&lt; int8::Activation::NONE &gt;)</td></tr>
<tr class="separator:a8323c8cc0a34d8a2ca1600bd8e4dcc6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a457480df84f19ae70a3fa1c0c07395e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a457480df84f19ae70a3fa1c0c07395e5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8AveragePoolRelu, <a class="el" href="classcaffe2_1_1int8_1_1_int8_average_pool_op.html">int8::Int8AveragePoolOp</a>&lt; int8::Activation::RELU &gt;)</td></tr>
<tr class="separator:a457480df84f19ae70a3fa1c0c07395e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a965a88b8682a82bfc86bed8c765170c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a965a88b8682a82bfc86bed8c765170c3"></a>
std::function&lt; void(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>AveragePoolDocGenerator</b> (const char *dim, bool relu_fused=false)</td></tr>
<tr class="separator:a965a88b8682a82bfc86bed8c765170c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab68fe3abb2fff05cca983ffd7554ca8a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab68fe3abb2fff05cca983ffd7554ca8a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8ChannelShuffle, <a class="el" href="classcaffe2_1_1int8_1_1_int8_channel_shuffle_op.html">int8::Int8ChannelShuffleOp</a>)</td></tr>
<tr class="separator:ab68fe3abb2fff05cca983ffd7554ca8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a123eb0188fce30a9850d94205b714208"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a123eb0188fce30a9850d94205b714208"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Concat, <a class="el" href="classcaffe2_1_1int8_1_1_int8_concat_op.html">int8::Int8ConcatOp</a>)</td></tr>
<tr class="separator:a123eb0188fce30a9850d94205b714208"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32c5a70a1cea8c0e937e097915291356"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32c5a70a1cea8c0e937e097915291356"></a>
Output tensor quantization offset&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;axis&quot;,&quot;Which axis to concat on&quot;).Arg(&quot;add_axis&quot;</td></tr>
<tr class="separator:a32c5a70a1cea8c0e937e097915291356"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ade3b97197fae1f7fe067c360150f38"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ade3b97197fae1f7fe067c360150f38"></a>
Output tensor quantization offset Pass to add the axis specified in arg axis to all input tensors&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> (<a class="el" href="classcaffe2_1_1_op_schema.html#afdce21f47ce7356877ebfccfa843a2cb">OpSchema::NeedsAllInputShapes</a>(TensorInferenceForConcat)).CostInferenceFunction(CostInferenceForConcat).SetDoc(&quot;Concatenate a list of tensors into a single tensor&quot;).Output(0</td></tr>
<tr class="separator:a4ade3b97197fae1f7fe067c360150f38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe07e69c2dde0c5e874cf214aa2337c8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe07e69c2dde0c5e874cf214aa2337c8"></a>
Output tensor quantization offset Pass to add the axis specified in arg axis to all input tensors Concatenated tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;split_info&quot;,&quot;The dimensions of the inputs.&quot;).InheritOnnxSchema(&quot;Concat&quot;)</td></tr>
<tr class="separator:abe07e69c2dde0c5e874cf214aa2337c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c8a4c281fe2ce4a63065e8575b73fdf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c8a4c281fe2ce4a63065e8575b73fdf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Conv, <a class="el" href="classcaffe2_1_1int8_1_1_int8_conv_op.html">int8::Int8ConvOp</a>&lt; int8::Activation::NONE &gt;)</td></tr>
<tr class="separator:a6c8a4c281fe2ce4a63065e8575b73fdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6cd791af4fd43e6243d92e95bbcf51e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac6cd791af4fd43e6243d92e95bbcf51e"></a>
std::function&lt; void(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>ConvDocGenerator</b> (const char *dim, bool relu_fused=false)</td></tr>
<tr class="separator:ac6cd791af4fd43e6243d92e95bbcf51e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17daaf127be89d15ca39e44cce34bf2a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17daaf127be89d15ca39e44cce34bf2a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8ConvRelu, <a class="el" href="classcaffe2_1_1int8_1_1_int8_conv_op.html">int8::Int8ConvOp</a>&lt; int8::Activation::RELU &gt;)</td></tr>
<tr class="separator:a17daaf127be89d15ca39e44cce34bf2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a7089caeedcf213eb9527ffeeaa0bba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1a7089caeedcf213eb9527ffeeaa0bba"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8ConvTranspose, <a class="el" href="classcaffe2_1_1int8_1_1_int8_conv_transpose_op.html">int8::Int8ConvTransposeOp</a>)</td></tr>
<tr class="separator:a1a7089caeedcf213eb9527ffeeaa0bba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad429f80be3864529a6058758ac219366"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad429f80be3864529a6058758ac219366"></a>
this is done throughout the image data and the output is computed As a side note on the implementation which is why they are separate files DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;Input data blob from previous layer; has size &quot;&quot;(N x H x W x <a class="el" href="struct_c.html">C</a>), where N is the batch size, <a class="el" href="struct_c.html">C</a> is the number of channels, and&quot;&quot; H and W are the height and width. Note that NHWC is supported now&quot;).Input(1</td></tr>
<tr class="separator:ad429f80be3864529a6058758ac219366"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a780b718a5f0a07d9e7c226a4ed92ef3d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a780b718a5f0a07d9e7c226a4ed92ef3d"></a>
has&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (<a class="el" href="struct_m.html">M</a> x kH x kW x <a class="el" href="struct_c.html">C</a>)</td></tr>
<tr class="separator:a780b718a5f0a07d9e7c226a4ed92ef3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a942109e38e9e63942f0974a34ab25e3f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a942109e38e9e63942f0974a34ab25e3f"></a>
has where <a class="el" href="struct_c.html">C</a> is the number of and kH and kW are the height and width of the kernel&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;bias&quot;,&quot;The 1D bias blob that is added through the convolution;&quot;&quot;has size (C). Optional, if not passed, will treat it as all 0.&quot;).Output(0</td></tr>
<tr class="separator:a942109e38e9e63942f0974a34ab25e3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba69243de94df90fe1cbcb2818622137"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aba69243de94df90fe1cbcb2818622137"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Dequantize, <a class="el" href="classcaffe2_1_1int8_1_1_int8_dequantize_op.html">int8::Int8DequantizeOp</a>)</td></tr>
<tr class="separator:aba69243de94df90fe1cbcb2818622137"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c72047a7714ef393b1e54d224a53ffd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c72047a7714ef393b1e54d224a53ffd"></a>
Int8 <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> qX&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;FP32 <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> that represents mapped real value of qX.&quot;)</td></tr>
<tr class="separator:a1c72047a7714ef393b1e54d224a53ffd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b043100adc206447f7509974e967521"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b043100adc206447f7509974e967521"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8FC, <a class="el" href="classcaffe2_1_1int8_1_1_int8_f_c_op.html">int8::Int8FCOp</a>)</td></tr>
<tr class="separator:a0b043100adc206447f7509974e967521"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa51e7d85e19a6edad6018ef149f18172"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa51e7d85e19a6edad6018ef149f18172"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Flatten, <a class="el" href="classcaffe2_1_1int8_1_1_int8_flatten_op.html">int8::Int8FlattenOp</a>)</td></tr>
<tr class="separator:aa51e7d85e19a6edad6018ef149f18172"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad41c213eae044e8296fc926dd46a6e6e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad41c213eae044e8296fc926dd46a6e6e"></a>
d_n then the output will have&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (d_0 X d_1...d_(axis-1), d_axis X d_(axis+1)...X dn)) DOC&quot;) .Input(0</td></tr>
<tr class="separator:ad41c213eae044e8296fc926dd46a6e6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad46f5690f67d430448132b77a60fd26a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad46f5690f67d430448132b77a60fd26a"></a>
d_n then the output will have <a class="el" href="struct_a.html">A</a> Int8 tensor of with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output Output tensor quantization offset&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;axis&quot;,&quot;(Default to 1) Indicate up to which input dimensions &quot;&quot;(exclusive) should be flattened to the outer dimension of the output&quot;)</td></tr>
<tr class="separator:ad46f5690f67d430448132b77a60fd26a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1c1b67564f40a3e7b75359787ca0279"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac1c1b67564f40a3e7b75359787ca0279"></a>
Input array of type&#160;</td><td class="memItemRight" valign="bottom"><b>char</b> (byte)&quot;) .Arg(&quot;shape&quot;</td></tr>
<tr class="separator:ac1c1b67564f40a3e7b75359787ca0279"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bffdccd53e79d40100cb54317801ca9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5bffdccd53e79d40100cb54317801ca9"></a>
Input array of type Input tensor shape Output tensor quantization offset&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
    Creates quantized tensor of type char(byte) with scale and zero point info.
)DOC&quot;).Output(0</td></tr>
<tr class="separator:a5bffdccd53e79d40100cb54317801ca9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aadf9625a95cec975a4635b21bbddb8a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aadf9625a95cec975a4635b21bbddb8a4"></a>
Input array of type int32&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;shape&quot;,&quot;Input tensor shape&quot;).Arg(&quot;Y_scale&quot;</td></tr>
<tr class="separator:aadf9625a95cec975a4635b21bbddb8a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87953c2b6b1b026793757e0cff454d24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87953c2b6b1b026793757e0cff454d24"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8GivenTensorFill, <a class="el" href="classcaffe2_1_1int8_1_1_int8_given_tensor_fill_op.html">int8::Int8GivenTensorFillOp</a>)</td></tr>
<tr class="separator:a87953c2b6b1b026793757e0cff454d24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa317399451f8b546ec2f2af124edba65"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa317399451f8b546ec2f2af124edba65"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8GivenIntTensorFill, <a class="el" href="classcaffe2_1_1int8_1_1_int8_given_int_tensor_fill_op.html">int8::Int8GivenIntTensorFillOp</a>)</td></tr>
<tr class="separator:aa317399451f8b546ec2f2af124edba65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0af547e9dc22c68573b11d56910018f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0af547e9dc22c68573b11d56910018f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8LeakyRelu, <a class="el" href="classcaffe2_1_1int8_1_1_int8_leaky_relu_op.html">int8::Int8LeakyReluOp</a>)</td></tr>
<tr class="separator:ac0af547e9dc22c68573b11d56910018f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af923f6f75f9f9b80b0568afc5800e133"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af923f6f75f9f9b80b0568afc5800e133"></a>
Coefficient of default value is Output tensor quantization offset and produces one output&#160;</td><td class="memItemRight" valign="bottom"><b>data</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&lt; <a class="el" href="struct_t.html">T</a> &gt;) where the function`f(x)</td></tr>
<tr class="separator:af923f6f75f9f9b80b0568afc5800e133"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af07f778bbe21ec9accf3ef5fcadba2a2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af07f778bbe21ec9accf3ef5fcadba2a2"></a>
Coefficient of default value is Output tensor quantization offset and produces one output is applied to the data tensor elementwise DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;1D input tensor&quot;).Output(0</td></tr>
<tr class="separator:af07f778bbe21ec9accf3ef5fcadba2a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adfa8f9ce8ad2f831f734555935ccaa55"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adfa8f9ce8ad2f831f734555935ccaa55"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8MaxPool, <a class="el" href="classcaffe2_1_1int8_1_1_int8_max_pool_op.html">int8::Int8MaxPoolOp</a>&lt; int8::Activation::NONE &gt;)</td></tr>
<tr class="separator:adfa8f9ce8ad2f831f734555935ccaa55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09f6d0a9d63d882312266fec3f7b59b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09f6d0a9d63d882312266fec3f7b59b9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8MaxPoolRelu, <a class="el" href="classcaffe2_1_1int8_1_1_int8_max_pool_op.html">int8::Int8MaxPoolOp</a>&lt; int8::Activation::RELU &gt;)</td></tr>
<tr class="separator:a09f6d0a9d63d882312266fec3f7b59b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b80e01000c9b6a989254bcadf4a8e18"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b80e01000c9b6a989254bcadf4a8e18"></a>
std::function&lt; void(<a class="el" href="classcaffe2_1_1_op_schema.html">OpSchema</a> &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>MaxPoolDocGenerator</b> (const char *dim, bool relu_fused=false)</td></tr>
<tr class="separator:a2b80e01000c9b6a989254bcadf4a8e18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4acc1ba4de7b160f8128f9adacae333"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab4acc1ba4de7b160f8128f9adacae333"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Quantize, <a class="el" href="classcaffe2_1_1int8_1_1_int8_quantize_op.html">int8::Int8QuantizeOp</a>)</td></tr>
<tr class="separator:ab4acc1ba4de7b160f8128f9adacae333"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3dfc92683558d8e017fe45bf847690d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab3dfc92683558d8e017fe45bf847690d"></a>
Output tensor quantization scale FP32 <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> X&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;Int8 <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> qX representing X with linear quantization.&quot;)</td></tr>
<tr class="separator:ab3dfc92683558d8e017fe45bf847690d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2464ea09205c8a9c383759eeb17a3f74"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2464ea09205c8a9c383759eeb17a3f74"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Relu, <a class="el" href="classcaffe2_1_1int8_1_1_int8_relu_op.html">int8::Int8ReluOp</a>)</td></tr>
<tr class="separator:a2464ea09205c8a9c383759eeb17a3f74"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aceadcfaec69d84d7d54a5e65ba97a30e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aceadcfaec69d84d7d54a5e65ba97a30e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceFunction</b> (CostInferenceForRelu).IdenticalTypeAndShape().SetDoc(R&quot;DOC( <a class="el" href="class_relu.html">Relu</a> takes one input data (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&lt;<a class="el" href="struct_t.html">T</a>&gt;) and produces one output data (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&lt;<a class="el" href="struct_t.html">T</a>&gt;) where the rectified linear function</td></tr>
<tr class="separator:aceadcfaec69d84d7d54a5e65ba97a30e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb86bb87a3254811b20e7d6dde889166"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb86bb87a3254811b20e7d6dde889166"></a>
is applied to the tensor elementwise DOC input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>InheritOnnxSchema</b> (&quot;Relu&quot;)</td></tr>
<tr class="separator:acb86bb87a3254811b20e7d6dde889166"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0b5968e19631d7d7cd6665c3d930770"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0b5968e19631d7d7cd6665c3d930770"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Reshape, <a class="el" href="classcaffe2_1_1int8_1_1_int8_reshape_op.html">int8::Int8ReshapeOp</a>)</td></tr>
<tr class="separator:ac0b5968e19631d7d7cd6665c3d930770"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17901726cd08bf68f0711d7e9ea00996"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17901726cd08bf68f0711d7e9ea00996"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
<a class="el" href="class_reshape.html">Reshape</a> the input tensor similar to numpy.reshape.

It takes a tensor as input and an <a class="el" href="classc10_1_1optional.html">optional</a> tensor specifying the new shape.
When the second input is absent, an extra argument `shape` must be specified.
It outputs the reshaped tensor as well as the original shape.

At most one dimension of the new shape can be -1. In this case, the value is
inferred from the size of the tensor and the remaining dimensions. <a class="el" href="struct_a.html">A</a> dimension
could also be 0, in which case the actual dimension value is going to be copied
from the input tensor.
)DOC&quot;).Arg(&quot;shape&quot;</td></tr>
<tr class="separator:a17901726cd08bf68f0711d7e9ea00996"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad1bed3bd6cb8b5bfeb891510c2981d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aad1bed3bd6cb8b5bfeb891510c2981d6"></a>
New shape Output tensor quantization offset New shape&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;reshaped&quot;,&quot;Reshaped data.&quot;).Output(1</td></tr>
<tr class="separator:aad1bed3bd6cb8b5bfeb891510c2981d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf976aeb400e1b7dfb3a80585f9760d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf976aeb400e1b7dfb3a80585f9760d4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8ResizeNearest, <a class="el" href="classcaffe2_1_1int8_1_1_int8_resize_nearest_op.html">int8::Int8ResizeNearestOp</a>)</td></tr>
<tr class="separator:adf976aeb400e1b7dfb3a80585f9760d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8cbdf3ca4bd23982e7de2eb0240559a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa8cbdf3ca4bd23982e7de2eb0240559a"></a>
Output tensor quantization scale Scale along width dimension&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;height_scale&quot;,&quot;Scale along height dimension&quot;).SetDoc(R&quot;DOC( Resizes the spatial dimensions of the input using nearest neighbor interpolation. The `width_scale` and `height_scale` arguments control the size of the output</td></tr>
<tr class="separator:aa8cbdf3ca4bd23982e7de2eb0240559a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88bb52ddda265e73a92d7f94d0d57c8b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a88bb52ddda265e73a92d7f94d0d57c8b"></a>
Output tensor quantization scale Scale along width dimension which is given Input Int8 tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;Output Int8 tensor&quot;)</td></tr>
<tr class="separator:a88bb52ddda265e73a92d7f94d0d57c8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8653731cb087b9f1431a1f5fd740c241"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8653731cb087b9f1431a1f5fd740c241"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8RoIAlign, <a class="el" href="classcaffe2_1_1int8_1_1_int8_ro_i_align_op.html">int8::Int8RoIAlignOp</a>)</td></tr>
<tr class="separator:a8653731cb087b9f1431a1f5fd740c241"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6f9159ea374c3300e4f6448da8ed41f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac6f9159ea374c3300e4f6448da8ed41f"></a>
Spatial scale of the input feature map X relative to the input image <a class="el" href="struct_e.html">E</a> if X has a stride of w r t the input image&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;pooled_h&quot;,&quot;(int) default 1; Pooled output Y's height.&quot;).Arg(&quot;pooled_w&quot;</td></tr>
<tr class="separator:ac6f9159ea374c3300e4f6448da8ed41f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fb3cdd581ebd796201ac66bf86353f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7fb3cdd581ebd796201ac66bf86353f9"></a>
Pooled output Y s width&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;sampling_ratio&quot;,&quot;(int) default -1; number of sampling points in the interpolation grid &quot;&quot;used to compute the output value of each pooled output bin. If &gt; 0, &quot;&quot;then exactly sampling_ratio x sampling_ratio grid points are used. If &quot;&quot;&lt;= 0, then an adaptive number of grid points are used (computed as &quot;&quot;ceil(roi_width / pooled_w), and likewise for height).&quot;).Input(0</td></tr>
<tr class="separator:a7fb3cdd581ebd796201ac66bf86353f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a080418e38c5f85b1d01b03d0ce7c545b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a080418e38c5f85b1d01b03d0ce7c545b"></a>
Pooled output Y s width Int8 <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> feature map input of&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (N, <a class="el" href="struct_c.html">C</a>, H, W).&quot;) .Input( 1</td></tr>
<tr class="separator:a080418e38c5f85b1d01b03d0ce7c545b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90f315063f70bf281ecff4fe6bc9ceb9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90f315063f70bf281ecff4fe6bc9ceb9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Sigmoid, <a class="el" href="classcaffe2_1_1int8_1_1_int8_sigmoid_op.html">int8::Int8SigmoidOp</a>)</td></tr>
<tr class="separator:a90f315063f70bf281ecff4fe6bc9ceb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40741255e47659ba6351ec701ce4d841"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a40741255e47659ba6351ec701ce4d841"></a>
Github The input tensor that s coerced into a matrix of&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (NxD)&quot; &quot;as described above.&quot;) .Output( 0</td></tr>
<tr class="separator:a40741255e47659ba6351ec701ce4d841"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7502f31ab5d4be2a5050b71665643bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae7502f31ab5d4be2a5050b71665643bb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Slice, <a class="el" href="classcaffe2_1_1int8_1_1_int8_slice_op.html">int8::Int8SliceOp</a>)</td></tr>
<tr class="separator:ae7502f31ab5d4be2a5050b71665643bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecd1981838da45a1ddc9f2ce47695938"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aecd1981838da45a1ddc9f2ce47695938"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Int8Softmax, <a class="el" href="classcaffe2_1_1int8_1_1_int8_softmax_op.html">int8::Int8SoftmaxOp</a>)</td></tr>
<tr class="separator:aecd1981838da45a1ddc9f2ce47695938"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6871fadac332ae77f8cec346d0194d94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6871fadac332ae77f8cec346d0194d94"></a>
it will be coerced into one For an arbitrary n dimensional tensor X in[a_0, a_1,..., a_{k-1}, a_k,..., a_{n-1}] and k is the axis then X will be coerced into a dimensional tensor with dimensions[a_0 *...*a_{k-1}, a_k *...*a_{n-1}] For the default case where this means the X tensor will be coerced into a tensor of where a_0 is often the batch size In this we must have or else the&#160;</td><td class="memItemRight" valign="bottom"><b>operator will throw errors.) DOC&quot;) .Arg</b> (&quot;axis&quot;,&quot;(int) default to 1; describes the axis of the inputs when coerced &quot;&quot;to 2D; defaults to one because the 0th axis most likely describes &quot;&quot;the batch_size&quot;).Input(0</td></tr>
<tr class="separator:a6871fadac332ae77f8cec346d0194d94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2424c184b710930d7c3b2f3d765997f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2424c184b710930d7c3b2f3d765997f6"></a>
float&#160;</td><td class="memItemRight" valign="bottom"><b>addErrorTolerance</b> (float scale)</td></tr>
<tr class="separator:a2424c184b710930d7c3b2f3d765997f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3536cc49c94c130899411beb95470ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3536cc49c94c130899411beb95470ed"></a>
std::unique_ptr&lt; <a class="el" href="structcaffe2_1_1int8_1_1_int8_tensor_c_p_u.html">int8::Int8TensorCPU</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>q</b> (const std::vector&lt; int64_t &gt; &amp;dims)</td></tr>
<tr class="separator:af3536cc49c94c130899411beb95470ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0dc38624b8554286006baecf5c64e3de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0dc38624b8554286006baecf5c64e3de"></a>
std::unique_ptr&lt; <a class="el" href="structcaffe2_1_1int8_1_1_int8_tensor_c_p_u.html">int8::Int8TensorCPU</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>biasq</b> (const std::vector&lt; int64_t &gt; &amp;dims, double scale)</td></tr>
<tr class="separator:a0dc38624b8554286006baecf5c64e3de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4d10174b9f29bd086d59b9d8d977a0a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4d10174b9f29bd086d59b9d8d977a0a"></a>
std::unique_ptr&lt; <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>dq</b> (const <a class="el" href="structcaffe2_1_1int8_1_1_int8_tensor_c_p_u.html">int8::Int8TensorCPU</a> &amp;XQ)</td></tr>
<tr class="separator:aa4d10174b9f29bd086d59b9d8d977a0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a1d5e8c8d1ba380c94a631f2486d37f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a1d5e8c8d1ba380c94a631f2486d37f"></a>
std::unique_ptr&lt; <a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>biasdq</b> (const <a class="el" href="structcaffe2_1_1int8_1_1_int8_tensor_c_p_u.html">int8::Int8TensorCPU</a> &amp;XQ)</td></tr>
<tr class="separator:a5a1d5e8c8d1ba380c94a631f2486d37f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33cc96dc2a18f91355191c1da14a2990"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a33cc96dc2a18f91355191c1da14a2990"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>int8Copy</b> (<a class="el" href="structcaffe2_1_1int8_1_1_int8_tensor_c_p_u.html">int8::Int8TensorCPU</a> *dst, const <a class="el" href="structcaffe2_1_1int8_1_1_int8_tensor_c_p_u.html">int8::Int8TensorCPU</a> &amp;src)</td></tr>
<tr class="separator:a33cc96dc2a18f91355191c1da14a2990"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affaf7803f1b565c9f1c97095be1965a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="affaf7803f1b565c9f1c97095be1965a1"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>add_input</b> (const vector&lt; int64_t &gt; &amp;shape, const vector&lt; float &gt; &amp;values, const string &amp;name, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *ws)</td></tr>
<tr class="separator:affaf7803f1b565c9f1c97095be1965a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5674d6e1817da3c196529cd43bb723f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5674d6e1817da3c196529cd43bb723f5"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>randomInt</b> (int a, int b)</td></tr>
<tr class="separator:a5674d6e1817da3c196529cd43bb723f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a630fa93fd02ebdceb055f06c67918aa8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a630fa93fd02ebdceb055f06c67918aa8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReciprocalGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_reciprocal_gradient_functor.html">ReciprocalGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a630fa93fd02ebdceb055f06c67918aa8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a48b14720ace8b42cf7ae612c27cb05"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a48b14720ace8b42cf7ae612c27cb05"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Reciprocal, GetReciprocalGradient)</td></tr>
<tr class="separator:a4a48b14720ace8b42cf7ae612c27cb05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a807f5897e1f31bab373d978f865aa189"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a807f5897e1f31bab373d978f865aa189"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Reciprocal, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_reciprocal_functor.html">ReciprocalFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a807f5897e1f31bab373d978f865aa189"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afed56e9829c1e22e77294b665ebbf64a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afed56e9829c1e22e77294b665ebbf64a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceFrontMax, <a class="el" href="classcaffe2_1_1_max_reduce_dims_op.html">MaxReduceDimsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;)</td></tr>
<tr class="separator:afed56e9829c1e22e77294b665ebbf64a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd6f0b1d121e5ac581fb97c4e4777883"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abd6f0b1d121e5ac581fb97c4e4777883"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceFrontMaxGradient, <a class="el" href="classcaffe2_1_1_max_reduce_dims_gradient_op.html">MaxReduceDimsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;)</td></tr>
<tr class="separator:abd6f0b1d121e5ac581fb97c4e4777883"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9b28b92857aaa543768789079152c90"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab9b28b92857aaa543768789079152c90"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceBackMax, <a class="el" href="classcaffe2_1_1_max_reduce_dims_op.html">MaxReduceDimsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false &gt;)</td></tr>
<tr class="separator:ab9b28b92857aaa543768789079152c90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af911cd29d47410ecfef1b45357f510b7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af911cd29d47410ecfef1b45357f510b7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceBackMaxGradient, <a class="el" href="classcaffe2_1_1_max_reduce_dims_gradient_op.html">MaxReduceDimsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false &gt;)</td></tr>
<tr class="separator:af911cd29d47410ecfef1b45357f510b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04349cba64700b565d65eec0b9305255"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04349cba64700b565d65eec0b9305255"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ReduceFrontMax, <a class="el" href="classcaffe2_1_1_get_reduce_front_max_gradient.html">GetReduceFrontMaxGradient</a>)</td></tr>
<tr class="separator:a04349cba64700b565d65eec0b9305255"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92bf96ee5953a075f8a573fda63fc280"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92bf96ee5953a075f8a573fda63fc280"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ReduceBackMax, <a class="el" href="classcaffe2_1_1_get_reduce_back_max_gradient.html">GetReduceBackMaxGradient</a>)</td></tr>
<tr class="separator:a92bf96ee5953a075f8a573fda63fc280"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e817c935bc21c1967d48098bd1021a3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5e817c935bc21c1967d48098bd1021a3"></a>
int can be which enforces that only a subset of the elements are considered in the max operation If input tensor X has&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (d_0, d_1, d_2,..., d_n)$</td></tr>
<tr class="separator:a5e817c935bc21c1967d48098bd1021a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a505e63b65d489cde0b0670b084a97bec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a505e63b65d489cde0b0670b084a97bec"></a>
int can be which enforces that only a subset of the elements are considered in the max operation If input tensor X has lengths must have&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (d_1 *d_2 *...*d_{n})$.-The values of the`lengths`tensor determine how many of the values to consider for each vector in the $d_</td></tr>
<tr class="separator:a505e63b65d489cde0b0670b084a97bec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9583603fed1bf04f85e3e8f9bdcb77a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac9583603fed1bf04f85e3e8f9bdcb77a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceFrontMean, <a class="el" href="classcaffe2_1_1_sum_reduce_dims_op.html">SumReduceDimsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true, true &gt;)</td></tr>
<tr class="separator:ac9583603fed1bf04f85e3e8f9bdcb77a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39d75f2b4c4c21fa0931f7ccb3fc41e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39d75f2b4c4c21fa0931f7ccb3fc41e5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceFrontMeanGradient, <a class="el" href="classcaffe2_1_1_sum_reduce_dims_gradient_op.html">SumReduceDimsGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true, true &gt;)</td></tr>
<tr class="separator:a39d75f2b4c4c21fa0931f7ccb3fc41e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe10cbb7b5f5e42e3c1e1497bdfe0f34"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe10cbb7b5f5e42e3c1e1497bdfe0f34"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ReduceFrontMean, <a class="el" href="classcaffe2_1_1_get_reduce_front_mean_gradient.html">GetReduceFrontMeanGradient</a>)</td></tr>
<tr class="separator:abe10cbb7b5f5e42e3c1e1497bdfe0f34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a943b5dba8b06a474f736631f78ca3b77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a943b5dba8b06a474f736631f78ca3b77"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceFrontSum, <a class="el" href="classcaffe2_1_1_sum_reduce_dims_op.html">SumReduceDimsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true, false &gt;)</td></tr>
<tr class="separator:a943b5dba8b06a474f736631f78ca3b77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74cae50e8868524aa652487bdbddb34c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a74cae50e8868524aa652487bdbddb34c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceFrontSumGradient, <a class="el" href="classcaffe2_1_1_sum_reduce_dims_gradient_op.html">SumReduceDimsGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true, false &gt;)</td></tr>
<tr class="separator:a74cae50e8868524aa652487bdbddb34c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa63b38160fa88432cf89e19d35d5158"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa63b38160fa88432cf89e19d35d5158"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ReduceFrontSum, <a class="el" href="classcaffe2_1_1_get_reduce_front_sum_gradient.html">GetReduceFrontSumGradient</a>)</td></tr>
<tr class="separator:afa63b38160fa88432cf89e19d35d5158"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a461180cd1ece4b4e934ab89cb67101ae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a461180cd1ece4b4e934ab89cb67101ae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceBackSum, <a class="el" href="classcaffe2_1_1_sum_reduce_dims_op.html">SumReduceDimsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false, false &gt;)</td></tr>
<tr class="separator:a461180cd1ece4b4e934ab89cb67101ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afcf19504c08e225f1216d8efd39c1580"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afcf19504c08e225f1216d8efd39c1580"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceBackSumGradient, <a class="el" href="classcaffe2_1_1_sum_reduce_dims_gradient_op.html">SumReduceDimsGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false, false &gt;)</td></tr>
<tr class="separator:afcf19504c08e225f1216d8efd39c1580"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbf18ca8ca4422f8813c2e004b56badf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acbf18ca8ca4422f8813c2e004b56badf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ReduceBackSum, <a class="el" href="classcaffe2_1_1_get_reduce_back_sum_gradient.html">GetReduceBackSumGradient</a>)</td></tr>
<tr class="separator:acbf18ca8ca4422f8813c2e004b56badf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8baf2c262c5701aa9a6de45b51e966b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8baf2c262c5701aa9a6de45b51e966b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceMin, <a class="el" href="classcaffe2_1_1_reduce_op.html">ReduceOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_min_reducer.html">MinReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a8baf2c262c5701aa9a6de45b51e966b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6dc00649908aaffa3020d455dd78b5e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6dc00649908aaffa3020d455dd78b5e5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceMinGradient, <a class="el" href="classcaffe2_1_1_reduce_gradient_op.html">ReduceGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_min_reducer.html">MinReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a6dc00649908aaffa3020d455dd78b5e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaecc95064114b16aa09f4a3c9860a2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afaecc95064114b16aa09f4a3c9860a2f"></a>
then the resulted tensor have the reduced dimension pruned DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;axes&quot;,&quot;<a class="el" href="struct_a.html">A</a> list of integers, along which to reduce.&quot;).Arg(&quot;keepdims&quot;</td></tr>
<tr class="separator:afaecc95064114b16aa09f4a3c9860a2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bf6f867871ca3d8ea2b9cf67fffb8f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3bf6f867871ca3d8ea2b9cf67fffb8f4"></a>
then the resulted tensor have the reduced dimension pruned DOC Keep the reduced default True keeps the reduced An input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;reduced&quot;,&quot;Reduced output tensor.&quot;)</td></tr>
<tr class="separator:a3bf6f867871ca3d8ea2b9cf67fffb8f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92d6ab1955d8792c4a79e0bcb7323a6b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92d6ab1955d8792c4a79e0bcb7323a6b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (ReduceMinGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a92d6ab1955d8792c4a79e0bcb7323a6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3cdbe950cdd2810b6dd5235a6bdffcb5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3cdbe950cdd2810b6dd5235a6bdffcb5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceMax, <a class="el" href="classcaffe2_1_1_reduce_op.html">ReduceOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_reducer.html">MaxReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a3cdbe950cdd2810b6dd5235a6bdffcb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a167346a251944da23d281b7d0fbc2ad2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a167346a251944da23d281b7d0fbc2ad2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceMaxGradient, <a class="el" href="classcaffe2_1_1_reduce_gradient_op.html">ReduceGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_reducer.html">MaxReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a167346a251944da23d281b7d0fbc2ad2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c6a1ffc12391d3cb002ae50f039b533"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4c6a1ffc12391d3cb002ae50f039b533"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (ReduceMaxGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:a4c6a1ffc12391d3cb002ae50f039b533"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb367d2ecd30e2549824b5a4b785a166"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb367d2ecd30e2549824b5a4b785a166"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceSum, <a class="el" href="classcaffe2_1_1_reduce_op.html">ReduceOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sum_reducer.html">SumReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:acb367d2ecd30e2549824b5a4b785a166"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae439bbb71012b8bf374500853192f30c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae439bbb71012b8bf374500853192f30c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReduceSumGradient, <a class="el" href="classcaffe2_1_1_reduce_gradient_op.html">ReduceGradientOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; std::int32_t, std::int64_t, float, double &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sum_reducer.html">SumReducer</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ae439bbb71012b8bf374500853192f30c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd2303e6bcba9a25f5d4e40f0e0d37e2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd2303e6bcba9a25f5d4e40f0e0d37e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SumElements, <a class="el" href="classcaffe2_1_1_sum_elements_op.html">SumElementsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:acd2303e6bcba9a25f5d4e40f0e0d37e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeaa52fea1cac023bfec8352b01dc1129"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeaa52fea1cac023bfec8352b01dc1129"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SumElementsInt, <a class="el" href="classcaffe2_1_1_sum_elements_int_op.html">SumElementsIntOp</a>&lt; int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aeaa52fea1cac023bfec8352b01dc1129"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3017fdecf785e6677b54593cda09493f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3017fdecf785e6677b54593cda09493f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SumSqrElements, <a class="el" href="classcaffe2_1_1_sum_sqr_elements_op.html">SumSqrElementsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3017fdecf785e6677b54593cda09493f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afac770f9cadd4711ad89994d241513d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afac770f9cadd4711ad89994d241513d0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SumElementsGradient, <a class="el" href="classcaffe2_1_1_sum_elements_gradient_op.html">SumElementsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afac770f9cadd4711ad89994d241513d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0a6f98d15795ab4e4cbf06dc49f43b1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0a6f98d15795ab4e4cbf06dc49f43b1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RowwiseMax, <a class="el" href="classcaffe2_1_1_max_reduction_op.html">MaxReductionOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;)</td></tr>
<tr class="separator:ac0a6f98d15795ab4e4cbf06dc49f43b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acee608cdef2e782d2f3e15b6113d3460"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acee608cdef2e782d2f3e15b6113d3460"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RowwiseMaxGradient, <a class="el" href="classcaffe2_1_1_max_reduction_gradient_op.html">MaxReductionGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, true &gt;)</td></tr>
<tr class="separator:acee608cdef2e782d2f3e15b6113d3460"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f4ced6c7fd61912a48b445cdca3eea4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f4ced6c7fd61912a48b445cdca3eea4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ColwiseMaxGradient, <a class="el" href="classcaffe2_1_1_max_reduction_gradient_op.html">MaxReductionGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false &gt;)</td></tr>
<tr class="separator:a7f4ced6c7fd61912a48b445cdca3eea4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9e56d0f06246205e192cf67e4eb53a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9e56d0f06246205e192cf67e4eb53a0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ColwiseMax, <a class="el" href="classcaffe2_1_1_max_reduction_op.html">MaxReductionOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, false &gt;)</td></tr>
<tr class="separator:aa9e56d0f06246205e192cf67e4eb53a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5507bcf3d153fe130c06d4442136eff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5507bcf3d153fe130c06d4442136eff"></a>
NumInputs(1).NumOutputs(1).ScalarType(TensorProto NumInputs(1).NumOutputs(1).ScalarType(TensorProto&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (SumElementsInt)</td></tr>
<tr class="separator:aa5507bcf3d153fe130c06d4442136eff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add493eb867a7d87390a605868da45fbe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="add493eb867a7d87390a605868da45fbe"></a>
NumInputs(1).NumOutputs(1).ScalarType(TensorProto&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (SumElementsGradient).NumInputs(2).NumOutputs(1)</td></tr>
<tr class="separator:add493eb867a7d87390a605868da45fbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a710e074e59057ba20c9305753de6fe1d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a710e074e59057ba20c9305753de6fe1d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SumElements, <a class="el" href="classcaffe2_1_1_get_sum_elements_gradient.html">GetSumElementsGradient</a>)</td></tr>
<tr class="separator:a710e074e59057ba20c9305753de6fe1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea49c96034f69676c32814c4fc0fd997"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea49c96034f69676c32814c4fc0fd997"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReluN, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_relu_n_functor.html">ReluNFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aea49c96034f69676c32814c4fc0fd997"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aacb90379108a1dc25da20a6fd7cb3f9c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aacb90379108a1dc25da20a6fd7cb3f9c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReluNGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseWithArgsOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_relu_n_gradient_functor.html">ReluNGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aacb90379108a1dc25da20a6fd7cb3f9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb3467cc500781a81328930af07d584e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb3467cc500781a81328930af07d584e"></a>
the cap of forward op output&#160;</td><td class="memItemRight" valign="bottom"><b>AllowInplace</b> ({{1, 0}}).SetDoc(R&quot;DOC( ReluGradient takes both Y and dY and uses this to update dX according to the chain rule and derivatives of the rectified linear function. )DOC&quot;)</td></tr>
<tr class="separator:acb3467cc500781a81328930af07d584e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad80d42b77bbf5aca4aa1ba2ea127fae4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad80d42b77bbf5aca4aa1ba2ea127fae4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ReluN, GetReluNGradient)</td></tr>
<tr class="separator:ad80d42b77bbf5aca4aa1ba2ea127fae4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a175f4cd1607522132df4ad75115181fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a175f4cd1607522132df4ad75115181fd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_relu.html">Relu</a>, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_relu_functor.html">ReluFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a175f4cd1607522132df4ad75115181fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9dceddd57d02ff622b50eb7ba04db844"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9dceddd57d02ff622b50eb7ba04db844"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (ReluGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_relu_gradient_functor.html">ReluGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a9dceddd57d02ff622b50eb7ba04db844"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af39ce3aea64f0df0d6e527af7063ead0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af39ce3aea64f0df0d6e527af7063ead0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
ReluGradient takes both Y and dY and uses this to update dX according to the
chain rule and derivatives of the rectified linear function.
)DOC&quot;)</td></tr>
<tr class="separator:af39ce3aea64f0df0d6e527af7063ead0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a242f063fedcfd6720f10b5a7b870c270"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a242f063fedcfd6720f10b5a7b870c270"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="class_relu.html">Relu</a>, GetReluGradient)</td></tr>
<tr class="separator:a242f063fedcfd6720f10b5a7b870c270"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8db97a798ea776535eb3e942e18dc4f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac8db97a798ea776535eb3e942e18dc4f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="class_relu.html">Relu</a>, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_op.html">CuDNNActivationOp</a>&lt; CUDNN_ACTIVATION_RELU &gt;)</td></tr>
<tr class="separator:ac8db97a798ea776535eb3e942e18dc4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5d48a8b3409e87a7d0f2a6c40059aa3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5d48a8b3409e87a7d0f2a6c40059aa3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (ReluGradient, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_gradient_op.html">CuDNNActivationGradientOp</a>&lt; CUDNN_ACTIVATION_RELU &gt;)</td></tr>
<tr class="separator:aa5d48a8b3409e87a7d0f2a6c40059aa3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb77e9bedf197eb81679492e72c7f78d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abb77e9bedf197eb81679492e72c7f78d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReplaceNaN, <a class="el" href="classcaffe2_1_1_replace_na_n_op.html">ReplaceNaNOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:abb77e9bedf197eb81679492e72c7f78d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91333c0430d3f7852e1c5494674ed889"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a91333c0430d3f7852e1c5494674ed889"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (ReplaceNaN)</td></tr>
<tr class="separator:a91333c0430d3f7852e1c5494674ed889"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9937a9917b9903bbe5e6a2ee616db41"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac9937a9917b9903bbe5e6a2ee616db41"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_reshape.html">Reshape</a>, <a class="el" href="classcaffe2_1_1_reshape_op.html">ReshapeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac9937a9917b9903bbe5e6a2ee616db41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca224e4b6d4df756ab84ef0ba0a98504"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca224e4b6d4df756ab84ef0ba0a98504"></a>
out[1]&#160;</td><td class="memItemRight" valign="bottom"><b>set_data_type</b> (TensorProto::INT64)</td></tr>
<tr class="separator:aca224e4b6d4df756ab84ef0ba0a98504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4b1b09fdc4a1a9364b9164d209ec0f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4b1b09fdc4a1a9364b9164d209ec0f6"></a>
out[1]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (in[0].dims_size())</td></tr>
<tr class="separator:aa4b1b09fdc4a1a9364b9164d209ec0f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a182b62362e577db6a6d7abd5c282d940"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a182b62362e577db6a6d7abd5c282d940"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (!helper.HasArgument(&quot;shape&quot;))</td></tr>
<tr class="separator:a182b62362e577db6a6d7abd5c282d940"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e736be17d0c687d49c4406c3cd54659"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2e736be17d0c687d49c4406c3cd54659"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE_EQ</b> (in.size(), 1,&quot;New shape must not be specified by the input blob and the &quot;&quot;argument `shape` at the same time.&quot;)</td></tr>
<tr class="separator:a2e736be17d0c687d49c4406c3cd54659"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5b537a2ce028d664a344edc783b7fed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5b537a2ce028d664a344edc783b7fed"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>for</b> (const auto d:in[0].dims())</td></tr>
<tr class="separator:ac5b537a2ce028d664a344edc783b7fed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4de0400a8ae0a47d470863e9cacd1c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab4de0400a8ae0a47d470863e9cacd1c1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (unknownIdx!=-1)</td></tr>
<tr class="separator:ab4de0400a8ae0a47d470863e9cacd1c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a291d79d41c89176d403f66243ed141ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a291d79d41c89176d403f66243ed141ad"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>for</b> (const auto d:actualNewShape)</td></tr>
<tr class="separator:a291d79d41c89176d403f66243ed141ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6ab2e70a3bfb7e2f0c7a0bb7fd0abec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6ab2e70a3bfb7e2f0c7a0bb7fd0abec"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="class_reshape.html">Reshape</a>, <a class="el" href="classcaffe2_1_1_reshape_op.html">ReshapeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aa6ab2e70a3bfb7e2f0c7a0bb7fd0abec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47ea0c1a67010ed426244920546d1308"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a47ea0c1a67010ed426244920546d1308"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>resizeNearestNCHW2x</b> (int batch_size, int num_channels, int input_height, int input_width, const float *input, float *output)</td></tr>
<tr class="separator:a47ea0c1a67010ed426244920546d1308"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade904b440a50a3605f59dabc45b1c6e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade904b440a50a3605f59dabc45b1c6e5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ResizeNearest, <a class="el" href="classcaffe2_1_1_resize_nearest_op.html">ResizeNearestOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ade904b440a50a3605f59dabc45b1c6e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7525d3be2e7ec6b1b76d5ab933911e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7525d3be2e7ec6b1b76d5ab933911e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (ResizeNearestGradient, <a class="el" href="classcaffe2_1_1_resize_nearest_gradient_op.html">ResizeNearestGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac7525d3be2e7ec6b1b76d5ab933911e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a563dbb755c542d872c27032342cd711a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a563dbb755c542d872c27032342cd711a"></a>
Scale along width dimension which is given Input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;scales&quot;,&quot;1D, 2-element, Scales tensor, [height_scale, width_scale]&quot;).Output(0</td></tr>
<tr class="separator:a563dbb755c542d872c27032342cd711a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a503900382d71854a99c665eb536f1e9f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a503900382d71854a99c665eb536f1e9f"></a>
Scale along width dimension which is given Input tensor Output tensor&#160;</td><td class="memItemRight" valign="bottom"><b>InheritOnnxSchema</b> (&quot;Upsample&quot;)</td></tr>
<tr class="separator:a503900382d71854a99c665eb536f1e9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a713cdbe8cf8e7dc849e6279a4e959d57"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a713cdbe8cf8e7dc849e6279a4e959d57"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ResizeNearest, <a class="el" href="classcaffe2_1_1_get_resize_nearest_gradient.html">GetResizeNearestGradient</a>)</td></tr>
<tr class="separator:a713cdbe8cf8e7dc849e6279a4e959d57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a043d03a0b74434f9e624e9bc23aa7377"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a043d03a0b74434f9e624e9bc23aa7377"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ReversePackedSegs, <a class="el" href="classcaffe2_1_1_reverse_packed_segs_op.html">ReversePackedSegsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a043d03a0b74434f9e624e9bc23aa7377"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1de3afd8d991258dd5bf7232eb467a2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac1de3afd8d991258dd5bf7232eb467a2"></a>
leaving paddings unchanged This&#160;</td><td class="memItemRight" valign="bottom"><b>operator is used to reverse input of a recurrent neural network to make it a BRNN.) DOC&quot;) .Input</b> (0,&quot;data&quot;,&quot;a 3-<a class="el" href="struct_d.html">D</a> (lengths, segments, embeddings,) tensor.&quot;).Input(1</td></tr>
<tr class="separator:ac1de3afd8d991258dd5bf7232eb467a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a392400dce5e7335e846f5c959985307c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a392400dce5e7335e846f5c959985307c"></a>
leaving paddings unchanged This length of each segment&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;reversed data&quot;,&quot;a (lengths, segments, embeddings,) tensor with each segment reversed&quot;&quot;and paddings unchanged.&quot;)</td></tr>
<tr class="separator:a392400dce5e7335e846f5c959985307c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa55813f369cb301e8c0051b56b96a318"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa55813f369cb301e8c0051b56b96a318"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ReversePackedSegs, <a class="el" href="classcaffe2_1_1_get_reverse_packed_segs_gradient.html">GetReversePackedSegsGradient</a>)</td></tr>
<tr class="separator:aa55813f369cb301e8c0051b56b96a318"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae23bb5b87e8ea0cfb2b5a63695f04d51"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae23bb5b87e8ea0cfb2b5a63695f04d51"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RMACRegions, <a class="el" href="classcaffe2_1_1_r_m_a_c_regions_op.html">RMACRegionsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae23bb5b87e8ea0cfb2b5a63695f04d51"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9f18da68fe856b465261495e1c3d156"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9f18da68fe856b465261495e1c3d156"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RecurrentNetworkBlobFetcher, <a class="el" href="classcaffe2_1_1_recurrent_network_blob_fetcher_op.html">RecurrentNetworkBlobFetcherOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad9f18da68fe856b465261495e1c3d156"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e4955b328bef2d421be2e834b2eb865"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5e4955b328bef2d421be2e834b2eb865"></a>
Prefix string to prepend extracted blobs&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;ScratchWorkspaceBlob&quot;,&quot;Name of scratch workspace blob returned by recurrent network.&quot;).Output(0</td></tr>
<tr class="separator:a5e4955b328bef2d421be2e834b2eb865"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9839977af794578804bb99724f69db55"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9839977af794578804bb99724f69db55"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (RecurrentNetworkBlobFetcher)</td></tr>
<tr class="separator:a9839977af794578804bb99724f69db55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd07e42c9acb1494e637f6b6489d842b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd07e42c9acb1494e637f6b6489d842b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (RecurrentNetworkBlobFetcher, <a class="el" href="classcaffe2_1_1_recurrent_network_blob_fetcher_op.html">RecurrentNetworkBlobFetcherOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:afd07e42c9acb1494e637f6b6489d842b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af626e8bd4defd97004472e4618071467"><td class="memTemplParams" colspan="2">template&lt;&gt; </td></tr>
<tr class="memitem:af626e8bd4defd97004472e4618071467"><td class="memTemplItemLeft" align="right" valign="top">std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_recurrent_network_executor_base.html">RecurrentNetworkExecutorBase</a> &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#af626e8bd4defd97004472e4618071467">createRNNExecutor&lt; CPUContext &gt;</a> (const NetDef &amp;step_net_def, std::map&lt; string, string &gt; &amp;recurrent_input_map, std::string timestep_blob, <a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> rnn_args)</td></tr>
<tr class="memdesc:af626e8bd4defd97004472e4618071467"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implementation of RecurrentNetworkExecutor that uses thread pool for multithreaded execution of RNNs.  <a href="#af626e8bd4defd97004472e4618071467">More...</a><br /></td></tr>
<tr class="separator:af626e8bd4defd97004472e4618071467"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41508631ed84d5827070d1d204621b45"><td class="memTemplParams" colspan="2"><a class="anchor" id="a41508631ed84d5827070d1d204621b45"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:a41508631ed84d5827070d1d204621b45"><td class="memTemplItemLeft" align="right" valign="top">std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_recurrent_network_executor_base.html">RecurrentNetworkExecutorBase</a> &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>createRNNExecutor</b> (const NetDef &amp;step_net_def, std::map&lt; string, string &gt; &amp;recurrent_input_map, std::string timestep_blob, <a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> rnn_args)</td></tr>
<tr class="separator:a41508631ed84d5827070d1d204621b45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ea3a6c453620aaf4bc05db9979b8f2b"><td class="memTemplParams" colspan="2"><a class="anchor" id="a5ea3a6c453620aaf4bc05db9979b8f2b"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a5ea3a6c453620aaf4bc05db9979b8f2b"><td class="memTemplItemLeft" align="right" valign="top">std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_recurrent_network_executor_base.html">RecurrentNetworkExecutorBase</a> &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>createRNNExecutor&lt; CUDAContext &gt;</b> (const NetDef &amp;step_net_def, std::map&lt; string, string &gt; &amp;recurrent_input_map, std::string timestep_blob, <a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> arg_helper)</td></tr>
<tr class="separator:a5ea3a6c453620aaf4bc05db9979b8f2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2440d0d739a8ff7780ca788a0e9c6fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad2440d0d739a8ff7780ca788a0e9c6fd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="structcaffe2_1_1detail_1_1_scratch_workspaces.html">detail::ScratchWorkspaces</a>)</td></tr>
<tr class="separator:ad2440d0d739a8ff7780ca788a0e9c6fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e4e5e322c97dfc904b690f67b3a7ed4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e4e5e322c97dfc904b690f67b3a7ed4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RecurrentNetwork, <a class="el" href="classcaffe2_1_1_recurrent_network_op.html">RecurrentNetworkOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1e4e5e322c97dfc904b690f67b3a7ed4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7f20ebf7a9f4b7d043508e628d578bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7f20ebf7a9f4b7d043508e628d578bd"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Run the input network in a recurrent fashion. This can be used to
implement fairly general recurrent neural networks (RNNs).

The operator proceeds as follows.

- First, initialized the states from the input recurrent states
- For each timestep <a class="el" href="struct_t.html">T</a>, apply the links (that map offsets from input/output
tensors into the inputs/outputs for the `step` network)
- Finally, alias the recurrent states to the specified output blobs.

This is a fairly special-case meta-operator, and so the implementation
is somewhat complex. It trades of generality (and frankly usability)
against performance and control (compared to e.g. TF
dynamic_rnn, Theano scan, etc).

See the usage examples for a flavor of how to use it.
)DOC&quot;)</td></tr>
<tr class="separator:ac7f20ebf7a9f4b7d043508e628d578bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3072d167ef5ca0c7db265ef083e6a5a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3072d167ef5ca0c7db265ef083e6a5a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RecurrentNetworkGradient, <a class="el" href="classcaffe2_1_1_recurrent_network_gradient_op.html">RecurrentNetworkGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af3072d167ef5ca0c7db265ef083e6a5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b1ac23d3f7602f3d04576798ec8736b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7b1ac23d3f7602f3d04576798ec8736b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (RecurrentNetworkGradient)</td></tr>
<tr class="separator:a7b1ac23d3f7602f3d04576798ec8736b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60e7a17169132702eab06cd99f41083c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a60e7a17169132702eab06cd99f41083c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (rnn_internal_accumulate_gradient_input, <a class="el" href="classcaffe2_1_1_accumulate_input_gradient_op.html">AccumulateInputGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a60e7a17169132702eab06cd99f41083c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a122355b1a16b247872c691033387bde6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a122355b1a16b247872c691033387bde6"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>EnforceInplace</b> ({{2, 0}}).Private().SetDoc(R&quot;DOC( Internal RNN operator. )DOC&quot;)</td></tr>
<tr class="separator:a122355b1a16b247872c691033387bde6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a3b03cb18e129bd217ab2a049529add"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a3b03cb18e129bd217ab2a049529add"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (rnn_internal_apply_link, <a class="el" href="classcaffe2_1_1_r_n_n_apply_link_op.html">RNNApplyLinkOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a5a3b03cb18e129bd217ab2a049529add"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9bac68523a2edaa6d77434877f9f504"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9bac68523a2edaa6d77434877f9f504"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Private</b> ().SetDoc(R&quot;DOC( Internal RNN operator. )DOC&quot;)</td></tr>
<tr class="separator:ad9bac68523a2edaa6d77434877f9f504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f3ca4e0250dfc68055be3726ad3322b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f3ca4e0250dfc68055be3726ad3322b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (RecurrentNetwork, <a class="el" href="structcaffe2_1_1_get_recurrent_network_gradient.html">GetRecurrentNetworkGradient</a>)</td></tr>
<tr class="separator:a9f3ca4e0250dfc68055be3726ad3322b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a912783262e703e193dcd0a6961569055"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a912783262e703e193dcd0a6961569055"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Recurrent, <a class="el" href="classcaffe2_1_1_recurrent_op.html">RecurrentOp</a>&lt; float &gt;)</td></tr>
<tr class="separator:a912783262e703e193dcd0a6961569055"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9009f0878a4ce0b5c4278150e3e1c639"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9009f0878a4ce0b5c4278150e3e1c639"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Recurrent).NumInputs(4).NumOutputs(5).SetDoc(R&quot;DOC( Recurrent wraps the CuDNN R5 RNN implementation. See the CuDNN R5 documentation for more information. In general</td></tr>
<tr class="separator:a9009f0878a4ce0b5c4278150e3e1c639"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad641a8ec93c63bf32de0f552aeec1c87"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad641a8ec93c63bf32de0f552aeec1c87"></a>
the implementation takes an&#160;</td><td class="memItemRight" valign="bottom"><b>input</b> (TxNxD) tensor</td></tr>
<tr class="separator:ad641a8ec93c63bf32de0f552aeec1c87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa49f4bd63db29f2344f61892e922a5f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa49f4bd63db29f2344f61892e922a5f8"></a>
the implementation takes an the hidden state&#160;</td><td class="memItemRight" valign="bottom"><b>input</b> (NxD)</td></tr>
<tr class="separator:aa49f4bd63db29f2344f61892e922a5f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76ea117f2274758ce3e6d8e8c36a420c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a76ea117f2274758ce3e6d8e8c36a420c"></a>
the implementation takes an the hidden state the cell and a weight&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (effectively an opaque blob, where the size and layout is dictated by CuDNN).The outputs are the output(again</td></tr>
<tr class="separator:a76ea117f2274758ce3e6d8e8c36a420c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f5cd275fcfa21ebde9feaabceea717c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f5cd275fcfa21ebde9feaabceea717c"></a>
the implementation takes an the hidden state the cell and a weight the final hidden cell&#160;</td><td class="memItemRight" valign="bottom"><b>states</b> (NxD).These can be reset(at sequence boundaries across minibatches) by multiplying by zero.The CuDNN arguments(hidden_size</td></tr>
<tr class="separator:a7f5cd275fcfa21ebde9feaabceea717c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43040ba9ca5c850af8a6bfae5ba33446"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a43040ba9ca5c850af8a6bfae5ba33446"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (RecurrentGradient, <a class="el" href="classcaffe2_1_1_recurrent_gradient_op.html">RecurrentGradientOp</a>&lt; float &gt;)</td></tr>
<tr class="separator:a43040ba9ca5c850af8a6bfae5ba33446"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4e6ac81e8902d9e9d6a48eb5f0a7e9f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af4e6ac81e8902d9e9d6a48eb5f0a7e9f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (7).NumOutputs(6).AllowInplace(</td></tr>
<tr class="separator:af4e6ac81e8902d9e9d6a48eb5f0a7e9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad63b4e71b179d2b7110046d646a4913b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad63b4e71b179d2b7110046d646a4913b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (RecurrentParamSet, <a class="el" href="classcaffe2_1_1_recurrent_param_access_op.html">RecurrentParamAccessOp</a>&lt; float, SET_PARAM &gt;)</td></tr>
<tr class="separator:ad63b4e71b179d2b7110046d646a4913b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e34f7c76611f9cb71ac58ace79cec17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e34f7c76611f9cb71ac58ace79cec17"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (&quot;Set individual parameters of a recurrent net.&quot;).Arg(&quot;param_type&quot;</td></tr>
<tr class="separator:a8e34f7c76611f9cb71ac58ace79cec17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25895797aeae6de8161aaedbb06e44d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a25895797aeae6de8161aaedbb06e44d2"></a>
R&#160;</td><td class="memItemRight" valign="bottom"><b>DOC</b> (<a class="el" href="structc10_1_1_type.html">Type</a> of param to be set:&quot;input_gate_w&quot;,&quot;forget_gate_w&quot;,&quot;cell_w&quot;,&quot;output_gate_w&quot;&quot;input_gate_b&quot;,&quot;forget_gate_b&quot;,&quot;cell_b&quot;,&quot;output_gate_b&quot;) DOC&quot;) .Arg(&quot;input_type&quot;</td></tr>
<tr class="separator:a25895797aeae6de8161aaedbb06e44d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e5a4d2eefc0b0ebc6a59c4fb6965f15"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e5a4d2eefc0b0ebc6a59c4fb6965f15"></a>
R recurrent or input&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;layer&quot;,&quot;layer index (starting from 0)&quot;).Input(0</td></tr>
<tr class="separator:a1e5a4d2eefc0b0ebc6a59c4fb6965f15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8296acd052e5c2f3130bf3a3f9031a46"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8296acd052e5c2f3130bf3a3f9031a46"></a>
R recurrent or input R&#160;</td><td class="memItemRight" valign="bottom"><b>DOC</b> (Input blob.Needed for inferring the shapes.A dummy tensor matching the input shape is ok.) DOC&quot;) .Input(1</td></tr>
<tr class="separator:a8296acd052e5c2f3130bf3a3f9031a46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd648a0c5fc20affdb53b3c36cba0201"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abd648a0c5fc20affdb53b3c36cba0201"></a>
R recurrent or input R <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> holding all the parameters&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;param&quot;,&quot;Values for the specified parameter&quot;).Output(0</td></tr>
<tr class="separator:abd648a0c5fc20affdb53b3c36cba0201"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f749bf3fab03c4b1604a866d40a6202"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f749bf3fab03c4b1604a866d40a6202"></a>
R recurrent or input R <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> holding all the parameters <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> holding all the&#160;</td><td class="memItemRight" valign="bottom"><b>parameters</b> (same as input(1))&quot;)</td></tr>
<tr class="separator:a1f749bf3fab03c4b1604a866d40a6202"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cd748f8781f46aa04974d549c5501b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0cd748f8781f46aa04974d549c5501b9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (RecurrentParamGet, <a class="el" href="classcaffe2_1_1_recurrent_param_access_op.html">RecurrentParamAccessOp</a>&lt; float, GET_PARAM &gt;)</td></tr>
<tr class="separator:a0cd748f8781f46aa04974d549c5501b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61289012b80f52b2b2c58fd9c3aae241"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a61289012b80f52b2b2c58fd9c3aae241"></a>
R recurrent or input R <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> holding all the parameters&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;param&quot;,&quot;<a class="el" href="classcaffe2_1_1_blob.html">Blob</a> holding the requested values&quot;)</td></tr>
<tr class="separator:a61289012b80f52b2b2c58fd9c3aae241"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a620fcbf44947b5e8e7b6aa94843a479d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a620fcbf44947b5e8e7b6aa94843a479d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Recurrent, <a class="el" href="structcaffe2_1_1_get_recurrent_gradient.html">GetRecurrentGradient</a>)</td></tr>
<tr class="separator:a620fcbf44947b5e8e7b6aa94843a479d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa02e3f0cf047e22fde957ff1944a75c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa02e3f0cf047e22fde957ff1944a75c3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RoIAlignGradient, <a class="el" href="classcaffe2_1_1_ro_i_align_gradient_op.html">RoIAlignGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa02e3f0cf047e22fde957ff1944a75c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18b61e2e35f1d6ad76c7b11fa81115d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a18b61e2e35f1d6ad76c7b11fa81115d1"></a>
See RoIPoolF&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;RoIs&quot;,&quot;See RoIPoolF.&quot;).Input(2</td></tr>
<tr class="separator:a18b61e2e35f1d6ad76c7b11fa81115d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ecddef0f549003ae2c2a62941797348"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6ecddef0f549003ae2c2a62941797348"></a>
See RoIPoolF Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>output</b> (Y)&quot;) .Output(0</td></tr>
<tr class="separator:a6ecddef0f549003ae2c2a62941797348"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe9cf8601b57d03a62e24cdeb93c3a96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe9cf8601b57d03a62e24cdeb93c3a96"></a>
See RoIPoolF Gradient of forward Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>input</b> (X)&quot;)</td></tr>
<tr class="separator:abe9cf8601b57d03a62e24cdeb93c3a96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a010a8d227eacf6ba571036bde754b67b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a010a8d227eacf6ba571036bde754b67b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (RoIAlign, GetRoIAlignGradient)</td></tr>
<tr class="separator:a010a8d227eacf6ba571036bde754b67b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeffa0928b5c4d64d88722b8a244774c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeffa0928b5c4d64d88722b8a244774c3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RoIAlign, <a class="el" href="classcaffe2_1_1_ro_i_align_op.html">RoIAlignOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aeffa0928b5c4d64d88722b8a244774c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e7dd21e6912f13600d4f5086e74ce3c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e7dd21e6912f13600d4f5086e74ce3c"></a>
See RoIAlignRotated&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;RoIs&quot;,&quot;See RoIAlignRotated.&quot;).Input(2</td></tr>
<tr class="separator:a4e7dd21e6912f13600d4f5086e74ce3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4360e9457246ed17eb8614f0b7ecc9b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4360e9457246ed17eb8614f0b7ecc9b6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (RoIAlignRotated, GetRoIAlignRotatedGradient)</td></tr>
<tr class="separator:a4360e9457246ed17eb8614f0b7ecc9b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbebfa12bc1884c3558b69a5e71f7456"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acbebfa12bc1884c3558b69a5e71f7456"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RoIAlignRotated, <a class="el" href="classcaffe2_1_1_ro_i_align_rotated_op.html">RoIAlignRotatedOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:acbebfa12bc1884c3558b69a5e71f7456"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad9c6d36284b653af0276dbee5a02c3a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aad9c6d36284b653af0276dbee5a02c3a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RoIPool, <a class="el" href="classcaffe2_1_1_ro_i_pool_op.html">RoIPoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aad9c6d36284b653af0276dbee5a02c3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a913e97c6cbb1f244d7623215027a5011"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a913e97c6cbb1f244d7623215027a5011"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RoIPoolGradient, <a class="el" href="classcaffe2_1_1_ro_i_pool_gradient_op.html">RoIPoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a913e97c6cbb1f244d7623215027a5011"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa54635d974bd63f5f747d294d8fe3b8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa54635d974bd63f5f747d294d8fe3b8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in){<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> helper(def);const StorageOrder order=StringToStorageOrder(helper.GetSingleArgument&lt; string &gt;(&quot;order&quot;,&quot;NCHW&quot;));const TensorShape &amp;X=in[0];const int num_channels=(order==StorageOrder::NCHW?X.dims(1):X.dims(3));const TensorShape &amp;R=in[1];const int num_rois=R.dims(0);const int pooled_height=helper.GetSingleArgument&lt; int &gt;(&quot;pooled_h&quot;, 1);const int pooled_width=helper.GetSingleArgument&lt; int &gt;(&quot;pooled_w&quot;, 1);TensorShape Y=CreateTensorShape(vector&lt; int &gt;({num_rois, num_channels, pooled_height, pooled_width}), X.data_type());bool is_test=helper.GetSingleArgument&lt; int &gt;(OpSchema::Arg_IsTest, 0);if(!is_test){TensorShape argmaxes=Y;argmaxes.set_data_type(TensorProto_DataType_INT32);return vector&lt; TensorShape &gt;({Y, argmaxes});}else{return vector&lt; TensorShape &gt;({Y});}}).SetDoc(R&quot;DOC( Carries out ROI Pooling for Faster-RCNN. Depending on the mode</td></tr>
<tr class="separator:aaa54635d974bd63f5f747d294d8fe3b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecaf93f8f892520e9d73f6a9eb15282a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aecaf93f8f892520e9d73f6a9eb15282a"></a>
there are multiple output&#160;</td><td class="memItemRight" valign="bottom"><b>argmaxes</b> (train mode) Output case) DOC&quot;) .Arg( &quot;is_test&quot;</td></tr>
<tr class="separator:aecaf93f8f892520e9d73f6a9eb15282a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab335b1ba59a0a33962131c798b43ac62"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab335b1ba59a0a33962131c798b43ac62"></a>
there are multiple output If run in test mode and skip computation of argmaxes(used for&quot; &quot;gradient computation).Only one output tensor is produced.&quot; &quot;(Default&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (RoIPoolGradient).NumInputs(4).NumOutputs(1)</td></tr>
<tr class="separator:ab335b1ba59a0a33962131c798b43ac62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7654c3b702689ba3c1a9728b405e364"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7654c3b702689ba3c1a9728b405e364"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (RoIPool, <a class="el" href="classcaffe2_1_1_get_ro_i_pool_gradient.html">GetRoIPoolGradient</a>)</td></tr>
<tr class="separator:ac7654c3b702689ba3c1a9728b405e364"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5381c1a3dc894584b3003ccb361e671b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5381c1a3dc894584b3003ccb361e671b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Rsqrt, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_rsqrt_functor.html">RsqrtFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a5381c1a3dc894584b3003ccb361e671b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef86a2f60a164a5c40604679dd293b2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef86a2f60a164a5c40604679dd293b2f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RsqrtGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_rsqrt_gradient_functor.html">RsqrtGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aef86a2f60a164a5c40604679dd293b2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac29e35364715d2ea46d5b2edd8d22bff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac29e35364715d2ea46d5b2edd8d22bff"></a>
ND input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;ND output tensor&quot;)</td></tr>
<tr class="separator:ac29e35364715d2ea46d5b2edd8d22bff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c691f0d68d33ebcb310b571bfbc3ed4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4c691f0d68d33ebcb310b571bfbc3ed4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Rsqrt, GetRsqrtGradient)</td></tr>
<tr class="separator:a4c691f0d68d33ebcb310b571bfbc3ed4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1159a62c926097876cded3160b7afe95"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1159a62c926097876cded3160b7afe95"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Scale, <a class="el" href="classcaffe2_1_1_scale_op.html">ScaleOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1159a62c926097876cded3160b7afe95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af02ecb0fbf2afa6ea64145dd15900e96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af02ecb0fbf2afa6ea64145dd15900e96"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Scale, <a class="el" href="classcaffe2_1_1_get_scale_gradient.html">GetScaleGradient</a>)</td></tr>
<tr class="separator:af02ecb0fbf2afa6ea64145dd15900e96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa07e060dd9c1c0f4a22082fa13abd792"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa07e060dd9c1c0f4a22082fa13abd792"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Scale, <a class="el" href="classcaffe2_1_1_scale_op.html">ScaleOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aa07e060dd9c1c0f4a22082fa13abd792"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5dc0a350e8ff4a9ea72f066e4470f63a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5dc0a350e8ff4a9ea72f066e4470f63a"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForSparseLengths</b> (const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;inputs, bool use_weight)</td></tr>
<tr class="separator:a5dc0a350e8ff4a9ea72f066e4470f63a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8de183a4bcfc534b34a74aab5871504"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae8de183a4bcfc534b34a74aab5871504"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsIndicesInGradientWeightedSumWithMainInputGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_with_main_input_gradient_op.html">AbstractLengthsWithMainInputGradientOp</a>&lt; float, float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, WeightedSumReducerDef::template ReducerGradient&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, true, true &gt;)</td></tr>
<tr class="separator:ae8de183a4bcfc534b34a74aab5871504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff644a53b8cf580d4b05c161a9053133"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff644a53b8cf580d4b05c161a9053133"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsIndicesInGradientWeightedSumGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">AbstractLengthsGradientOp</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, WeightedSumReducerDef::template ReducerGradient&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, true &gt;)</td></tr>
<tr class="separator:aff644a53b8cf580d4b05c161a9053133"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ee4fbd38ead2ffa712e22a020094b2d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0ee4fbd38ead2ffa712e22a020094b2d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsIndicesInGradientSumGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">AbstractLengthsGradientOp</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, SumReducerDef::template ReducerGradient&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, true &gt;)</td></tr>
<tr class="separator:a0ee4fbd38ead2ffa712e22a020094b2d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3d6dd1f6e01d4b156c6595613c0f0f2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3d6dd1f6e01d4b156c6595613c0f0f2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (LengthsIndicesInGradientSumGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:af3d6dd1f6e01d4b156c6595613c0f0f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed489fa4cf75c02fa66a66da804522d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed489fa4cf75c02fa66a66da804522d6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsIndicesInGradientSumGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">AbstractLengthsGradientOp</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, SumReducerDef::template ReducerGradient&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, true &gt;)</td></tr>
<tr class="separator:aed489fa4cf75c02fa66a66da804522d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abda9c0af62047e7508782d2e204368f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abda9c0af62047e7508782d2e204368f0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseLengthsIndicesInGradientMeanGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">AbstractLengthsGradientOp</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, MeanReducerDef::template ReducerGradient&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, true &gt;)</td></tr>
<tr class="separator:abda9c0af62047e7508782d2e204368f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf5e04ba8cc8b280320cd2fb20be81e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abf5e04ba8cc8b280320cd2fb20be81e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsIndicesInGradientMeanGradient, <a class="el" href="classcaffe2_1_1_abstract_lengths_gradient_op.html">AbstractLengthsGradientOp</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, MeanReducerDef::template ReducerGradient&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;, true &gt;)</td></tr>
<tr class="separator:abf5e04ba8cc8b280320cd2fb20be81e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc21b30af0fee994cd1802c64c4b7617"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc21b30af0fee994cd1802c64c4b7617"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_LENGTHS_OPS_MAIN_INPUT_AND_FORWARD_OUTPUT_GRADIENT</b> (LengthsMax, LengthsMaxWithMainInputAndForwardOutputGradient, <a class="el" href="structcaffe2_1_1_abstract_lengths_def.html">AbstractLengthsDef</a>&lt; float, int, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_max_reducer_def.html">MaxReducerDef</a> &gt;)</td></tr>
<tr class="separator:adc21b30af0fee994cd1802c64c4b7617"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a765ec9d4e39ebf931654f2c753d52065"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a765ec9d4e39ebf931654f2c753d52065"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Selu, <a class="el" href="classcaffe2_1_1_selu_op.html">SeluOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a765ec9d4e39ebf931654f2c753d52065"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a016d28f688e82e9b264309c577b389ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a016d28f688e82e9b264309c577b389ed"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SeluGradient, <a class="el" href="classcaffe2_1_1_selu_gradient_op.html">SeluGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a016d28f688e82e9b264309c577b389ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae897ba88d1994d84709fa0d1464f4b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aae897ba88d1994d84709fa0d1464f4b6"></a>
affects the activation function itself&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;Y&quot;,&quot;input tensor&quot;).Input(1</td></tr>
<tr class="separator:aae897ba88d1994d84709fa0d1464f4b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaef2b5f398ce932ceda8ea5e6f365b3c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaef2b5f398ce932ceda8ea5e6f365b3c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Selu, <a class="el" href="classcaffe2_1_1_get_selu_gradient.html">GetSeluGradient</a>)</td></tr>
<tr class="separator:aaef2b5f398ce932ceda8ea5e6f365b3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a457dd70408b41358d19dc630796e39bc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a457dd70408b41358d19dc630796e39bc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AddPadding, <a class="el" href="classcaffe2_1_1_add_padding_op.html">AddPaddingOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a457dd70408b41358d19dc630796e39bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a675075e89d477f05f8d7086eb11f0aab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a675075e89d477f05f8d7086eb11f0aab"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RemovePadding, <a class="el" href="classcaffe2_1_1_remove_padding_op.html">RemovePaddingOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a675075e89d477f05f8d7086eb11f0aab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e17c64c70ff762d285c362af49eb59a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9e17c64c70ff762d285c362af49eb59a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GatherPadding, <a class="el" href="classcaffe2_1_1_gather_padding_op.html">GatherPaddingOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a9e17c64c70ff762d285c362af49eb59a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca82e1ba385039e99aff711d3b972240"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca82e1ba385039e99aff711d3b972240"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PadEmptySamples, <a class="el" href="classcaffe2_1_1_pad_empty_samples_op.html">PadEmptySamplesOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aca82e1ba385039e99aff711d3b972240"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79da49fb460bb50acc1db902386e2e93"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79da49fb460bb50acc1db902386e2e93"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (AddPadding, <a class="el" href="structcaffe2_1_1_get_add_padding_gradient.html">GetAddPaddingGradient</a>)</td></tr>
<tr class="separator:a79da49fb460bb50acc1db902386e2e93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a6f136ea5a1e636c7b3f222755d20b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2a6f136ea5a1e636c7b3f222755d20b6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (RemovePadding, <a class="el" href="structcaffe2_1_1_get_remove_padding_gradient.html">GetRemovePaddingGradient</a>)</td></tr>
<tr class="separator:a2a6f136ea5a1e636c7b3f222755d20b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d649f5698e37af075f288c57a56f117"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8d649f5698e37af075f288c57a56f117"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given a partitioned tensor $<a class="el" href="struct_t.html">T</a>&lt;N, D_1, ..., D_n&gt;$, where the partitions are
defined as ranges on its outer-most (slowest varying) dimension $N$,
return a tensor $<a class="el" href="struct_t.html">T</a>&lt;(N + 2 * padding\_width), D_1, ..., D_n&gt;$ with paddings
added to the start and end of each range.

Optionally, different paddings can be provided for beginning and end.
Paddings provided must be a tensor $<a class="el" href="struct_t.html">T</a>&lt;D_1, ..., D_n&gt;$. If no padding is
provided, add zero padding. If no lengths vector is provided, add padding
only once, at the start and end of data.

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/sequence_ops.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;AddPadding&quot;,
    [&quot;X&quot;, &quot;lengths&quot;],
    [&quot;Y&quot;, &quot;lengths_out&quot;],
    padding_width=1

)

workspace.FeedBlob(&quot;X&quot;, (np.random.rand(3,2,2).astype(np.float32)))
workspace.FeedBlob(&quot;lengths&quot;, np.array([3]).astype(np.int32))

print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
print(&quot;lengths_out:&quot;, workspace.FetchBlob(&quot;lengths_out&quot;))
```

**Result**

```
X: [[[0.2531572  0.4588472 ]
  [0.45140603 0.61161053]]

 [[0.92500854 0.8045306 ]
  [0.03356671 0.30233648]]

 [[0.4660227  0.6287745 ]
  [0.79372746 0.08609265]]]
Y: [[[0.         0.        ]
  [0.         0.        ]]

 [[0.2531572  0.4588472 ]
  [0.45140603 0.61161053]]

 [[0.92500854 0.8045306 ]
  [0.03356671 0.30233648]]

 [[0.4660227  0.6287745 ]
  [0.79372746 0.08609265]]

 [[0.         0.        ]
  [0.         0.        ]]]
lengths_out: [5]
```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;padding_width&quot;</td></tr>
<tr class="separator:a8d649f5698e37af075f288c57a56f117"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaac64309a878ffdc1ef92b144a026e14"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaac64309a878ffdc1ef92b144a026e14"></a>
will use same as padding_width&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;data_in&quot;,&quot;*(type: <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>)* Input data ($<a class="el" href="struct_t.html">T</a>&lt;N, D_1, ..., D_n&gt;$).&quot;).Input(1</td></tr>
<tr class="separator:aaac64309a878ffdc1ef92b144a026e14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2605fd139f1544bc972b2debd3fb37f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2605fd139f1544bc972b2debd3fb37f"></a>
will use same as padding_width D_n&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;end_padding&quot;,&quot;*(type: <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;int&gt;`)* [OPTIONAL] Padding for range end. If not &quot;&quot;provided, `start_padding` is used ($<a class="el" href="struct_t.html">T</a>&lt;D_1, ..., D_n&gt;$).&quot;).Output(0</td></tr>
<tr class="separator:ac2605fd139f1544bc972b2debd3fb37f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a428db799c25a9ae865811661c949ede7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a428db799c25a9ae865811661c949ede7"></a>
will use same as padding_width D_n D_n&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;lengths_out&quot;,&quot;*(type: <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;int&gt;`)* [OPTIONAL] Lengths for each padded range.&quot;)</td></tr>
<tr class="separator:a428db799c25a9ae865811661c949ede7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf33ff506f4a14a5b653b6af3d9922d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaf33ff506f4a14a5b653b6af3d9922d1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Remove padding around the edges of each segment of the input data. This is the
reverse operation of **AddPadding**, and uses the same arguments and conventions
for input and output data format.

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/sequence_ops.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

addpad_op = core.CreateOperator(
    &quot;AddPadding&quot;,
    [&quot;X&quot;, &quot;lengths_add&quot;],
    [&quot;Y&quot;, &quot;lengths_out_add&quot;],
    padding_width=1
)

rmpad_op = core.CreateOperator(
    &quot;RemovePadding&quot;,
    [&quot;Y&quot;, &quot;lengths_rm&quot;],
    [&quot;Z&quot;, &quot;lengths_out_rm&quot;],
    padding_width=1
)

workspace.FeedBlob(&quot;X&quot;, (np.random.randint(20, size=(3,5))))
workspace.FeedBlob(&quot;lengths_add&quot;, np.array([3]).astype(np.int32))
workspace.FeedBlob(&quot;lengths_rm&quot;, np.array([5]).astype(np.int32))

print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
workspace.RunOperatorOnce(addpad_op)
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))
print(&quot;lengths_out_add:&quot;, workspace.FetchBlob(&quot;lengths_out_add&quot;))

workspace.RunOperatorOnce(rmpad_op)
print(&quot;Z:&quot;, workspace.FetchBlob(&quot;Z&quot;))
print(&quot;lengths_out_rm:&quot;, workspace.FetchBlob(&quot;lengths_out_rm&quot;))
```

**Result**

```
X: [[17 19  1  9  1]
 [19  3  5 19  1]
 [16  0  0  0  4]]
Y: [[ 0  0  0  0  0]
 [17 19  1  9  1]
 [19  3  5 19  1]
 [16  0  0  0  4]
 [ 0  0  0  0  0]]
lengths_out_add: [5]
Z: [[17 19  1  9  1]
 [19  3  5 19  1]
 [16  0  0  0  4]]
lengths_out_rm: [3]
```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;padding_width&quot;</td></tr>
<tr class="separator:aaf33ff506f4a14a5b653b6af3d9922d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b492f8138e6df94e3e98e0c4a0ce55b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7b492f8138e6df94e3e98e0c4a0ce55b"></a>
will use same as padding_width&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;data_in&quot;,&quot;Input tensor ($<a class="el" href="struct_t.html">T</a>&lt;N, D_1, ..., D_n&gt;$).&quot;).Input(1</td></tr>
<tr class="separator:a7b492f8138e6df94e3e98e0c4a0ce55b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34a14a1314cea60e728e626657a7eae7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a34a14a1314cea60e728e626657a7eae7"></a>
will use same as padding_width considers all data as a single segment&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;data_out&quot;,&quot;*(type: <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>)* Padded data tensor &quot;&quot;($<a class="el" href="struct_t.html">T</a>&lt;N + 2*padding_width, D_1, ..., D_n&gt;$).&quot;).Output(1</td></tr>
<tr class="separator:a34a14a1314cea60e728e626657a7eae7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f34acd34d51b4f51a1a476e374d356a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8f34acd34d51b4f51a1a476e374d356a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Gather the sum of start and end paddings in a padded input sequence. Used in
order to compute the gradients of AddPadding w.r.t the padding tensors.
)DOC&quot;).Arg(&quot;padding_width&quot;</td></tr>
<tr class="separator:a8f34acd34d51b4f51a1a476e374d356a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed1f15be8218bd2945b479d6144dc5d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed1f15be8218bd2945b479d6144dc5d0"></a>
Outer size of padding present around each range&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;end_padding_width&quot;,&quot;(Optional) Specifies a different end-padding width.&quot;).Input(0</td></tr>
<tr class="separator:aed1f15be8218bd2945b479d6144dc5d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1fb5e152e469500f34bb06a03d737d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac1fb5e152e469500f34bb06a03d737d0"></a>
Outer size of padding present around each range <a class="el" href="struct_t.html">T</a>&lt; N, D1..., Dn &gt; Padded input data&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;lengths&quot;,&quot;(i64) Num of elements in each range. sum(lengths) = N. &quot;&quot;If not provided, considers all data as a single segment.&quot;).Output(0</td></tr>
<tr class="separator:ac1fb5e152e469500f34bb06a03d737d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6115935115021115751564d81f3ac33"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6115935115021115751564d81f3ac33"></a>
Outer size of padding present around each range <a class="el" href="struct_t.html">T</a>&lt; N, D1..., Dn &gt; Padded input data <a class="el" href="class_sum.html">Sum</a> of all start or of all paddings if end_padding_sum is not provided&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;end_padding_sum&quot;,&quot;<a class="el" href="struct_t.html">T</a>&lt;D1..., Dn&gt; <a class="el" href="class_sum.html">Sum</a> of all end paddings, if provided.&quot;)</td></tr>
<tr class="separator:ae6115935115021115751564d81f3ac33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab83f113ffa9943e7ff8ba7abe29bde50"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab83f113ffa9943e7ff8ba7abe29bde50"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Pad empty field given lengths and index features,

Input(0) is a blob pointing to the lengths of samples in one batch,
[Input(1),... Input(num_fields)] a list of tensors containing the data for
each field of the features.

PadEmptySamples is thread safe.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:ab83f113ffa9943e7ff8ba7abe29bde50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb0ca8450d1746db37b2e14fe187ce0b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adb0ca8450d1746db37b2e14fe187ce0b"></a>
INT_MAX <a class="el" href="struct_a.html">A</a> blob containing a pointer to the lengths&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;out_lengths&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> containing lengths with empty sample padded.&quot;)</td></tr>
<tr class="separator:adb0ca8450d1746db37b2e14fe187ce0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e97663b7dbf517f27fbe11677f5260a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e97663b7dbf517f27fbe11677f5260a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Shape, <a class="el" href="classcaffe2_1_1_shape_op.html">ShapeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8e97663b7dbf517f27fbe11677f5260a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d0a42041a1e404c1d9579d471a47a2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8d0a42041a1e404c1d9579d471a47a2f"></a>
this&#160;</td><td class="memItemRight" valign="bottom"><b>operator only returns the dimensions of the given axes.&quot; &quot;Otherwise, the operator returns the dimensions of all axes.&quot;) .TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in){<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> args(def);const vector&lt; int &gt; &amp;axes=args.GetRepeatedArgument&lt; int &gt;(&quot;axes&quot;);vector&lt; TensorShape &gt; out(1);if(axes.empty()){out[0].add_dims(in[0].dims().size());}else{out[0].add_dims(axes.size());}out[0].set_data_type(TensorProto::INT64);return out;}).SetDoc(R&quot;DOC( Produce a 1D int64 tensor with the shape of the input tensor. If called with an optional argument `axes`</td></tr>
<tr class="separator:a8d0a42041a1e404c1d9579d471a47a2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28d619277791d08459896110ae0b22f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28d619277791d08459896110ae0b22f0"></a>
this the result will only contain the dimensions of specified axes Github workspace FeedBlob(&quot;X&quot;,(np.random.randint(10, size=(2, 3)))) print(&quot;X&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Shape)</td></tr>
<tr class="separator:a28d619277791d08459896110ae0b22f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a570069e0367edaef71f55323bafa08d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a570069e0367edaef71f55323bafa08d0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Shape, <a class="el" href="classcaffe2_1_1_shape_op.html">ShapeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a570069e0367edaef71f55323bafa08d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02193c1bc3d0381c78381de301bdde1d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02193c1bc3d0381c78381de301bdde1d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SigmoidGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sigmoid_gradient_functor.html">SigmoidGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a02193c1bc3d0381c78381de301bdde1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55a39de2621fd3600d6f7b973422bd36"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55a39de2621fd3600d6f7b973422bd36"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="classdnnlowp_1_1_sigmoid.html">Sigmoid</a>, GetSigmoidGradient)</td></tr>
<tr class="separator:a55a39de2621fd3600d6f7b973422bd36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab32b655cb83f7e2b197beaa6d8209449"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab32b655cb83f7e2b197beaa6d8209449"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="classdnnlowp_1_1_sigmoid.html">Sigmoid</a>, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sigmoid_functor.html">SigmoidFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ab32b655cb83f7e2b197beaa6d8209449"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e16d0636c3fe6f41ff3c2acf707907a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e16d0636c3fe6f41ff3c2acf707907a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
SigmoidGradient takes both Y and dY and uses this to update dX according to the
chain rule and derivatives of the sigmoid function.
)DOC&quot;)</td></tr>
<tr class="separator:a6e16d0636c3fe6f41ff3c2acf707907a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39cd146e432a7c9087c34a2d0dd306f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39cd146e432a7c9087c34a2d0dd306f5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="classdnnlowp_1_1_sigmoid.html">Sigmoid</a>, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_op.html">CuDNNActivationOp</a>&lt; CUDNN_ACTIVATION_SIGMOID &gt;)</td></tr>
<tr class="separator:a39cd146e432a7c9087c34a2d0dd306f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a511dea670615ebf44ab368decccb174a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a511dea670615ebf44ab368decccb174a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (SigmoidGradient, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_gradient_op.html">CuDNNActivationGradientOp</a>&lt; CUDNN_ACTIVATION_SIGMOID &gt;)</td></tr>
<tr class="separator:a511dea670615ebf44ab368decccb174a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ca3eedac09e304a32e7569035d6a6da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ca3eedac09e304a32e7569035d6a6da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Sin, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sin_functor.html">SinFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a4ca3eedac09e304a32e7569035d6a6da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a830a1fe9e6693d1deae1de465ddcd2ae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a830a1fe9e6693d1deae1de465ddcd2ae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SinGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sin_gradient_functor.html">SinGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a830a1fe9e6693d1deae1de465ddcd2ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9920d65bd72dee1a6b039019ddc47b2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9920d65bd72dee1a6b039019ddc47b2f"></a>
element wise Github workspace FeedBlob(&quot;X&quot;, np.random.rand(5).astype(np.float32)) print(&quot;X&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (SinGradient).NumInputs(2).NumOutputs(1).IdenticalTypeAndShape()</td></tr>
<tr class="separator:a9920d65bd72dee1a6b039019ddc47b2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77e0d94d77754852fc8522925954f6f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a77e0d94d77754852fc8522925954f6f3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Sin, GetSinGradient)</td></tr>
<tr class="separator:a77e0d94d77754852fc8522925954f6f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40cc8636dc516a1728be60a19b058b5d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a40cc8636dc516a1728be60a19b058b5d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Sinh, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sinh_functor.html">SinhFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a40cc8636dc516a1728be60a19b058b5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef5b6d2999a8e8de428522df78784e88"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef5b6d2999a8e8de428522df78784e88"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SinhGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sinh_gradient_functor.html">SinhGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aef5b6d2999a8e8de428522df78784e88"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d7bca71093b29dc4184d3996af857b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d7bca71093b29dc4184d3996af857b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Sinh, GetSinhGradient)</td></tr>
<tr class="separator:a4d7bca71093b29dc4184d3996af857b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87d4b756535d478a0666d976258040d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87d4b756535d478a0666d976258040d6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SinusoidPositionEncoding, <a class="el" href="classcaffe2_1_1_sinusoid_position_encoding_op.html">SinusoidPositionEncodingOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a87d4b756535d478a0666d976258040d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aadfd33bc9870a035b09ea87ef5865bb3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aadfd33bc9870a035b09ea87ef5865bb3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Slice, <a class="el" href="classcaffe2_1_1_slice_op.html">SliceOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aadfd33bc9870a035b09ea87ef5865bb3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d8d32a262b46a98b7ede4ff5cf536f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2d8d32a262b46a98b7ede4ff5cf536f9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (SliceGradient, <a class="el" href="classcaffe2_1_1_slice_gradient_op.html">SliceGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2d8d32a262b46a98b7ede4ff5cf536f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac17ef3610cd70fcfeffff59ff583cc80"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac17ef3610cd70fcfeffff59ff583cc80"></a>
vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>dst_sizes</b> (data.dims_size())</td></tr>
<tr class="separator:ac17ef3610cd70fcfeffff59ff583cc80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38689ed050d878df3bb175f14eb22dbc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38689ed050d878df3bb175f14eb22dbc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>*): sliced output tensor&quot;).InheritOnnxSchema()</td></tr>
<tr class="separator:a38689ed050d878df3bb175f14eb22dbc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc6baf384e3375ff3a59f094140c970a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc6baf384e3375ff3a59f094140c970a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>GRADIENT_OPERATOR_SCHEMA</b> (SliceGradient)</td></tr>
<tr class="separator:adc6baf384e3375ff3a59f094140c970a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71aa3c09cfa4a5e1b53317e6710f3f5a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a71aa3c09cfa4a5e1b53317e6710f3f5a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Slice, GetSliceGradient)</td></tr>
<tr class="separator:a71aa3c09cfa4a5e1b53317e6710f3f5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad02cb3e67bee38b29103a878b3d710c0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad02cb3e67bee38b29103a878b3d710c0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_softmax.html">Softmax</a>, <a class="el" href="classcaffe2_1_1_softmax_op.html">SoftmaxOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad02cb3e67bee38b29103a878b3d710c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a977c21a3b799ba605432b87a4d3b0eb7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a977c21a3b799ba605432b87a4d3b0eb7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (SoftmaxGradient, <a class="el" href="classcaffe2_1_1_softmax_gradient_op.html">SoftmaxGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a977c21a3b799ba605432b87a4d3b0eb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a582339020ace2b83c80ffeafacca9513"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a582339020ace2b83c80ffeafacca9513"></a>
and sum to The softmax&#160;</td><td class="memItemRight" valign="bottom"><b>operator is typically the last layer in a classifier network, as its output can be interpreted as confidence probabilities of an input belonging to each class.The input is a 2-D tensor</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>) of size(batch_size x input_feature_dimensions).The output tensor has the same shape and contains the softmax normalized values of the corresponding input.The softmax function is defined as follows</td></tr>
<tr class="separator:a582339020ace2b83c80ffeafacca9513"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af330cbed1de990a2c5811866b84ce32f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af330cbed1de990a2c5811866b84ce32f"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>SoftmaxCPU</b> (<a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &amp;context, const int N, const int <a class="el" href="struct_d.html">D</a>, const float *Xdata, float *Ydata, float *scale, const float *sum_multiplier, bool logarithmic, float *rowmax)</td></tr>
<tr class="separator:af330cbed1de990a2c5811866b84ce32f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab68815986ef2a1b95f96ffbf3a9bb2bf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab68815986ef2a1b95f96ffbf3a9bb2bf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SoftmaxWithLoss, <a class="el" href="classcaffe2_1_1_softmax_with_loss_op.html">SoftmaxWithLossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab68815986ef2a1b95f96ffbf3a9bb2bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6b83c6ed7b2c6a7e5828fbd2ceb419b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6b83c6ed7b2c6a7e5828fbd2ceb419b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SoftmaxWithLossGradient, <a class="el" href="classcaffe2_1_1_softmax_with_loss_gradient_op.html">SoftmaxWithLossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae6b83c6ed7b2c6a7e5828fbd2ceb419b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6923dd503673e4a99b2d259489172209"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6923dd503673e4a99b2d259489172209"></a>
vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>out</b> (2)</td></tr>
<tr class="separator:a6923dd503673e4a99b2d259489172209"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6876a6c09b269f742ac40ad44fa22c17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6876a6c09b269f742ac40ad44fa22c17"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>set_data_type</b> (logits.data_type())</td></tr>
<tr class="separator:a6876a6c09b269f742ac40ad44fa22c17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad08b9645e83c41b7e5887bf6ccabe3db"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad08b9645e83c41b7e5887bf6ccabe3db"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (batch_size)</td></tr>
<tr class="separator:ad08b9645e83c41b7e5887bf6ccabe3db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae843583eef085c95eaaf039302d2becc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae843583eef085c95eaaf039302d2becc"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (num_classes)</td></tr>
<tr class="separator:ae843583eef085c95eaaf039302d2becc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c11e913d84151d0470ab8829993f738"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c11e913d84151d0470ab8829993f738"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Combined <a class="el" href="class_softmax.html">Softmax</a> and Cross-Entropy loss operator. The operator first computes the softmax normalized values for each layer in the batch of the given input, then computes cross-entropy loss. This operator is numerically more stable than separate `<a class="el" href="class_softmax.html">Softmax</a>` and `CrossEntropy` ops. The inputs are a 2-<a class="el" href="struct_d.html">D</a> tensor `logits` of size (batch_size x input_feature_dimensions), which represents the unscaled log probabilities, and a 1-dimensional integer `labels` tensor for ground truth. An <a class="el" href="classc10_1_1optional.html">optional</a> third input blob (`weight_tensor`) can be used to weight the samples for the loss, which is useful if the training set is unbalanced. This operator outputs a `softmax` tensor which contains the probability for each label for each example (same shape is `logits` input), and a scalar `loss` value, which is the averaged cross-entropy loss between the softmax probabilities and the ground truth values. Use parameter `label_prob`=1 to enable inputting labels as a probability distribution.

<a class="el" href="class_softmax.html">Softmax</a> cross-entropy loss function:

$$loss(x, class) = -\log{\biggl(\frac{\exp(x[class])}{\sum_{j} \exp(x[j])}\biggr)} = -x[class] + \log{\biggl(\sum_{j} \exp(x[j])\biggr)}$$

or if the `weight_tensor` has been passed:

$$loss(x, class) = weight[class]\biggl(-x[class] + \log{\biggl(\sum_{j} \exp(x[j])\biggr)}\biggr)$$

The `logits` input does not need to explicitly be a 2D vector; rather, it will be coerced into one. For an arbitrary n-dimensional tensor `X` in $[a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}]$, where k is the `axis` provided, then `X` will be coerced into a 2-dimensional tensor with dimensions $[(a_0 * ... * a_{k-1}), (a_k * ... * a_{n-1})]$. For the default case where `axis`=1, the `X` tensor will be coerced into a 2D tensor of dimensions $[a_0, (a_1 * ... * a_{n-1})]$, where $a_0$ is often the batch size. In this situation, we must have $a_0 = N$ and $a_1 * ... * a_{n-1} = D$. Each of these dimensions must be matched correctly, or else the operator will throw errors.

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/softmax_with_loss_op.cc


&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;SoftmaxWithLoss&quot;,
    [&quot;logits&quot;, &quot;labels&quot;],
    [&quot;softmax&quot;, &quot;avgloss&quot;]
)

workspace.FeedBlob(&quot;logits&quot;, np.random.randn(1, 5).astype(np.float32))
workspace.FeedBlob(&quot;labels&quot;, np.asarray([4]).astype(np.int32))
print(&quot;logits:&quot;, workspace.FetchBlob(&quot;logits&quot;))
print(&quot;labels:&quot;, workspace.FetchBlob(&quot;labels&quot;))
workspace.RunOperatorOnce(op)
print(&quot;softmax:&quot;, workspace.FetchBlob(&quot;softmax&quot;))
print(&quot;avgloss:&quot;, workspace.FetchBlob(&quot;avgloss&quot;))

```

**Result**

```

logits: [[-0.3429451  -0.80375195  0.23104447  1.4569176  -0.5268362 ]]
labels: [4]
softmax: [[0.09721052 0.0613179  0.17258129 0.58800864 0.0808817 ]]
avgloss: 2.5147676

```

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example 2&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;SoftmaxWithLoss&quot;,
    [&quot;logits&quot;, &quot;labels&quot;],
    [&quot;softmax&quot;, &quot;avgloss&quot;],
    scale=5.0
)

workspace.FeedBlob(&quot;logits&quot;, np.asarray([[.1, .4, .7, 1.5, .2]]).astype(np.float32))
workspace.FeedBlob(&quot;labels&quot;, np.asarray([4]).astype(np.int32))
print(&quot;logits:&quot;, workspace.FetchBlob(&quot;logits&quot;))
print(&quot;labels:&quot;, workspace.FetchBlob(&quot;labels&quot;))
workspace.RunOperatorOnce(op)
print(&quot;softmax:&quot;, workspace.FetchBlob(&quot;softmax&quot;))
print(&quot;avgloss:&quot;, workspace.FetchBlob(&quot;avgloss&quot;))

```

**Result**

```

logits: [[0.1 0.4 0.7 1.5 0.2]]
labels: [4]
softmax: [[0.10715417 0.144643   0.19524762 0.4345316  0.11842369]]
avgloss: 10.667433

```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;label_prob&quot;</td></tr>
<tr class="separator:a6c11e913d84151d0470ab8829993f738"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a735204b31b0d014e5562cea64a8198"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8a735204b31b0d014e5562cea64a8198"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (SoftmaxWithLossGradient).NumOutputs(1)</td></tr>
<tr class="separator:a8a735204b31b0d014e5562cea64a8198"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa38e74c82fca95c4524df696642fe77a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa38e74c82fca95c4524df696642fe77a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Softplus, <a class="el" href="classcaffe2_1_1_softplus_op.html">SoftplusOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa38e74c82fca95c4524df696642fe77a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36000d81d5598901b3ce01b744e7487f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a36000d81d5598901b3ce01b744e7487f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SoftplusGradient, <a class="el" href="classcaffe2_1_1_softplus_gradient_op.html">SoftplusGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a36000d81d5598901b3ce01b744e7487f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42ecfb1a5c9ef3e173961468e81760d8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42ecfb1a5c9ef3e173961468e81760d8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Softplus, <a class="el" href="classcaffe2_1_1_get_softplus_gradient.html">GetSoftplusGradient</a>)</td></tr>
<tr class="separator:a42ecfb1a5c9ef3e173961468e81760d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09d64f4656348d65cb355ab44de04d9b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09d64f4656348d65cb355ab44de04d9b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Softsign, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_softsign_functor.html">SoftsignFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a09d64f4656348d65cb355ab44de04d9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a617bb89f27ceb8063cc111c6dbb77f67"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a617bb89f27ceb8063cc111c6dbb77f67"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_GRADIENT_OPERATOR</b> (SoftsignGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_softsign_gradient_functor.html">SoftsignGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a617bb89f27ceb8063cc111c6dbb77f67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adafde3a73a6859f7c257053509c23f17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adafde3a73a6859f7c257053509c23f17"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Calculates the softsign gradient (sgn(x)/(1+|x|)^2) of the given input tensor
element-wise.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:adafde3a73a6859f7c257053509c23f17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66f2772ef3acd9daef530ca364c7e7cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a66f2772ef3acd9daef530ca364c7e7cf"></a>
<a class="el" href="struct_d.html">D</a> input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;input&quot;,&quot;1-<a class="el" href="struct_d.html">D</a> input tensor&quot;).Output(0</td></tr>
<tr class="separator:a66f2772ef3acd9daef530ca364c7e7cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff5147e9c8f7b8a0fbed365ce5ab835f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff5147e9c8f7b8a0fbed365ce5ab835f"></a>
<a class="el" href="struct_d.html">D</a> input tensor The softsign&#160;</td><td class="memItemRight" valign="bottom"><b>gradient</b> (sgn(x)/(1+|x|)^2) values of the input tensor&quot; &quot;computed element-wise&quot;)</td></tr>
<tr class="separator:aff5147e9c8f7b8a0fbed365ce5ab835f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a9b1a4af9e42555e0b6b2920fdaf0f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a9b1a4af9e42555e0b6b2920fdaf0f9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Softsign, GetSoftsignGradient)</td></tr>
<tr class="separator:a9a9b1a4af9e42555e0b6b2920fdaf0f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab420c1d380ece4ea2b2ceda61059caa9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab420c1d380ece4ea2b2ceda61059caa9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SpaceToBatch, <a class="el" href="classcaffe2_1_1_space_to_batch_op.html">SpaceToBatchOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab420c1d380ece4ea2b2ceda61059caa9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a324f214084b05a0238c94fe21907330a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a324f214084b05a0238c94fe21907330a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (SpaceToBatch).NumInputs(1).NumOutputs(1).SetDoc(R&quot;DOC( Zero-pads and then rearranges (permutes) blocks of spatial data into batch. More specifically</td></tr>
<tr class="separator:a324f214084b05a0238c94fe21907330a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae254d9f9eeafbecdea613560086a6d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aae254d9f9eeafbecdea613560086a6d5"></a>
only NCHW order is currently&#160;</td><td class="memItemRight" valign="bottom"><b>supported</b> (default=\&quot;NCHW\&quot;)&quot;).Input(0</td></tr>
<tr class="separator:aae254d9f9eeafbecdea613560086a6d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c4af83599ba3c1b2ba3bf3ce8e3c933"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c4af83599ba3c1b2ba3bf3ce8e3c933"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchToSpace, <a class="el" href="classcaffe2_1_1_batch_to_space_op.html">BatchToSpaceOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6c4af83599ba3c1b2ba3bf3ce8e3c933"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a81e46813e3f0c86c3283152e08a62d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a81e46813e3f0c86c3283152e08a62d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (BatchToSpace).NumInputs(1).NumOutputs(1).SetDoc(R&quot;DOC( Rearranges (permutes) data from batch into blocks of spatial data</td></tr>
<tr class="separator:a0a81e46813e3f0c86c3283152e08a62d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a040264084b11f8885462eabf2e448ccf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a040264084b11f8885462eabf2e448ccf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SpaceToBatch, <a class="el" href="classcaffe2_1_1_get_space_to_batch_gradient.html">GetSpaceToBatchGradient</a>)</td></tr>
<tr class="separator:a040264084b11f8885462eabf2e448ccf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae99ac6250b0b0383f1ca68a59d853528"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae99ac6250b0b0383f1ca68a59d853528"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (BatchToSpace, <a class="el" href="classcaffe2_1_1_get_batch_to_space_gradient.html">GetBatchToSpaceGradient</a>)</td></tr>
<tr class="separator:ae99ac6250b0b0383f1ca68a59d853528"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b517dc4d2e20c8e0136c8bad2c10e5e"><td class="memTemplParams" colspan="2"><a class="anchor" id="a3b517dc4d2e20c8e0136c8bad2c10e5e"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a3b517dc4d2e20c8e0136c8bad2c10e5e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>spaceToBatch</b> (const <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;input, int pad_t, int pad_l, int block_size, <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *output, Context *)</td></tr>
<tr class="separator:a3b517dc4d2e20c8e0136c8bad2c10e5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada0de897a5a934409464c3112c7ebb3d"><td class="memTemplParams" colspan="2"><a class="anchor" id="ada0de897a5a934409464c3112c7ebb3d"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:ada0de897a5a934409464c3112c7ebb3d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>batchToSpace</b> (const <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> &amp;input, int pad_t, int pad_l, int block_size, <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> *output, Context *)</td></tr>
<tr class="separator:ada0de897a5a934409464c3112c7ebb3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ad28f101d7677a0b3a740b404e8f713"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7ad28f101d7677a0b3a740b404e8f713"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseNormalize, <a class="el" href="classcaffe2_1_1_sparse_normalize_op.html">SparseNormalizeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7ad28f101d7677a0b3a740b404e8f713"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af11db6b664e5991a32021e3ead53c753"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af11db6b664e5991a32021e3ead53c753"></a>
Parameters to be normalized&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;indices&quot;,&quot;Sparse indices&quot;).Input(2</td></tr>
<tr class="separator:af11db6b664e5991a32021e3ead53c753"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e9949e506c97983c304e6def927d310"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3e9949e506c97983c304e6def927d310"></a>
Parameters to be normalized Gradient computed&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output_param&quot;,&quot;Normalized parameters&quot;).EnforceOneToOneInplace().Arg(&quot;use_max_norm&quot;</td></tr>
<tr class="separator:a3e9949e506c97983c304e6def927d310"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70bbc8cc8136b15d45cb1aa3249cff80"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a70bbc8cc8136b15d45cb1aa3249cff80"></a>
Parameters to be normalized Gradient computed <a class="el" href="struct_a.html">A</a> bool variable to control whether to use max norm or constant norm When constant norm is used so that all the embedding vectors are scaled to have a L2 norm equals to&#160;</td><td class="memItemRight" valign="bottom"><b>A</b> (see blow arugment norm=<a class="el" href="struct_a.html">A</a>).If use_max_norm</td></tr>
<tr class="separator:a70bbc8cc8136b15d45cb1aa3249cff80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad30ab7763e1b43ddf59571e3d4273fbf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad30ab7763e1b43ddf59571e3d4273fbf"></a>
Parameters to be normalized Gradient computed <a class="el" href="struct_a.html">A</a> bool variable to control whether to use max norm or constant norm When constant norm is used so that all the embedding vectors are scaled to have a L2 norm equals to max norm is used so that embedding is scaled so that its l2 norm is no larger than <a class="el" href="struct_a.html">A</a> If an embedding s norm is less than <a class="el" href="struct_a.html">A</a> the embedding is left unchanged The default is True&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;norm&quot;,&quot;L2 norm of the embedding. The default is 1.0.&quot;).SetDoc(R&quot;DOC( Given a sparse matrix</td></tr>
<tr class="separator:ad30ab7763e1b43ddf59571e3d4273fbf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac36c4a2e2bcada3dfabbea97bd7bb56e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac36c4a2e2bcada3dfabbea97bd7bb56e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (SparseNormalize)</td></tr>
<tr class="separator:ac36c4a2e2bcada3dfabbea97bd7bb56e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09acb13ce73b40a3605ef0995ed15260"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09acb13ce73b40a3605ef0995ed15260"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseToDense, <a class="el" href="classcaffe2_1_1_sparse_to_dense_op.html">SparseToDenseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a09acb13ce73b40a3605ef0995ed15260"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6aa1d3a7496d212ca81184a586ea21aa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6aa1d3a7496d212ca81184a586ea21aa"></a>
value represented as indices vector and values tensor into a compacted tensor where the first dimension is determined by the first dimension of the input if it is given or the max index Missing values are filled with zeros The op supports duplicated indices and performs summation over corresponding values This behavior is useful for converting GradientSlices into dense representation After running this&#160;</td><td class="memItemRight" valign="bottom"><b>len</b> (mask)]+shape(default_value)`(if`lengths`is not provided the&quot; &quot;first dimension is omitted)&quot;)</td></tr>
<tr class="separator:a6aa1d3a7496d212ca81184a586ea21aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9e07bf5c8fe8cf9b4271e54079dbe7b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9e07bf5c8fe8cf9b4271e54079dbe7b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SpatialBNGradient, <a class="el" href="classcaffe2_1_1_spatial_b_n_gradient_op.html">SpatialBNGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa9e07bf5c8fe8cf9b4271e54079dbe7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d1d13cabc445187bfb179291dc92224"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0d1d13cabc445187bfb179291dc92224"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> ({5, 7}).NumOutputs(3).AllowInplace(</td></tr>
<tr class="separator:a0d1d13cabc445187bfb179291dc92224"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93a270cc689758874f92fe7d28977027"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a93a270cc689758874f92fe7d28977027"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SpatialBN, GetSpatialBNGradient)</td></tr>
<tr class="separator:a93a270cc689758874f92fe7d28977027"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4982d345187b05f9ad755a509398e7b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4982d345187b05f9ad755a509398e7b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SpatialBN, <a class="el" href="classcaffe2_1_1_spatial_b_n_op.html">SpatialBNOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4982d345187b05f9ad755a509398e7b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb6938e286e8d8c9c81c1a66f5e827f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb6938e286e8d8c9c81c1a66f5e827f6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>AllowInplace</b> ({{0, 0},{5, 3},{6, 4}}).EnforceInplace(</td></tr>
<tr class="separator:acb6938e286e8d8c9c81c1a66f5e827f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51a53a8269f3cb8ab8d99f2674153ad3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a51a53a8269f3cb8ab8d99f2674153ad3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceFunction</b> (CostInferenceForSpatialBN).TensorInferenceFunction([](const OperatorDef &amp;def</td></tr>
<tr class="separator:a51a53a8269f3cb8ab8d99f2674153ad3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20a55f146d684e0d9557bf0f138a6361"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a20a55f146d684e0d9557bf0f138a6361"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (!is_test)</td></tr>
<tr class="separator:a20a55f146d684e0d9557bf0f138a6361"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f532991420ecc68bca56316aa6609c8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4f532991420ecc68bca56316aa6609c8"></a>
SetDoc(R&quot;DOC( Applies spatial batch normalization to the input tensor as described in the original paper, [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167). Be aware, this operator has two different output sets, depending on the value of *is_test*. According to the paper, the primary operation of spatial batch normalization is: $$Y = \frac{X - \mu_x}{\sqrt{\sigma^2_{x} + \epsilon}}*\gamma + b$$ In the equation, $\mu_x$ is the *mean*, $X$ is the input data, $\sigma^2_{x}$ is the *var*, $\epsilon$ is *epsilon*, $\gamma$ is the *scale*, $b$ is the *bias*, and $Y$ is the output data. The *momentum* arg also affects this calculation in the computation of the running mean and variance. The influence of *momentum* is as follows: $$running\_mean = running\_mean * momentum + mean * (1 - momentum)$$ $$running\_var = running\_var * momentum + var * (1 - momentum)$$ Output when is_test = 0 (train mode): *Y, mean, var, saved_mean, saved_var* Output when is_test = 1 (test mode): *Y* Github Links: - https://github.com/pytorch/pytorch/blob/master/caffe2/operators/spatial_batch_norm_op.cc - https://github.com/pytorch/pytorch/blob/master/caffe2/operators/spatial_batch_norm_op.h )DOC&quot;).ArgIsTest(&quot;*(type run spatial batch normalization in test mode&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;epsilon&quot;,&quot;*(type: float; default: 1e-5)* The epsilon value to use to avoid division by zero.&quot;).Arg(&quot;order&quot;</td></tr>
<tr class="separator:a4f532991420ecc68bca56316aa6609c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc79c49317bf65423a9142ad4659c49d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc79c49317bf65423a9142ad4659c49d"></a>
default where $N is batch $<a class="el" href="struct_c.html">C</a> is number of $H is spatial and $W is spatial width The only other valid option is NHWC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;momentum&quot;,&quot;*(type: float; default: 0.9)* Factor used in computing the running mean and variance. e.g., running_mean = running_mean x momentum + mean x (1 - momentum)&quot;).Arg(&quot;num_batches&quot;</td></tr>
<tr class="separator:abc79c49317bf65423a9142ad4659c49d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac716720c13db8ad08339f58c2a48373a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac716720c13db8ad08339f58c2a48373a"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;scale&quot;,&quot;The scale as a 1-dimensional tensor of size $C$ to be applied to the output.&quot;).Input(2</td></tr>
<tr class="separator:ac716720c13db8ad08339f58c2a48373a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afff66078054da3c0f0fafba3c7eb36c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afff66078054da3c0f0fafba3c7eb36c7"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;mean&quot;,&quot;The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size $C$.&quot;).Input(4</td></tr>
<tr class="separator:afff66078054da3c0f0fafba3c7eb36c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d99ca62a7fa72509f8b0b774c4814ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d99ca62a7fa72509f8b0b774c4814ff"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output The running&#160;</td><td class="memItemRight" valign="bottom"><b>variance</b> (training) or the estimated variance(testing) as a 1-dimensional tensor of size $<a class="el" href="struct_c.html">C</a> $.&quot;) .Input( 5</td></tr>
<tr class="separator:a4d99ca62a7fa72509f8b0b774c4814ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f87edd1634e7e668a106c3974d84361"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0f87edd1634e7e668a106c3974d84361"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output The running *<a class="el" href="classc10_1_1optional.html">optional</a> *Per channel sums of elements to be used to determine the mean and variance for this batch&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (6,&quot;sumsq&quot;,&quot;*(<a class="el" href="classc10_1_1optional.html">optional</a>)* Per-channel sum of elements squared per channel to be used to determine the variance for this batch.&quot;).Output(0</td></tr>
<tr class="separator:a0f87edd1634e7e668a106c3974d84361"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e47f1488b14c20530138490777494fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7e47f1488b14c20530138490777494fd"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output The running *<a class="el" href="classc10_1_1optional.html">optional</a> *Per channel sums of elements to be used to determine the mean and variance for this batch The output dimensional tensor of the same shape as $X&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;mean&quot;,&quot;The running mean after the spatial BN operator. Must be in-place with the input *mean*. Should not be used for testing.&quot;).Output(2</td></tr>
<tr class="separator:a7e47f1488b14c20530138490777494fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a674c3db9adfa68626fbf54b57b8ce065"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a674c3db9adfa68626fbf54b57b8ce065"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output The running *<a class="el" href="classc10_1_1optional.html">optional</a> *Per channel sums of elements to be used to determine the mean and variance for this batch The output dimensional tensor of the same shape as $X The running variance after the spatial BN&#160;</td><td class="memItemRight" valign="bottom"><b>operator.Must be in-place with the input *var *.Should not be used for testing.&quot;) .Output</b> (3,&quot;saved_mean&quot;,&quot;Saved mean used during training to speed up gradient computation. Should not be used for testing.&quot;).Output(4</td></tr>
<tr class="separator:a674c3db9adfa68626fbf54b57b8ce065"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef4d8c22623da551896a506709606b45"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef4d8c22623da551896a506709606b45"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output The running *<a class="el" href="classc10_1_1optional.html">optional</a> *Per channel sums of elements to be used to determine the mean and variance for this batch The output dimensional tensor of the same shape as $X The running variance after the spatial BN Saved variance used during training to speed up gradient computation Should not be used for testing&#160;</td><td class="memItemRight" valign="bottom"><b>InheritOnnxSchema</b> (&quot;BatchNormalization&quot;)</td></tr>
<tr class="separator:aef4d8c22623da551896a506709606b45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c9bcafb209f807b50be88e9a5709613"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c9bcafb209f807b50be88e9a5709613"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SpatialSoftmaxWithLoss, <a class="el" href="classcaffe2_1_1_spatial_softmax_with_loss_op.html">SpatialSoftmaxWithLossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3c9bcafb209f807b50be88e9a5709613"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed6a5c55dc68fae54d5f4027159314b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed6a5c55dc68fae54d5f4027159314b4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SpatialSoftmaxWithLossGradient, <a class="el" href="classcaffe2_1_1_spatial_softmax_with_loss_gradient_op.html">SpatialSoftmaxWithLossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aed6a5c55dc68fae54d5f4027159314b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec7bd8f08453c3359bc855816705d7c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec7bd8f08453c3359bc855816705d7c5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE_EQ</b> (logits.dims_size(), 4)</td></tr>
<tr class="separator:aec7bd8f08453c3359bc855816705d7c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b1f94dd12c0042a6b995dfaa75a026a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b1f94dd12c0042a6b995dfaa75a026a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE_EQ</b> (labels.dims_size(), 3)</td></tr>
<tr class="separator:a3b1f94dd12c0042a6b995dfaa75a026a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6eeaa79a67fecbd0ad33c2d03e1a5fd0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6eeaa79a67fecbd0ad33c2d03e1a5fd0"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (in[0].dims(2))</td></tr>
<tr class="separator:a6eeaa79a67fecbd0ad33c2d03e1a5fd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5bb29a6a84d03b75bd36da6a80e38f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5bb29a6a84d03b75bd36da6a80e38f0"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>add_dims</b> (in[0].dims(3))</td></tr>
<tr class="separator:ac5bb29a6a84d03b75bd36da6a80e38f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a331f22d827132ef5c5dac88575b459f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a331f22d827132ef5c5dac88575b459f4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Combined Spatial <a class="el" href="class_softmax.html">Softmax</a> and Cross-Entropy loss operator.
Similar to SoftmaxWithLoss, this operator computes the spatial softmax
normalized values for each layer in the batch of the given input, after which
cross-entropy loss is computed. This operator is numerically more stable than
separate <a class="el" href="class_softmax.html">Softmax</a> and CrossEntropy ops. The inputs are a 2-<a class="el" href="struct_d.html">D</a> tensor
(<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>) of size (batch_size x input_feature_dimensions) and tensor of
labels (ground truth).
Output is tensor with the probability for each label in a pixel for each example
(N x <a class="el" href="struct_d.html">D</a> x W x H) and averaged loss (scalar).
For spatial softmax, weighting is by x,y position of the input.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a331f22d827132ef5c5dac88575b459f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f0fa99118192da210b5c7fe8f6a7c99"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2f0fa99118192da210b5c7fe8f6a7c99"></a>
Unscaled log probabilities&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;labels&quot;,&quot;Ground truth&quot;).Input(2</td></tr>
<tr class="separator:a2f0fa99118192da210b5c7fe8f6a7c99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91aa94028a5011a43bc4388077f64d5d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a91aa94028a5011a43bc4388077f64d5d"></a>
Unscaled log probabilities Optional blob to be used to weight the samples for the loss With spatial weighting is by y of the input&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;softmax&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> with softmax cross entropy loss&quot;).Output(1</td></tr>
<tr class="separator:a91aa94028a5011a43bc4388077f64d5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6460a1858caca6712da0ef4a4b70956"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af6460a1858caca6712da0ef4a4b70956"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (SpatialSoftmaxWithLossGradient).NumOutputs(1)</td></tr>
<tr class="separator:af6460a1858caca6712da0ef4a4b70956"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0315b6cd8328cc1564946a9c64113284"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0315b6cd8328cc1564946a9c64113284"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Sqr, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sqr_functor.html">SqrFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a0315b6cd8328cc1564946a9c64113284"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dbe9c17bf7ec88acaf9751bf48e31f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dbe9c17bf7ec88acaf9751bf48e31f5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Sqr, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_sqr_functor.html">SqrFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a3dbe9c17bf7ec88acaf9751bf48e31f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a403328f6b216bfadc2dadc0c72b8bb78"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a403328f6b216bfadc2dadc0c72b8bb78"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Sqrt, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_sqrt_functor.html">SqrtFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a403328f6b216bfadc2dadc0c72b8bb78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d892864e1389ad4820d765d8e90b0c4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d892864e1389ad4820d765d8e90b0c4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Sqrt, GetSqrtGradient)</td></tr>
<tr class="separator:a9d892864e1389ad4820d765d8e90b0c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acaf2ade9cc2ccf832fc123741e93e620"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acaf2ade9cc2ccf832fc123741e93e620"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Sqrt, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a>, <a class="el" href="structcaffe2_1_1_sqrt_functor.html">SqrtFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;&gt;)</td></tr>
<tr class="separator:acaf2ade9cc2ccf832fc123741e93e620"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0c3b548215e4cec56262725afda6b4c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0c3b548215e4cec56262725afda6b4c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SquareRootDivide, <a class="el" href="classcaffe2_1_1_square_root_divide_op.html">SquareRootDivideOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab0c3b548215e4cec56262725afda6b4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abcb72afa45c13fc89d6eaf103b15aa6e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abcb72afa45c13fc89d6eaf103b15aa6e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Given DATA tensor with first dimension N and SCALE vector of the same size N
produces an output tensor with same dimensions as DATA. Which consists of DATA
slices. i-th slice is divided by sqrt(SCALE[i]) elementwise. If SCALE[i] == 0
output slice is identical to the input one (no scaling)

Example:

  <a class="el" href="classnom_1_1repr_1_1_data.html">Data</a> = [
    [2.0, 4.0],
    [9.0, 12.0]
  ]

  SCALE = [4, 9]

  OUTPUT = [
    [1.0, 2.0],
    [3.0, 4.0]
  ]

)DOC&quot;)</td></tr>
<tr class="separator:abcb72afa45c13fc89d6eaf103b15aa6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0e55834dad0dcb118ea8da02d9d5d4b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af0e55834dad0dcb118ea8da02d9d5d4b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SquareRootDivide, <a class="el" href="classcaffe2_1_1_get_square_root_divide_gradient.html">GetSquareRootDivideGradient</a>)</td></tr>
<tr class="separator:af0e55834dad0dcb118ea8da02d9d5d4b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a947b928814ca9f64e4f32f3a7fee42d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a947b928814ca9f64e4f32f3a7fee42d6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StatRegistryCreate, <a class="el" href="classcaffe2_1_1_stat_registry_create_op.html">StatRegistryCreateOp</a>)</td></tr>
<tr class="separator:a947b928814ca9f64e4f32f3a7fee42d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bb1ebf8f3c49af26f704b0abcb55a9d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9bb1ebf8f3c49af26f704b0abcb55a9d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StatRegistryUpdate, <a class="el" href="classcaffe2_1_1_stat_registry_update_op.html">StatRegistryUpdateOp</a>)</td></tr>
<tr class="separator:a9bb1ebf8f3c49af26f704b0abcb55a9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4fcd969fdcee60b30fbc53cacde305ce"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4fcd969fdcee60b30fbc53cacde305ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StatRegistryExport, <a class="el" href="classcaffe2_1_1_stat_registry_export_op.html">StatRegistryExportOp</a>)</td></tr>
<tr class="separator:a4fcd969fdcee60b30fbc53cacde305ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f762eed64a7875a6caae9f43fbe6b85"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6f762eed64a7875a6caae9f43fbe6b85"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TimerBegin, <a class="el" href="structcaffe2_1_1_timer_begin_op.html">TimerBeginOp</a>)</td></tr>
<tr class="separator:a6f762eed64a7875a6caae9f43fbe6b85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab73b9c12c10069e14de4781ef1ea0dae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab73b9c12c10069e14de4781ef1ea0dae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TimerEnd, <a class="el" href="structcaffe2_1_1_timer_end_op.html">TimerEndOp</a>)</td></tr>
<tr class="separator:ab73b9c12c10069e14de4781ef1ea0dae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49b3b697e874e1137d79248796227788"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a49b3b697e874e1137d79248796227788"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TimerGetAndEnd, <a class="el" href="structcaffe2_1_1_timer_get_and_end_op.html">TimerGetAndEndOp</a>)</td></tr>
<tr class="separator:a49b3b697e874e1137d79248796227788"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ec4b8457442b8958e7b79653dc6f47f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0ec4b8457442b8958e7b79653dc6f47f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TimerGet, <a class="el" href="structcaffe2_1_1_timer_get_op.html">TimerGetOp</a>)</td></tr>
<tr class="separator:a0ec4b8457442b8958e7b79653dc6f47f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada795b1960e8d3ffe34b092ac0806418"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada795b1960e8d3ffe34b092ac0806418"></a>
or the global with the values of counters for the given keys DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;keys&quot;,&quot;1D string tensor with the key names to update.&quot;).Input(1</td></tr>
<tr class="separator:ada795b1960e8d3ffe34b092ac0806418"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa23b57e12b7dc88039a836441541817"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa23b57e12b7dc88039a836441541817"></a>
or the global with the values of counters for the given keys DOC int64 tensor with the values to update&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;handle&quot;,&quot;If provided, update the given StatRegistry. &quot;&quot;Otherwise, update the global singleton.&quot;)</td></tr>
<tr class="separator:afa23b57e12b7dc88039a836441541817"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1d980522c1c72552127407d3a5a3743"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad1d980522c1c72552127407d3a5a3743"></a>
If export values from given <a class="el" href="classcaffe2_1_1_stat_registry.html">StatRegistry</a> export values from the global singleton <a class="el" href="classcaffe2_1_1_stat_registry.html">StatRegistry</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;keys&quot;,&quot;1D string tensor with exported key names&quot;).Output(1</td></tr>
<tr class="separator:ad1d980522c1c72552127407d3a5a3743"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add1af22e4a93991716a74fcd1196974f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="add1af22e4a93991716a74fcd1196974f"></a>
If export values from given <a class="el" href="classcaffe2_1_1_stat_registry.html">StatRegistry</a> export values from the global singleton <a class="el" href="classcaffe2_1_1_stat_registry.html">StatRegistry</a> int64 tensor with exported values&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (2,&quot;timestamps&quot;,&quot;The unix timestamp at counter retrieval.&quot;).Arg(&quot;reset&quot;</td></tr>
<tr class="separator:add1af22e4a93991716a74fcd1196974f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2bb9d28bd739a5b06c4f585ce3c67a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2bb9d28bd739a5b06c4f585ce3c67a1"></a>
if not set use output name&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;timer&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;ptr&gt;`*): pointer to a timer object&quot;)</td></tr>
<tr class="separator:ab2bb9d28bd739a5b06c4f585ce3c67a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e7355ede007fdc232adcac831116ee2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e7355ede007fdc232adcac831116ee2"></a>
obtained from **TimerBegin **op&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;nanos&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;int64&gt;`*): scalar tensor containing time in nanoseconds&quot;)</td></tr>
<tr class="separator:a1e7355ede007fdc232adcac831116ee2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad935703605922e78fa8bd9b82c7f7cbe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad935703605922e78fa8bd9b82c7f7cbe"></a>
NumInputs(1).NumOutputs(1).SetDoc(R&quot;DOC( Queries the current time of a timer object in nanoseconds. Github Links obtained from** TimerBegin** op&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;nanos&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;int64&gt;`*): scalar containing time in nanoseconds&quot;)</td></tr>
<tr class="separator:ad935703605922e78fa8bd9b82c7f7cbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6af853c31c48049e4fb29e79f4a7dd7b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6af853c31c48049e4fb29e79f4a7dd7b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="classcaffe2_1_1_timer_instance.html">TimerInstance</a> *)</td></tr>
<tr class="separator:a6af853c31c48049e4fb29e79f4a7dd7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a81ede51ee5a53b2ae755e010c7bbd1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a81ede51ee5a53b2ae755e010c7bbd1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_stat_registry.html">caffe2::StatRegistry</a> &gt;)</td></tr>
<tr class="separator:a7a81ede51ee5a53b2ae755e010c7bbd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75ba506799a8917026a4edcdb7bdb518"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75ba506799a8917026a4edcdb7bdb518"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_TEMPLATED_STAT_PUT_OP</b> (AveragePut, AveragePutStat, CAFFE_AVG_EXPORTED_STAT).NumInputs(1).NumOutputs(0).Arg(&quot;name&quot;</td></tr>
<tr class="separator:a75ba506799a8917026a4edcdb7bdb518"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88d069b12a05a4e14e8d34ec85d797dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a88d069b12a05a4e14e8d34ec85d797dc"></a>
str then uses name of input blob&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;magnitude_expand&quot;,&quot;(*int64_t*): number to multiply input values by (used when inputting floats, as stats can only receive integers&quot;).Arg(&quot;bound&quot;</td></tr>
<tr class="separator:a88d069b12a05a4e14e8d34ec85d797dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a213c36b983d82f919175573304a2bdfc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a213c36b983d82f919175573304a2bdfc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_TEMPLATED_STAT_PUT_OP</b> (IncrementPut, IncrementPutStat, CAFFE_EXPORTED_STAT).NumInputs(1).NumOutputs(0).Arg(&quot;name&quot;</td></tr>
<tr class="separator:a213c36b983d82f919175573304a2bdfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c001d143f41c71a2ae9a1d096abaa4a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c001d143f41c71a2ae9a1d096abaa4a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_TEMPLATED_STAT_PUT_OP</b> (StdDevPut, StdDevPutStat, CAFFE_STDDEV_EXPORTED_STAT).NumInputs(1).NumOutputs(0).Arg(&quot;name&quot;</td></tr>
<tr class="separator:a1c001d143f41c71a2ae9a1d096abaa4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c9c44b3bbe9a0c7261d2fa150ed44f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c9c44b3bbe9a0c7261d2fa150ed44f0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StopGradient, <a class="el" href="classcaffe2_1_1_stop_gradient_op.html">StopGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3c9c44b3bbe9a0c7261d2fa150ed44f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad70b4f20dad2d5a18250d99f5fc0e240"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad70b4f20dad2d5a18250d99f5fc0e240"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (1, 1).NumOutputs(1</td></tr>
<tr class="separator:ad70b4f20dad2d5a18250d99f5fc0e240"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17f3e2378b53644049d680b1e2eacf51"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17f3e2378b53644049d680b1e2eacf51"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (StopGradient)</td></tr>
<tr class="separator:a17f3e2378b53644049d680b1e2eacf51"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af43c511fa3130c7afe22940995b8b5f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af43c511fa3130c7afe22940995b8b5f8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (StopGradient, <a class="el" href="classcaffe2_1_1_stop_gradient_op.html">StopGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:af43c511fa3130c7afe22940995b8b5f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae75914ab559eb16ba25307c73efc4671"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae75914ab559eb16ba25307c73efc4671"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StumpFunc, <a class="el" href="classcaffe2_1_1_stump_func_op.html">StumpFuncOp</a>&lt; float, float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae75914ab559eb16ba25307c73efc4671"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc441f354e6b0356f5ea2eae8b73540b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc441f354e6b0356f5ea2eae8b73540b"></a>
tensor of float&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Y&quot;,&quot;tensor of float&quot;).SetDoc(R&quot;DOC( Converts each input element into either high_ or low_value based on the given threshold. )DOC&quot;)</td></tr>
<tr class="separator:abc441f354e6b0356f5ea2eae8b73540b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09d3cac23910d2f6a70c09aef7688183"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09d3cac23910d2f6a70c09aef7688183"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (StumpFunc)</td></tr>
<tr class="separator:a09d3cac23910d2f6a70c09aef7688183"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17248dddb71b5b0ce62bce7fedbfbe53"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17248dddb71b5b0ce62bce7fedbfbe53"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (StumpFuncIndex, <a class="el" href="classcaffe2_1_1_stump_func_index_op.html">StumpFuncIndexOp</a>&lt; float, int64_t, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a17248dddb71b5b0ce62bce7fedbfbe53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad5743abb54d69625e63331a4fa8777d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aad5743abb54d69625e63331a4fa8777d"></a>
tensor of float&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;Index_Low&quot;,&quot;tensor of int64 indices for elements below/equal threshold&quot;).Output(1</td></tr>
<tr class="separator:aad5743abb54d69625e63331a4fa8777d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb5b25a56195e67af3e25aab94c1ef5c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abb5b25a56195e67af3e25aab94c1ef5c"></a>
tensor of float tensor of int64 indices for elements above threshold&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Split the elemnts and return the indices based on the given threshold.
)DOC&quot;)</td></tr>
<tr class="separator:abb5b25a56195e67af3e25aab94c1ef5c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accf0f26b4689b599f498a4969d7a993b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="accf0f26b4689b599f498a4969d7a993b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (StumpFuncIndex)</td></tr>
<tr class="separator:accf0f26b4689b599f498a4969d7a993b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79be8b7fdf68059a885842174018f40f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79be8b7fdf68059a885842174018f40f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Summarize, <a class="el" href="classcaffe2_1_1_summarize_op.html">SummarizeOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a79be8b7fdf68059a885842174018f40f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79ded43c280d87674af5e0eb246800d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79ded43c280d87674af5e0eb246800d2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Summarize computes four statistics of the input tensor (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>)- min,
max, mean and standard deviation. The output will be written to a 1-<a class="el" href="struct_d.html">D</a> tensor of
size 4 if an output tensor is provided. Else, if the argument 'to_file' is
greater than 0, the values are written to a log file in the root folder.
)DOC&quot;).Arg(&quot;to_file&quot;</td></tr>
<tr class="separator:a79ded43c280d87674af5e0eb246800d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf6d9c1271270be19a367258a67a6250"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf6d9c1271270be19a367258a67a6250"></a>
default flag to indicate if the summarized statistics have to be written to a log file&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;data&quot;,&quot;The input data as Tensor.&quot;).Output(0</td></tr>
<tr class="separator:adf6d9c1271270be19a367258a67a6250"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a557f680c65f7c60f730e3434de03a9d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a557f680c65f7c60f730e3434de03a9d9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Summarize)</td></tr>
<tr class="separator:a557f680c65f7c60f730e3434de03a9d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ace4c0d4a0c937f1e60f14389dc26d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ace4c0d4a0c937f1e60f14389dc26d5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Swish, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_swish_functor.html">SwishFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a5ace4c0d4a0c937f1e60f14389dc26d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a973504de09e21e287f4c07e100ebc990"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a973504de09e21e287f4c07e100ebc990"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SwishGradient, <a class="el" href="classcaffe2_1_1_swish_gradient_op.html">SwishGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a973504de09e21e287f4c07e100ebc990"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74f588c2b952bc81bdb006316f4d7445"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a74f588c2b952bc81bdb006316f4d7445"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
SwishGradient takes X, Y and dY and uses this to update dX according to the
chain rule and derivatives of the swish function.
)DOC&quot;)</td></tr>
<tr class="separator:a74f588c2b952bc81bdb006316f4d7445"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ef8e2c5ad3aef552dd397e80a117924"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0ef8e2c5ad3aef552dd397e80a117924"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Swish, GetSwishGradient)</td></tr>
<tr class="separator:a0ef8e2c5ad3aef552dd397e80a117924"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08971ebeba95f0a8ac32dc3114baffd1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08971ebeba95f0a8ac32dc3114baffd1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Tan, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_tan_functor.html">TanFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a08971ebeba95f0a8ac32dc3114baffd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a564dbc66c96181b0d9e71891b0ca9f58"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a564dbc66c96181b0d9e71891b0ca9f58"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TanGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_tan_gradient_functor.html">TanGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:a564dbc66c96181b0d9e71891b0ca9f58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85ee179aeffb22d159f202f35c98eb0f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a85ee179aeffb22d159f202f35c98eb0f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (TanGradient).NumInputs(2).NumOutputs(1).IdenticalTypeAndShape()</td></tr>
<tr class="separator:a85ee179aeffb22d159f202f35c98eb0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a102ea416ac36e1b8f54b729347a39dad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a102ea416ac36e1b8f54b729347a39dad"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Tan, GetTanGradient)</td></tr>
<tr class="separator:a102ea416ac36e1b8f54b729347a39dad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea464381f9fcf03a441d5425b2654f5d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea464381f9fcf03a441d5425b2654f5d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TanhGradient, <a class="el" href="classcaffe2_1_1_binary_elementwise_with_args_op.html">BinaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_tanh_gradient_functor.html">TanhGradientFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:aea464381f9fcf03a441d5425b2654f5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acee5d1c143195645494061c4633bd99c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acee5d1c143195645494061c4633bd99c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (<a class="el" href="classdnnlowp_1_1_tanh.html">Tanh</a>, GetTanhGradient)</td></tr>
<tr class="separator:acee5d1c143195645494061c4633bd99c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae18f24761f5d085c9e36b8ff1058e83a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae18f24761f5d085c9e36b8ff1058e83a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="classdnnlowp_1_1_tanh.html">Tanh</a>, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_op.html">UnaryElementwiseOp</a>&lt; <a class="el" href="structcaffe2_1_1_tensor_types.html">TensorTypes</a>&lt; float &gt;, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, <a class="el" href="structcaffe2_1_1_tanh_functor.html">TanhFunctor</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&gt;)</td></tr>
<tr class="separator:ae18f24761f5d085c9e36b8ff1058e83a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d7c29504207f039052d65f7b5e1d70d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6d7c29504207f039052d65f7b5e1d70d"></a>
by providing the same input and output blobs Github workspace FeedBlob(&quot;X&quot;, np.random.randn(3, 3).astype(np.float32)) print(&quot;X&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (TanhGradient).NumInputs(2).NumOutputs(1).AllowInplace(</td></tr>
<tr class="separator:a6d7c29504207f039052d65f7b5e1d70d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad58956d0b0a375fa7d7277fe31eac7c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad58956d0b0a375fa7d7277fe31eac7c9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (<a class="el" href="classdnnlowp_1_1_tanh.html">Tanh</a>, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_op.html">CuDNNActivationOp</a>&lt; CUDNN_ACTIVATION_TANH &gt;)</td></tr>
<tr class="separator:ad58956d0b0a375fa7d7277fe31eac7c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e21e70471c964de4bb999bd1ddd73ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e21e70471c964de4bb999bd1ddd73ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (TanhGradient, <a class="el" href="classcaffe2_1_1_cu_d_n_n_activation_gradient_op.html">CuDNNActivationGradientOp</a>&lt; CUDNN_ACTIVATION_TANH &gt;)</td></tr>
<tr class="separator:a4e21e70471c964de4bb999bd1ddd73ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a219c46db626227d4ff918d046d71f6de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a219c46db626227d4ff918d046d71f6de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a>, <a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a219c46db626227d4ff918d046d71f6de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93d5eebb6c87e935c3d2a04966ad1b65"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a93d5eebb6c87e935c3d2a04966ad1b65"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
<a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a> is a simple input operator that basically reads things
from a db where each key-value pair stores an index as key, and a TensorProtos
object as value. These TensorProtos objects should have the same size, and they
will be grouped into batches of the given size. The DB Reader is provided as
input to the operator and it returns as many output tensors as the size of the
TensorProtos object. Each output will simply be a tensor containing a batch of
data with size specified by the 'batch_size' argument containing data from the
corresponding index in the TensorProtos objects in the DB.
)DOC&quot;).Arg(&quot;batch_size&quot;</td></tr>
<tr class="separator:a93d5eebb6c87e935c3d2a04966ad1b65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad35c38ea3c93f0262c826ba9e68cc4b8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad35c38ea3c93f0262c826ba9e68cc4b8"></a>
INT_MAX default the number of samples in a batch The default value of means that the&#160;</td><td class="memItemRight" valign="bottom"><b>operator will attempt to insert the&quot; &quot;entire data in a single output blob.&quot;) .Input</b> (0,&quot;data&quot;,&quot;<a class="el" href="struct_a.html">A</a> pre-initialized DB reader. Typically, this is obtained &quot;&quot;by calling CreateDB operator with a db_name and a db_type. The &quot;&quot;resulting output blob is a DB Reader tensor&quot;).Output(0</td></tr>
<tr class="separator:ad35c38ea3c93f0262c826ba9e68cc4b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7748fe15bc09a061bf89e9a247e047b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad7748fe15bc09a061bf89e9a247e047b"></a>
INT_MAX default the number of samples in a batch The default value of means that the The output tensor in which the batches of data are returned The number of output tensors is equal to the size&#160;</td><td class="memItemRight" valign="bottom"><b>of</b> (number of TensorProto's in) the TensorProtos objects stored in the&quot; &quot;DB as values.Each output tensor will be of size specified by the&quot; &quot;'batch_size'argument of the operator&quot;)</td></tr>
<tr class="separator:ad7748fe15bc09a061bf89e9a247e047b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae92e600afc08d689214d6599a487711c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae92e600afc08d689214d6599a487711c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (<a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a>)</td></tr>
<tr class="separator:ae92e600afc08d689214d6599a487711c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7232ef46b5b3aec6fc354c6a405a69fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7232ef46b5b3aec6fc354c6a405a69fe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a>, <a class="el" href="classcaffe2_1_1_tensor_protos_d_b_input.html">TensorProtosDBInput</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a7232ef46b5b3aec6fc354c6a405a69fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada8e805d96f97616cd7c18e7d907e68b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada8e805d96f97616cd7c18e7d907e68b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>convert</b> (TensorProto_DataType dst_type, const char *src_start, const char *src_end, void *dst)</td></tr>
<tr class="separator:ada8e805d96f97616cd7c18e7d907e68b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab56b6d215becf9a310049b4bb853f3a2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab56b6d215becf9a310049b4bb853f3a2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (std::unique_ptr&lt; <a class="el" href="structcaffe2_1_1_text_file_reader_instance.html">TextFileReaderInstance</a> &gt;)</td></tr>
<tr class="separator:ab56b6d215becf9a310049b4bb853f3a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf9ee50ab7d20684506fa4dcbda07ed6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf9ee50ab7d20684506fa4dcbda07ed6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CreateTextFileReader, <a class="el" href="classcaffe2_1_1_create_text_file_reader_op.html">CreateTextFileReaderOp</a>)</td></tr>
<tr class="separator:adf9ee50ab7d20684506fa4dcbda07ed6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5cfbe745c880086940762dea36c1e2a9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5cfbe745c880086940762dea36c1e2a9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TextFileReaderRead, <a class="el" href="classcaffe2_1_1_text_file_reader_read_op.html">TextFileReaderReadOp</a>)</td></tr>
<tr class="separator:a5cfbe745c880086940762dea36c1e2a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6d6c3d33bdb04eae6c1c6f75b1e86a9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af6d6c3d33bdb04eae6c1c6f75b1e86a9"></a>
Path to the file&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;num_passes&quot;,&quot;Number of passes over the file.&quot;).Arg(&quot;field_types&quot;</td></tr>
<tr class="separator:af6d6c3d33bdb04eae6c1c6f75b1e86a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d70e0e4f2ec0ab30e9748fa226ee11d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5d70e0e4f2ec0ab30e9748fa226ee11d"></a>
Path to the file List with type of each field <a class="el" href="structc10_1_1_type.html">Type</a> enum is found at core DataType&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;handler&quot;,&quot;Pointer to the created TextFileReaderInstance.&quot;)</td></tr>
<tr class="separator:a5d70e0e4f2ec0ab30e9748fa226ee11d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6451fbf98f4e05b993bc4af56aeea1cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6451fbf98f4e05b993bc4af56aeea1cd"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (&quot;Read a batch of rows from the given text file reader instance. &quot;&quot;Expects the number of fields to be equal to the number of outputs. &quot;&quot;Each output is a 1D tensor containing the values for the given field &quot;&quot;for each row. When end of file is reached, returns empty tensors.&quot;).Input(0</td></tr>
<tr class="separator:a6451fbf98f4e05b993bc4af56aeea1cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a136d24eb740516b496943705ac3e5c7a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a136d24eb740516b496943705ac3e5c7a"></a>
INT_MAX Pointer to an existing <a class="el" href="structcaffe2_1_1_text_file_reader_instance.html">TextFileReaderInstance</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;batch_size&quot;,&quot;Maximum number of rows to read.&quot;)</td></tr>
<tr class="separator:a136d24eb740516b496943705ac3e5c7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2a2b51625c32a85bb9d121d9a2bf0e8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae2a2b51625c32a85bb9d121d9a2bf0e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (CreateTextFileReader)</td></tr>
<tr class="separator:ae2a2b51625c32a85bb9d121d9a2bf0e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0caaac7cf5c9d7e053638babf99bdbe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0caaac7cf5c9d7e053638babf99bdbe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (TextFileReaderRead)</td></tr>
<tr class="separator:ab0caaac7cf5c9d7e053638babf99bdbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bb6e77295467e6a75b22d917da50f71"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4bb6e77295467e6a75b22d917da50f71"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ThresholdedRelu, <a class="el" href="classcaffe2_1_1_thresholded_relu_op.html">ThresholdedReluOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4bb6e77295467e6a75b22d917da50f71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19c8e69a96cb294a7072d3345b30aa04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a19c8e69a96cb294a7072d3345b30aa04"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ThresholdedReluGradient, <a class="el" href="classcaffe2_1_1_thresholded_relu_gradient_op.html">ThresholdedReluGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a19c8e69a96cb294a7072d3345b30aa04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aced5b04811dbf39ebcee085bb455bfd7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aced5b04811dbf39ebcee085bb455bfd7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Tile, <a class="el" href="classcaffe2_1_1_tile_op.html">TileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aced5b04811dbf39ebcee085bb455bfd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad071156c05886ae5ce8ac821501e7070"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad071156c05886ae5ce8ac821501e7070"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TileGradient, <a class="el" href="classcaffe2_1_1_tile_gradient_op.html">TileGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad071156c05886ae5ce8ac821501e7070"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a568d4a61e2de1126edd7197cf1e12bb0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a568d4a61e2de1126edd7197cf1e12bb0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (in.size() &gt; 1)</td></tr>
<tr class="separator:a568d4a61e2de1126edd7197cf1e12bb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a69515e1123cfcce23781a643803a22"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a69515e1123cfcce23781a643803a22"></a>
out[0]&#160;</td><td class="memItemRight" valign="bottom"><b>set_dims</b> (canonical_axis, out[0].dims().Get(canonical_axis)*tiles)</td></tr>
<tr class="separator:a0a69515e1123cfcce23781a643803a22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab008242ce75bb065e9a4e80d87ab4adf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab008242ce75bb065e9a4e80d87ab4adf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Constructs a tensor by tiling a given tensor along a specified axis. This operation creates a new tensor by replicating the input tensor a number of times specified by the `tiles` argument along the `axis` dimension. The output tensor's `axis` dimension has $(X.dims(axis) * tiles)$ elements.

Github Links:
- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/tile_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```

workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Tile&quot;,
    [&quot;X&quot;, &quot;tiles&quot;, &quot;axis&quot;],
    [&quot;Y&quot;]
)

workspace.FeedBlob(&quot;X&quot;, np.random.randint(10, size=(5,5)))
workspace.FeedBlob(&quot;tiles&quot;, np.array([5]).astype(np.int32))
workspace.FeedBlob(&quot;axis&quot;, np.array([1]).astype(np.int32))
print(&quot;X:&quot;, workspace.FetchBlob(&quot;X&quot;))
workspace.RunOperatorOnce(op)
print(&quot;Y:&quot;, workspace.FetchBlob(&quot;Y&quot;))

```

**Result**

```

X:
[[9 1 7 1 3]
 [2 3 6 2 5]
 [0 9 2 6 4]
 [5 8 1 5 9]
 [2 0 1 3 7]]
Y:
[[9 1 7 1 3 9 1 7 1 3 9 1 7 1 3 9 1 7 1 3 9 1 7 1 3]
 [2 3 6 2 5 2 3 6 2 5 2 3 6 2 5 2 3 6 2 5 2 3 6 2 5]
 [0 9 2 6 4 0 9 2 6 4 0 9 2 6 4 0 9 2 6 4 0 9 2 6 4]
 [5 8 1 5 9 5 8 1 5 9 5 8 1 5 9 5 8 1 5 9 5 8 1 5 9]
 [2 0 1 3 7 2 0 1 3 7 2 0 1 3 7 2 0 1 3 7 2 0 1 3 7]]

```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;tiles&quot;</td></tr>
<tr class="separator:ab008242ce75bb065e9a4e80d87ab4adf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b19f8c7e52f0be20be3e3ac9b79499f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b19f8c7e52f0be20be3e3ac9b79499f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (TileGradient).NumInputs(1</td></tr>
<tr class="separator:a0b19f8c7e52f0be20be3e3ac9b79499f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf75898e19a1c52e1528eb3440a208de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf75898e19a1c52e1528eb3440a208de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Tile, GetTileGradient)</td></tr>
<tr class="separator:adf75898e19a1c52e1528eb3440a208de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b28296fcf9749bca35b17dbfc2a2ba1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4b28296fcf9749bca35b17dbfc2a2ba1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TopK, <a class="el" href="classcaffe2_1_1_top_k_op.html">TopKOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4b28296fcf9749bca35b17dbfc2a2ba1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a990b405ba4c8182efbaea6a6905633e2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a990b405ba4c8182efbaea6a6905633e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (TopKGradient, <a class="el" href="classcaffe2_1_1_top_k_gradient_op.html">TopKGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a990b405ba4c8182efbaea6a6905633e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a804378e4b4b30882f8a4c62f5ab2b2a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a804378e4b4b30882f8a4c62f5ab2b2a0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in){vector&lt; TensorShape &gt; out={in[0], in[0]};<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> helper(def);auto k=helper.GetSingleArgument(&quot;k&quot;,-1);auto dims_size=in[0].dims_size();out[0].set_dims(dims_size-1, k);out[1].set_dims(dims_size-1, k);out[1].set_data_type(TensorProto_DataType_INT32);if(def.output_size() &gt; 2){TensorShape flatten_indices_shape;flatten_indices_shape.set_data_type(TensorProto_DataType_INT32);flatten_indices_shape.add_dims(std::accumulate(in[0].dims().begin(), in[0].dims().end()-1, 1, std::multiplies&lt; long &gt;())*k);out.push_back(flatten_indices_shape);}return out;}).SetDoc(R&quot;DOC( Retrieve the top-K elements of the last dimension. Given an input tensor of shape $(a_1</td></tr>
<tr class="separator:a804378e4b4b30882f8a4c62f5ab2b2a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abead22ac4f7834d4a7d940a2a14728bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abead22ac4f7834d4a7d940a2a14728bb"></a>
r and integer argument return up to three k which contains the values of the top k elements along the last dimension <a class="el" href="structcaffe2_1_1_index.html">Index</a> tensor of&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (a_1, a_2,..., a_n, k)$which contains the indices of the top k elements(original indices from the input tensor).3.[OPTIONAL] Flattened index tensor of shape $(a_1 *a_2 *...*a_n *k</td></tr>
<tr class="separator:abead22ac4f7834d4a7d940a2a14728bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa865e4885a4fa02c18605ce2137a9f59"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa865e4885a4fa02c18605ce2137a9f59"></a>
r and integer argument return up to three k which contains the values of the top k elements along the last dimension <a class="el" href="structcaffe2_1_1_index.html">Index</a> tensor of Given two equivalent this&#160;</td><td class="memItemRight" valign="bottom"><b>operator uses the indices along the last dimension as a tiebreaker.That is, the element with the lower index will appear first.Github Links:-https:&lt; details &gt;&lt; summary &gt;&lt; b &gt;Example&lt;/b &gt;&lt;/summary &gt; **Code **```workspace.ResetWorkspace</b> () op</td></tr>
<tr class="separator:aa865e4885a4fa02c18605ce2137a9f59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fd6a0af82304ebe88cdaaf2d1603e38"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0fd6a0af82304ebe88cdaaf2d1603e38"></a>
indices values refer to each element s index in the last dimension of the X input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (2,&quot;Flattened_indices&quot;,&quot;(*<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>`&lt;int&gt;`*): tensor of indices of shape $(a_1 * a_2 * ... * a_n * k,)$; indices values refer to each element's index in the flattened input tensor `X`&quot;).Arg(&quot;k&quot;</td></tr>
<tr class="separator:a0fd6a0af82304ebe88cdaaf2d1603e38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affc3da3e59a50ff7ae720341129e89b7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="affc3da3e59a50ff7ae720341129e89b7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (TopKGradient).NumInputs(3).NumOutputs(1)</td></tr>
<tr class="separator:affc3da3e59a50ff7ae720341129e89b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af33c32b9ceb4778f282b50465e3687fa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af33c32b9ceb4778f282b50465e3687fa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (TopK, <a class="el" href="classcaffe2_1_1_get_top_k_gradient.html">GetTopKGradient</a>)</td></tr>
<tr class="separator:af33c32b9ceb4778f282b50465e3687fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf0487b1160adba1852af6eef9181d7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf0487b1160adba1852af6eef9181d7f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Transpose, <a class="el" href="classcaffe2_1_1_transpose_op.html">TransposeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:adf0487b1160adba1852af6eef9181d7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f489cfb91e4c05e08ba01fc596af21a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4f489cfb91e4c05e08ba01fc596af21a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (axes.empty())</td></tr>
<tr class="separator:a4f489cfb91e4c05e08ba01fc596af21a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8fc48b7eafb065688a641e2fbd13fdc8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8fc48b7eafb065688a641e2fbd13fdc8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE</b> (valid_axes,&quot;Axes argument passed in had invalid values&quot;)</td></tr>
<tr class="separator:a8fc48b7eafb065688a641e2fbd13fdc8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af209e13d35f1d704be21702b622f33f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af209e13d35f1d704be21702b622f33f4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE</b> (axes.size()==tensor_size,&quot;Axes argument passed in had the incorrect size&quot;)</td></tr>
<tr class="separator:af209e13d35f1d704be21702b622f33f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bcaaa8592fc67c999a17c5f39daa3a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3bcaaa8592fc67c999a17c5f39daa3a4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>for</b> (auto axis=axes.begin();axis!=axes.end();++axis)</td></tr>
<tr class="separator:a3bcaaa8592fc67c999a17c5f39daa3a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67d09bde9af1a954f1859c45639c6260"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67d09bde9af1a954f1859c45639c6260"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Transpose the input tensor by permuting the axes of the input according
to the `axes` argument. Similar to numpy's
[transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html)
function.

For example, when axes=(1, 0, 2), given an input tensor of shape
(1, 2, 3), the output shape will be (2, 1, 3).

Github Links:

- https://github.com/pytorch/pytorch/blob/master/caffe2/operators/transpose_op.cc

&lt;details&gt;

&lt;summary&gt; &lt;b&gt;Example&lt;/b&gt; &lt;/summary&gt;

**Code**

```
workspace.ResetWorkspace()

op = core.CreateOperator(
    &quot;Transpose&quot;,
    [&quot;X&quot;],
    [&quot;Y&quot;],
    axes=(0,3,1,2)
)

x = np.random.rand(1,32,32,3)
workspace.FeedBlob(&quot;X&quot;, x)
print(&quot;X.shape(NHWC order):&quot;, workspace.FetchBlob(&quot;X&quot;).shape)
workspace.RunOperatorOnce(op)
print(&quot;Y.shape(NCHW order):&quot;, workspace.FetchBlob(&quot;Y&quot;).shape)
```

**Result**

```
X.shape (NHWC order): (1, 32, 32, 3)
Y.shape (NCHW order): (1, 3, 32, 32)
```

&lt;/details&gt;

)DOC&quot;).Arg(&quot;axes&quot;</td></tr>
<tr class="separator:a67d09bde9af1a954f1859c45639c6260"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8886b5fffc193adc7678c913d0739052"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8886b5fffc193adc7678c913d0739052"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (Transpose, <a class="el" href="classcaffe2_1_1_get_transpose_gradient.html">GetTransposeGradient</a>)</td></tr>
<tr class="separator:a8886b5fffc193adc7678c913d0739052"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10f4078c9362f6abbf685aa1c1b5ca9c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a10f4078c9362f6abbf685aa1c1b5ca9c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (Transpose, CuDNNTransposeOp)</td></tr>
<tr class="separator:a10f4078c9362f6abbf685aa1c1b5ca9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc9625fbfbca8dffa2b0b5523a796a61"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afc9625fbfbca8dffa2b0b5523a796a61"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Unique, <a class="el" href="classcaffe2_1_1_unique_op.html">UniqueOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afc9625fbfbca8dffa2b0b5523a796a61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a7ddc2c2eecfb9348954ce202265aaf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a7ddc2c2eecfb9348954ce202265aaf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Deduplicates input indices vector and optionally produces reverse remapping.
There's no guarantees on the ordering of the output indices.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a0a7ddc2c2eecfb9348954ce202265aaf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3995f761538d217c25c56ce8d5c81b83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3995f761538d217c25c56ce8d5c81b83"></a>
tensor of int32 or int64 indices&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;unique_indices&quot;,&quot;1D tensor of deduped entries.&quot;).Output(1</td></tr>
<tr class="separator:a3995f761538d217c25c56ce8d5c81b83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a830ba062c3f046a55b4eb3e506306ce8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a830ba062c3f046a55b4eb3e506306ce8"></a>
tensor of int32 or int64 indices <a class="el" href="classc10_1_1optional.html">optional</a> mapping from indices to unique_indices This has the same shape as indices Its elements are the indices into unique_indices such that&#160;</td><td class="memItemRight" valign="bottom"><b>Gather</b> (['unique_indices', 'remapping'])`&quot; &quot;yields`indices`.&quot;) .TensorInferenceFunction([]( const OperatorDef&amp; def</td></tr>
<tr class="separator:a830ba062c3f046a55b4eb3e506306ce8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4541bb4d1e1f6c6bd066d6f3dfdf8a4f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4541bb4d1e1f6c6bd066d6f3dfdf8a4f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_ENFORCE_EQ</b> (in[0].dims_size(), 1)</td></tr>
<tr class="separator:a4541bb4d1e1f6c6bd066d6f3dfdf8a4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accf2d2116b2fde6c0d2dff28e6b8cdde"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="accf2d2116b2fde6c0d2dff28e6b8cdde"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (in[0].dims(0)&lt;=1)</td></tr>
<tr class="separator:accf2d2116b2fde6c0d2dff28e6b8cdde"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a928cf5e44b7ac15ce713d334278579e0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a928cf5e44b7ac15ce713d334278579e0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (def.output_size() &gt; 1)</td></tr>
<tr class="separator:a928cf5e44b7ac15ce713d334278579e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aadd5a54f63a70fa79f258fdd177c2b8d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aadd5a54f63a70fa79f258fdd177c2b8d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Unique)</td></tr>
<tr class="separator:aadd5a54f63a70fa79f258fdd177c2b8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96310355eeb6db93ad7c9c58b0e59d84"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96310355eeb6db93ad7c9c58b0e59d84"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UpsampleBilinear, <a class="el" href="classcaffe2_1_1_upsample_bilinear_op.html">UpsampleBilinearOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a96310355eeb6db93ad7c9c58b0e59d84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7aec54e96e1aed5f495617c65d826d63"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7aec54e96e1aed5f495617c65d826d63"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UpsampleBilinearGradient, <a class="el" href="classcaffe2_1_1_upsample_bilinear_gradient_op.html">UpsampleBilinearGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7aec54e96e1aed5f495617c65d826d63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a049645630b197b9b082369ff796f9e70"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a049645630b197b9b082369ff796f9e70"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (UpsampleBilinear, <a class="el" href="classcaffe2_1_1_get_upsample_bilinear_gradient.html">GetUpsampleBilinearGradient</a>)</td></tr>
<tr class="separator:a049645630b197b9b082369ff796f9e70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c644b168bcb6c82087829eed4cf67e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c644b168bcb6c82087829eed4cf67e1"></a>
std::vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>WeightedSumShapeInference</b> (const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a3c644b168bcb6c82087829eed4cf67e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1810660b35f9014a7de283349ee5243b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1810660b35f9014a7de283349ee5243b"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForWeightedSum</b> (const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:a1810660b35f9014a7de283349ee5243b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4b46540691eb1afcf1547e3a91b57a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae4b46540691eb1afcf1547e3a91b57a5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WallClockTime, <a class="el" href="classcaffe2_1_1_wall_clock_time_op.html">WallClockTimeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae4b46540691eb1afcf1547e3a91b57a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad89258398f3cc3618d00035f0230dd47"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad89258398f3cc3618d00035f0230dd47"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Print, <a class="el" href="classcaffe2_1_1_print_op.html">PrintOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad89258398f3cc3618d00035f0230dd47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a520ac7ca6bb4e5c58248527effc9755c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a520ac7ca6bb4e5c58248527effc9755c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (FlattenToVec, <a class="el" href="classcaffe2_1_1_flatten_to_vec_op.html">FlattenToVecOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a520ac7ca6bb4e5c58248527effc9755c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab33a021e8766ed8a069056a5fef6a219"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab33a021e8766ed8a069056a5fef6a219"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Alias, <a class="el" href="classcaffe2_1_1_alias_op.html">AliasOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab33a021e8766ed8a069056a5fef6a219"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac99c902c10fcc4c740225d2e92d23ac4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac99c902c10fcc4c740225d2e92d23ac4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ResizeLike, <a class="el" href="classcaffe2_1_1_resize_like_op.html">ResizeLikeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac99c902c10fcc4c740225d2e92d23ac4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1c5967b5a9c33819f0d47045f7fed6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad1c5967b5a9c33819f0d47045f7fed6d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SumInt, <a class="el" href="classcaffe2_1_1_sum_op.html">SumOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad1c5967b5a9c33819f0d47045f7fed6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a177ef4037d8a1560bd61c47798c4a078"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a177ef4037d8a1560bd61c47798c4a078"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WeightedSum, <a class="el" href="classcaffe2_1_1_weighted_sum_op.html">WeightedSumOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a177ef4037d8a1560bd61c47798c4a078"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4fce6d9f20ad9b777c83ff28add34965"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4fce6d9f20ad9b777c83ff28add34965"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WeightedSumGradient, <a class="el" href="classcaffe2_1_1_weighted_sum_gradient_op.html">WeightedSumGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4fce6d9f20ad9b777c83ff28add34965"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cbfff336193d2ecb5fa64f5a36cf434"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8cbfff336193d2ecb5fa64f5a36cf434"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ScatterWeightedSum, <a class="el" href="classcaffe2_1_1_scatter_weighted_sum_op.html">ScatterWeightedSumOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8cbfff336193d2ecb5fa64f5a36cf434"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a046774787ee2fa03fc8c3285426e2520"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a046774787ee2fa03fc8c3285426e2520"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ScatterAssign, <a class="el" href="classcaffe2_1_1_scatter_assign_op.html">ScatterAssignOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a046774787ee2fa03fc8c3285426e2520"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a815977f8c140f506d4fc3792180a1d43"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a815977f8c140f506d4fc3792180a1d43"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsToShape, <a class="el" href="classcaffe2_1_1_lengths_to_shape_op.html">LengthsToShapeOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a815977f8c140f506d4fc3792180a1d43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85b807d8754dc2e4cb8eb0888b87c21e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a85b807d8754dc2e4cb8eb0888b87c21e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (HasElements, <a class="el" href="classcaffe2_1_1_has_elements_op.html">HasElementsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a85b807d8754dc2e4cb8eb0888b87c21e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77929d08f345c156764caa27cd657179"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a77929d08f345c156764caa27cd657179"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GatherRanges, <a class="el" href="classcaffe2_1_1_gather_ranges_op.html">GatherRangesOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a77929d08f345c156764caa27cd657179"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd98b44084f36957d000676d1a9c92a9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd98b44084f36957d000676d1a9c92a9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsGather, <a class="el" href="classcaffe2_1_1_lengths_gather_op.html">LengthsGatherOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:acd98b44084f36957d000676d1a9c92a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a814526a9f15708d215ba04a8a89173f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a814526a9f15708d215ba04a8a89173f8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsToSegmentIds, <a class="el" href="classcaffe2_1_1_lengths_to_segment_ids_op.html">LengthsToSegmentIdsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a814526a9f15708d215ba04a8a89173f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2775339e1ddc54710638bb4be2307b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad2775339e1ddc54710638bb4be2307b4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsToRanges, <a class="el" href="classcaffe2_1_1_lengths_to_ranges_op.html">LengthsToRangesOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad2775339e1ddc54710638bb4be2307b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad64450dcd999e7cd2ca206f6c5c74f54"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad64450dcd999e7cd2ca206f6c5c74f54"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SegmentIdsToLengths, <a class="el" href="classcaffe2_1_1_segment_ids_to_lengths_op.html">SegmentIdsToLengthsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad64450dcd999e7cd2ca206f6c5c74f54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48089cf88fff8b981d2a274ca69fb3bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a48089cf88fff8b981d2a274ca69fb3bb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SegmentIdsToRanges, <a class="el" href="classcaffe2_1_1_segment_ids_to_ranges_op.html">SegmentIdsToRangesOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a48089cf88fff8b981d2a274ca69fb3bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af56d34cf4fe5bc72c7f4ef5b16bfa5ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af56d34cf4fe5bc72c7f4ef5b16bfa5ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LengthsToWeights, <a class="el" href="classcaffe2_1_1_lengths_to_weights_op.html">LengthsToWeightsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af56d34cf4fe5bc72c7f4ef5b16bfa5ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6af8be33595de71a93f223fdf520d82"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6af8be33595de71a93f223fdf520d82"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (EnsureDense, <a class="el" href="classcaffe2_1_1_ensure_dense_op.html">EnsureDenseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae6af8be33595de71a93f223fdf520d82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad77aa2a71bc9ba02ed8e43b70d5dad1e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad77aa2a71bc9ba02ed8e43b70d5dad1e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AccumulateHistogram, <a class="el" href="classcaffe2_1_1_accumulate_histogram_op.html">AccumulateHistogramOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad77aa2a71bc9ba02ed8e43b70d5dad1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b844077ac87f219c4be3ea4a0bc7b80"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b844077ac87f219c4be3ea4a0bc7b80"></a>
bool saves contents to the root folder of the current appending the tensor contents to a file named after the blob name logs to stderr&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;limit&quot;,&quot;(int, default 0) If set, prints the first `limit` elements of tensor. &quot;&quot;If 0, prints the first `k_limit_default`(1000) elements of tensor&quot;).Arg(&quot;every_n&quot;</td></tr>
<tr class="separator:a0b844077ac87f219c4be3ea4a0bc7b80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bbf153872f8dc4a2ce4f41ba1c4b9fb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7bbf153872f8dc4a2ce4f41ba1c4b9fb"></a>
bool saves contents to the root folder of the current appending the tensor contents to a file named after the blob name logs to stderr default Print tensor every every_n runs&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;tensor&quot;,&quot;The tensor to print.&quot;)</td></tr>
<tr class="separator:a7bbf153872f8dc4a2ce4f41ba1c4b9fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3a880882b44dbb07bfeb6152d6ab75e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3a880882b44dbb07bfeb6152d6ab75e"></a>
<a class="el" href="structcaffe2_1_1_op_schema_1_1_cost.html">OpSchema::Cost</a>&#160;</td><td class="memItemRight" valign="bottom"><b>CostInferenceForSum</b> (const OperatorDef &amp;def, const std::vector&lt; TensorShape &gt; &amp;in)</td></tr>
<tr class="separator:ad3a880882b44dbb07bfeb6152d6ab75e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6726a7139eb09d6e53b496307184a819"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6726a7139eb09d6e53b496307184a819"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDNN_OPERATOR</b> (WeightedSum, <a class="el" href="classcaffe2_1_1_cu_d_n_n_weighted_sum_op.html">CuDNNWeightedSumOp</a>)</td></tr>
<tr class="separator:a6726a7139eb09d6e53b496307184a819"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6501a13281b3ddeb0f98f331e6fcb054"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6501a13281b3ddeb0f98f331e6fcb054"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (VariableLengthSequencePadding, <a class="el" href="classcaffe2_1_1_variable_length_sequence_padding_op.html">VariableLengthSequencePaddingOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6501a13281b3ddeb0f98f331e6fcb054"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6925ed9748e4f3062b408f893bc0205"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa6925ed9748e4f3062b408f893bc0205"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Super special-case operator. Used to pad a tensor to mimic pytorch's
pad_packed_sequence.

Given an input tensor INPUT of size NxBxM and an input tensor LENS
of size <a class="el" href="struct_b.html">B</a>, where

N = maximum sequence length
<a class="el" href="struct_b.html">B</a> = batch size
<a class="el" href="struct_m.html">M</a> = hidden size

set each element of INPUT to zero if it is is past the end of the
corresponding sequence (i.e. if LENS[j] &gt; i for an index (i,j,k)).

)DOC&quot;)</td></tr>
<tr class="separator:aa6925ed9748e4f3062b408f893bc0205"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afad0b20587ea19821f71ff78b4ee9707"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afad0b20587ea19821f71ff78b4ee9707"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WeightedMultiSampling, <a class="el" href="classcaffe2_1_1_weighted_multi_sampling_op.html">WeightedMultiSamplingOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afad0b20587ea19821f71ff78b4ee9707"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08b4e04261d6a611479b92006dadf105"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08b4e04261d6a611479b92006dadf105"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (in[0].dims(0)==0)</td></tr>
<tr class="separator:a08b4e04261d6a611479b92006dadf105"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa62dc5a68b84ad9578676a013ebb1ed4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa62dc5a68b84ad9578676a013ebb1ed4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>if</b> (args.HasArgument(&quot;num_samples&quot;))</td></tr>
<tr class="separator:aa62dc5a68b84ad9578676a013ebb1ed4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab107b882c3877cf3da6f6dc6b8f16f54"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab107b882c3877cf3da6f6dc6b8f16f54"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
The operator performs sampling based on the input sampling weights.
All weights are cummulative probability thus sorted. The output is
a 1-<a class="el" href="struct_d.html">D</a> tensor (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>). If two inputs are given, the second input
is used to provide shape of the output sample tensor. Otherwise, we use
argument `num_samples` to determine the number of samples to generate.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:ab107b882c3877cf3da6f6dc6b8f16f54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57646727c59a35919e916aa6a0e8459a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a57646727c59a35919e916aa6a0e8459a"></a>
An <a class="el" href="classc10_1_1optional.html">optional</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> Input cumulative sampling&#160;</td><td class="memItemRight" valign="bottom"><b>probability</b> (such as[0.2, 0.5, 0.8, 1.5]).&quot; &quot;All weights must be non-negative numbers.Note that the last value of&quot; &quot;CDF is not necessary 1.If the last value is not 1</td></tr>
<tr class="separator:a57646727c59a35919e916aa6a0e8459a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d554486be132f9718f102ffa1c11e02"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2d554486be132f9718f102ffa1c11e02"></a>
An <a class="el" href="classc10_1_1optional.html">optional</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> Input cumulative sampling all values in sampling_cdf will be scaled by this number&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;shape_tensor (<a class="el" href="classc10_1_1optional.html">optional</a>)&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> whose shape will be applied to output.&quot;).Output(0</td></tr>
<tr class="separator:a2d554486be132f9718f102ffa1c11e02"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afcae3454566139294797cd6c4a291fa4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afcae3454566139294797cd6c4a291fa4"></a>
An <a class="el" href="classc10_1_1optional.html">optional</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> Input cumulative sampling all values in sampling_cdf will be scaled by this number The output tensor contains indices sampled from distribution given by the weight vector in the input tensor The output is a <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of size determined by argument num_samples or the second input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;num_samples&quot;,&quot;number of samples to sample from the input data&quot;)</td></tr>
<tr class="separator:afcae3454566139294797cd6c4a291fa4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab55f00e812cdf720a689b464f6f28f33"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab55f00e812cdf720a689b464f6f28f33"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (WeightedMultiSample)</td></tr>
<tr class="separator:ab55f00e812cdf720a689b464f6f28f33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab079c71ac67fe9eb47f08939c74314cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab079c71ac67fe9eb47f08939c74314cb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WeightedSample, <a class="el" href="classcaffe2_1_1_weighted_sample_op.html">WeightedSampleOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab079c71ac67fe9eb47f08939c74314cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29d8774b6670f5e86a3b7fa1570dddba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29d8774b6670f5e86a3b7fa1570dddba"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;in){vector&lt; TensorShape &gt; out(2);int batch_size=in[0].dims(0);out[0]=CreateTensorShape(vector&lt; int &gt;{batch_size}, TensorProto::INT32);out[1]=CreateTensorShape(vector&lt; int &gt;{batch_size}, TensorProto::FLOAT);return out;}).SetDoc(R&quot;DOC( The operator performs sampling based on the input sampling weights for each batch. All weights must be non-negative numbers. The input is a 2-<a class="el" href="struct_d.html">D</a> tensor (<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>) of size (batch_size x weights_dim). For each batch</td></tr>
<tr class="separator:a29d8774b6670f5e86a3b7fa1570dddba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4cc4a9f477e913495924a1d77eb4cd3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac4cc4a9f477e913495924a1d77eb4cd3"></a>
an index is randomly sampled from the distribution given by the weights of the corresponding batch The output is a <a class="el" href="struct_d.html">D</a> <a class="el" href="struct_a.html">A</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> (batch_size x weights_dim).&quot; &quot;All weights must be non-negative numbers.&quot;) .Input( 1</td></tr>
<tr class="separator:ac4cc4a9f477e913495924a1d77eb4cd3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a964a3c156a80bca19ca9a4b45e3ae7e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a964a3c156a80bca19ca9a4b45e3ae7e4"></a>
an index is randomly sampled from the distribution given by the weights of the corresponding batch The output is a <a class="el" href="struct_d.html">D</a> <a class="el" href="struct_a.html">A</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of An <a class="el" href="classc10_1_1optional.html">optional</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of The output tensor contains&#160;</td><td class="memItemRight" valign="bottom"><b>index</b> (es) sampled from distribution given&quot; &quot;by the weight vector(s) in the input tensor&quot; &quot;The output is a 1-<a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of size(batch_size x 1)&quot;) .Output( 1</td></tr>
<tr class="separator:a964a3c156a80bca19ca9a4b45e3ae7e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e2939baab7342da416b186d40a5903d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3e2939baab7342da416b186d40a5903d"></a>
an index is randomly sampled from the distribution given by the weights of the corresponding batch The output is a <a class="el" href="struct_d.html">D</a> <a class="el" href="struct_a.html">A</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of An <a class="el" href="classc10_1_1optional.html">optional</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of The output tensor contains The output tensor contains&#160;</td><td class="memItemRight" valign="bottom"><b>value</b> (s) selected by the sampled index(es)&quot; &quot;It is a 1-<a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of size(batch_size x 1)&quot;)</td></tr>
<tr class="separator:a3e2939baab7342da416b186d40a5903d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76c809c643823734ab57c3a85a5e9170"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a76c809c643823734ab57c3a85a5e9170"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (WeightedSample)</td></tr>
<tr class="separator:a76c809c643823734ab57c3a85a5e9170"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a102ffa79682074513d591e377397b042"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a102ffa79682074513d591e377397b042"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="classnom_1_1repr_1_1_while.html">While</a>, <a class="el" href="classcaffe2_1_1_while_op.html">WhileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a102ffa79682074513d591e377397b042"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10960ed9ca2cd58c3a11246a399403c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a10960ed9ca2cd58c3a11246a399403c3"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
'<a class="el" href="classnom_1_1repr_1_1_while.html">While</a>' control operator, first input is a scalar boolean blob that stores loop's
condition value. Accepts 'loop_net' (required) and 'cond_net' (<a class="el" href="classc10_1_1optional.html">optional</a>) arguments for
loop's body and condition subnets respectively. If condition subnet is specified,
it is executed before the first and after each iteration. Subnets are executed in
the same workspace as '<a class="el" href="classnom_1_1repr_1_1_while.html">While</a>'.
    )DOC&quot;).Arg(&quot;loop_net&quot;</td></tr>
<tr class="separator:a10960ed9ca2cd58c3a11246a399403c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f51b13606550f3cfd379146a552809c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f51b13606550f3cfd379146a552809c"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed on each iteration&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;cond_net&quot;,&quot;<a class="el" href="struct_net.html">Net</a> to (re)compute condition value&quot;).Input(0</td></tr>
<tr class="separator:a5f51b13606550f3cfd379146a552809c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f21c6c1b8416cc320cd2a77b367d632"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6f21c6c1b8416cc320cd2a77b367d632"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (<a class="el" href="classnom_1_1repr_1_1_while.html">While</a>, <a class="el" href="classcaffe2_1_1_while_op.html">WhileOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a6f21c6c1b8416cc320cd2a77b367d632"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86f526c762e31c803fbb22e25978d1ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86f526c762e31c803fbb22e25978d1ff"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ZeroGradient, <a class="el" href="classcaffe2_1_1_zero_gradient_op.html">ZeroGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a86f526c762e31c803fbb22e25978d1ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada778193a182df6ced292b0e04f500a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada778193a182df6ced292b0e04f500a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (ZeroGradient, <a class="el" href="structcaffe2_1_1_get_zero_gradient_op_gradient.html">GetZeroGradientOpGradient</a>)</td></tr>
<tr class="separator:ada778193a182df6ced292b0e04f500a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa61627ee70d1645f2d0cd56fb0f46e08"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa61627ee70d1645f2d0cd56fb0f46e08"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (ZeroGradient, <a class="el" href="classcaffe2_1_1_zero_gradient_op.html">ZeroGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aa61627ee70d1645f2d0cd56fb0f46e08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a863e455d37000d9c67d6706fe5641266"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a863e455d37000d9c67d6706fe5641266"></a>
std::vector&lt; TensorShape &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>InferOutput</b> (const OperatorDef &amp;op, const std::vector&lt; TensorShape &gt; &amp;input_shapes)</td></tr>
<tr class="separator:a863e455d37000d9c67d6706fe5641266"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3d4e40a3b229a9badef3ba238d27efd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa3d4e40a3b229a9badef3ba238d27efd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (ConverterRegistry, <a class="el" href="classcaffe2_1_1_converter.html">Converter</a>)</td></tr>
<tr class="separator:aa3d4e40a3b229a9badef3ba238d27efd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a339a040c78241807aae29279e6625de1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a339a040c78241807aae29279e6625de1"></a>
<a class="el" href="classnom_1_1repr_1_1_neural_net_operator.html#a4abb8a611f0f1c4281cb92204b7d0973">repr::NeuralNetOperator::NNLayout</a>&#160;</td><td class="memItemRight" valign="bottom"><b>getLayout</b> (std::map&lt; std::string, <a class="el" href="structc10_1_1_argument.html">caffe2::Argument</a> &gt; argMap)</td></tr>
<tr class="separator:a339a040c78241807aae29279e6625de1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a520e799a34accbeb753a7061fbac2287"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a520e799a34accbeb753a7061fbac2287"></a>
std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>getKernelShape</b> (std::map&lt; std::string, <a class="el" href="structc10_1_1_argument.html">caffe2::Argument</a> &gt; argMap)</td></tr>
<tr class="separator:a520e799a34accbeb753a7061fbac2287"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2272f9cfabdbafd27dee3b968ef02c33"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2272f9cfabdbafd27dee3b968ef02c33"></a>
std::unique_ptr&lt; <a class="el" href="classnom_1_1repr_1_1_neural_net_operator.html">repr::NeuralNetOperator</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>convertToNeuralNetOperator</b> (const caffe2::OperatorDef &amp;op)</td></tr>
<tr class="separator:a2272f9cfabdbafd27dee3b968ef02c33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af932547d95616517ff8fe091eb3ba698"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structnom_1_1repr_1_1_n_n_module.html">repr::NNModule</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#af932547d95616517ff8fe091eb3ba698">convertToNNModule</a> (const caffe2::NetDef &amp;net, bool strict, std::vector&lt; <a class="el" href="classnom_1_1_node.html">repr::NNGraph::NodeRef</a> &gt; *opNodeVec)</td></tr>
<tr class="memdesc:af932547d95616517ff8fe091eb3ba698"><td class="mdescLeft">&#160;</td><td class="mdescRight">Ingest a <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> protobuf model and output an NNModule.  <a href="#af932547d95616517ff8fe091eb3ba698">More...</a><br /></td></tr>
<tr class="separator:af932547d95616517ff8fe091eb3ba698"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9fd1eba5b576a3c78efe08c32fb3f22"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9fd1eba5b576a3c78efe08c32fb3f22"></a>
caffe2::OperatorDef&#160;</td><td class="memItemRight" valign="bottom"><b>convertToOperatorDef</b> (const <a class="el" href="classnom_1_1_node.html">repr::NNGraph::NodeRef</a> &amp;instrNode)</td></tr>
<tr class="separator:aa9fd1eba5b576a3c78efe08c32fb3f22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0cab6b8f270e73270575237b86bab2b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0cab6b8f270e73270575237b86bab2b"></a>
<a class="el" href="classcaffe2_1_1_caffe2_annotation.html">Caffe2Annotation</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>getOrAddCaffe2Annotation</b> (<a class="el" href="classnom_1_1_node.html">nom::repr::NNGraph::NodeRef</a> &amp;instrNode)</td></tr>
<tr class="separator:ac0cab6b8f270e73270575237b86bab2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bf9b39253eb5e43878d109b53d458c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0bf9b39253eb5e43878d109b53d458c3"></a>
caffe2::NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>convertToCaffe2Proto</b> (<a class="el" href="structnom_1_1repr_1_1_n_n_module.html">repr::NNModule</a> &amp;m)</td></tr>
<tr class="separator:a0bf9b39253eb5e43878d109b53d458c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abcb64af4fc5e032f880392c05ca5a1ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abcb64af4fc5e032f880392c05ca5a1ad"></a>
std::vector&lt; std::string &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>mergeExternalTensors</b> (const std::unordered_set&lt; <a class="el" href="classnom_1_1_node.html">repr::NNGraph::NodeRef</a> &gt; &amp;currExternal, const std::vector&lt; std::string &gt; &amp;oldExternal)</td></tr>
<tr class="separator:abcb64af4fc5e032f880392c05ca5a1ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adac52a23b71b1b98e42385296447dd59"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adac52a23b71b1b98e42385296447dd59"></a>
caffe2::NetDef&#160;</td><td class="memItemRight" valign="bottom"><b>convertToCaffe2Proto</b> (<a class="el" href="structnom_1_1repr_1_1_n_n_module.html">repr::NNModule</a> &amp;m, const caffe2::NetDef &amp;oldNet)</td></tr>
<tr class="separator:adac52a23b71b1b98e42385296447dd59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a797ea92943d89f8385768fc13adfe82b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a797ea92943d89f8385768fc13adfe82b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>pushOpToFront</b> (caffe2::OperatorDef &amp;op, caffe2::NetDef *net)</td></tr>
<tr class="separator:a797ea92943d89f8385768fc13adfe82b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75fff0601e7dabec597d20ef35aaa4c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75fff0601e7dabec597d20ef35aaa4c7"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>injectDataEdgeIndicators</b> (caffe2::NetDef *net)</td></tr>
<tr class="separator:a75fff0601e7dabec597d20ef35aaa4c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbc2d975cadca3f2790f5c92f8755030"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adbc2d975cadca3f2790f5c92f8755030"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>removeDataEdgeIndicators</b> (caffe2::NetDef *net)</td></tr>
<tr class="separator:adbc2d975cadca3f2790f5c92f8755030"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b29e6c380745c1fe5cd12d9ad712a75"><td class="memItemLeft" align="right" valign="top">CAFFE2_API <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a8b29e6c380745c1fe5cd12d9ad712a75">convertToNNModule</a> (const caffe2::NetDef &amp;net, bool strict=false, std::vector&lt; <a class="el" href="classnom_1_1_node.html">nom::repr::NNGraph::NodeRef</a> &gt; *=nullptr)</td></tr>
<tr class="memdesc:a8b29e6c380745c1fe5cd12d9ad712a75"><td class="mdescLeft">&#160;</td><td class="mdescRight">Ingest a <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> protobuf model and output an NNModule.  <a href="#a8b29e6c380745c1fe5cd12d9ad712a75">More...</a><br /></td></tr>
<tr class="separator:a8b29e6c380745c1fe5cd12d9ad712a75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6882f6f831afcf2ccdcd9935a811d4c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af6882f6f831afcf2ccdcd9935a811d4c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (ConverterRegistry, <a class="el" href="classcaffe2_1_1_converter.html">Converter</a>)</td></tr>
<tr class="separator:af6882f6f831afcf2ccdcd9935a811d4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff73f7b0f28dbca279755fbab3871048"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff73f7b0f28dbca279755fbab3871048"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>setDeviceOption</b> (<a class="el" href="classnom_1_1_node.html">NNGraph::NodeRef</a> n, caffe2::DeviceOption &amp;d)</td></tr>
<tr class="separator:aff73f7b0f28dbca279755fbab3871048"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a882a6d5eb5b21f3f19113c171b8a276f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a882a6d5eb5b21f3f19113c171b8a276f">addBlobDeviceOptions</a> (std::map&lt; std::string, caffe2::DeviceOption &gt; blobMap, <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a> *nn)</td></tr>
<tr class="memdesc:a882a6d5eb5b21f3f19113c171b8a276f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Helpers for the convertToNNModule for use if you already have an NNModule.  <a href="#a882a6d5eb5b21f3f19113c171b8a276f">More...</a><br /></td></tr>
<tr class="separator:a882a6d5eb5b21f3f19113c171b8a276f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f2304ea9065450bb21d401c2b007fc8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8f2304ea9065450bb21d401c2b007fc8"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>injectDataEdgeIndicators</b> (<a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a> *nn)</td></tr>
<tr class="separator:a8f2304ea9065450bb21d401c2b007fc8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50e46e246ac332ff8503e82d4671feec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a50e46e246ac332ff8503e82d4671feec"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>removeDataEdgeIndicators</b> (<a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a> *nn)</td></tr>
<tr class="separator:a50e46e246ac332ff8503e82d4671feec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa622473d4ffc538d61f14a134ad03e20"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#aa622473d4ffc538d61f14a134ad03e20">convertToNNModule</a> (caffe2::NetDef &amp;, std::map&lt; std::string, caffe2::DeviceOption &gt;)</td></tr>
<tr class="memdesc:aa622473d4ffc538d61f14a134ad03e20"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convert to an NNModule and apply a mapping of tensor names to DeviceOptions to it.  <a href="#aa622473d4ffc538d61f14a134ad03e20">More...</a><br /></td></tr>
<tr class="separator:aa622473d4ffc538d61f14a134ad03e20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80b58a4d33209f681a4ecf65ee67d200"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a80b58a4d33209f681a4ecf65ee67d200"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (WorkspaceOptimizationPassRegistry, <a class="el" href="classcaffe2_1_1_workspace_optimization_pass.html">WorkspaceOptimizationPass</a>, <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">NNModule</a> *, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a80b58a4d33209f681a4ecf65ee67d200"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad02287761ce3480cb6c2b0b142566388"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad02287761ce3480cb6c2b0b142566388"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DEFINE_REGISTRY</b> (OptimizationPassRegistry, <a class="el" href="classcaffe2_1_1_optimization_pass.html">OptimizationPass</a>, <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">NNModule</a> *)</td></tr>
<tr class="separator:ad02287761ce3480cb6c2b0b142566388"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28a8cbaeba69cfefc10791a5666b4af9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28a8cbaeba69cfefc10791a5666b4af9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (WorkspaceOptimizationPassRegistry, <a class="el" href="classcaffe2_1_1_workspace_optimization_pass.html">WorkspaceOptimizationPass</a>, <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">NNModule</a> *, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *)</td></tr>
<tr class="separator:a28a8cbaeba69cfefc10791a5666b4af9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32799a8ca4a66cea1269ccac2692d7eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32799a8ca4a66cea1269ccac2692d7eb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>C10_DECLARE_REGISTRY</b> (OptimizationPassRegistry, <a class="el" href="classcaffe2_1_1_optimization_pass.html">OptimizationPass</a>, <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">NNModule</a> *)</td></tr>
<tr class="separator:a32799a8ca4a66cea1269ccac2692d7eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a663343edc6e6f4134a0b2acf77b25aa1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a663343edc6e6f4134a0b2acf77b25aa1"></a>
<a class="el" href="structcaffe2_1_1_shape_info.html">ShapeInfo</a>&#160;</td><td class="memItemRight" valign="bottom"><b>getShapeInfoFromBlob</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *blob)</td></tr>
<tr class="separator:a663343edc6e6f4134a0b2acf77b25aa1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64d1cff93c0d46e910265a052ecbab2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a64d1cff93c0d46e910265a052ecbab2f"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>operator==</b> (const <a class="el" href="structcaffe2_1_1_shape_info.html">ShapeInfo</a> &amp;lhs, const <a class="el" href="structcaffe2_1_1_shape_info.html">ShapeInfo</a> &amp;rhs)</td></tr>
<tr class="separator:a64d1cff93c0d46e910265a052ecbab2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb833d5c4a1892e69c9e0e157611bb1e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeb833d5c4a1892e69c9e0e157611bb1e"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update__base</b> (int N, const float *w, const float *g, const float *h, float *nw, float *nh, float epsilon, float decay, const float lr)</td></tr>
<tr class="separator:aeb833d5c4a1892e69c9e0e157611bb1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab14613a424ef7607e4e6ba9124b3716a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab14613a424ef7607e4e6ba9124b3716a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update_prefetch__base</b> (int N, const float *w, const float *, const float *g, const float *h, const float *, float *nw, float *, float *nh, float *, float epsilon, float lr)</td></tr>
<tr class="separator:ab14613a424ef7607e4e6ba9124b3716a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b69e10320473333b0ac96ebd3f4f6e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b69e10320473333b0ac96ebd3f4f6e4"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_fp16_update_prefetch__base</b> (int N, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *w, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *, const float *g, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *h, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nw, <a class="el" href="structc10_1_1_half.html">at::Half</a> *, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nh, <a class="el" href="structc10_1_1_half.html">at::Half</a> *, float epsilon, float lr)</td></tr>
<tr class="separator:a2b69e10320473333b0ac96ebd3f4f6e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2ecde8d5cabea0d1ed43c3390fac59e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad2ecde8d5cabea0d1ed43c3390fac59e"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>rowwise_adagrad_update__base</b> (int N, float *w, float *w_n, const float *g, float *h, float *h_n, float epsilon, float lr)</td></tr>
<tr class="separator:ad2ecde8d5cabea0d1ed43c3390fac59e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afde94df3b3dbc34f17e45b72c2ba276e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afde94df3b3dbc34f17e45b72c2ba276e"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update</b> (int N, const float *w, const float *g, const float *h, float *nw, float *nh, float epsilon, float decay, float lr)</td></tr>
<tr class="separator:afde94df3b3dbc34f17e45b72c2ba276e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adeda19698176555e903b802769f5fec4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adeda19698176555e903b802769f5fec4"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update_prefetch</b> (int N, const float *w, const float *w_n, const float *g, const float *h, const float *h_n, float *nw, float *nw_n, float *nh, float *nh_n, float epsilon, float lr)</td></tr>
<tr class="separator:adeda19698176555e903b802769f5fec4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4712fa1d7bbe389ff2c477bcf59c295"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4712fa1d7bbe389ff2c477bcf59c295"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_fp16_update_prefetch</b> (int N, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *w, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *w_n, const float *g, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *h, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *h_n, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nw, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nw_n, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nh, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nh_n, float epsilon, float lr)</td></tr>
<tr class="separator:aa4712fa1d7bbe389ff2c477bcf59c295"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc407c3f971604fe9c7c221937f954d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc407c3f971604fe9c7c221937f954d9"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>rowwise_adagrad_update</b> (int N, float *w, float *w_n, const float *g, float *h, float *h_n, float epsilon, float lr)</td></tr>
<tr class="separator:adc407c3f971604fe9c7c221937f954d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7472a76551202d31e08be181ef6c8ebd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7472a76551202d31e08be181ef6c8ebd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SPARSE_ADAGRAD_SPECIALIZATION</b> (int32_t, base)</td></tr>
<tr class="separator:a7472a76551202d31e08be181ef6c8ebd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11f8ee7b76e9077ad74a401986fc3b26"><td class="memTemplParams" colspan="2"><a class="anchor" id="a11f8ee7b76e9077ad74a401986fc3b26"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a11f8ee7b76e9077ad74a401986fc3b26"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>sparse_adagrad</b> (int num_rows, int block_size, uint64_t param_size, const float *w, const float *g, const float *h, const int32_t *indices, float *nw, float *nh, float epsilon, float lr)</td></tr>
<tr class="separator:a11f8ee7b76e9077ad74a401986fc3b26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a3a0bc99f12d7a40f642fbda3561adc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a3a0bc99f12d7a40f642fbda3561adc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SPARSE_ADAGRAD_SPECIALIZATION</b> (int64_t, base)</td></tr>
<tr class="separator:a0a3a0bc99f12d7a40f642fbda3561adc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b7865bf1b75db0c16701aba2332e121"><td class="memTemplParams" colspan="2"><a class="anchor" id="a7b7865bf1b75db0c16701aba2332e121"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a7b7865bf1b75db0c16701aba2332e121"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>sparse_adagrad</b> (int num_rows, int block_size, uint64_t param_size, const float *w, const float *g, const float *h, const int64_t *indices, float *nw, float *nh, float epsilon, float lr)</td></tr>
<tr class="separator:a7b7865bf1b75db0c16701aba2332e121"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9004d4d17e6bab9445bcb231d4b097ef"><td class="memTemplParams" colspan="2">template&lt;typename SIndex &gt; </td></tr>
<tr class="memitem:a9004d4d17e6bab9445bcb231d4b097ef"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a9004d4d17e6bab9445bcb231d4b097ef">sparse_adagrad</a> (int num_rows, int block_size, std::uint64_t param_size, const float *w, const float *g, const float *h, const SIndex *indices, float *nw, float *nh, float epsilon, float lr)</td></tr>
<tr class="separator:a9004d4d17e6bab9445bcb231d4b097ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70b3a3a6077fbb621726ae0df4eb4972"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a70b3a3a6077fbb621726ae0df4eb4972"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update__avx_f16c</b> (int N, const float *w, const float *g, const float *h, float *nw, float *nh, float epsilon, float decay, float lr)</td></tr>
<tr class="separator:a70b3a3a6077fbb621726ae0df4eb4972"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf4cc7c49bfb0e8bec0a6190355f2779"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acf4cc7c49bfb0e8bec0a6190355f2779"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update_prefetch__avx_f16c</b> (int N, const float *w, const float *w_n, const float *g, const float *h, const float *h_n, float *nw, float *nw_n, float *nh, float *nh_n, float epsilon, float lr)</td></tr>
<tr class="separator:acf4cc7c49bfb0e8bec0a6190355f2779"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc9593712ea7ba3cdbfc9bc979b8f0b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc9593712ea7ba3cdbfc9bc979b8f0b5"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_fp16_update_prefetch__avx_f16c</b> (int N, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *w, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *w_n, const float *g, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *h, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *h_n, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nw, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nw_n, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nh, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nh_n, float epsilon, float lr)</td></tr>
<tr class="separator:abc9593712ea7ba3cdbfc9bc979b8f0b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd7a248987ba6c8f04e81ed2e959a866"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abd7a248987ba6c8f04e81ed2e959a866"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>rowwise_adagrad_update__avx_f16c</b> (int N, float *w, float *w_n, const float *g, float *h, float *h_n, float epsilon, float lr)</td></tr>
<tr class="separator:abd7a248987ba6c8f04e81ed2e959a866"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9225b2c2070adafce5e4316efb237f40"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9225b2c2070adafce5e4316efb237f40"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SPARSE_ADAGRAD_SPECIALIZATION</b> (int32_t, avx_f16c)</td></tr>
<tr class="separator:a9225b2c2070adafce5e4316efb237f40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac367b381f8c2c1c84a787811fc52d608"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac367b381f8c2c1c84a787811fc52d608"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SPARSE_ADAGRAD_SPECIALIZATION</b> (int64_t, avx_f16c)</td></tr>
<tr class="separator:ac367b381f8c2c1c84a787811fc52d608"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31f4cf9e7306132d8e25fceeb58410dd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a31f4cf9e7306132d8e25fceeb58410dd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int32_t, float, float, float, false)</td></tr>
<tr class="separator:a31f4cf9e7306132d8e25fceeb58410dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e87b2b2c922d9c9c4076a2ddeb9b990"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e87b2b2c922d9c9c4076a2ddeb9b990"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int64_t, float, float, float, false)</td></tr>
<tr class="separator:a6e87b2b2c922d9c9c4076a2ddeb9b990"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51dc172f673c4a0bf802fc09511dbea3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a51dc172f673c4a0bf802fc09511dbea3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int32_t, half, <a class="el" href="structc10_1_1_half.html">at::Half</a>, float, false)</td></tr>
<tr class="separator:a51dc172f673c4a0bf802fc09511dbea3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec2e35e11d31c6e08da735483bf30b2e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec2e35e11d31c6e08da735483bf30b2e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int64_t, half, <a class="el" href="structc10_1_1_half.html">at::Half</a>, float, false)</td></tr>
<tr class="separator:aec2e35e11d31c6e08da735483bf30b2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf4c5cca221a23c20cf3f5dc9bd46676"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf4c5cca221a23c20cf3f5dc9bd46676"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int32_t, uint8_t, uint8_t, float, false)</td></tr>
<tr class="separator:adf4c5cca221a23c20cf3f5dc9bd46676"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3858118da238ac2e689c3c22c5bea670"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3858118da238ac2e689c3c22c5bea670"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int64_t, uint8_t, uint8_t, float, false)</td></tr>
<tr class="separator:a3858118da238ac2e689c3c22c5bea670"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51fd6f6cca3b78e2e0f9510ffbee7354"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a51fd6f6cca3b78e2e0f9510ffbee7354"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int32_t, float, float, float, true)</td></tr>
<tr class="separator:a51fd6f6cca3b78e2e0f9510ffbee7354"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90040a1af859dcff32aa520837f081d3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90040a1af859dcff32aa520837f081d3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int64_t, float, float, float, true)</td></tr>
<tr class="separator:a90040a1af859dcff32aa520837f081d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a262c697d1ad2a70565ac28c317a7bd0c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a262c697d1ad2a70565ac28c317a7bd0c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int32_t, half, <a class="el" href="structc10_1_1_half.html">at::Half</a>, float, true)</td></tr>
<tr class="separator:a262c697d1ad2a70565ac28c317a7bd0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac43dcd0e5b4aac991f043f905c85c7dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac43dcd0e5b4aac991f043f905c85c7dc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int64_t, half, <a class="el" href="structc10_1_1_half.html">at::Half</a>, float, true)</td></tr>
<tr class="separator:ac43dcd0e5b4aac991f043f905c85c7dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac7cec379223c4c106729894daafcd6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aac7cec379223c4c106729894daafcd6d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int32_t, uint8_t, uint8_t, float, true)</td></tr>
<tr class="separator:aac7cec379223c4c106729894daafcd6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a472ceb7954595ac0c5507630dd6c56a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a472ceb7954595ac0c5507630dd6c56a1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EMBEDDING_SPECIALIZATION</b> (int64_t, uint8_t, uint8_t, float, true)</td></tr>
<tr class="separator:a472ceb7954595ac0c5507630dd6c56a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a069c8118feb23c3b2ad89f3e10b8198d"><td class="memTemplParams" colspan="2">template&lt;typename IndexType , typename InType , typename OutType , bool IS_WEIGHT_POSITIONAL = false&gt; </td></tr>
<tr class="memitem:a069c8118feb23c3b2ad89f3e10b8198d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a069c8118feb23c3b2ad89f3e10b8198d">EmbeddingLookup</a> (const std::int64_t block_size, const std::int64_t output_size, const std::int64_t index_size, const std::int64_t data_size, const InType *input, const IndexType *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, OutType *out)</td></tr>
<tr class="memdesc:a069c8118feb23c3b2ad89f3e10b8198d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Embedding lookup with reduction.  <a href="#a069c8118feb23c3b2ad89f3e10b8198d">More...</a><br /></td></tr>
<tr class="separator:a069c8118feb23c3b2ad89f3e10b8198d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9f8402c25ab041e2d204f5403abbb66"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad9f8402c25ab041e2d204f5403abbb66"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int32_t_float_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:ad9f8402c25ab041e2d204f5403abbb66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b5eb7c574feca0ee475688e41bcdf1f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8b5eb7c574feca0ee475688e41bcdf1f"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int32_t_float_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a8b5eb7c574feca0ee475688e41bcdf1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d924d7460f556bbdfb6fb34a7647de7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5d924d7460f556bbdfb6fb34a7647de7"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int64_t_float_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int64_t *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a5d924d7460f556bbdfb6fb34a7647de7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5812f90628ed83d3c0f699f9c47d94bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5812f90628ed83d3c0f699f9c47d94bd"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int64_t_float_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int64_t *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a5812f90628ed83d3c0f699f9c47d94bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a994df7e2a8c9f4da4c68948f7437c3a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a994df7e2a8c9f4da4c68948f7437c3a5"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int32_t_half_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a994df7e2a8c9f4da4c68948f7437c3a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acedc765e5f284e1c38466b2eca7ca280"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acedc765e5f284e1c38466b2eca7ca280"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int32_t_half_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:acedc765e5f284e1c38466b2eca7ca280"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4853ec3174ffcfe6409084cd99295bf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4853ec3174ffcfe6409084cd99295bf"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int64_t_half_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int64_t *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:aa4853ec3174ffcfe6409084cd99295bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86eee901090955af62144f2784dcc734"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86eee901090955af62144f2784dcc734"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int64_t_half_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int64_t *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a86eee901090955af62144f2784dcc734"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9460b01bb9237df95e2b23311e2eacf0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9460b01bb9237df95e2b23311e2eacf0"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int32_t_uint8_t_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a9460b01bb9237df95e2b23311e2eacf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a892bda99694a5b207dbe7312a84d2c5b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a892bda99694a5b207dbe7312a84d2c5b"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int32_t_uint8_t_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a892bda99694a5b207dbe7312a84d2c5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cbd5f30a04886aba3c7deafecb57c1a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8cbd5f30a04886aba3c7deafecb57c1a"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int64_t_uint8_t_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int64_t *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a8cbd5f30a04886aba3c7deafecb57c1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a239150e300fb83ee156025017a20d907"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a239150e300fb83ee156025017a20d907"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>EmbeddingLookup_int64_t_uint8_t_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int64_t *indices, const int *lengths, const float *weights, const float *scale_bias, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a239150e300fb83ee156025017a20d907"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a373bbc05ed054468668c8cdeec8dee9e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a373bbc05ed054468668c8cdeec8dee9e"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int32_t_float_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a373bbc05ed054468668c8cdeec8dee9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a788dfa3794a5fa0113a0c0e536b49c3f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a788dfa3794a5fa0113a0c0e536b49c3f"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int32_t_float_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a788dfa3794a5fa0113a0c0e536b49c3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dfd22660bd5ba4d4ea876f8a6358024"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dfd22660bd5ba4d4ea876f8a6358024"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int64_t_float_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int64_t *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a3dfd22660bd5ba4d4ea876f8a6358024"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2c222b842a790488bfd8469ca485029"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2c222b842a790488bfd8469ca485029"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int64_t_float_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const float *input, const int64_t *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:ab2c222b842a790488bfd8469ca485029"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d694417f9e016212b4e755277051e35"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d694417f9e016212b4e755277051e35"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int32_t_half_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a1d694417f9e016212b4e755277051e35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abec1c798e9928182a9f291e0bb49ff50"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abec1c798e9928182a9f291e0bb49ff50"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int32_t_half_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:abec1c798e9928182a9f291e0bb49ff50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a448c24003901d3ad3f305e22373fc4eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a448c24003901d3ad3f305e22373fc4eb"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int64_t_half_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int64_t *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a448c24003901d3ad3f305e22373fc4eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af09d1fd3e24b8e36600cc1102c7636b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af09d1fd3e24b8e36600cc1102c7636b6"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int64_t_half_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *input, const int64_t *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:af09d1fd3e24b8e36600cc1102c7636b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb1f82b8a9b3ed9b5d74e36e7e6e9698"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afb1f82b8a9b3ed9b5d74e36e7e6e9698"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:afb1f82b8a9b3ed9b5d74e36e7e6e9698"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25a65a50c7bca3abb60cd19fe0ad7679"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a25a65a50c7bca3abb60cd19fe0ad7679"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a25a65a50c7bca3abb60cd19fe0ad7679"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abadda99c433e8b48b57a94ddb042f7c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abadda99c433e8b48b57a94ddb042f7c9"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_false__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int64_t *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:abadda99c433e8b48b57a94ddb042f7c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e594b8671d2323d9ad7b954cfcfff9c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e594b8671d2323d9ad7b954cfcfff9c"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_true__avx2_fma</b> (const int64_t block_size, const int64_t output_size, const int64_t index_size, const int64_t data_size, const uint8_t *input, const int64_t *indices, const int *lengths, const float *weights, bool normalize_by_lengths, float *out)</td></tr>
<tr class="separator:a4e594b8671d2323d9ad7b954cfcfff9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87351407eefb8a8660c50f23af417012"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87351407eefb8a8660c50f23af417012"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>FUSED_8BIT_ROWWISE_EMBEDDING_SPECIALIZATION</b> (int32_t, float)</td></tr>
<tr class="separator:a87351407eefb8a8660c50f23af417012"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2fa494d7fb1af7999487396eaad50469"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2fa494d7fb1af7999487396eaad50469"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>FUSED_8BIT_ROWWISE_EMBEDDING_SPECIALIZATION</b> (int64_t, float)</td></tr>
<tr class="separator:a2fa494d7fb1af7999487396eaad50469"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75e437e39d446084ae41c0ba6afad2a2"><td class="memTemplParams" colspan="2">template&lt;typename IndexType , typename InType , typename OutType , bool IS_WEIGHT_POSITIONAL = false&gt; </td></tr>
<tr class="memitem:a75e437e39d446084ae41c0ba6afad2a2"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a75e437e39d446084ae41c0ba6afad2a2">Fused8BitRowwiseEmbeddingLookup</a> (const std::int64_t block_size, const std::int64_t output_size, const std::int64_t index_size, const std::int64_t data_size, const InType *input, const IndexType *indices, const int *lengths, const float *weights, bool normalize_by_lengths, OutType *out)</td></tr>
<tr class="memdesc:a75e437e39d446084ae41c0ba6afad2a2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Embedding lookup with reduction.  <a href="#a75e437e39d446084ae41c0ba6afad2a2">More...</a><br /></td></tr>
<tr class="separator:a75e437e39d446084ae41c0ba6afad2a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5496fbdc2cb8dde299857e6b90093dfe"><td class="memTemplParams" colspan="2"><a class="anchor" id="a5496fbdc2cb8dde299857e6b90093dfe"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a5496fbdc2cb8dde299857e6b90093dfe"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>TypedAxpy&lt; float, float &gt;</b> (int N, const float a, const float *x, float *y)</td></tr>
<tr class="separator:a5496fbdc2cb8dde299857e6b90093dfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af21f7602c98f46d4a483de7e39061c21"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af21f7602c98f46d4a483de7e39061c21"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpyHalffloat__base</b> (int N, const float a, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *x, float *y)</td></tr>
<tr class="separator:af21f7602c98f46d4a483de7e39061c21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a848dad8d760296462574c599fb3cb939"><td class="memTemplParams" colspan="2"><a class="anchor" id="a848dad8d760296462574c599fb3cb939"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a848dad8d760296462574c599fb3cb939"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>TypedAxpy&lt; at::Half, float &gt;</b> (int N, const float a, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *x, float *y)</td></tr>
<tr class="separator:a848dad8d760296462574c599fb3cb939"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f03fa74e51e214bde37bea2b5a060ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f03fa74e51e214bde37bea2b5a060ad"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpy_uint8_float__base</b> (int N, const float a, const std::uint8_t *x, float *y)</td></tr>
<tr class="separator:a9f03fa74e51e214bde37bea2b5a060ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a475524f78a260b2f1c5688254fef332d"><td class="memTemplParams" colspan="2"><a class="anchor" id="a475524f78a260b2f1c5688254fef332d"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a475524f78a260b2f1c5688254fef332d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>TypedAxpy&lt; std::uint8_t, float &gt;</b> (int N, const float a, const std::uint8_t *x, float *y)</td></tr>
<tr class="separator:a475524f78a260b2f1c5688254fef332d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31911563cde2f40247726cd126da6c75"><td class="memTemplParams" colspan="2"><a class="anchor" id="a31911563cde2f40247726cd126da6c75"></a>
template&lt;typename IN , typename OUT &gt; </td></tr>
<tr class="memitem:a31911563cde2f40247726cd126da6c75"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>TypedAxpy</b> (int N, const OUT a, const IN *x, OUT *y)</td></tr>
<tr class="separator:a31911563cde2f40247726cd126da6c75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f22948fc877f905f79cd02ee0a93930"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0f22948fc877f905f79cd02ee0a93930"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpyHalffloat__avx_f16c</b> (int N, const float a, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *x, float *y)</td></tr>
<tr class="separator:a0f22948fc877f905f79cd02ee0a93930"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ab0368ca379a814905e0ecfe36f3fe2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ab0368ca379a814905e0ecfe36f3fe2"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpyHalffloat__avx2_fma</b> (int N, const float a, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *x, float *y)</td></tr>
<tr class="separator:a5ab0368ca379a814905e0ecfe36f3fe2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a0fe630d1fc251b4ccb093469400af1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2a0fe630d1fc251b4ccb093469400af1"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpy_uint8_float__avx2_fma</b> (int N, const float a, const std::uint8_t *x, float *y)</td></tr>
<tr class="separator:a2a0fe630d1fc251b4ccb093469400af1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab88c9749fe42e59c71b57c9b72fb2c6e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab88c9749fe42e59c71b57c9b72fb2c6e"></a>
<a class="el" href="structcaffe2_1_1_predictor_config.html">PredictorConfig</a>&#160;</td><td class="memItemRight" valign="bottom"><b>makePredictorConfig</b> (const MetaNetDef &amp;def, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *parent, bool run_init)</td></tr>
<tr class="separator:ab88c9749fe42e59c71b57c9b72fb2c6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add2e722071b50b4dff66bc1179805c85"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="add2e722071b50b4dff66bc1179805c85"></a>
<a class="el" href="structcaffe2_1_1_predictor_config.html">PredictorConfig</a>&#160;</td><td class="memItemRight" valign="bottom"><b>makePredictorConfig</b> (const NetDef &amp;init_net, const NetDef &amp;run_net, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *parent, bool run_init, int optimization)</td></tr>
<tr class="separator:add2e722071b50b4dff66bc1179805c85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c644c09d127ee8077a1bfcec57e9477"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2c644c09d127ee8077a1bfcec57e9477"></a>
CAFFE2_API <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a>&#160;</td><td class="memItemRight" valign="bottom"><b>makeWorkspace</b> (std::shared_ptr&lt; PredictorParameters &gt; parameters)</td></tr>
<tr class="separator:a2c644c09d127ee8077a1bfcec57e9477"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1825d0b672c19d0516ac5bea191cb08d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1825d0b672c19d0516ac5bea191cb08d"></a>
CAFFE2_API DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>ProtoToType</b> (const caffe2::DeviceTypeProto p)</td></tr>
<tr class="separator:a1825d0b672c19d0516ac5bea191cb08d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7fba83f75e11dfbafe499c07fa71ecf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af7fba83f75e11dfbafe499c07fa71ecf"></a>
CAFFE2_API DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>ProtoToType</b> (int p)</td></tr>
<tr class="separator:af7fba83f75e11dfbafe499c07fa71ecf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b5bff7502d1c8d85f06159692881315"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4b5bff7502d1c8d85f06159692881315"></a>
CAFFE2_API DeviceTypeProto&#160;</td><td class="memItemRight" valign="bottom"><b>TypeToProto</b> (const DeviceType &amp;t)</td></tr>
<tr class="separator:a4b5bff7502d1c8d85f06159692881315"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff1d077a4def5382b1115ef30de2f252"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff1d077a4def5382b1115ef30de2f252"></a>
CAFFE2_API caffe2::DeviceOption&#160;</td><td class="memItemRight" valign="bottom"><b>DeviceToOption</b> (const <a class="el" href="structc10_1_1_device.html">at::Device</a> &amp;device)</td></tr>
<tr class="separator:aff1d077a4def5382b1115ef30de2f252"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee7fb395c795d8d30ecf0922b3958265"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aee7fb395c795d8d30ecf0922b3958265"></a>
CAFFE2_API <a class="el" href="structc10_1_1_device.html">at::Device</a>&#160;</td><td class="memItemRight" valign="bottom"><b>OptionToDevice</b> (const caffe2::DeviceOption option)</td></tr>
<tr class="separator:aee7fb395c795d8d30ecf0922b3958265"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf701974181bb570f71815f8f5413350"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abf701974181bb570f71815f8f5413350"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ExtractDeviceOption</b> (DeviceOption *device_option, const <a class="el" href="structc10_1_1_device.html">at::Device</a> &amp;device)</td></tr>
<tr class="separator:abf701974181bb570f71815f8f5413350"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41f778f548b8b7d1826ef055cd3d319e"><td class="memTemplParams" colspan="2"><a class="anchor" id="a41f778f548b8b7d1826ef055cd3d319e"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a41f778f548b8b7d1826ef055cd3d319e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>FindMinMax</b> (const <a class="el" href="struct_t.html">T</a> *data, float *min, float *max, int len)</td></tr>
<tr class="separator:a41f778f548b8b7d1826ef055cd3d319e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad14e7d24f34f32c70ebab9f02b408808"><td class="memTemplParams" colspan="2"><a class="anchor" id="ad14e7d24f34f32c70ebab9f02b408808"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:ad14e7d24f34f32c70ebab9f02b408808"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>FindMinMax&lt; float &gt;</b> (const float *data, float *min, float *max, int len)</td></tr>
<tr class="separator:ad14e7d24f34f32c70ebab9f02b408808"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b3c7384207422fdc3f018ea46216fa8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5b3c7384207422fdc3f018ea46216fa8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (BatchMatMul, DNNLOWP, <a class="el" href="classcaffe2_1_1_batch_mat_mul_d_n_n_low_p_op.html">BatchMatMulDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a5b3c7384207422fdc3f018ea46216fa8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae09e7a1a813b740bc6cc223215d90b69"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae09e7a1a813b740bc6cc223215d90b69"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (BatchMatMul, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_batch_mat_mul_d_n_n_low_p_op.html">BatchMatMulDNNLowPOp</a>&lt; uint16_t &gt;)</td></tr>
<tr class="separator:ae09e7a1a813b740bc6cc223215d90b69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e6de7c6c28c8315d2a9238a6878da55"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e6de7c6c28c8315d2a9238a6878da55"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8BatchMatMul, DNNLOWP, <a class="el" href="classcaffe2_1_1_batch_mat_mul_d_n_n_low_p_op.html">BatchMatMulDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a0e6de7c6c28c8315d2a9238a6878da55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b6945cd6e3b7c5b44935a2f36770ce4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b6945cd6e3b7c5b44935a2f36770ce4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (BatchPermutation, DNNLOWP, <a class="el" href="classcaffe2_1_1_batch_permutation_d_n_n_low_p_op.html">BatchPermutationDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a0b6945cd6e3b7c5b44935a2f36770ce4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac271ea248ddb47be46e4d2ea692c67d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac271ea248ddb47be46e4d2ea692c67d4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8BatchPermutation, DNNLOWP, <a class="el" href="classcaffe2_1_1_batch_permutation_d_n_n_low_p_op.html">BatchPermutationDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:ac271ea248ddb47be46e4d2ea692c67d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3154cf2e53e801feaa006601ada6a2b1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3154cf2e53e801feaa006601ada6a2b1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Int8BatchPermutation).NumInputs(2).NumOutputs(1)</td></tr>
<tr class="separator:a3154cf2e53e801feaa006601ada6a2b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca3ffe3c32255a664a0e28e57c5468ba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca3ffe3c32255a664a0e28e57c5468ba"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_channel_shuffle.html">ChannelShuffle</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_channel_shuffle_d_n_n_low_p_op.html">ChannelShuffleDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:aca3ffe3c32255a664a0e28e57c5468ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5c5914c572118c327f2b7ed6ded04fd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af5c5914c572118c327f2b7ed6ded04fd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8ChannelShuffle, DNNLOWP, <a class="el" href="classcaffe2_1_1_channel_shuffle_d_n_n_low_p_op.html">ChannelShuffleDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:af5c5914c572118c327f2b7ed6ded04fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2d295972edf8dd1d4a4b256aeb4a9f2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa2d295972edf8dd1d4a4b256aeb4a9f2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_channel_shuffle.html">ChannelShuffle</a>, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_channel_shuffle_d_n_n_low_p_op.html">ChannelShuffleDNNLowPOp</a>&lt; uint16_t &gt;)</td></tr>
<tr class="separator:aa2d295972edf8dd1d4a4b256aeb4a9f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2f84ad01bb86b6a283880fc4be1d98f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2f84ad01bb86b6a283880fc4be1d98f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_concat.html">Concat</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_concat_d_n_n_low_p_op.html">ConcatDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:ab2f84ad01bb86b6a283880fc4be1d98f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d451b38af14b76b030fc1c904976508"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8d451b38af14b76b030fc1c904976508"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Concat, DNNLOWP, <a class="el" href="classcaffe2_1_1_concat_d_n_n_low_p_op.html">ConcatDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a8d451b38af14b76b030fc1c904976508"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab659c51236ba6dfd7edf412e24d0ee5d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab659c51236ba6dfd7edf412e24d0ee5d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_conv.html">Conv</a>, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_acc16_op.html">ConvDNNLowPAcc16Op</a>&lt; false &gt;)</td></tr>
<tr class="separator:ab659c51236ba6dfd7edf412e24d0ee5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40af9a315f7cfdee02241c96dbc5bc2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a40af9a315f7cfdee02241c96dbc5bc2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_conv_relu.html">ConvRelu</a>, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_acc16_op.html">ConvDNNLowPAcc16Op</a>&lt; true &gt;)</td></tr>
<tr class="separator:a40af9a315f7cfdee02241c96dbc5bc2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b1edfecc03a182e9841b76bf821bcd6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5b1edfecc03a182e9841b76bf821bcd6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Conv, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_acc16_op.html">ConvDNNLowPAcc16Op</a>&lt; false &gt;)</td></tr>
<tr class="separator:a5b1edfecc03a182e9841b76bf821bcd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72d0a4d3af9dc3830a21de7547562131"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a72d0a4d3af9dc3830a21de7547562131"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8ConvRelu, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_acc16_op.html">ConvDNNLowPAcc16Op</a>&lt; true &gt;)</td></tr>
<tr class="separator:a72d0a4d3af9dc3830a21de7547562131"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e60ad5332e363b7927c9cfcd07a105c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e60ad5332e363b7927c9cfcd07a105c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (<a class="el" href="class_conv_relu.html">ConvRelu</a>).NumInputs(2</td></tr>
<tr class="separator:a0e60ad5332e363b7927c9cfcd07a105c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab05b359f95fa2fad9d5e5d3a9c5e192f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab05b359f95fa2fad9d5e5d3a9c5e192f"></a>
NumOutputs(1).TensorInferenceFunction(<a class="el" href="classcaffe2_1_1_conv_pool_op_base.html">ConvPoolOpBase</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_conv.html">Conv</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_op.html">ConvDNNLowPOp</a>&lt; uint8_t, false &gt;)</td></tr>
<tr class="separator:ab05b359f95fa2fad9d5e5d3a9c5e192f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a980fa1b7653e33883e61c10ddfa59752"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a980fa1b7653e33883e61c10ddfa59752"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_conv_relu.html">ConvRelu</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_op.html">ConvDNNLowPOp</a>&lt; uint8_t, true &gt;)</td></tr>
<tr class="separator:a980fa1b7653e33883e61c10ddfa59752"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86855da8edff021099e2ea12e6c6a9a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86855da8edff021099e2ea12e6c6a9a1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Conv, DNNLOWP, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_op.html">ConvDNNLowPOp</a>&lt; uint8_t, false &gt;)</td></tr>
<tr class="separator:a86855da8edff021099e2ea12e6c6a9a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a496fdc5e09b04ab631b487f8c0eab395"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a496fdc5e09b04ab631b487f8c0eab395"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8ConvRelu, DNNLOWP, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_op.html">ConvDNNLowPOp</a>&lt; uint8_t, true &gt;)</td></tr>
<tr class="separator:a496fdc5e09b04ab631b487f8c0eab395"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20428f7444a128c6663519ec87d75e4c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a20428f7444a128c6663519ec87d75e4c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_conv.html">Conv</a>, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_op.html">ConvDNNLowPOp</a>&lt; uint16_t, false &gt;)</td></tr>
<tr class="separator:a20428f7444a128c6663519ec87d75e4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a689bc2907547849cbe4d94fda098f044"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a689bc2907547849cbe4d94fda098f044"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_conv_relu.html">ConvRelu</a>, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_op.html">ConvDNNLowPOp</a>&lt; uint16_t, true &gt;)</td></tr>
<tr class="separator:a689bc2907547849cbe4d94fda098f044"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7373da96dda66fc5b290a77201a23986"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7373da96dda66fc5b290a77201a23986"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_conv_relu.html">ConvRelu</a>, <a class="el" href="classcaffe2_1_1_conv_relu_op.html">ConvReluOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7373da96dda66fc5b290a77201a23986"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a370c82cee309e82135ec89ead2a0b6c2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a370c82cee309e82135ec89ead2a0b6c2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Dequantize, DNNLOWP, <a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a>&lt; std::uint8_t &gt;)</td></tr>
<tr class="separator:a370c82cee309e82135ec89ead2a0b6c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae206c2d4fdc237e65ac4e00b83af6dba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae206c2d4fdc237e65ac4e00b83af6dba"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Dequantize, DNNLOWP_ROWWISE, <a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a>&lt; std::uint8_t &gt;)</td></tr>
<tr class="separator:ae206c2d4fdc237e65ac4e00b83af6dba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc93821769cf18502369a51cbeaed51c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc93821769cf18502369a51cbeaed51c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Dequantize, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a>&lt; std::uint16_t &gt;)</td></tr>
<tr class="separator:adc93821769cf18502369a51cbeaed51c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab61102effbc5d6568a393c1b94cffe4b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab61102effbc5d6568a393c1b94cffe4b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Dequantize, DNNLOWP_ROWWISE_16, <a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a>&lt; std::uint16_t &gt;)</td></tr>
<tr class="separator:ab61102effbc5d6568a393c1b94cffe4b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c0a3147e28267c9ef019e5328635a65"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c0a3147e28267c9ef019e5328635a65"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Dequantize, DNNLOWP, <a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a>&lt; std::uint8_t &gt;)</td></tr>
<tr class="separator:a1c0a3147e28267c9ef019e5328635a65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a2571d1dfd8aa66d1fc58b4b2ae1c35"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a2571d1dfd8aa66d1fc58b4b2ae1c35"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Dequantize, DNNLOWP_ROWWISE, <a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a>&lt; std::uint8_t &gt;)</td></tr>
<tr class="separator:a4a2571d1dfd8aa66d1fc58b4b2ae1c35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a469000140d0f2085a81676d53a1b9318"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a469000140d0f2085a81676d53a1b9318"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8DequantizeRowWise, DNNLOWP, <a class="el" href="classcaffe2_1_1_dequantize_d_n_n_low_p_op.html">DequantizeDNNLowPOp</a>&lt; std::uint8_t &gt;)</td></tr>
<tr class="separator:a469000140d0f2085a81676d53a1b9318"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85e4d4b6d9a038ee88b2f87f101713c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a85e4d4b6d9a038ee88b2f87f101713c1"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>dnnlowp_get_num_threads</b> ()</td></tr>
<tr class="separator:a85e4d4b6d9a038ee88b2f87f101713c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee7c0d3211063f830b2478bb78e9a056"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aee7c0d3211063f830b2478bb78e9a056"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>dnnlowp_get_max_threads</b> ()</td></tr>
<tr class="separator:aee7c0d3211063f830b2478bb78e9a056"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a618e325686a9fadc227b1562d862dd4e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a618e325686a9fadc227b1562d862dd4e"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>dnnlowp_get_thread_num</b> ()</td></tr>
<tr class="separator:a618e325686a9fadc227b1562d862dd4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afca6955a094c9c3ebe7a85e9736e3fdc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afca6955a094c9c3ebe7a85e9736e3fdc"></a>
std::pair&lt; size_t, size_t &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Get1DPartition</b> (size_t work, int nthreads, int tid, int work_align)</td></tr>
<tr class="separator:afca6955a094c9c3ebe7a85e9736e3fdc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc9c70f728fa0ccd1bca146cd1d282ae"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#acc9c70f728fa0ccd1bca146cd1d282ae">Get1DPartitionOf2D</a> (int m, int n, int nthreads, int thread_id, int *m_begin, int *m_end, int *n_begin, int *n_end, int n_align=1)</td></tr>
<tr class="memdesc:acc9c70f728fa0ccd1bca146cd1d282ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">1D-partition m x n 2D work.  <a href="#acc9c70f728fa0ccd1bca146cd1d282ae">More...</a><br /></td></tr>
<tr class="separator:acc9c70f728fa0ccd1bca146cd1d282ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe324683d7cbf3983f9233fc368d5532"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe324683d7cbf3983f9233fc368d5532"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_add.html">Add</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_add_d_n_n_low_p_op.html">AddDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:abe324683d7cbf3983f9233fc368d5532"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70adde5acf46bb891dc5b907c915e9cc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a70adde5acf46bb891dc5b907c915e9cc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Add, DNNLOWP, <a class="el" href="classcaffe2_1_1_add_d_n_n_low_p_op.html">AddDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a70adde5acf46bb891dc5b907c915e9cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a5a5ab717bb50ae4e7b94b5aa01e0c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a5a5ab717bb50ae4e7b94b5aa01e0c1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (ElementwiseLinear, DNNLOWP, <a class="el" href="classcaffe2_1_1_elementwise_linear_d_n_n_low_p_op.html">ElementwiseLinearDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a4a5a5ab717bb50ae4e7b94b5aa01e0c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed2a5a599880b3d6dbc7e92669504781"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed2a5a599880b3d6dbc7e92669504781"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8ElementwiseLinear, DNNLOWP, <a class="el" href="classcaffe2_1_1_elementwise_linear_d_n_n_low_p_op.html">ElementwiseLinearDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:aed2a5a599880b3d6dbc7e92669504781"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e8c533acb20703dca5fc115e9e2b876"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e8c533acb20703dca5fc115e9e2b876"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Mul, DNNLOWP, <a class="el" href="classcaffe2_1_1_mul_d_n_n_low_p_op.html">MulDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a6e8c533acb20703dca5fc115e9e2b876"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8fefea31e0754c17d639cc87bbb0fda9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8fefea31e0754c17d639cc87bbb0fda9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Mul, DNNLOWP, <a class="el" href="classcaffe2_1_1_mul_d_n_n_low_p_op.html">MulDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a8fefea31e0754c17d639cc87bbb0fda9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b62c98bd5bad2e1cdfe74c7ef091e1d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b62c98bd5bad2e1cdfe74c7ef091e1d"></a>
First of the input tensors Can be inplace&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;sum&quot;,&quot;Output tensor. Same dimension as inputs.&quot;)</td></tr>
<tr class="separator:a2b62c98bd5bad2e1cdfe74c7ef091e1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30cac7121f76bb6020195967776b064e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a30cac7121f76bb6020195967776b064e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_sum.html">Sum</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_sum_d_n_n_low_p_op.html">SumDNNLowPOp</a>&lt; uint8_t, false &gt;)</td></tr>
<tr class="separator:a30cac7121f76bb6020195967776b064e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa83ce639a45403aa53fda6f24ccaf250"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa83ce639a45403aa53fda6f24ccaf250"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_sum_relu.html">SumRelu</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_sum_d_n_n_low_p_op.html">SumDNNLowPOp</a>&lt; uint8_t, true &gt;)</td></tr>
<tr class="separator:aa83ce639a45403aa53fda6f24ccaf250"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35751a19a96649976aba957bca50cb08"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a35751a19a96649976aba957bca50cb08"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Sum, DNNLOWP, <a class="el" href="classcaffe2_1_1_sum_d_n_n_low_p_op.html">SumDNNLowPOp</a>&lt; uint8_t, false &gt;)</td></tr>
<tr class="separator:a35751a19a96649976aba957bca50cb08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a875f54fc962f8faae93465013dc957d3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a875f54fc962f8faae93465013dc957d3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8SumRelu, DNNLOWP, <a class="el" href="classcaffe2_1_1_sum_d_n_n_low_p_op.html">SumDNNLowPOp</a>&lt; uint8_t, true &gt;)</td></tr>
<tr class="separator:a875f54fc962f8faae93465013dc957d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03520be6a7625aa7749b0a8c644bf73f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a03520be6a7625aa7749b0a8c644bf73f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_sum.html">Sum</a>, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_sum_d_n_n_low_p_op.html">SumDNNLowPOp</a>&lt; uint16_t, false &gt;)</td></tr>
<tr class="separator:a03520be6a7625aa7749b0a8c644bf73f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afcf03da070c8986136486187bfd4a1ab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afcf03da070c8986136486187bfd4a1ab"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_sum_relu.html">SumRelu</a>, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_sum_d_n_n_low_p_op.html">SumDNNLowPOp</a>&lt; uint16_t, true &gt;)</td></tr>
<tr class="separator:afcf03da070c8986136486187bfd4a1ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bc368db142cfa15abe66b5106421989"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5bc368db142cfa15abe66b5106421989"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="class_sum_relu.html">SumRelu</a>, <a class="el" href="classcaffe2_1_1_sum_relu_op.html">SumReluOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a5bc368db142cfa15abe66b5106421989"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd28ca01b79fa2887016809efbdf8631"><td class="memTemplParams" colspan="2"><a class="anchor" id="afd28ca01b79fa2887016809efbdf8631"></a>
template&lt;typename ACC_T &gt; </td></tr>
<tr class="memitem:afd28ca01b79fa2887016809efbdf8631"><td class="memTemplItemLeft" align="right" valign="top">shared_ptr&lt; fbgemm::PackBMatrix&lt; int8_t, ACC_T &gt; &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>GetOrCreateFbgemmPackBMatrix</b> (fbgemm::matrix_op_t trans, int32_t m, int32_t n, const void *orig_data, const int8_t *quantized_data, int32_t ld)</td></tr>
<tr class="separator:afd28ca01b79fa2887016809efbdf8631"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae419e4e1eeb2a7bfd53bb93ec13d84b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae419e4e1eeb2a7bfd53bb93ec13d84b0"></a>
template shared_ptr&lt; fbgemm::PackBMatrix&lt; int8_t, int16_t &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetOrCreateFbgemmPackBMatrix&lt; int16_t &gt;</b> (fbgemm::matrix_op_t trans, int32_t m, int32_t n, const void *orig_data, const int8_t *quantized_data, int32_t ld)</td></tr>
<tr class="separator:ae419e4e1eeb2a7bfd53bb93ec13d84b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad24fee2e400fb7610080c6e567a14047"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad24fee2e400fb7610080c6e567a14047"></a>
template shared_ptr&lt; fbgemm::PackBMatrix&lt; int8_t, int32_t &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetOrCreateFbgemmPackBMatrix&lt; int32_t &gt;</b> (fbgemm::matrix_op_t trans, int32_t m, int32_t n, const void *orig_data, const int8_t *quantized_data, int32_t ld)</td></tr>
<tr class="separator:ad24fee2e400fb7610080c6e567a14047"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9b241203d1057494c9eefcde409a05e"><td class="memTemplParams" colspan="2">template&lt;typename ACC_T &gt; </td></tr>
<tr class="memitem:ae9b241203d1057494c9eefcde409a05e"><td class="memTemplItemLeft" align="right" valign="top">std::shared_ptr&lt; fbgemm::PackBMatrix&lt; int8_t, ACC_T &gt; &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#ae9b241203d1057494c9eefcde409a05e">GetOrCreateFbgemmPackBMatrix</a> (fbgemm::matrix_op_t trans, std::int32_t m, std::int32_t n, const void *orig_data, const std::int8_t *quantized_data, std::int32_t ld)</td></tr>
<tr class="memdesc:ae9b241203d1057494c9eefcde409a05e"><td class="mdescLeft">&#160;</td><td class="mdescRight">If there's an existing packed matrix for the same matrix, reuse it.  <a href="#ae9b241203d1057494c9eefcde409a05e">More...</a><br /></td></tr>
<tr class="separator:ae9b241203d1057494c9eefcde409a05e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab892a824d432c7b1d42d9bd8b944da0e"><td class="memTemplParams" colspan="2"><a class="anchor" id="ab892a824d432c7b1d42d9bd8b944da0e"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ab892a824d432c7b1d42d9bd8b944da0e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>QuantizeWeight</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, int kernel_dim, int <a class="el" href="struct_m.html">M</a>, vector&lt; TensorQuantizationParams &gt; &amp;qparams, vector&lt; typename make_signed&lt; <a class="el" href="struct_t.html">T</a> &gt;::type &gt; &amp;W_quantized, <a class="el" href="classdnnlowp_1_1_quantization_factory.html">dnnlowp::QuantizationFactory</a> *qfactory)</td></tr>
<tr class="separator:ab892a824d432c7b1d42d9bd8b944da0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00c9d2e2d09c0905d16e4b882db52732"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a00c9d2e2d09c0905d16e4b882db52732"></a>
template void&#160;</td><td class="memItemRight" valign="bottom"><b>QuantizeWeight&lt; uint8_t &gt;</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, int kernel_dim, int <a class="el" href="struct_m.html">M</a>, vector&lt; TensorQuantizationParams &gt; &amp;qparams, vector&lt; int8_t &gt; &amp;W_quantized, <a class="el" href="classdnnlowp_1_1_quantization_factory.html">dnnlowp::QuantizationFactory</a> *qfactory)</td></tr>
<tr class="separator:a00c9d2e2d09c0905d16e4b882db52732"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ead3129f973e608cb3884738a11b83f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ead3129f973e608cb3884738a11b83f"></a>
template void&#160;</td><td class="memItemRight" valign="bottom"><b>QuantizeWeight&lt; uint16_t &gt;</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, int kernel_dim, int <a class="el" href="struct_m.html">M</a>, vector&lt; TensorQuantizationParams &gt; &amp;qparams, vector&lt; int16_t &gt; &amp;W_quantized, <a class="el" href="classdnnlowp_1_1_quantization_factory.html">dnnlowp::QuantizationFactory</a> *qfactory)</td></tr>
<tr class="separator:a4ead3129f973e608cb3884738a11b83f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27f0e17878a70ad9504a83ae403ded59"><td class="memTemplParams" colspan="2"><a class="anchor" id="a27f0e17878a70ad9504a83ae403ded59"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a27f0e17878a70ad9504a83ae403ded59"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ComputeColumnOffsets</b> (int num_rows, int num_cols, const <a class="el" href="struct_t.html">T</a> *W, const vector&lt; TensorQuantizationParams &gt; &amp;qparams, vector&lt; int32_t &gt; &amp;col_offsets)</td></tr>
<tr class="separator:a27f0e17878a70ad9504a83ae403ded59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe2dd3f222b6586afb9582851c4ab799"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe2dd3f222b6586afb9582851c4ab799"></a>
template void&#160;</td><td class="memItemRight" valign="bottom"><b>ComputeColumnOffsets&lt; int8_t &gt;</b> (int num_rows, int num_cols, const int8_t *W, const vector&lt; TensorQuantizationParams &gt; &amp;qparams, vector&lt; int32_t &gt; &amp;col_offsets)</td></tr>
<tr class="separator:abe2dd3f222b6586afb9582851c4ab799"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe2b53d3d975b2fdd5e630fa9e504547"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe2b53d3d975b2fdd5e630fa9e504547"></a>
template void&#160;</td><td class="memItemRight" valign="bottom"><b>ComputeColumnOffsets&lt; int16_t &gt;</b> (int num_rows, int num_cols, const int16_t *W, const vector&lt; TensorQuantizationParams &gt; &amp;qparams, vector&lt; int32_t &gt; &amp;col_offsets)</td></tr>
<tr class="separator:abe2b53d3d975b2fdd5e630fa9e504547"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa64fa8e5eac5f10d2a623ef913d3f99e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa64fa8e5eac5f10d2a623ef913d3f99e"></a>
fbgemm::CompressedSparseColumn *&#160;</td><td class="memItemRight" valign="bottom"><b>ExtractOutlierMatrix</b> (int groups, int kernel_dim, int <a class="el" href="struct_m.html">M</a>, int nbits_in_non_outlier, vector&lt; int8_t &gt; &amp;W_quantized)</td></tr>
<tr class="separator:aa64fa8e5eac5f10d2a623ef913d3f99e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa45393a4512ca56191d08c1e87758109"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa45393a4512ca56191d08c1e87758109"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="structcaffe2_1_1_int8_f_c_d_n_n_low_p_packed_weight_blob.html">Int8FCDNNLowPPackedWeightBlob</a>)</td></tr>
<tr class="separator:aa45393a4512ca56191d08c1e87758109"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58058d4f4199320b9e817b093e9cddbd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a58058d4f4199320b9e817b093e9cddbd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (<a class="el" href="structcaffe2_1_1_int8_conv_d_n_n_low_p_packed_weight_blob.html">Int8ConvDNNLowPPackedWeightBlob</a>)</td></tr>
<tr class="separator:a58058d4f4199320b9e817b093e9cddbd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abeac0af3c031d725dde6972c15b7f507"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abeac0af3c031d725dde6972c15b7f507"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8FCPackWeight, DNNLOWP, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_pack_weight_op.html">FullyConnectedDNNLowPPackWeightOp</a>)</td></tr>
<tr class="separator:abeac0af3c031d725dde6972c15b7f507"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd3d40331f677969b6c93bdc2cbfd5bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acd3d40331f677969b6c93bdc2cbfd5bb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8FCPackWeight, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_pack_weight_op.html">FullyConnectedDNNLowPPackWeightOp</a>)</td></tr>
<tr class="separator:acd3d40331f677969b6c93bdc2cbfd5bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8fcd810f5d00ece3d3dbfa737045c52a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8fcd810f5d00ece3d3dbfa737045c52a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8FCPackWeight, DNNLOWP_ROWWISE, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_pack_weight_op.html">FullyConnectedDNNLowPPackWeightOp</a>)</td></tr>
<tr class="separator:a8fcd810f5d00ece3d3dbfa737045c52a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca93b5243b3a77cde97de9f22804a33d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca93b5243b3a77cde97de9f22804a33d"></a>
Weight tensor in KRSC layout&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;b&quot;,&quot;Bias tensor&quot;).Output(0</td></tr>
<tr class="separator:aca93b5243b3a77cde97de9f22804a33d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a5fdca790e95e8c9172957df9a2fbb0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a5fdca790e95e8c9172957df9a2fbb0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8ConvPackWeight, DNNLOWP, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_pack_weight_op.html">ConvDNNLowPPackWeightOp</a>)</td></tr>
<tr class="separator:a5a5fdca790e95e8c9172957df9a2fbb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe586e1379998e94a0c38db375ea9a00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe586e1379998e94a0c38db375ea9a00"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8ConvPackWeight, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_conv_d_n_n_low_p_pack_weight_op.html">ConvDNNLowPPackWeightOp</a>)</td></tr>
<tr class="separator:abe586e1379998e94a0c38db375ea9a00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2739e5cbb61970f663a1137b88ac8362"><td class="memTemplParams" colspan="2"><a class="anchor" id="a2739e5cbb61970f663a1137b88ac8362"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a2739e5cbb61970f663a1137b88ac8362"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>QuantizeWeight</b> (const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;blob, int kernel_dim, int <a class="el" href="struct_m.html">M</a>, vector&lt; dnnlowp::TensorQuantizationParams &gt; &amp;qparams, vector&lt; typename std::make_signed&lt; <a class="el" href="struct_t.html">T</a> &gt;::type &gt; &amp;w_quantized, <a class="el" href="classdnnlowp_1_1_quantization_factory.html">dnnlowp::QuantizationFactory</a> *qfactory)</td></tr>
<tr class="separator:a2739e5cbb61970f663a1137b88ac8362"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a598eb1dd260a469dd6432b292697ebf5"><td class="memItemLeft" align="right" valign="top">fbgemm::CompressedSparseColumn *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a598eb1dd260a469dd6432b292697ebf5">ExtractOutlierMatrix</a> (int groups, int kernel_dim, int <a class="el" href="struct_m.html">M</a>, int nbits_in_non_outlier, vector&lt; std::int8_t &gt; &amp;W_quantized)</td></tr>
<tr class="separator:a598eb1dd260a469dd6432b292697ebf5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89ca4308ab52264e6b005c0539bccdb0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a89ca4308ab52264e6b005c0539bccdb0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_acc16_op.html">FullyConnectedDNNLowPAcc16Op</a>)</td></tr>
<tr class="separator:a89ca4308ab52264e6b005c0539bccdb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2a026f27bb49e083d964e244224b43e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2a026f27bb49e083d964e244224b43e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8FC, DNNLOWP_ACC16, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_acc16_op.html">FullyConnectedDNNLowPAcc16Op</a>)</td></tr>
<tr class="separator:ab2a026f27bb49e083d964e244224b43e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa026b80b0d4f3f72000f6c8a0c50938"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa026b80b0d4f3f72000f6c8a0c50938"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_op.html">FullyConnectedDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:afa026b80b0d4f3f72000f6c8a0c50938"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c8898299ac25d21291346db6f20d8ef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7c8898299ac25d21291346db6f20d8ef"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_op.html">FullyConnectedDNNLowPOp</a>&lt; uint16_t &gt;)</td></tr>
<tr class="separator:a7c8898299ac25d21291346db6f20d8ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c8693ca28642ff32ad996b433e7d3f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c8693ca28642ff32ad996b433e7d3f5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8FC, DNNLOWP, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_op.html">FullyConnectedDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a6c8693ca28642ff32ad996b433e7d3f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0e46fbeb4abf2a5af6e76cf18b027ce"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae0e46fbeb4abf2a5af6e76cf18b027ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, DNNLOWP_ROWWISE, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_op.html">FullyConnectedDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:ae0e46fbeb4abf2a5af6e76cf18b027ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40112805e29bba4c3b642a72398b5cd1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a40112805e29bba4c3b642a72398b5cd1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, DNNLOWP_ROWWISE_16, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_op.html">FullyConnectedDNNLowPOp</a>&lt; uint16_t &gt;)</td></tr>
<tr class="separator:a40112805e29bba4c3b642a72398b5cd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4c632dcad62653c0fc73a49e73dd57d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af4c632dcad62653c0fc73a49e73dd57d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8FC, DNNLOWP_ROWWISE, <a class="el" href="classcaffe2_1_1_fully_connected_d_n_n_low_p_op.html">FullyConnectedDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:af4c632dcad62653c0fc73a49e73dd57d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a938fc2d49ccc75d752097c9ddcfd68d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a938fc2d49ccc75d752097c9ddcfd68d7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, FAKE_FP16, <a class="el" href="classcaffe2_1_1_fully_connected_fake_lowp_f_p_op.html">FullyConnectedFakeLowpFPOp</a>&lt; fp32_to_fp16, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a938fc2d49ccc75d752097c9ddcfd68d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a65a2e0598b8fd93ea22c3f45db2c14"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6a65a2e0598b8fd93ea22c3f45db2c14"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (FCGradient, FAKE_FP16, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_fake_lowp_f_p_op.html">FullyConnectedGradientFakeLowpFPOp</a>&lt; fp32_to_fp16, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6a65a2e0598b8fd93ea22c3f45db2c14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8721cbdfb351813ea277685e057e678"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac8721cbdfb351813ea277685e057e678"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, FAKE_BFP_16, <a class="el" href="classcaffe2_1_1_fully_connected_fake_lowp_f_p_op.html">FullyConnectedFakeLowpFPOp</a>&lt; fp32_to_bfp16, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac8721cbdfb351813ea277685e057e678"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6606b58114f39815092e64784ebcd951"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6606b58114f39815092e64784ebcd951"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (FCGradient, FAKE_BFP_16, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_fake_lowp_f_p_op.html">FullyConnectedGradientFakeLowpFPOp</a>&lt; fp32_to_bfp16, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a6606b58114f39815092e64784ebcd951"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a843ed6167051a9f01438b285c5701ed0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a843ed6167051a9f01438b285c5701ed0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, FAKE_BFP_24, <a class="el" href="classcaffe2_1_1_fully_connected_fake_lowp_f_p_op.html">FullyConnectedFakeLowpFPOp</a>&lt; fp32_to_bfp24, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a843ed6167051a9f01438b285c5701ed0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ad7fb10bc8e93ee24b635119d52fe9d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1ad7fb10bc8e93ee24b635119d52fe9d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (FCGradient, FAKE_BFP_24, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_fake_lowp_f_p_op.html">FullyConnectedGradientFakeLowpFPOp</a>&lt; fp32_to_bfp24, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1ad7fb10bc8e93ee24b635119d52fe9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc551735e1bb1ec355a4bb509e750e6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc551735e1bb1ec355a4bb509e750e6d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, FAKE_BFP_14, <a class="el" href="classcaffe2_1_1_fully_connected_fake_lowp_f_p_op.html">FullyConnectedFakeLowpFPOp</a>&lt; fp32_to_bfp14, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:adc551735e1bb1ec355a4bb509e750e6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa84aa80e7704a0dfc6c68f2f6c11aeaf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa84aa80e7704a0dfc6c68f2f6c11aeaf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (FCGradient, FAKE_BFP_14, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_fake_lowp_f_p_op.html">FullyConnectedGradientFakeLowpFPOp</a>&lt; fp32_to_bfp14, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa84aa80e7704a0dfc6c68f2f6c11aeaf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afac34528cb1a408115c5c1374b20e142"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afac34528cb1a408115c5c1374b20e142"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_f_c.html">FC</a>, FAKE_BFP_16_ROUND, <a class="el" href="classcaffe2_1_1_fully_connected_fake_lowp_f_p_op.html">FullyConnectedFakeLowpFPOp</a>&lt; fp32_to_bfp16_round, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afac34528cb1a408115c5c1374b20e142"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02bce4f30daf4ed64bcfad87046dd45e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02bce4f30daf4ed64bcfad87046dd45e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (FCGradient, FAKE_BFP_16_ROUND, <a class="el" href="classcaffe2_1_1_fully_connected_gradient_fake_lowp_f_p_op.html">FullyConnectedGradientFakeLowpFPOp</a>&lt; fp32_to_bfp16_round, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a02bce4f30daf4ed64bcfad87046dd45e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a394b75ec455b5685e97a7da11992b4b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a394b75ec455b5685e97a7da11992b4b0"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>fp32_to_bfp16</b> (const float *source, size_t size, float *dest)</td></tr>
<tr class="separator:a394b75ec455b5685e97a7da11992b4b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a4248a30bc8280d216222ebd672371e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6a4248a30bc8280d216222ebd672371e"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>fp32_to_bfp24</b> (const float *source, size_t size, float *dest)</td></tr>
<tr class="separator:a6a4248a30bc8280d216222ebd672371e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e2a0aa91a9479c8b8b94e09385513c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7e2a0aa91a9479c8b8b94e09385513c7"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>fp32_to_bfp14</b> (const float *source, size_t size, float *dest)</td></tr>
<tr class="separator:a7e2a0aa91a9479c8b8b94e09385513c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b0fbd64b6cd7c3bf49975e146462aa8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b0fbd64b6cd7c3bf49975e146462aa8"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>fp32_to_bfp16_scalar</b> (const float *source, size_t size, float *dest)</td></tr>
<tr class="separator:a0b0fbd64b6cd7c3bf49975e146462aa8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04a29c702ab8a94bcba8323c9863c1c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04a29c702ab8a94bcba8323c9863c1c1"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>fp32_to_fp16</b> (const float *source, size_t size, float *dest)</td></tr>
<tr class="separator:a04a29c702ab8a94bcba8323c9863c1c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4be3039b556e29a73bf7319734667e0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af4be3039b556e29a73bf7319734667e0"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>fp32_to_bfp16_round</b> (const float *source, size_t size, float *dest)</td></tr>
<tr class="separator:af4be3039b556e29a73bf7319734667e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09d01eeba51ff849816a40a7ed94f16f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09d01eeba51ff849816a40a7ed94f16f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (GroupNorm, DNNLOWP, <a class="el" href="classcaffe2_1_1_group_norm_d_n_n_low_p_op.html">GroupNormDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a09d01eeba51ff849816a40a7ed94f16f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2ba4232b900f2b4249315fab3ba4267"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa2ba4232b900f2b4249315fab3ba4267"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8GroupNorm, DNNLOWP, <a class="el" href="classcaffe2_1_1_group_norm_d_n_n_low_p_op.html">GroupNormDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:aa2ba4232b900f2b4249315fab3ba4267"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71be255b59d8e195afc6cfc9379e558c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a71be255b59d8e195afc6cfc9379e558c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Int8GroupNorm).NumInputs(3).NumOutputs(</td></tr>
<tr class="separator:a71be255b59d8e195afc6cfc9379e558c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a762c5c149b3027b20533add8c577c4fb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a762c5c149b3027b20533add8c577c4fb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (LSTMUnit, DNNLOWP, <a class="el" href="classcaffe2_1_1_l_s_t_m_unit_d_n_n_low_p_op.html">LSTMUnitDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a762c5c149b3027b20533add8c577c4fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a550257940433af8921f9efa88a994cd6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a550257940433af8921f9efa88a994cd6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8LSTMUnit, DNNLOWP, <a class="el" href="classcaffe2_1_1_l_s_t_m_unit_d_n_n_low_p_op.html">LSTMUnitDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a550257940433af8921f9efa88a994cd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae078171370871a49e83ff57148d86600"><td class="memTemplParams" colspan="2"><a class="anchor" id="ae078171370871a49e83ff57148d86600"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae078171370871a49e83ff57148d86600"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>StoreMatrixInMatrixMarketFormat</b> (int m, int n, const <a class="el" href="struct_t.html">T</a> *a, const std::string &amp;matrix_name)</td></tr>
<tr class="separator:ae078171370871a49e83ff57148d86600"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411058fe07c09f4ab8ba99fdb79a4879"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a411058fe07c09f4ab8ba99fdb79a4879"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>max_pool_avx2</b> (const uint8_t *Xdata, int n, int height, int width, int channels, int pooled_height, int pooled_width, int kernel_h, int kernel_w, int stride_h, int stride_w, int pad_t, int pad_l, uint8_t *Ydata)</td></tr>
<tr class="separator:a411058fe07c09f4ab8ba99fdb79a4879"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a198fded6272259068d1af0a6238f8e2a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a198fded6272259068d1af0a6238f8e2a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecaffe2.html#a198fded6272259068d1af0a6238f8e2a">max_pool_avx2</a> (const std::uint8_t *Xdata, int n, int height, int width, int channels, int pooled_height, int pooled_width, int kernel_h, int kernel_w, int stride_h, int stride_w, int pad_t, int pad_l, std::uint8_t *Ydata)</td></tr>
<tr class="memdesc:a198fded6272259068d1af0a6238f8e2a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimized using AVX2 intrinsics for max pool 2D in NHWC layout. <br /></td></tr>
<tr class="separator:a198fded6272259068d1af0a6238f8e2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6de6ae38fecc263aff0f41c3ba67067"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac6de6ae38fecc263aff0f41c3ba67067"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Quantize, DNNLOWP, <a class="el" href="classcaffe2_1_1_quantize_d_n_n_low_p_op.html">QuantizeDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:ac6de6ae38fecc263aff0f41c3ba67067"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71523af8112125085af2941d66272529"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a71523af8112125085af2941d66272529"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Quantize, DNNLOWP_ROWWISE, <a class="el" href="classcaffe2_1_1_quantize_d_n_n_low_p_op.html">QuantizeDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a71523af8112125085af2941d66272529"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d8dd162a3872a8baa445a91e48c9271"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d8dd162a3872a8baa445a91e48c9271"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Quantize, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_quantize_d_n_n_low_p_op.html">QuantizeDNNLowPOp</a>&lt; uint16_t &gt;)</td></tr>
<tr class="separator:a1d8dd162a3872a8baa445a91e48c9271"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad26db5fe44213e6bcbfbd4a5d6d1df1a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad26db5fe44213e6bcbfbd4a5d6d1df1a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Quantize, DNNLOWP_ROWWISE_16, <a class="el" href="classcaffe2_1_1_quantize_d_n_n_low_p_op.html">QuantizeDNNLowPOp</a>&lt; uint16_t &gt;)</td></tr>
<tr class="separator:ad26db5fe44213e6bcbfbd4a5d6d1df1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad349191718516d3bcd95d21fe4945bad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad349191718516d3bcd95d21fe4945bad"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Quantize, DNNLOWP, <a class="el" href="classcaffe2_1_1_quantize_d_n_n_low_p_op.html">QuantizeDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:ad349191718516d3bcd95d21fe4945bad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae750d5ed607acae6b5b17f86a1f2d158"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae750d5ed607acae6b5b17f86a1f2d158"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Quantize, DNNLOWP_ROWWISE, <a class="el" href="classcaffe2_1_1_quantize_d_n_n_low_p_op.html">QuantizeDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:ae750d5ed607acae6b5b17f86a1f2d158"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afbce17ac6f39b40774c8fb229743d211"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afbce17ac6f39b40774c8fb229743d211"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_relu.html">Relu</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_relu_d_n_n_low_p_op.html">ReluDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:afbce17ac6f39b40774c8fb229743d211"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa97771536df5e7bba28f8747efb7524f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa97771536df5e7bba28f8747efb7524f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_relu.html">Relu</a>, DNNLOWP_16, <a class="el" href="classcaffe2_1_1_relu_d_n_n_low_p_op.html">ReluDNNLowPOp</a>&lt; uint16_t &gt;)</td></tr>
<tr class="separator:aa97771536df5e7bba28f8747efb7524f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5d2d1d2b5889963990d0e4736c8a0f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af5d2d1d2b5889963990d0e4736c8a0f8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Relu, DNNLOWP, <a class="el" href="classcaffe2_1_1_relu_d_n_n_low_p_op.html">ReluDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:af5d2d1d2b5889963990d0e4736c8a0f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c71e4eab8e1bd6ba6191a44138e5eb2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c71e4eab8e1bd6ba6191a44138e5eb2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8ResizeNearest, DNNLOWP, <a class="el" href="classcaffe2_1_1_resize_nearest_d_n_n_low_p_op.html">ResizeNearestDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a3c71e4eab8e1bd6ba6191a44138e5eb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5de15a6236cf25a802a30f41fdcb954a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5de15a6236cf25a802a30f41fdcb954a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="classdnnlowp_1_1_sigmoid.html">Sigmoid</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_d_n_n_low_p_op.html">UnaryElementwiseWithArgsDNNLowPOp</a>&lt; std::uint8_t, <a class="el" href="structcaffe2_1_1_sigmoid_functor.html">SigmoidFunctor</a>&lt; std::uint8_t &gt;&gt;)</td></tr>
<tr class="separator:a5de15a6236cf25a802a30f41fdcb954a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a4f6853f8a4968e564ced056317c709"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a4f6853f8a4968e564ced056317c709"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Sigmoid, DNNLOWP, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_d_n_n_low_p_op.html">UnaryElementwiseWithArgsDNNLowPOp</a>&lt; std::uint8_t, <a class="el" href="structcaffe2_1_1_sigmoid_functor.html">SigmoidFunctor</a>&lt; std::uint8_t &gt;&gt;)</td></tr>
<tr class="separator:a9a4f6853f8a4968e564ced056317c709"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1c1ea99d9e1c9d8c0ec22f10e948687"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af1c1ea99d9e1c9d8c0ec22f10e948687"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (SpatialBN, DNNLOWP, <a class="el" href="classcaffe2_1_1_spatial_b_n_d_n_n_low_p_op.html">SpatialBNDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:af1c1ea99d9e1c9d8c0ec22f10e948687"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95fba27d4a6f047da161b20d8ced854b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a95fba27d4a6f047da161b20d8ced854b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8SpatialBN, DNNLOWP, <a class="el" href="classcaffe2_1_1_spatial_b_n_d_n_n_low_p_op.html">SpatialBNDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:a95fba27d4a6f047da161b20d8ced854b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fd86b25dc8c79b0b31036b1ea398b32"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1fd86b25dc8c79b0b31036b1ea398b32"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="classdnnlowp_1_1_tanh.html">Tanh</a>, DNNLOWP, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_d_n_n_low_p_op.html">UnaryElementwiseWithArgsDNNLowPOp</a>&lt; std::uint8_t, <a class="el" href="structcaffe2_1_1_tanh_functor.html">TanhFunctor</a>&lt; std::uint8_t &gt;&gt;)</td></tr>
<tr class="separator:a1fd86b25dc8c79b0b31036b1ea398b32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2fdce02185a54ba995d3c68a08d940a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2fdce02185a54ba995d3c68a08d940a8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Tanh, DNNLOWP, <a class="el" href="classcaffe2_1_1_unary_elementwise_with_args_d_n_n_low_p_op.html">UnaryElementwiseWithArgsDNNLowPOp</a>&lt; std::uint8_t, <a class="el" href="structcaffe2_1_1_tanh_functor.html">TanhFunctor</a>&lt; std::uint8_t &gt;&gt;)</td></tr>
<tr class="separator:a2fdce02185a54ba995d3c68a08d940a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf42f6a0a5bd15932c985e080fc99193"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abf42f6a0a5bd15932c985e080fc99193"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Gather, DNNLOWP, <a class="el" href="classcaffe2_1_1_gather_d_n_n_low_p_op.html">GatherDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:abf42f6a0a5bd15932c985e080fc99193"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7949743110a5edbda71b4133eeded97"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab7949743110a5edbda71b4133eeded97"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (Int8Gather, DNNLOWP, <a class="el" href="classcaffe2_1_1_gather_d_n_n_low_p_op.html">GatherDNNLowPOp</a>&lt; uint8_t &gt;)</td></tr>
<tr class="separator:ab7949743110a5edbda71b4133eeded97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a050a59050cee23f2396f5e10997050a6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a050a59050cee23f2396f5e10997050a6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (std::shared_ptr&lt; <a class="el" href="classcaffe2_1_1_blobs_queue.html">BlobsQueue</a> &gt;)</td></tr>
<tr class="separator:a050a59050cee23f2396f5e10997050a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d08fe955467bcab0d55b1da49c78ea3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3d08fe955467bcab0d55b1da49c78ea3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CreateBlobsQueue, <a class="el" href="classcaffe2_1_1_create_blobs_queue_op.html">CreateBlobsQueueOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3d08fe955467bcab0d55b1da49c78ea3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc3a0730dc2efc0c8bf27ecc274a57c4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc3a0730dc2efc0c8bf27ecc274a57c4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (EnqueueBlobs, <a class="el" href="classcaffe2_1_1_enqueue_blobs_op.html">EnqueueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:abc3a0730dc2efc0c8bf27ecc274a57c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaa80a228741c5b32dc50bd12b5ad762"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afaa80a228741c5b32dc50bd12b5ad762"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (DequeueBlobs, <a class="el" href="classcaffe2_1_1_dequeue_blobs_op.html">DequeueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:afaa80a228741c5b32dc50bd12b5ad762"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96f157af0b2dbaa599297dcd3479bfda"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96f157af0b2dbaa599297dcd3479bfda"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (CloseBlobsQueue, <a class="el" href="classcaffe2_1_1_close_blobs_queue_op.html">CloseBlobsQueueOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a96f157af0b2dbaa599297dcd3479bfda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb8bdff09f365a4910b36705480f3ceb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adb8bdff09f365a4910b36705480f3ceb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SafeEnqueueBlobs, <a class="el" href="classcaffe2_1_1_safe_enqueue_blobs_op.html">SafeEnqueueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:adb8bdff09f365a4910b36705480f3ceb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af547c162adbe651e91c8569334110347"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af547c162adbe651e91c8569334110347"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SafeDequeueBlobs, <a class="el" href="classcaffe2_1_1_safe_dequeue_blobs_op.html">SafeDequeueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af547c162adbe651e91c8569334110347"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7eb563fa919e5cfbeabb350f432ea1b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7eb563fa919e5cfbeabb350f432ea1b2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (WeightedSampleDequeueBlobs, <a class="el" href="classcaffe2_1_1_weighted_sample_dequeue_blobs_op.html">WeightedSampleDequeueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a7eb563fa919e5cfbeabb350f432ea1b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa108c917884eb0e3e25a3e41ca576863"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa108c917884eb0e3e25a3e41ca576863"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (CreateBlobsQueue).NumInputs(0).NumOutputs(1)</td></tr>
<tr class="separator:aa108c917884eb0e3e25a3e41ca576863"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a541c9026323eb7c2d89d0de356b204db"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a541c9026323eb7c2d89d0de356b204db"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputsOutputs</b> ([](int inputs, int outputs){return inputs &gt;=2 &amp;&amp;outputs &gt;=1 &amp;&amp;inputs==outputs+1;}).EnforceInplace([](int input</td></tr>
<tr class="separator:a541c9026323eb7c2d89d0de356b204db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabc9a2ccec2537b9e212a95953c3e51d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabc9a2ccec2537b9e212a95953c3e51d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputsOutputs</b> ([](int inputs, int outputs){return inputs==1 &amp;&amp;outputs &gt;=1;}).SetDoc(R&quot;DOC( Dequeue the blobs from queue. )DOC&quot;).Arg(&quot;timeout_secs&quot;</td></tr>
<tr class="separator:aabc9a2ccec2537b9e212a95953c3e51d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28430392a9a607ea5b72208aea71b8ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28430392a9a607ea5b72208aea71b8ca"></a>
Timeout in The shared pointer for the <a class="el" href="classcaffe2_1_1_blobs_queue.html">BlobsQueue</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;blob&quot;,&quot;The blob to store the dequeued data&quot;)</td></tr>
<tr class="separator:a28430392a9a607ea5b72208aea71b8ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56400e7db97acdb8d20260e747876595"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a56400e7db97acdb8d20260e747876595"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (CloseBlobsQueue).NumInputs(1).NumOutputs(0)</td></tr>
<tr class="separator:a56400e7db97acdb8d20260e747876595"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f8d02811af4b46249942d20e8500a21"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f8d02811af4b46249942d20e8500a21"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputsOutputs</b> ([](int inputs, int outputs){return inputs &gt;=2 &amp;&amp;outputs &gt;=2 &amp;&amp;inputs==outputs;}).EnforceInplace([](int input</td></tr>
<tr class="separator:a7f8d02811af4b46249942d20e8500a21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7073f71c7d6b5545e27616b3287008c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7073f71c7d6b5545e27616b3287008c5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Enqueue the blobs into queue. When the queue is closed and full, the output
status will be set to true which can be used as exit criteria for execution
step.
The 1st input is the queue and the last output is the status. The rest are
data blobs.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a7073f71c7d6b5545e27616b3287008c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d766c33dfec707d286f875ddf2bdd30"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d766c33dfec707d286f875ddf2bdd30"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputsOutputs</b> ([](int inputs, int outputs){return inputs==1 &amp;&amp;outputs &gt;=2;}).SetDoc(R&quot;DOC( Dequeue the blobs from queue. When the queue is closed and empty</td></tr>
<tr class="separator:a1d766c33dfec707d286f875ddf2bdd30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa38e795404dd0bccc4ad8004c1ea0e87"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa38e795404dd0bccc4ad8004c1ea0e87"></a>
the output status will be set to true which can be used as exit criteria for execution step The input is the queue and the last output is the status The rest are data blobs DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;num_records&quot;,&quot;(default 1) If &gt; 1, multiple records will be dequeued and tensors &quot;&quot;for each column will be concatenated. This requires all tensors in &quot;&quot;the records to be at least 1D, and to have the same inner dimensions.&quot;).Input(0</td></tr>
<tr class="separator:aa38e795404dd0bccc4ad8004c1ea0e87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13c98bc459911afabe77cabbaa6a9b69"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a13c98bc459911afabe77cabbaa6a9b69"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Dequeue the blobs from multiple queues. When one of queues is closed and empty,
the output status will be set to true which can be used as exit criteria for
execution step.
The 1st input is the queue and the last output is the status. The rest are
data blobs.
)DOC&quot;).Arg(&quot;weights&quot;</td></tr>
<tr class="separator:a13c98bc459911afabe77cabbaa6a9b69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac476b804725e7b2840d154107684c4cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac476b804725e7b2840d154107684c4cb"></a>
INT_MAX Weights for sampling from multiple queues&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;table_idx_blob&quot;,&quot;The index of the blob (among the output blob list) &quot;&quot;that will be used to store the index of the table chosen to read the &quot;&quot;current batch.&quot;)</td></tr>
<tr class="separator:ac476b804725e7b2840d154107684c4cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bf8929088680b81f5f66c26b4ee20f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7bf8929088680b81f5f66c26b4ee20f3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (CreateBlobsQueue)</td></tr>
<tr class="separator:a7bf8929088680b81f5f66c26b4ee20f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a357f4d3f2d14ea7d366be90153e19f53"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a357f4d3f2d14ea7d366be90153e19f53"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (EnqueueBlobs)</td></tr>
<tr class="separator:a357f4d3f2d14ea7d366be90153e19f53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3815b5eb1e08d00057593e8f457a22ea"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3815b5eb1e08d00057593e8f457a22ea"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (DequeueBlobs)</td></tr>
<tr class="separator:a3815b5eb1e08d00057593e8f457a22ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab827355b441c918e25d4b80a76f900c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab827355b441c918e25d4b80a76f900c1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (CloseBlobsQueue)</td></tr>
<tr class="separator:ab827355b441c918e25d4b80a76f900c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a6fd20c9ee048bb5217bbafc73e5786"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a6fd20c9ee048bb5217bbafc73e5786"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SafeEnqueueBlobs)</td></tr>
<tr class="separator:a9a6fd20c9ee048bb5217bbafc73e5786"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49f60df3c55c85a5dc1ad041cec23bd4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a49f60df3c55c85a5dc1ad041cec23bd4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (SafeDequeueBlobs)</td></tr>
<tr class="separator:a49f60df3c55c85a5dc1ad041cec23bd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aacdb2be4139d4d31669ef96634a01857"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aacdb2be4139d4d31669ef96634a01857"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (WeightedSampleDequeueBlobs)</td></tr>
<tr class="separator:aacdb2be4139d4d31669ef96634a01857"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e4f33b32b373b18f9fe66143ea3e8dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3e4f33b32b373b18f9fe66143ea3e8dc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CreateBlobsQueue, <a class="el" href="classcaffe2_1_1_create_blobs_queue_op.html">CreateBlobsQueueOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a3e4f33b32b373b18f9fe66143ea3e8dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c9b371e732330cdf8b8d0ec93ec5613"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7c9b371e732330cdf8b8d0ec93ec5613"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (EnqueueBlobs, <a class="el" href="classcaffe2_1_1_enqueue_blobs_op.html">EnqueueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a7c9b371e732330cdf8b8d0ec93ec5613"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55b89cd90a1ce2627bf1e8aff627b8b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55b89cd90a1ce2627bf1e8aff627b8b6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (DequeueBlobs, <a class="el" href="classcaffe2_1_1_dequeue_blobs_op.html">DequeueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a55b89cd90a1ce2627bf1e8aff627b8b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9cd6df4aaa20225d3118c02e87161df"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af9cd6df4aaa20225d3118c02e87161df"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (CloseBlobsQueue, <a class="el" href="classcaffe2_1_1_close_blobs_queue_op.html">CloseBlobsQueueOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:af9cd6df4aaa20225d3118c02e87161df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5598fe404cb1ec5db79c7c265b7b46c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5598fe404cb1ec5db79c7c265b7b46c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (SafeEnqueueBlobs, <a class="el" href="classcaffe2_1_1_safe_enqueue_blobs_op.html">SafeEnqueueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aa5598fe404cb1ec5db79c7c265b7b46c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0ec76fc3e77c96d1c77b8a1066abb62"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae0ec76fc3e77c96d1c77b8a1066abb62"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (SafeDequeueBlobs, <a class="el" href="classcaffe2_1_1_safe_dequeue_blobs_op.html">SafeDequeueBlobsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ae0ec76fc3e77c96d1c77b8a1066abb62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae097b8dbd7befdac3c5893994197e4e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae097b8dbd7befdac3c5893994197e4e1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_KNOWN_TYPE</b> (RebatchingQueuePtr)</td></tr>
<tr class="separator:ae097b8dbd7befdac3c5893994197e4e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50a421cfb6b07a4c8f952c3f69b62527"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a50a421cfb6b07a4c8f952c3f69b62527"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Adadelta, <a class="el" href="classcaffe2_1_1_adadelta_op.html">AdadeltaOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a50a421cfb6b07a4c8f952c3f69b62527"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeffbdee28293fc63b15384e47832103e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeffbdee28293fc63b15384e47832103e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(

Computes the AdaDelta update (https://arxiv.org/abs/1212.5701) for an input
gradient and accumulated history of squared gradients. Concretely, given
inputs (param, moment, moment_delta, grad, learning_rate), computes:

    new_moment = moment * decay + square(grad) * (1 - decay)
    new_grad = sqrt(moment_delta + epsilon) / sqrt(new_moment + epsilon) * grad
    new_param = param + learning_rate * new_grad
    new_moment_delta = moment_delta * decay + square(new_grad) * (1 - decay)

and returns (new_param, new_moment, new_moment_delta).

)DOC&quot;).Input(0</td></tr>
<tr class="separator:aeffbdee28293fc63b15384e47832103e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af791d90283d1e1f6a6507e85af121c62"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af791d90283d1e1f6a6507e85af121c62"></a>
Parameters to be updated&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;moment&quot;,&quot;Average of squared gradients&quot;).Input(2</td></tr>
<tr class="separator:af791d90283d1e1f6a6507e85af121c62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04a8db996c498e3cfd1d6561033dcb1b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04a8db996c498e3cfd1d6561033dcb1b"></a>
Parameters to be updated Average of squared parameter updates&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;grad&quot;,&quot;Gradient computed&quot;).Input(4</td></tr>
<tr class="separator:a04a8db996c498e3cfd1d6561033dcb1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23291e67394ab618af15eb38b5ba63e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a23291e67394ab618af15eb38b5ba63e4"></a>
Parameters to be updated Average of squared parameter updates Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output_param&quot;,&quot;Updated parameters&quot;).Output(1</td></tr>
<tr class="separator:a23291e67394ab618af15eb38b5ba63e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3b609c54233b078048f1ac8eb7237d3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab3b609c54233b078048f1ac8eb7237d3"></a>
Parameters to be updated Average of squared parameter updates Learning rate Updated average squared gradient&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (2,&quot;output_moment_delta&quot;,&quot;Updated average of squared parameter updates&quot;).Arg(&quot;epsilon&quot;</td></tr>
<tr class="separator:ab3b609c54233b078048f1ac8eb7237d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad66cfeecaa6b392cf654e4e6404be558"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad66cfeecaa6b392cf654e4e6404be558"></a>
Parameters to be updated Average of squared parameter updates Learning rate Updated average squared gradient Default&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;decay&quot;,&quot;Default 0.95, the squared gradient sum is decayed by this factor.&quot;)</td></tr>
<tr class="separator:ad66cfeecaa6b392cf654e4e6404be558"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07321e1200995a9296de6e40c1c065b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a07321e1200995a9296de6e40c1c065b4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseAdadelta, <a class="el" href="classcaffe2_1_1_sparse_adadelta_op.html">SparseAdadeltaOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a07321e1200995a9296de6e40c1c065b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9fd26129379a60b9ed01f4ec6c46b973"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9fd26129379a60b9ed01f4ec6c46b973"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (6).NumOutputs(3).EnforceOneToOneInplace().SetDoc(R&quot;DOC( Given inputs (param</td></tr>
<tr class="separator:a9fd26129379a60b9ed01f4ec6c46b973"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad63e0cd0a7e836b889e1cda116109ea4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad63e0cd0a7e836b889e1cda116109ea4"></a>
runs the dense AdaDelta update&#160;</td><td class="memItemRight" valign="bottom"><b>on</b> (param, grad, moment[indices], moment_delta[indices], lr)</td></tr>
<tr class="separator:ad63e0cd0a7e836b889e1cda116109ea4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4b57b7ae71f63d27b7a1a77f1bf2fa7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae4b57b7ae71f63d27b7a1a77f1bf2fa7"></a>
runs the dense AdaDelta update and&#160;</td><td class="memItemRight" valign="bottom"><b>returns</b> (new_param, new_moment, new_moment_delta) as in the dense case.) DOC&quot;) .Input(0</td></tr>
<tr class="separator:ae4b57b7ae71f63d27b7a1a77f1bf2fa7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8f65b02b5176200a7121dfc9b7a95d0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab8f65b02b5176200a7121dfc9b7a95d0"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;indices&quot;,&quot;Sparse indices&quot;).Input(4</td></tr>
<tr class="separator:ab8f65b02b5176200a7121dfc9b7a95d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a980488bd998b4a7e378f1ee2804b9f7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a980488bd998b4a7e378f1ee2804b9f7f"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates Gradient computed&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (5,&quot;lr&quot;,&quot;learning rate&quot;).Output(0</td></tr>
<tr class="separator:a980488bd998b4a7e378f1ee2804b9f7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ee5af9aef0c69932aa5d2f8f7103db4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8ee5af9aef0c69932aa5d2f8f7103db4"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates Gradient computed Updated parameters&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;output_moment&quot;,&quot;Updated average squared gradient&quot;).Output(2</td></tr>
<tr class="separator:a8ee5af9aef0c69932aa5d2f8f7103db4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c345a6949f24c7c8b4b18f5111009d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c345a6949f24c7c8b4b18f5111009d1"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates Gradient computed Updated parameters Updated average of squared parameter updates&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;epsilon&quot;,&quot;Default 1e-5&quot;).Arg(&quot;decay&quot;</td></tr>
<tr class="separator:a6c345a6949f24c7c8b4b18f5111009d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1aaa32d9e158c07d1cf73057a338b76"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1aaa32d9e158c07d1cf73057a338b76"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Adadelta)</td></tr>
<tr class="separator:ab1aaa32d9e158c07d1cf73057a338b76"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dd03f932e4aa51b5b106dcf54e314cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dd03f932e4aa51b5b106dcf54e314cf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (SparseAdadelta)</td></tr>
<tr class="separator:a3dd03f932e4aa51b5b106dcf54e314cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3b7fb160455401466308ec5db0c93f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa3b7fb160455401466308ec5db0c93f1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Adagrad, <a class="el" href="classcaffe2_1_1_adagrad_op.html">AdagradOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa3b7fb160455401466308ec5db0c93f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad796d7763bba51a3fa37126067238417"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad796d7763bba51a3fa37126067238417"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>AllowInplace</b> ({{0, 0},{1, 1}}).SetDoc(R&quot;DOC( Computes the AdaGrad update for an input gradient and accumulated history. Concretely</td></tr>
<tr class="separator:ad796d7763bba51a3fa37126067238417"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92a17c552f5e639feacb0a0299ed32c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92a17c552f5e639feacb0a0299ed32c5"></a>
given&#160;</td><td class="memItemRight" valign="bottom"><b>inputs</b> (param, grad, moment, learning_rate)</td></tr>
<tr class="separator:a92a17c552f5e639feacb0a0299ed32c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52caf415e26784864b15d1805ff7989a"><td class="memTemplParams" colspan="2"><a class="anchor" id="a52caf415e26784864b15d1805ff7989a"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a52caf415e26784864b15d1805ff7989a"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>adagrad_update</b> (int N, const float *w, const float *g, const float *h, float *nw, float *nh, float epsilon, float decay, const float *lr, Context *)</td></tr>
<tr class="separator:a52caf415e26784864b15d1805ff7989a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adcb2754bd7c6105393337e9c145d7cbc"><td class="memTemplParams" colspan="2"><a class="anchor" id="adcb2754bd7c6105393337e9c145d7cbc"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:adcb2754bd7c6105393337e9c145d7cbc"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>adagrad_update_output_effective_lr</b> (int N, const float *paramIn, const float *gradIn, const float *momentIn, float *paramOut, float *momentOut, float *effectiveLROut, float epsilon, float decay, const float *lr, Context *)</td></tr>
<tr class="separator:adcb2754bd7c6105393337e9c145d7cbc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab49b5315807beede9c0ac1ad8a1b60f0"><td class="memTemplParams" colspan="2"><a class="anchor" id="ab49b5315807beede9c0ac1ad8a1b60f0"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:ab49b5315807beede9c0ac1ad8a1b60f0"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>adagrad_update_output_effective_lr_and_update</b> (int N, const float *paramIn, const float *gradIn, const float *momentIn, float *paramOut, float *momentOut, float *effectiveLROut, float *updateOut, float epsilon, float decay, const float *lr, Context *)</td></tr>
<tr class="separator:ab49b5315807beede9c0ac1ad8a1b60f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46f1267836a46dfedf7588466f02db90"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46f1267836a46dfedf7588466f02db90"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Adam, <a class="el" href="classcaffe2_1_1_adam_op.html">AdamOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a46f1267836a46dfedf7588466f02db90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b97ca72e48107794a375cd6636ad6ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4b97ca72e48107794a375cd6636ad6ed"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>AllowInplace</b> ({{0, 0},{1, 1},{2, 2}}).DeviceInferenceFunction([](const OperatorDef &amp;def)</td></tr>
<tr class="separator:a4b97ca72e48107794a375cd6636ad6ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a649fa714e5835b73f01a4cd12ff33b23"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a649fa714e5835b73f01a4cd12ff33b23"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(

Computes the Adam update (https://arxiv.org/abs/1412.6980) for an
input gradient and momentum parameters. Concretely, given inputs
(param, m1, m2, grad, lr, iters),

    t = iters + 1
    correction_multiplier = sqrt(1 - power(beta2, t)) /
      (1 - power(beta1, t))
    m1_o = (beta1 * m1) + (1 - beta1) * grad
    m2_o = (beta2 * m2) + (1 - beta2) * np.square(grad)
    grad_o = correction_multiplier * m1_o / \
        (sqrt(m2_o) + epsilon)
    param_o = param + lr * grad_o

and returns (param_o, m1_o, m2_o, grad_o), in which grad_o is an <a class="el" href="classc10_1_1optional.html">optional</a> output

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a649fa714e5835b73f01a4cd12ff33b23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39e6989fd660acab352cbdf16e6b80a7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39e6989fd660acab352cbdf16e6b80a7"></a>
Parameters to be updated&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;moment_1&quot;,&quot;First moment history&quot;).Input(2</td></tr>
<tr class="separator:a39e6989fd660acab352cbdf16e6b80a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaad294da194caaa6e3c1597250c7aaa1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaad294da194caaa6e3c1597250c7aaa1"></a>
Parameters to be updated Second moment history learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (5,&quot;iter&quot;,&quot;iteration number&quot;).Output(0</td></tr>
<tr class="separator:aaad294da194caaa6e3c1597250c7aaa1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1752da0ba036ab45c3dcc9b3f9da9d01"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1752da0ba036ab45c3dcc9b3f9da9d01"></a>
Parameters to be updated Second moment history learning rate Updated parameters&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;output_moment_1&quot;,&quot;Updated first moment&quot;).Output(2</td></tr>
<tr class="separator:a1752da0ba036ab45c3dcc9b3f9da9d01"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46d87844341a119a7b862110540556fb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46d87844341a119a7b862110540556fb"></a>
Parameters to be updated Second moment history learning rate Updated parameters Updated second moment&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (3,&quot;output_grad&quot;,&quot;Optional Effective gradient&quot;).Arg(&quot;beta1&quot;</td></tr>
<tr class="separator:a46d87844341a119a7b862110540556fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68a1c44ca38d6a3e9009321cc29744dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a68a1c44ca38d6a3e9009321cc29744dc"></a>
Parameters to be updated Second moment history learning rate Updated parameters Updated second moment Default&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;beta2&quot;,&quot;Default 0.999&quot;).Arg(&quot;epsilon&quot;</td></tr>
<tr class="separator:a68a1c44ca38d6a3e9009321cc29744dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e9f6b19d8ef9b88e5951823b273ca77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e9f6b19d8ef9b88e5951823b273ca77"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseAdam, <a class="el" href="classcaffe2_1_1_sparse_adam_op.html">SparseAdamOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1e9f6b19d8ef9b88e5951823b273ca77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae26b1419c817f70cf24b4ff668e91543"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae26b1419c817f70cf24b4ff668e91543"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EnforceInplace</b> ({{0, 0},{1, 1},{2, 2}}).SetDoc(R&quot;DOC( Computes the Adam Update for the sparse case. Given inputs (param</td></tr>
<tr class="separator:ae26b1419c817f70cf24b4ff668e91543"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaacc4738c608f4589e2c100a428e8f94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaacc4738c608f4589e2c100a428e8f94"></a>
runs the dense Adam&#160;</td><td class="memItemRight" valign="bottom"><b>on</b> (param, moment1[indices], momemnt2[indices], lr, iter) and returns(new_param</td></tr>
<tr class="separator:aaacc4738c608f4589e2c100a428e8f94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a28919343c39c7d57c363399a06d6e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1a28919343c39c7d57c363399a06d6e6"></a>
runs the dense Adam new_moment2 as in dense case DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;param&quot;,&quot;Parameters to be updated&quot;).Input(1</td></tr>
<tr class="separator:a1a28919343c39c7d57c363399a06d6e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82d6fb9aef17bceec837c4adf9c1ae09"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a82d6fb9aef17bceec837c4adf9c1ae09"></a>
runs the dense Adam new_moment2 as in dense case DOC First moment history&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;moment_2&quot;,&quot;Second moment history&quot;).Input(3</td></tr>
<tr class="separator:a82d6fb9aef17bceec837c4adf9c1ae09"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a897c5c077240eb294a501bf85b828065"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a897c5c077240eb294a501bf85b828065"></a>
runs the dense Adam new_moment2 as in dense case DOC First moment history Sparse indices&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (4,&quot;grad&quot;,&quot;Gradient computed&quot;).Input(5</td></tr>
<tr class="separator:a897c5c077240eb294a501bf85b828065"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ca1437a569e68a83f56b2ebdc0f2453"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ca1437a569e68a83f56b2ebdc0f2453"></a>
runs the dense Adam new_moment2 as in dense case DOC First moment history Sparse indices learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (6,&quot;iter&quot;,&quot;iteration number&quot;).Output(0</td></tr>
<tr class="separator:a4ca1437a569e68a83f56b2ebdc0f2453"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b0354020289fcbc627d1dc764eef18b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1b0354020289fcbc627d1dc764eef18b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RowWiseSparseAdam, <a class="el" href="classcaffe2_1_1_row_wise_sparse_adam_op.html">RowWiseSparseAdamOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1b0354020289fcbc627d1dc764eef18b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a7ff2e0352036a9ebac1d32caf8c9d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0a7ff2e0352036a9ebac1d32caf8c9d6"></a>
runs the Adam update&#160;</td><td class="memItemRight" valign="bottom"><b>on</b> (param, moment1[indices], moment2[indices], lr, iter) and returns(new_param</td></tr>
<tr class="separator:a0a7ff2e0352036a9ebac1d32caf8c9d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f4750713478bdc53029a1d45b53e2a6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f4750713478bdc53029a1d45b53e2a6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (Adam)</td></tr>
<tr class="separator:a5f4750713478bdc53029a1d45b53e2a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4918dbf8c1590d5dc79bafa7cdf29f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4918dbf8c1590d5dc79bafa7cdf29f8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (SparseAdam)</td></tr>
<tr class="separator:aa4918dbf8c1590d5dc79bafa7cdf29f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85e8dd590744313c3687101a07143322"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a85e8dd590744313c3687101a07143322"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (RowWiseSparseAdam)</td></tr>
<tr class="separator:a85e8dd590744313c3687101a07143322"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaad673b1c06055f145a885459af259d9"><td class="memTemplParams" colspan="2"><a class="anchor" id="aaad673b1c06055f145a885459af259d9"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:aaad673b1c06055f145a885459af259d9"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>adam_update</b> (int N, const float *g, const float *m, const float *v, float *ng, float *nm, float *nv, float beta1, float beta2, float eps_hat, float correction, const float *lr, Context *)</td></tr>
<tr class="separator:aaad673b1c06055f145a885459af259d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13a21d356a425abb26679238d3e423d3"><td class="memTemplParams" colspan="2"><a class="anchor" id="a13a21d356a425abb26679238d3e423d3"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a13a21d356a425abb26679238d3e423d3"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>adam_compute</b> (int N, const float *w, const float *g, const float *m, const float *v, float *nw, float *nm, float *nv, float beta1, float beta2, float eps_hat, float correction, const float *lr, Context *)</td></tr>
<tr class="separator:a13a21d356a425abb26679238d3e423d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64ad201bfafa1fa1de21f2be0c5caef3"><td class="memTemplParams" colspan="2"><a class="anchor" id="a64ad201bfafa1fa1de21f2be0c5caef3"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a64ad201bfafa1fa1de21f2be0c5caef3"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>adam_compute_output_grad</b> (int N, const float *w, const float *g, const float *m, const float *v, float *nw, float *nm, float *nv, float *ng, float beta1, float beta2, float eps_hat, float correction, const float *lr, Context *)</td></tr>
<tr class="separator:a64ad201bfafa1fa1de21f2be0c5caef3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3b355dd533c36c687f287ab1211c154"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af3b355dd533c36c687f287ab1211c154"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (ClipTensorByScaling, <a class="el" href="classcaffe2_1_1_clip_tensor_by_scaling_op.html">ClipTensorByScalingOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:af3b355dd533c36c687f287ab1211c154"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c8417ef8ace36adefef31fd129fa21a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c8417ef8ace36adefef31fd129fa21a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
    Clips the input tensor by scaling based on the input value and the threshold.
    The value is usually the (pre-computed) norm of the tensor. If the value is
    larger than the threshold, scaling would be performed in this way:

          tensor *= (threshold / value).

    An <a class="el" href="classc10_1_1optional.html">optional</a> input called additional_threshold can be provided which
    will scale the original threshold before it is used. That is,
    the final threshold will become threshold * additional_threshold.
    This op could be used for gradient clipping.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a9c8417ef8ace36adefef31fd129fa21a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a523f540d8c7536f2f5f99dabb64a847b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a523f540d8c7536f2f5f99dabb64a847b"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of floats to be clipped&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;val&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_value.html">Value</a> to be compared against the threshold&quot;).Input(2</td></tr>
<tr class="separator:a523f540d8c7536f2f5f99dabb64a847b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67382e332444f9ac681a3ecf8e8a4acd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67382e332444f9ac681a3ecf8e8a4acd"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of floats to be clipped An <a class="el" href="classc10_1_1optional.html">optional</a> additonal threshold to scale the orignal threshold&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;threshold&quot;,&quot;Threshold to determine whether to scale down the tensor&quot;).Output(0</td></tr>
<tr class="separator:a67382e332444f9ac681a3ecf8e8a4acd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4c9b48563b67fdf64af6fe535c797dd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae4c9b48563b67fdf64af6fe535c797dd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (ClipTensorByScaling)</td></tr>
<tr class="separator:ae4c9b48563b67fdf64af6fe535c797dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84e4e413da1a70d1dfea4ff9cfa09bf5"><td class="memTemplParams" colspan="2"><a class="anchor" id="a84e4e413da1a70d1dfea4ff9cfa09bf5"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:a84e4e413da1a70d1dfea4ff9cfa09bf5"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>fp16_momentum_sgd_update</b> (int N, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *g, const <a class="el" href="structc10_1_1_half.html">at::Half</a> *m, <a class="el" href="structc10_1_1_half.html">at::Half</a> *ng, <a class="el" href="structc10_1_1_half.html">at::Half</a> *nm, const float *lr, float momentum, bool nesterov, float weight_decay, bool fp32_update, <a class="el" href="structc10_1_1_half.html">at::Half</a> *param, Context *)</td></tr>
<tr class="separator:a84e4e413da1a70d1dfea4ff9cfa09bf5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafc3e89243f7989891f1e3a3f5c36d24"><td class="memTemplParams" colspan="2"><a class="anchor" id="aafc3e89243f7989891f1e3a3f5c36d24"></a>
template&lt;class Context &gt; </td></tr>
<tr class="memitem:aafc3e89243f7989891f1e3a3f5c36d24"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>fp32_momentum_sgd_update</b> (int N, const float *g, const float *m, float *ng, float *nm, const float *lr, float momentum, bool nesterov, float weight_decay, float *param, Context *)</td></tr>
<tr class="separator:aafc3e89243f7989891f1e3a3f5c36d24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16a5937c8436cf4791e689d943200c7a"><td class="memTemplParams" colspan="2"><a class="anchor" id="a16a5937c8436cf4791e689d943200c7a"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a16a5937c8436cf4791e689d943200c7a"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="struct_t.html">T</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>sgn</b> (const <a class="el" href="struct_t.html">T</a> x)</td></tr>
<tr class="separator:a16a5937c8436cf4791e689d943200c7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8705b9ad77634eb047afca0b24737e0c"><td class="memTemplParams" colspan="2"><a class="anchor" id="a8705b9ad77634eb047afca0b24737e0c"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a8705b9ad77634eb047afca0b24737e0c"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ftrl_compute</b> (const <a class="el" href="struct_t.html">T</a> w, const <a class="el" href="struct_t.html">T</a> n, const <a class="el" href="struct_t.html">T</a> z, const <a class="el" href="struct_t.html">T</a> g, <a class="el" href="struct_t.html">T</a> &amp;nw, <a class="el" href="struct_t.html">T</a> &amp;nn, <a class="el" href="struct_t.html">T</a> &amp;nz, const <a class="el" href="structcaffe2_1_1_ftrl_params.html">FtrlParams</a>&lt; <a class="el" href="struct_t.html">T</a> &gt; &amp;params)</td></tr>
<tr class="separator:a8705b9ad77634eb047afca0b24737e0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5d83bad64c7bb33db49c289d7b61f78"><td class="memTemplParams" colspan="2"><a class="anchor" id="ab5d83bad64c7bb33db49c289d7b61f78"></a>
template&lt;typename Context , typename T &gt; </td></tr>
<tr class="memitem:ab5d83bad64c7bb33db49c289d7b61f78"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>ftrl_update</b> (int N, const <a class="el" href="struct_t.html">T</a> *w, const <a class="el" href="struct_t.html">T</a> *nz, const <a class="el" href="struct_t.html">T</a> *g, <a class="el" href="struct_t.html">T</a> *new_w, <a class="el" href="struct_t.html">T</a> *new_nz, const <a class="el" href="structcaffe2_1_1_ftrl_params.html">FtrlParams</a>&lt; <a class="el" href="struct_t.html">T</a> &gt; &amp;params, Context *)</td></tr>
<tr class="separator:ab5d83bad64c7bb33db49c289d7b61f78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18931d73351afa60ce00f998c3c573a0"><td class="memTemplParams" colspan="2"><a class="anchor" id="a18931d73351afa60ce00f998c3c573a0"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a18931d73351afa60ce00f998c3c573a0"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>gftrl_compute</b> (const <a class="el" href="struct_t.html">T</a> &amp;w, const <a class="el" href="struct_t.html">T</a> &amp;n, const <a class="el" href="struct_t.html">T</a> &amp;z, const <a class="el" href="struct_t.html">T</a> &amp;g, <a class="el" href="struct_t.html">T</a> &amp;nw, <a class="el" href="struct_t.html">T</a> &amp;nn, <a class="el" href="struct_t.html">T</a> &amp;nz, const <a class="el" href="struct_t.html">T</a> &amp;z_norm, const int OutputDim, const <a class="el" href="structcaffe2_1_1_g_ftrl_params.html">GFtrlParams</a>&lt; <a class="el" href="struct_t.html">T</a> &gt; &amp;params)</td></tr>
<tr class="separator:a18931d73351afa60ce00f998c3c573a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a676623e692519241f5cbb81f56a68f7f"><td class="memTemplParams" colspan="2"><a class="anchor" id="a676623e692519241f5cbb81f56a68f7f"></a>
template&lt;typename Context , typename T &gt; </td></tr>
<tr class="memitem:a676623e692519241f5cbb81f56a68f7f"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>gftrl_update</b> (int OutputDim, int InputDim, const <a class="el" href="struct_t.html">T</a> *w, const <a class="el" href="struct_t.html">T</a> *nz, const <a class="el" href="struct_t.html">T</a> *g, <a class="el" href="struct_t.html">T</a> *new_w, <a class="el" href="struct_t.html">T</a> *new_nz, const <a class="el" href="structcaffe2_1_1_g_ftrl_params.html">GFtrlParams</a>&lt; <a class="el" href="struct_t.html">T</a> &gt; &amp;params, Context *)</td></tr>
<tr class="separator:a676623e692519241f5cbb81f56a68f7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62eb2309a93b3e4e1b0858c6ceeefbd5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62eb2309a93b3e4e1b0858c6ceeefbd5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Iter, <a class="el" href="classcaffe2_1_1_iter_op.html">IterOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a62eb2309a93b3e4e1b0858c6ceeefbd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8d2904a82671957e8cb3d50705d05f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab8d2904a82671957e8cb3d50705d05f9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (AtomicIter, <a class="el" href="classcaffe2_1_1_atomic_iter_op.html">AtomicIterOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab8d2904a82671957e8cb3d50705d05f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac90b4bd2ed2e46b5c17a1400c46aeb75"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac90b4bd2ed2e46b5c17a1400c46aeb75"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_BLOB_SERIALIZER</b> ((TypeMeta::Id&lt; std::unique_ptr&lt; std::mutex &gt;&gt;()), <a class="el" href="classcaffe2_1_1_mutex_serializer.html">MutexSerializer</a>)</td></tr>
<tr class="separator:ac90b4bd2ed2e46b5c17a1400c46aeb75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa76ee30697814ee55ca6b7c2401cf927"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa76ee30697814ee55ca6b7c2401cf927"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_BLOB_DESERIALIZER</b> (std::unique_ptr&lt; std::mutex &gt;, <a class="el" href="classcaffe2_1_1_mutex_deserializer.html">MutexDeserializer</a>)</td></tr>
<tr class="separator:aa76ee30697814ee55ca6b7c2401cf927"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f038928b82ec9c9b9521bc80ffc83a7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f038928b82ec9c9b9521bc80ffc83a7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Stores a singe integer, that gets incremented on each call to Run().
Useful for tracking the iteration count during SGD, for example.
)DOC&quot;)</td></tr>
<tr class="separator:a5f038928b82ec9c9b9521bc80ffc83a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f98e51a81de34a8a53053daa2934705"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f98e51a81de34a8a53053daa2934705"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Similar to Iter, but takes a mutex as the first input to make sure that
updates are carried out atomically. This can be used in e.g. Hogwild sgd
algorithms.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a5f98e51a81de34a8a53053daa2934705"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca541221bb9f3e08690ed028a8253833"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aca541221bb9f3e08690ed028a8253833"></a>
The mutex used to do atomic increment&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;iter&quot;,&quot;The iter counter as an int64_t TensorCPU.&quot;)</td></tr>
<tr class="separator:aca541221bb9f3e08690ed028a8253833"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac719df125c37019704abe5c7f53ea318"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac719df125c37019704abe5c7f53ea318"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (Iter)</td></tr>
<tr class="separator:ac719df125c37019704abe5c7f53ea318"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ca995e1c8a5d198e1ce9945d43079b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ca995e1c8a5d198e1ce9945d43079b9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (AtomicIter)</td></tr>
<tr class="separator:a4ca995e1c8a5d198e1ce9945d43079b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a153f3c396bac274030d0fb5fe7421585"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a153f3c396bac274030d0fb5fe7421585"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>IncrementIter</b> (<a class="el" href="classnom_1_1repr_1_1_tensor.html">TensorCPU</a> *output)</td></tr>
<tr class="separator:a153f3c396bac274030d0fb5fe7421585"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a257144a05c7bc7118a38c1682b3f2d7c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a257144a05c7bc7118a38c1682b3f2d7c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (Iter, <a class="el" href="classcaffe2_1_1_iter_op.html">IterOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:a257144a05c7bc7118a38c1682b3f2d7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adccb1da1f9193dd20fadb69e7588b852"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adccb1da1f9193dd20fadb69e7588b852"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (AtomicIter, <a class="el" href="classcaffe2_1_1_atomic_iter_op.html">AtomicIterOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:adccb1da1f9193dd20fadb69e7588b852"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c25209811cb75148c0220861bf79155"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2c25209811cb75148c0220861bf79155"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Lars, <a class="el" href="classcaffe2_1_1_lars_op.html">LarsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2c25209811cb75148c0220861bf79155"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac00a02d495e9f86f300f34d8ad9674d6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac00a02d495e9f86f300f34d8ad9674d6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LearningRateAdaption, <a class="el" href="classcaffe2_1_1_learning_rate_adaption_op.html">LearningRateAdaptionOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac00a02d495e9f86f300f34d8ad9674d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa750180d0ede3134359ef9280c542879"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa750180d0ede3134359ef9280c542879"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
      Learning Rate Adaption is an operation that perform one iteration of
      gradient descent based on learning rate:
        lr(k) = lr(k-1) - lr_alpha * df(k-1)/dlr,
      where df(k-1)/dlr is the gradient of objective function f on lr, and
      lr_alpha is a learning rate hyperparameter. It can be prove that
      df(k-1)/dlr equals INNERPRODUCT(grad(k-1), -grad(k-2)), where grad(k-1) is
      the grad of f(k-1) on parameters. When the argument
      &quot;normalized_lr_adaption&quot; is false, we simply perform the
      following update:
      lr(k) = lr(k-1) - lr_alpha * INNERPRODUCT(grad(k-1), grad(k-2)).
      If we set &quot;normalized_lr_adaption&quot; to be true, we do not directly apply
      INNERPRODUCT(grad(k-1), -grad(k-2)) as the grad. Instead, we perform the
      following update:
      lr(k) = lr(k-1) + lr_alpha * cosineSimilarity(grad(k-1), grad(k-2)).
)DOC&quot;).Arg(&quot;lr_alpha&quot;</td></tr>
<tr class="separator:aa750180d0ede3134359ef9280c542879"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd6b3b0154a796c30f513255da8f0b4a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd6b3b0154a796c30f513255da8f0b4a"></a>
the learning rate for performing gradient descent on learning rate lr&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;normalized_lr_adaption&quot;,&quot;whether to apply normalized lr adaption or not&quot;).Input(0</td></tr>
<tr class="separator:afd6b3b0154a796c30f513255da8f0b4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21a837934f02933d3ae2cb68dfcf024b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a21a837934f02933d3ae2cb68dfcf024b"></a>
the learning rate for performing gradient descent on learning rate lr Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;grad&quot;,&quot;Gradient computed&quot;).Input(2</td></tr>
<tr class="separator:a21a837934f02933d3ae2cb68dfcf024b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88cf2d3d0d30a9e764339b2ba7769924"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a88cf2d3d0d30a9e764339b2ba7769924"></a>
the learning rate for performing gradient descent on learning rate lr Learning rate The effective grad&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output_lr&quot;,&quot;Updated learning rate&quot;)</td></tr>
<tr class="separator:a88cf2d3d0d30a9e764339b2ba7769924"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae25b0222d13d98d1f8dc95d9115ece99"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae25b0222d13d98d1f8dc95d9115ece99"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (LearningRateAdaption)</td></tr>
<tr class="separator:ae25b0222d13d98d1f8dc95d9115ece99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7cb1f7227365af4b3c622887075a14d"><td class="memTemplParams" colspan="2"><a class="anchor" id="ae7cb1f7227365af4b3c622887075a14d"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:ae7cb1f7227365af4b3c622887075a14d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>lr_update</b> (int n, const float *grad, const float *effgrad, const float *lr, float *nlr, float lr_alpha, bool normalized_lr_adaption, Context *)</td></tr>
<tr class="separator:ae7cb1f7227365af4b3c622887075a14d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ebe1cda68cef6846906968b891c98b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8ebe1cda68cef6846906968b891c98b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (LearningRate, <a class="el" href="classcaffe2_1_1_learning_rate_op.html">LearningRateOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8ebe1cda68cef6846906968b891c98b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7f81397a4037790bd3c31b33e1372b1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa7f81397a4037790bd3c31b33e1372b1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (LearningRate, <a class="el" href="classcaffe2_1_1_learning_rate_op.html">LearningRateOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:aa7f81397a4037790bd3c31b33e1372b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06058e388890cc66dcfe34c26887b400"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a06058e388890cc66dcfe34c26887b400"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MomentumSGD, <a class="el" href="classcaffe2_1_1_momentum_s_g_d_op.html">MomentumSGDOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a06058e388890cc66dcfe34c26887b400"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a363b4a7143feff24e281018ff96fca2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a363b4a7143feff24e281018ff96fca2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;in){vector&lt; TensorShape &gt; out(2);out[0]=in[0];out[1]=in[1];return out;}).SetDoc(R&quot;DOC( Computes a momentum SGD update for an input gradient and momentum parameters. Concretely</td></tr>
<tr class="separator:a363b4a7143feff24e281018ff96fca2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d02bdb33af75f50e798248acb9b04f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0d02bdb33af75f50e798248acb9b04f1"></a>
given&#160;</td><td class="memItemRight" valign="bottom"><b>inputs</b> (grad, m, lr) and parameters(momentum</td></tr>
<tr class="separator:a0d02bdb33af75f50e798248acb9b04f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6be29eecd8f5475a405b86e6ea2cd828"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6be29eecd8f5475a405b86e6ea2cd828"></a>
given adjusted_gradient m_new Output&#160;</td><td class="memItemRight" valign="bottom"><b>is</b> (grad, momentum) Note the difference to MomemtumSGDUpdate</td></tr>
<tr class="separator:a6be29eecd8f5475a405b86e6ea2cd828"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6aff43e7aa0ccff31188a67b364eeb76"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6aff43e7aa0ccff31188a67b364eeb76"></a>
given adjusted_gradient m_new Output which actually performs the parameter&#160;</td><td class="memItemRight" valign="bottom"><b>update</b> (and is thus faster).) DOC&quot;)</td></tr>
<tr class="separator:a6aff43e7aa0ccff31188a67b364eeb76"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a888fa7c9e77dc141bbdded7fa03766d8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a888fa7c9e77dc141bbdded7fa03766d8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (MomentumSGD)</td></tr>
<tr class="separator:a888fa7c9e77dc141bbdded7fa03766d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02f8dc6505fb594b1ea42226095c7df3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02f8dc6505fb594b1ea42226095c7df3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (MomentumSGDUpdate, <a class="el" href="classcaffe2_1_1_momentum_s_g_d_update_op.html">MomentumSGDUpdateOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a02f8dc6505fb594b1ea42226095c7df3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae17865fdf00c4c036edc36bb86fd7e02"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae17865fdf00c4c036edc36bb86fd7e02"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;, const vector&lt; TensorShape &gt; &amp;in){vector&lt; TensorShape &gt; out(3);out[0]=in[0];out[1]=in[1];out[2]=in[3];return out;}).SetDoc(R&quot;DOC( Performs a momentum SGD update for an input gradient and momentum parameters. Concretely</td></tr>
<tr class="separator:ae17865fdf00c4c036edc36bb86fd7e02"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d337e8e55be7b94f9687b45e9c22b72"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5d337e8e55be7b94f9687b45e9c22b72"></a>
given&#160;</td><td class="memItemRight" valign="bottom"><b>inputs</b> (grad, m, lr, param) and arguments(momentum</td></tr>
<tr class="separator:a5d337e8e55be7b94f9687b45e9c22b72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73fb9d12d5d00d54747873d788b5859c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a73fb9d12d5d00d54747873d788b5859c"></a>
given param&#160;</td><td class="memItemRight" valign="bottom"><b>return</b> ((1+momentum)*m_new-momentum *m, m_new, param) Output is(grad</td></tr>
<tr class="separator:a73fb9d12d5d00d54747873d788b5859c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e2fc43856b6b48cefada73f27cb3618"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e2fc43856b6b48cefada73f27cb3618"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (MomentumSGDUpdate)</td></tr>
<tr class="separator:a1e2fc43856b6b48cefada73f27cb3618"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29067a3f5dbbdcb2140b3ee9bc7a0644"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29067a3f5dbbdcb2140b3ee9bc7a0644"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SparseMomentumSGDUpdate, <a class="el" href="classcaffe2_1_1_sparse_momentum_s_g_d_update_op.html">SparseMomentumSGDUpdateOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a29067a3f5dbbdcb2140b3ee9bc7a0644"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a273efb9a376640fb9e08ef84fb9c4b68"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a273efb9a376640fb9e08ef84fb9c4b68"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>EnforceInplace</b> ({{1, 1},{3, 2}}).TensorInferenceFunction([](const OperatorDef &amp;</td></tr>
<tr class="separator:a273efb9a376640fb9e08ef84fb9c4b68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac052eb9d58a07a56eaaf70956debd924"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac052eb9d58a07a56eaaf70956debd924"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(

Performs a momentum SGD update analogous to MomentumSGDUpdate, but using a
GradientSlice and indices into the full param and momentum tables. Both param
and momentum should be in-place (corresponding inputs and outputs should be the
same blobs).



)DOC&quot;).Input(0</td></tr>
<tr class="separator:ac052eb9d58a07a56eaaf70956debd924"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a576102af3c5284d48ebe9b85f060bfac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a576102af3c5284d48ebe9b85f060bfac"></a>
GradientSlice with gradients for updated indices&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;moment&quot;,&quot;Momentum blob, same shape as param.&quot;).Input(2</td></tr>
<tr class="separator:a576102af3c5284d48ebe9b85f060bfac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97174aec4705e2654ac0369b82671d5f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a97174aec4705e2654ac0369b82671d5f"></a>
GradientSlice with gradients for updated indices Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;param&quot;,&quot;Full parameter blob.&quot;).Input(4</td></tr>
<tr class="separator:a97174aec4705e2654ac0369b82671d5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9df01e983d4971cc151e5245a0e6023e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9df01e983d4971cc151e5245a0e6023e"></a>
GradientSlice with gradients for updated indices Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Indices</b> (in first dimension of param) where updates are performed.&quot;) .Output(0</td></tr>
<tr class="separator:a9df01e983d4971cc151e5245a0e6023e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af90e51b8ce609f0e353e994d0e7df7cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af90e51b8ce609f0e353e994d0e7df7cd"></a>
GradientSlice with gradients for updated indices Learning rate Adjusted gradient&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;output_moment&quot;,&quot;Updated momentum.&quot;).Output(2</td></tr>
<tr class="separator:af90e51b8ce609f0e353e994d0e7df7cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5a34f5d286bc76ea194fdb24c791a38"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af5a34f5d286bc76ea194fdb24c791a38"></a>
GradientSlice with gradients for updated indices Learning rate Adjusted gradient Updated parameter&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;momentum&quot;,&quot;Momentum hyperparameter.&quot;).Arg(&quot;nesterov&quot;</td></tr>
<tr class="separator:af5a34f5d286bc76ea194fdb24c791a38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aadde0286b179d85bed73ee10dcc51b68"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aadde0286b179d85bed73ee10dcc51b68"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (SparseMomentumSGDUpdate)</td></tr>
<tr class="separator:aadde0286b179d85bed73ee10dcc51b68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c6ad2b102c2dbbb3ee0e6008974d60d"><td class="memTemplParams" colspan="2"><a class="anchor" id="a3c6ad2b102c2dbbb3ee0e6008974d60d"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a3c6ad2b102c2dbbb3ee0e6008974d60d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>momentum_sgd_update</b> (const int N, const float *g, const float *m, float *ng, float *nm, const float *lr, const float momentum, const bool nesterov, float *param, Context *)</td></tr>
<tr class="separator:a3c6ad2b102c2dbbb3ee0e6008974d60d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3024274d23e0aa690e9ede7b3e79ecb2"><td class="memTemplParams" colspan="2"><a class="anchor" id="a3024274d23e0aa690e9ede7b3e79ecb2"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:a3024274d23e0aa690e9ede7b3e79ecb2"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>rmsprop_update&lt; CPUContext &gt;</b> (int N, const float *g, const float *ms, const float *mom, float *ng, float *nms, float *nmom, float decay, float momentum, float epsilon, const float *lr, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> *)</td></tr>
<tr class="separator:a3024274d23e0aa690e9ede7b3e79ecb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97b90ea97be1a556b20e63346816d4f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a97b90ea97be1a556b20e63346816d4f0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RmsProp, <a class="el" href="classcaffe2_1_1_rms_prop_op.html">RmsPropOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a97b90ea97be1a556b20e63346816d4f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89e95977c65ff678c1161df753483829"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a89e95977c65ff678c1161df753483829"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Computes the RMSProp update
(http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf).
Concretely, given inputs (grad, mean_squares, mom, lr), computes:

    mean_squares_o = mean_squares + (1 - decay) * (square(grad) - mean_squares)
    mom_o = momentum * mom + lr * grad / sqrt(epsilon + mean_squares_o)
    grad_o = mom_o

Returns (grad_o, mean_squares_o, mom_o).
)DOC&quot;)</td></tr>
<tr class="separator:a89e95977c65ff678c1161df753483829"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8e7a8e73e8793ec9ee086c500e62e2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab8e7a8e73e8793ec9ee086c500e62e2f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (RmsProp)</td></tr>
<tr class="separator:ab8e7a8e73e8793ec9ee086c500e62e2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c1cbdf70bb22108c3b37d00943ca4b3"><td class="memTemplParams" colspan="2"><a class="anchor" id="a7c1cbdf70bb22108c3b37d00943ca4b3"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a7c1cbdf70bb22108c3b37d00943ca4b3"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>rmsprop_update</b> (int N, const float *g, const float *ms, const float *mom, float *ng, float *nms, float *nmom, float decay, float momentum, float epsilon, const float *lr, Context *context)</td></tr>
<tr class="separator:a7c1cbdf70bb22108c3b37d00943ca4b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26d9164ec0cdd177045f2f5e89b5481c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a26d9164ec0cdd177045f2f5e89b5481c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Wngrad, <a class="el" href="classcaffe2_1_1_wngrad_op.html">WngradOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a26d9164ec0cdd177045f2f5e89b5481c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9e534b26594d516eb0e280af94abb17"><td class="memTemplParams" colspan="2"><a class="anchor" id="ae9e534b26594d516eb0e280af94abb17"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:ae9e534b26594d516eb0e280af94abb17"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>wngrad_update</b> (int N, const float *w, const float *g, const float *h, float *nw, float *nh, float epsilon, const float *lr, Context *)</td></tr>
<tr class="separator:ae9e534b26594d516eb0e280af94abb17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f8bdf8bacb8eb0b9dcdb00bb03456eb"><td class="memTemplParams" colspan="2"><a class="anchor" id="a0f8bdf8bacb8eb0b9dcdb00bb03456eb"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:a0f8bdf8bacb8eb0b9dcdb00bb03456eb"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>wngrad_update_output_effective_lr</b> (int N, const float *paramIn, const float *gradIn, const float *seqBIn, float *paramOut, float *seqBOut, float *effectiveLROut, float epsilon, const float *lr, Context *)</td></tr>
<tr class="separator:a0f8bdf8bacb8eb0b9dcdb00bb03456eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6be651af72677b0d43a0d23352c1cba"><td class="memTemplParams" colspan="2"><a class="anchor" id="ad6be651af72677b0d43a0d23352c1cba"></a>
template&lt;typename Context &gt; </td></tr>
<tr class="memitem:ad6be651af72677b0d43a0d23352c1cba"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>wngrad_update_output_effective_lr_and_update</b> (int N, const float *paramIn, const float *gradIn, const float *seqBIn, float *paramOut, float *seqBOut, float *effectiveLROut, float *updateOut, float epsilon, const float *lr, Context *)</td></tr>
<tr class="separator:ad6be651af72677b0d43a0d23352c1cba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6241feb2dd8e48a9a813cc86874c140"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6241feb2dd8e48a9a813cc86874c140"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (YellowFin, <a class="el" href="classcaffe2_1_1_yellow_fin_op.html">YellowFinOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ad6241feb2dd8e48a9a813cc86874c140"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2b8f78d7267835a0bba59ca78b4c1fa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab2b8f78d7267835a0bba59ca78b4c1fa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NumInputs</b> (10).NumOutputs(8).AllowInplace(</td></tr>
<tr class="separator:ab2b8f78d7267835a0bba59ca78b4c1fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a864c62617d26b6fef41551736eed77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a864c62617d26b6fef41551736eed77"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(

Computes the YellowFin update (https://arxiv.org/abs/1706.03471) and performs
momentum SGD optimization step. lr and mu are not being shared between
parameters. curv_win, g_avg, g2_avg and scalars_memory are just auxiliary
memory for computing moving averages (see the publication). Takes arguments
beta: coefficient for moving averages,
curv_win_width: timeframe when average squared gradient is being stored,
epsilon: for numerical purposes,
nesterov and zero_debias for debias of moving average.

)DOC&quot;).Input(0</td></tr>
<tr class="separator:a9a864c62617d26b6fef41551736eed77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67fe7d7e65bdf6635caf0ea43db13c94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67fe7d7e65bdf6635caf0ea43db13c94"></a>
Parameters to be updated&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;moment&quot;,&quot;Momentum&quot;).Input(2</td></tr>
<tr class="separator:a67fe7d7e65bdf6635caf0ea43db13c94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1142745b278aa45fd37fa0f2fddb15fa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1142745b278aa45fd37fa0f2fddb15fa"></a>
Parameters to be updated Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;mu&quot;,&quot;Momentum coefficient&quot;).Input(4</td></tr>
<tr class="separator:a1142745b278aa45fd37fa0f2fddb15fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84aab5b1c3627c8c2a29e7fe7e62ea26"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a84aab5b1c3627c8c2a29e7fe7e62ea26"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (5,&quot;g_avg&quot;,&quot;Moving average of gradient&quot;).Input(6</td></tr>
<tr class="separator:a84aab5b1c3627c8c2a29e7fe7e62ea26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04e949f20096c2dbea98f93119d89900"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04e949f20096c2dbea98f93119d89900"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (7,&quot;scalars_memory&quot;,&quot;Memory for stateful scalars&quot;).Input(8</td></tr>
<tr class="separator:a04e949f20096c2dbea98f93119d89900"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff9c2d63ae50964044021320dd5d6357"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff9c2d63ae50964044021320dd5d6357"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (9,&quot;iter&quot;,&quot;Iteration number&quot;).Output(0</td></tr>
<tr class="separator:aff9c2d63ae50964044021320dd5d6357"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0a76c6d0a15511bc059a2878e09a4ec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae0a76c6d0a15511bc059a2878e09a4ec"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;output_moment&quot;,&quot;Momentum&quot;).Output(2</td></tr>
<tr class="separator:ae0a76c6d0a15511bc059a2878e09a4ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0d08fe45e97859bcfda68625e51eb94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0d08fe45e97859bcfda68625e51eb94"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated Output learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (3,&quot;output_mu&quot;,&quot;Output momentum coefficient&quot;).Output(4</td></tr>
<tr class="separator:ab0d08fe45e97859bcfda68625e51eb94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a859265056a54d031b1d3c807f8d42c92"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a859265056a54d031b1d3c807f8d42c92"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated Output learning rate Output memory for latest curvature ranges&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (5,&quot;output_g_avg&quot;,&quot;Output moving average of gradient&quot;).Output(6</td></tr>
<tr class="separator:a859265056a54d031b1d3c807f8d42c92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a721f76e4820af51fa471eb1404c717e5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a721f76e4820af51fa471eb1404c717e5"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated Output learning rate Output memory for latest curvature ranges Output moving average of squared gradient&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (7,&quot;output_scalars_memory&quot;,&quot;Output memory for stateful scalars&quot;).Arg(&quot;beta&quot;</td></tr>
<tr class="separator:a721f76e4820af51fa471eb1404c717e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab87fb870be0ce47472f63d0002110d08"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab87fb870be0ce47472f63d0002110d08"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated Output learning rate Output memory for latest curvature ranges Output moving average of squared gradient Default&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;curv_win_width&quot;,&quot;Default 20&quot;).Arg(&quot;epsilon&quot;</td></tr>
<tr class="separator:ab87fb870be0ce47472f63d0002110d08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e24f3a19fb3af59eb992852a1f7b04a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e24f3a19fb3af59eb992852a1f7b04a"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated Output learning rate Output memory for latest curvature ranges Output moving average of squared gradient Default Default&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;nesterov&quot;,&quot;Default false&quot;).Arg(&quot;zero_debias&quot;</td></tr>
<tr class="separator:a8e24f3a19fb3af59eb992852a1f7b04a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a614581fe220bb4852ba056a8ef579a29"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a614581fe220bb4852ba056a8ef579a29"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (YellowFin)</td></tr>
<tr class="separator:a614581fe220bb4852ba056a8ef579a29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad138bc472309a6859cd5a50fb4dc64ae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad138bc472309a6859cd5a50fb4dc64ae"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>initNNPACK</b> ()</td></tr>
<tr class="separator:ad138bc472309a6859cd5a50fb4dc64ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79995aa56787333ca75efbbb79c8bc61"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79995aa56787333ca75efbbb79c8bc61"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR_WITH_ENGINE</b> (<a class="el" href="class_conv.html">Conv</a>, NNPACK, <a class="el" href="classcaffe2_1_1_n_n_p_a_c_k_conv_op.html">NNPACKConvOp</a>)</td></tr>
<tr class="separator:a79995aa56787333ca75efbbb79c8bc61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac251f4b88db090cb5d63c9e0cc783f91"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac251f4b88db090cb5d63c9e0cc783f91"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (QuantDecompZstd, <a class="el" href="classcaffe2_1_1_quant_decomp_zstd_op.html">QuantDecompZstdOp</a>)</td></tr>
<tr class="separator:ac251f4b88db090cb5d63c9e0cc783f91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52c2b50421e5129e4ad89d1250e1f66d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a52c2b50421e5129e4ad89d1250e1f66d"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
 Decompress a set of tensors that are compressed using zstd.
 The data can be compressed using mutils.compress_data_list(), see
 quant_decomp_op_test.py for an example.
 The number of outputs depended on the input.
 )DOC&quot;).Input(0</td></tr>
<tr class="separator:a52c2b50421e5129e4ad89d1250e1f66d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bcf58f3d62b4c9b0cf0ec94d0ef41f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1bcf58f3d62b4c9b0cf0ec94d0ef41f1"></a>
INT_MAX Compressed data in&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b> (uint8_t)</td></tr>
<tr class="separator:a1bcf58f3d62b4c9b0cf0ec94d0ef41f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0f092565e57a6cc19c9457cee62adc9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab0f092565e57a6cc19c9457cee62adc9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SHOULD_NOT_DO_GRADIENT</b> (QuantDecompZstd)</td></tr>
<tr class="separator:ab0f092565e57a6cc19c9457cee62adc9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a308109b3449984670fb7857df21939"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2a308109b3449984670fb7857df21939"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>are_nodes_common</b> (const <a class="el" href="classnom_1_1_graph.html">Graph</a> &amp;g, int model_idx, int candidate_idx)</td></tr>
<tr class="separator:a2a308109b3449984670fb7857df21939"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2e71d23701ed932b2aa1aeecfb50418"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad2e71d23701ed932b2aa1aeecfb50418"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_TRANSFORM</b> (CommonSubexpressionElimination, <a class="el" href="classcaffe2_1_1_common_subexpression_elimination_transform.html">CommonSubexpressionEliminationTransform</a>)</td></tr>
<tr class="separator:ad2e71d23701ed932b2aa1aeecfb50418"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8514f554606ce65accb85d0fe3d8de86"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8514f554606ce65accb85d0fe3d8de86"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_TRANSFORM</b> (ConvToNNPack, <a class="el" href="classcaffe2_1_1_conv_to_n_n_pack_transform.html">ConvToNNPackTransform</a>)</td></tr>
<tr class="separator:a8514f554606ce65accb85d0fe3d8de86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4de906b41a8aabb7bdddcf918de41a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac4de906b41a8aabb7bdddcf918de41a5"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>compare_ops</b> (const OperatorDef &amp;p_op, const OperatorDef &amp;g_op, bool arg_match)</td></tr>
<tr class="separator:ac4de906b41a8aabb7bdddcf918de41a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1395390f47002d9d48c1c7ddf456d58d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1395390f47002d9d48c1c7ddf456d58d"></a>
uint32_t&#160;</td><td class="memItemRight" valign="bottom"><b>wipe_cache</b> ()</td></tr>
<tr class="separator:a1395390f47002d9d48c1c7ddf456d58d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a415daf787ec8776bdb27e21a9f4864cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a415daf787ec8776bdb27e21a9f4864cf"></a>
const <a class="el" href="classcaffe2_1_1_cpu_id.html">CpuId</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>GetCpuId</b> ()</td></tr>
<tr class="separator:a415daf787ec8776bdb27e21a9f4864cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fa0c77b4cbcd62877fd0f120cf46d80"><td class="memTemplParams" colspan="2"><a class="anchor" id="a0fa0c77b4cbcd62877fd0f120cf46d80"></a>
template&lt;class Map , typename Key  = typename Map::key_type, typename Value  = typename Map::mapped_type&gt; </td></tr>
<tr class="memitem:a0fa0c77b4cbcd62877fd0f120cf46d80"><td class="memTemplItemLeft" align="right" valign="top">Map::mapped_type&#160;</td><td class="memTemplItemRight" valign="bottom"><b>get_default</b> (const Map &amp;map, const Key &amp;key, <a class="el" href="classnom_1_1repr_1_1_value.html">Value</a> &amp;&amp;dflt)</td></tr>
<tr class="separator:a0fa0c77b4cbcd62877fd0f120cf46d80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3da9c276eaa60e471e5782245870b763"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3da9c276eaa60e471e5782245870b763"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>MurmurHash3_x86_32</b> (const void *key, int len, uint32_t seed, void *out)</td></tr>
<tr class="separator:a3da9c276eaa60e471e5782245870b763"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7be24256e9245ccd71c0b012ad4f45b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7be24256e9245ccd71c0b012ad4f45b4"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>MurmurHash3_x86_128</b> (const void *key, const int len, uint32_t seed, void *out)</td></tr>
<tr class="separator:a7be24256e9245ccd71c0b012ad4f45b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5c9229fa909eeb94b774d82630ffc98"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab5c9229fa909eeb94b774d82630ffc98"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>MurmurHash3_x64_128</b> (const void *key, const int len, const uint32_t seed, void *out)</td></tr>
<tr class="separator:ab5c9229fa909eeb94b774d82630ffc98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ef696615ea0d5bafdf48bf4dfbe26f1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ef696615ea0d5bafdf48bf4dfbe26f1"></a>
C10_EXPORT std::string&#160;</td><td class="memItemRight" valign="bottom"><b>DeviceTypeName</b> (const int32_t &amp;d)</td></tr>
<tr class="separator:a5ef696615ea0d5bafdf48bf4dfbe26f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9c6edebcef2883168e5642a9d8661b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9c6edebcef2883168e5642a9d8661b9"></a>
C10_EXPORT int&#160;</td><td class="memItemRight" valign="bottom"><b>DeviceId</b> (const DeviceOption &amp;option)</td></tr>
<tr class="separator:aa9c6edebcef2883168e5642a9d8661b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae68f69b9f269ed300d120a3cc1a64bb3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae68f69b9f269ed300d120a3cc1a64bb3"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>IsSameDevice</b> (const DeviceOption &amp;lhs, const DeviceOption &amp;rhs)</td></tr>
<tr class="separator:ae68f69b9f269ed300d120a3cc1a64bb3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64137c83dabcc1c14ff9d69aefeb1901"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a64137c83dabcc1c14ff9d69aefeb1901"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>IsCPUDeviceType</b> (int device_type)</td></tr>
<tr class="separator:a64137c83dabcc1c14ff9d69aefeb1901"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a057724811bf88260c8f299de51297fec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a057724811bf88260c8f299de51297fec"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>IsGPUDeviceType</b> (int device_type)</td></tr>
<tr class="separator:a057724811bf88260c8f299de51297fec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a637e1956334959abc3b331ebe594d0d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a637e1956334959abc3b331ebe594d0d2"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>ReadStringFromFile</b> (const char *filename, string *str)</td></tr>
<tr class="separator:a637e1956334959abc3b331ebe594d0d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a651f89f2311264dd5eb9f1bdc0acad28"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a651f89f2311264dd5eb9f1bdc0acad28"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>WriteStringToFile</b> (const string &amp;str, const char *filename)</td></tr>
<tr class="separator:a651f89f2311264dd5eb9f1bdc0acad28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6d81864eda3b55ea4e4ab1b2d7cb944"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6d81864eda3b55ea4e4ab1b2d7cb944"></a>
C10_EXPORT string&#160;</td><td class="memItemRight" valign="bottom"><b>ProtoDebugString</b> (const Message &amp;proto)</td></tr>
<tr class="separator:ad6d81864eda3b55ea4e4ab1b2d7cb944"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2819fedc8dd6a4df57e11d48cf9d72ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2819fedc8dd6a4df57e11d48cf9d72ed"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>ParseProtoFromLargeString</b> (const string &amp;str, Message *proto)</td></tr>
<tr class="separator:a2819fedc8dd6a4df57e11d48cf9d72ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24b478cda45a3a54ae421f7e90fd49fb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a24b478cda45a3a54ae421f7e90fd49fb"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>ReadProtoFromTextFile</b> (const char *filename, Message *proto)</td></tr>
<tr class="separator:a24b478cda45a3a54ae421f7e90fd49fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79969cd5b0bab7da83d63cc030a39504"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79969cd5b0bab7da83d63cc030a39504"></a>
C10_EXPORT void&#160;</td><td class="memItemRight" valign="bottom"><b>WriteProtoToTextFile</b> (const Message &amp;proto, const char *filename)</td></tr>
<tr class="separator:a79969cd5b0bab7da83d63cc030a39504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47f15aa91bb20ea13b1ef22b4a0ab87c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a47f15aa91bb20ea13b1ef22b4a0ab87c"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>ReadProtoFromBinaryFile</b> (const char *filename, MessageLite *proto)</td></tr>
<tr class="separator:a47f15aa91bb20ea13b1ef22b4a0ab87c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2bd9f1f6975a76a5a6af78719c354bf4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2bd9f1f6975a76a5a6af78719c354bf4"></a>
C10_EXPORT void&#160;</td><td class="memItemRight" valign="bottom"><b>WriteProtoToBinaryFile</b> (const MessageLite &amp;proto, const char *filename)</td></tr>
<tr class="separator:a2bd9f1f6975a76a5a6af78719c354bf4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02de292b6d9d8eec4669f4a41237d5d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02de292b6d9d8eec4669f4a41237d5d9"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>operator==</b> (const NetDef &amp;l, const NetDef &amp;r)</td></tr>
<tr class="separator:a02de292b6d9d8eec4669f4a41237d5d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9f6ec4b6a64af60b595c14df4ca9d04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac9f6ec4b6a64af60b595c14df4ca9d04"></a>
std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>operator&lt;&lt;</b> (std::ostream &amp;output, const NetDef &amp;n)</td></tr>
<tr class="separator:ac9f6ec4b6a64af60b595c14df4ca9d04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8a9d3d933bff01f25809a14e210bcb3"><td class="memTemplParams" colspan="2"><a class="anchor" id="ac8a9d3d933bff01f25809a14e210bcb3"></a>
template&lt;&gt; </td></tr>
<tr class="memitem:ac8a9d3d933bff01f25809a14e210bcb3"><td class="memTemplItemLeft" align="right" valign="top">C10_EXPORT <a class="el" href="structc10_1_1_argument.html">Argument</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>MakeArgument</b> (const string &amp;name, const MessageLite &amp;value)</td></tr>
<tr class="separator:ac8a9d3d933bff01f25809a14e210bcb3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac536d1074ab3a1a40fdcaf271b1936d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac536d1074ab3a1a40fdcaf271b1936d9"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>HasOutput</b> (const OperatorDef &amp;op, const std::string &amp;output)</td></tr>
<tr class="separator:ac536d1074ab3a1a40fdcaf271b1936d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a805b9cc94d867b8a266b69c1ea2aac00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a805b9cc94d867b8a266b69c1ea2aac00"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>HasInput</b> (const OperatorDef &amp;op, const std::string &amp;input)</td></tr>
<tr class="separator:a805b9cc94d867b8a266b69c1ea2aac00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec545f26d689c64e40e1b5b8aa2053b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec545f26d689c64e40e1b5b8aa2053b5"></a>
C10_EXPORT int&#160;</td><td class="memItemRight" valign="bottom"><b>GetArgumentIndex</b> (const google::protobuf::RepeatedPtrField&lt; <a class="el" href="structc10_1_1_argument.html">Argument</a> &gt; &amp;args, const string &amp;name)</td></tr>
<tr class="separator:aec545f26d689c64e40e1b5b8aa2053b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdf9bffdb09dc6db27e5d1325341649a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afdf9bffdb09dc6db27e5d1325341649a"></a>
C10_EXPORT const <a class="el" href="structc10_1_1_argument.html">Argument</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>GetArgument</b> (const OperatorDef &amp;def, const string &amp;name)</td></tr>
<tr class="separator:afdf9bffdb09dc6db27e5d1325341649a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a502e3baa6360023de089ec2e74b1102a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a502e3baa6360023de089ec2e74b1102a"></a>
C10_EXPORT const <a class="el" href="structc10_1_1_argument.html">Argument</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>GetArgument</b> (const NetDef &amp;def, const string &amp;name)</td></tr>
<tr class="separator:a502e3baa6360023de089ec2e74b1102a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59d89753890e9ac4ef27a62d60dbaf24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a59d89753890e9ac4ef27a62d60dbaf24"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>GetFlagArgument</b> (const google::protobuf::RepeatedPtrField&lt; <a class="el" href="structc10_1_1_argument.html">Argument</a> &gt; &amp;args, const string &amp;name, bool default_value)</td></tr>
<tr class="separator:a59d89753890e9ac4ef27a62d60dbaf24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acacc31a2e0d9dbf2af3c809a4d37365a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acacc31a2e0d9dbf2af3c809a4d37365a"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>GetFlagArgument</b> (const OperatorDef &amp;def, const string &amp;name, bool default_value)</td></tr>
<tr class="separator:acacc31a2e0d9dbf2af3c809a4d37365a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7f775dfffe24c404e9fc2b63d67175d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab7f775dfffe24c404e9fc2b63d67175d"></a>
C10_EXPORT bool&#160;</td><td class="memItemRight" valign="bottom"><b>GetFlagArgument</b> (const NetDef &amp;def, const string &amp;name, bool default_value)</td></tr>
<tr class="separator:ab7f775dfffe24c404e9fc2b63d67175d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4148fc398d4045bbb44ba236a2e31dfe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4148fc398d4045bbb44ba236a2e31dfe"></a>
C10_EXPORT <a class="el" href="structc10_1_1_argument.html">Argument</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>GetMutableArgument</b> (const string &amp;name, const bool create_if_missing, OperatorDef *def)</td></tr>
<tr class="separator:a4148fc398d4045bbb44ba236a2e31dfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7014e29ce11c4df85ee7f178e57b0b6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad7014e29ce11c4df85ee7f178e57b0b6"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>ReadProtoFromBinaryFile</b> (const string filename, MessageLite *proto)</td></tr>
<tr class="separator:ad7014e29ce11c4df85ee7f178e57b0b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7e48bc7da22ad09a9e6c53c029fc166"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa7e48bc7da22ad09a9e6c53c029fc166"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>WriteProtoToBinaryFile</b> (const MessageLite &amp;proto, const string &amp;filename)</td></tr>
<tr class="separator:aa7e48bc7da22ad09a9e6c53c029fc166"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2e4d270640fe3295f155f0a325451f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa2e4d270640fe3295f155f0a325451f8"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>ReadProtoFromTextFile</b> (const string filename, Message *proto)</td></tr>
<tr class="separator:aa2e4d270640fe3295f155f0a325451f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c9842cb97b5568c533b21f5e0d34694"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2c9842cb97b5568c533b21f5e0d34694"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>WriteProtoToTextFile</b> (const Message &amp;proto, const string &amp;filename)</td></tr>
<tr class="separator:a2c9842cb97b5568c533b21f5e0d34694"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cd4c76aea16a60bb6194c5235a2b5b1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4cd4c76aea16a60bb6194c5235a2b5b1"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>ReadProtoFromFile</b> (const char *filename, Message *proto)</td></tr>
<tr class="separator:a4cd4c76aea16a60bb6194c5235a2b5b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed6c104b71dcb8d6689e47c8eb1c9edd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed6c104b71dcb8d6689e47c8eb1c9edd"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>ReadProtoFromFile</b> (const string &amp;filename, Message *proto)</td></tr>
<tr class="separator:aed6c104b71dcb8d6689e47c8eb1c9edd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebbf56a50048541aae3fc997a79e2315"><td class="memTemplParams" colspan="2"><a class="anchor" id="aebbf56a50048541aae3fc997a79e2315"></a>
template&lt;class IterableInputs  = std::initializer_list&lt;string&gt;, class IterableOutputs  = std::initializer_list&lt;string&gt;, class IterableArgs  = std::initializer_list&lt;Argument&gt;&gt; </td></tr>
<tr class="memitem:aebbf56a50048541aae3fc997a79e2315"><td class="memTemplItemLeft" align="right" valign="top">OperatorDef&#160;</td><td class="memTemplItemRight" valign="bottom"><b>CreateOperatorDef</b> (const string &amp;type, const string &amp;name, const IterableInputs &amp;inputs, const IterableOutputs &amp;outputs, const IterableArgs &amp;args, const DeviceOption &amp;device_option=DeviceOption(), const string &amp;engine=&quot;&quot;)</td></tr>
<tr class="separator:aebbf56a50048541aae3fc997a79e2315"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b29e74962bf44701fd387c5f129b68c"><td class="memTemplParams" colspan="2"><a class="anchor" id="a1b29e74962bf44701fd387c5f129b68c"></a>
template&lt;class IterableInputs  = std::initializer_list&lt;string&gt;, class IterableOutputs  = std::initializer_list&lt;string&gt;&gt; </td></tr>
<tr class="memitem:a1b29e74962bf44701fd387c5f129b68c"><td class="memTemplItemLeft" align="right" valign="top">OperatorDef&#160;</td><td class="memTemplItemRight" valign="bottom"><b>CreateOperatorDef</b> (const string &amp;type, const string &amp;name, const IterableInputs &amp;inputs, const IterableOutputs &amp;outputs, const DeviceOption &amp;device_option=DeviceOption(), const string &amp;engine=&quot;&quot;)</td></tr>
<tr class="separator:a1b29e74962bf44701fd387c5f129b68c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a491e39435d8fe984a65591faa2969f97"><td class="memTemplParams" colspan="2"><a class="anchor" id="a491e39435d8fe984a65591faa2969f97"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a491e39435d8fe984a65591faa2969f97"><td class="memTemplItemLeft" align="right" valign="top">CAFFE2_API <a class="el" href="structc10_1_1_argument.html">Argument</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>MakeArgument</b> (const string &amp;name, const <a class="el" href="struct_t.html">T</a> &amp;value)</td></tr>
<tr class="separator:a491e39435d8fe984a65591faa2969f97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6fe7c3dabef65d5aee07f54aa8a85e8e"><td class="memTemplParams" colspan="2"><a class="anchor" id="a6fe7c3dabef65d5aee07f54aa8a85e8e"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a6fe7c3dabef65d5aee07f54aa8a85e8e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>AddArgument</b> (const string &amp;name, const <a class="el" href="struct_t.html">T</a> &amp;value, OperatorDef *def)</td></tr>
<tr class="separator:a6fe7c3dabef65d5aee07f54aa8a85e8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea81b709fceb86f663d11ab502b1d1ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea81b709fceb86f663d11ab502b1d1ff"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>operator==</b> (const DeviceOption &amp;dl, const DeviceOption &amp;dr)</td></tr>
<tr class="separator:aea81b709fceb86f663d11ab502b1d1ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac043fa0d17be8a2696415c5fc254c1ae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac043fa0d17be8a2696415c5fc254c1ae"></a>
CAFFE2_APIconst::std::string &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>GetEmptyStringAlreadyInited</b> ()</td></tr>
<tr class="separator:ac043fa0d17be8a2696415c5fc254c1ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6e7afdc7c26130d04a23d13bf1aabc5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab6e7afdc7c26130d04a23d13bf1aabc5"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ShutdownProtobufLibrary</b> ()</td></tr>
<tr class="separator:ab6e7afdc7c26130d04a23d13bf1aabc5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9681d9c5cbe25a7e3ac4b7a32f80391b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9681d9c5cbe25a7e3ac4b7a32f80391b"></a>
std::vector&lt; std::string &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>split</b> (char separator, const std::string &amp;string)</td></tr>
<tr class="separator:a9681d9c5cbe25a7e3ac4b7a32f80391b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28cb1a3f1c54bc544b3a985d7a07c4cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28cb1a3f1c54bc544b3a985d7a07c4cd"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><b>trim</b> (const std::string &amp;str)</td></tr>
<tr class="separator:a28cb1a3f1c54bc544b3a985d7a07c4cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58921b60d95c9118dc1ff3d76418096c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a58921b60d95c9118dc1ff3d76418096c"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><b>editDistance</b> (const std::string &amp;s1, const std::string &amp;s2, size_t max_distance)</td></tr>
<tr class="separator:a58921b60d95c9118dc1ff3d76418096c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affd014a8157a7c0c50bbb971706cb45e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="affd014a8157a7c0c50bbb971706cb45e"></a>
int32_t&#160;</td><td class="memItemRight" valign="bottom"><b>editDistanceHelper</b> (const char *s1, size_t s1_len, const char *s2, size_t s2_len, std::vector&lt; size_t &gt; &amp;current, std::vector&lt; size_t &gt; &amp;previous, std::vector&lt; size_t &gt; &amp;previous1, size_t max_distance)</td></tr>
<tr class="separator:affd014a8157a7c0c50bbb971706cb45e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37ddbd734a57280ea422d9a1fc691d77"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a37ddbd734a57280ea422d9a1fc691d77"></a>
CAFFE2_API bool&#160;</td><td class="memItemRight" valign="bottom"><b>StartsWith</b> (const std::string &amp;str, const std::string &amp;prefix)</td></tr>
<tr class="separator:a37ddbd734a57280ea422d9a1fc691d77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17123f0fb2581b0b8cd3427420253073"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17123f0fb2581b0b8cd3427420253073"></a>
CAFFE2_API bool&#160;</td><td class="memItemRight" valign="bottom"><b>EndsWith</b> (const std::string &amp;full, const std::string &amp;ending)</td></tr>
<tr class="separator:a17123f0fb2581b0b8cd3427420253073"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39806ba605fafaac38f9e9c539706f4c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39806ba605fafaac38f9e9c539706f4c"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>Do256NOPs</b> ()</td></tr>
<tr class="separator:a39806ba605fafaac38f9e9c539706f4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2c95d7b8489a4665a6fd90de8e93df0"><td class="memTemplParams" colspan="2"><a class="anchor" id="ae2c95d7b8489a4665a6fd90de8e93df0"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae2c95d7b8489a4665a6fd90de8e93df0"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="struct_t.html">T</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>WaitForVariableChange</b> (std::atomic&lt; <a class="el" href="struct_t.html">T</a> &gt; *var, <a class="el" href="struct_t.html">T</a> initial_value, std::condition_variable *cond, std::mutex *mutex)</td></tr>
<tr class="separator:ae2c95d7b8489a4665a6fd90de8e93df0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad06975f79f2761859f54567b4c0ab1f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad06975f79f2761859f54567b4c0ab1f6"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>OpticalFlowExtractor</b> (const cv::Mat &amp;prev_gray, const cv::Mat &amp;curr_gray, const int flow_alg_type, cv::Mat &amp;flow)</td></tr>
<tr class="separator:ad06975f79f2761859f54567b4c0ab1f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac508d77cbce42907eb769c3af6a33d71"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac508d77cbce42907eb769c3af6a33d71"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>MergeOpticalFlow</b> (cv::Mat &amp;prev_flow, const cv::Mat &amp;curr_flow)</td></tr>
<tr class="separator:ac508d77cbce42907eb769c3af6a33d71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a241d9ae73921604aaf500633d2c96e3a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a241d9ae73921604aaf500633d2c96e3a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>MultiFrameOpticalFlowExtractor</b> (const std::vector&lt; cv::Mat &gt; &amp;grays, const int optical_flow_alg_type, cv::Mat &amp;flow)</td></tr>
<tr class="separator:a241d9ae73921604aaf500633d2c96e3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47ac2eb7e450d80ba2700e9d49bb7803"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a47ac2eb7e450d80ba2700e9d49bb7803"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (VideoInput, <a class="el" href="classcaffe2_1_1_video_input_op.html">VideoInputOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a47ac2eb7e450d80ba2700e9d49bb7803"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7866928eb54d9801cb869da86329975d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7866928eb54d9801cb869da86329975d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TensorInferenceFunction</b> ([](const OperatorDef &amp;def, const vector&lt; TensorShape &gt; &amp;){<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a> helper(def);int batch_size=helper.GetSingleArgument&lt; int &gt;(&quot;batch_size&quot;, 0);int clip_per_video=helper.GetSingleArgument&lt; int &gt;(&quot;clip_per_video&quot;, 1);int crop_height=helper.GetSingleArgument&lt; int &gt;(&quot;crop_height&quot;, helper.GetSingleArgument&lt; int &gt;(&quot;crop_size&quot;, 0));int crop_width=helper.GetSingleArgument&lt; int &gt;(&quot;crop_width&quot;, helper.GetSingleArgument&lt; int &gt;(&quot;crop_size&quot;, 0));int length_rgb=helper.GetSingleArgument&lt; int &gt;(&quot;length_rgb&quot;, 0);int channels_rgb=helper.GetSingleArgument&lt; int &gt;(&quot;channels_rgb&quot;, 3);int length_of=helper.GetSingleArgument&lt; int &gt;(&quot;length_of&quot;, 0);int channels_of=helper.GetSingleArgument&lt; int &gt;(&quot;channels_of&quot;, 2);bool get_rgb=helper.GetSingleArgument&lt; bool &gt;(&quot;get_rgb&quot;, true);bool get_optical_flow=helper.GetSingleArgument&lt; bool &gt;(&quot;get_optical_flow&quot;, false);bool do_multi_label=helper.GetSingleArgument&lt; bool &gt;(&quot;do_multi_label&quot;, false);bool get_video_id=helper.GetSingleArgument&lt; bool &gt;(&quot;get_video_id&quot;, false);int output_size=1;if(get_rgb){output_size++;}if(get_optical_flow){output_size++;}if(get_video_id){output_size++;}int index=0;vector&lt; TensorShape &gt; out(output_size);CHECK_GT(crop_height, 0);CHECK_GT(crop_width, 0);batch_size *=clip_per_video;if(get_rgb){out[index++]=CreateTensorShape(vector&lt; int &gt;{batch_size, channels_rgb, length_rgb, crop_height, crop_width}, TensorProto::FLOAT);}if(get_optical_flow){out[index++]=CreateTensorShape(vector&lt; int &gt;{batch_size, channels_of, length_of, crop_height, crop_width}, TensorProto::FLOAT);}if(!do_multi_label){out[index++]=CreateTensorShape(vector&lt; int &gt;{1, batch_size}, TensorProto::INT32);}else{int num_of_class=helper.GetSingleArgument&lt; int &gt;(&quot;num_of_class&quot;, 0);out[index++]=CreateTensorShape(vector&lt; int &gt;{batch_size, num_of_class}, TensorProto::INT32);}if(get_video_id){out[index]=CreateTensorShape(vector&lt; int &gt;{1, batch_size}, TensorProto::INT32);}return out;})</td></tr>
<tr class="separator:a7866928eb54d9801cb869da86329975d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08128f09da097f94938d256fe2ca0db7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08128f09da097f94938d256fe2ca0db7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>NO_GRADIENT</b> (VideoInput)</td></tr>
<tr class="separator:a08128f09da097f94938d256fe2ca0db7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8a1119be7ed5fbbe15f12e9e6f908ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae8a1119be7ed5fbbe15f12e9e6f908ad"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CUDA_OPERATOR</b> (VideoInput, <a class="el" href="classcaffe2_1_1_video_input_op.html">VideoInputOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_u_d_a_context.html">CUDAContext</a> &gt;)</td></tr>
<tr class="separator:ae8a1119be7ed5fbbe15f12e9e6f908ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62fa77afbe3272c8aee7667bd504175a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62fa77afbe3272c8aee7667bd504175a"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>Saturation</b> (float *clip, const int length, const int crop_height, const int crop_width, const float alpha_rand, std::mt19937 *randgen)</td></tr>
<tr class="separator:a62fa77afbe3272c8aee7667bd504175a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63a906d5d8188b122429b1a7cbb4bedd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a63a906d5d8188b122429b1a7cbb4bedd"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>Brightness</b> (float *clip, const int length, const int crop_height, const int crop_width, const float alpha_rand, std::mt19937 *randgen)</td></tr>
<tr class="separator:a63a906d5d8188b122429b1a7cbb4bedd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1cae843791901a20f962d51ba26488f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad1cae843791901a20f962d51ba26488f"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>Contrast</b> (float *clip, const int length, const int crop_height, const int crop_width, const float alpha_rand, std::mt19937 *randgen)</td></tr>
<tr class="separator:ad1cae843791901a20f962d51ba26488f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a282bff30c49c6c699ed9eb2687cf74dc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a282bff30c49c6c699ed9eb2687cf74dc"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ColorJitter</b> (float *clip, const int length, const int crop_height, const int crop_width, const float saturation, const float brightness, const float contrast, std::mt19937 *randgen)</td></tr>
<tr class="separator:a282bff30c49c6c699ed9eb2687cf74dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7acc5e6c3040a1986c8e8736d01e8ec5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7acc5e6c3040a1986c8e8736d01e8ec5"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ColorLighting</b> (float *clip, const int length, const int crop_height, const int crop_width, const float alpha_std, const std::vector&lt; std::vector&lt; float &gt;&gt; &amp;eigvecs, const std::vector&lt; float &gt; &amp;eigvals, std::mt19937 *randgen)</td></tr>
<tr class="separator:a7acc5e6c3040a1986c8e8736d01e8ec5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70033d27ddd9ea416d746eeb332fec3f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a70033d27ddd9ea416d746eeb332fec3f"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ColorNormalization</b> (float *clip, const int length, const int crop_height, const int crop_width, const int channels, const std::vector&lt; float &gt; &amp;mean, const std::vector&lt; float &gt; &amp;inv_std)</td></tr>
<tr class="separator:a70033d27ddd9ea416d746eeb332fec3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a928639fc7611c5c118d13ac7edb44563"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a928639fc7611c5c118d13ac7edb44563"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ClipTransformRGB</b> (const unsigned char *buffer_rgb, const int multi_crop_count, const int crop_height, const int crop_width, const int length_rgb, const int channels_rgb, const int sampling_rate_rgb, const int height, const int width, const int h_off, const int w_off, const int *multi_crop_h_off, const int *multi_crop_w_off, const bool mirror_me, const bool color_jitter, const float saturation, const float brightness, const float contrast, const bool color_lighting, const float color_lighting_std, const std::vector&lt; std::vector&lt; float &gt;&gt; &amp;color_lighting_eigvecs, const std::vector&lt; float &gt; &amp;color_lighting_eigvals, const std::vector&lt; float &gt; &amp;mean_rgb, const std::vector&lt; float &gt; &amp;inv_std_rgb, std::mt19937 *randgen, float *transformed_clip)</td></tr>
<tr class="separator:a928639fc7611c5c118d13ac7edb44563"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ed353088efbca2f2de1e37dab9ff0bc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8ed353088efbca2f2de1e37dab9ff0bc"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ClipTransformOpticalFlow</b> (const unsigned char *buffer_rgb, const int crop_height, const int crop_width, const int length_of, const int channels_of, const int sampling_rate_of, const int height, const int width, const cv::Rect &amp;rect, const int channels_rgb, const bool mirror_me, const int flow_alg_type, const int flow_data_type, const int frame_gap_of, const bool do_flow_aggregation, const std::vector&lt; float &gt; &amp;mean_of, const std::vector&lt; float &gt; &amp;inv_std_of, float *transformed_clip)</td></tr>
<tr class="separator:a8ed353088efbca2f2de1e37dab9ff0bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d019bef7be6a43f5c7d58c6fab2a8ed"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d019bef7be6a43f5c7d58c6fab2a8ed"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>FreeDecodedData</b> (std::vector&lt; std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_decoded_frame.html">DecodedFrame</a> &gt;&gt; &amp;sampledFrames)</td></tr>
<tr class="separator:a9d019bef7be6a43f5c7d58c6fab2a8ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9cecbe0a7961c777e62cede5d11b2a47"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9cecbe0a7961c777e62cede5d11b2a47"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>DecodeMultipleClipsFromVideo</b> (const char *video_buffer, const std::string &amp;video_filename, const int encoded_size, const <a class="el" href="classcaffe2_1_1_params.html">Params</a> &amp;params, const int start_frm, const int clip_per_video, const bool use_local_file, int &amp;height, int &amp;width, std::vector&lt; unsigned char * &gt; &amp;buffer_rgb)</td></tr>
<tr class="separator:a9cecbe0a7961c777e62cede5d11b2a47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38f082d8c4f145d5f51c67aa508efbb6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38f082d8c4f145d5f51c67aa508efbb6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchPermutation, <a class="el" href="classcaffe2_1_1_batch_permutation_op.html">BatchPermutationOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a38f082d8c4f145d5f51c67aa508efbb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a9cfb9d3abf26a0c05194a325492a2a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a9cfb9d3abf26a0c05194a325492a2a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (BatchPermutationGradient, <a class="el" href="classcaffe2_1_1_batch_permutation_gradient_op.html">BatchPermutationGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a3a9cfb9d3abf26a0c05194a325492a2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c17b91a2241ea55b117106f987b66fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c17b91a2241ea55b117106f987b66fe"></a>
NumInputs(2).NumOutputs(1).SetDoc(R&quot;DOC( Permute the batch elements of the input tensor X according to the permutation specified in the input indices. <a class="el" href="classc10_1_1_warning.html">Warning</a> gradient comptuation is only correct if indices is a permutation DOC&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of at least 1D shape (N, D0, D1, ...).&quot;).Input(1</td></tr>
<tr class="separator:a9c17b91a2241ea55b117106f987b66fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8844154623370dfe13de610ddeaefd3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad8844154623370dfe13de610ddeaefd3"></a>
NumInputs(2).NumOutputs(1).SetDoc(R&quot;DOC( Permute the batch elements of the input tensor X according to the permutation specified in the input indices. <a class="el" href="classc10_1_1_warning.html">Warning</a> gradient comptuation is only correct if indices is a permutation DOC tensor of type int with&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (N,) specifying a valid permutation&quot; &quot;of the indices in[0</td></tr>
<tr class="separator:ad8844154623370dfe13de610ddeaefd3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7283537f107df33c628746c81afc5fc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7283537f107df33c628746c81afc5fc"></a>
NumInputs(2).NumOutputs(1).SetDoc(R&quot;DOC( Permute the batch elements of the input tensor X according to the permutation specified in the input indices. <a class="el" href="classc10_1_1_warning.html">Warning</a> gradient comptuation is only correct if indices is a permutation DOC tensor of type int with&#160;</td><td class="memItemRight" valign="bottom"><b>N</b> (inclusive).&quot;) .Output( 0</td></tr>
<tr class="separator:ac7283537f107df33c628746c81afc5fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae15915f53dc52c111731276f12346174"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae15915f53dc52c111731276f12346174"></a>
NumInputs(2).NumOutputs(1).SetDoc(R&quot;DOC( Permute the batch elements of the input tensor X according to the permutation specified in the input indices. <a class="el" href="classc10_1_1_warning.html">Warning</a> gradient comptuation is only correct if indices is a permutation DOC tensor of type int with <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> with the same shape as X where&#160;</td><td class="memItemRight" valign="bottom"><b>the</b> (D0, D1,...) dimensional&quot; &quot;batch elements of X are permuted according to the input indices.&quot;)</td></tr>
<tr class="separator:ae15915f53dc52c111731276f12346174"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3214f6f7a79fb0a93316fbf6301108ac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3214f6f7a79fb0a93316fbf6301108ac"></a>
See BatchPermutation&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;dY&quot;,&quot;Gradient of forward output 0 (Y).&quot;).Output(0</td></tr>
<tr class="separator:a3214f6f7a79fb0a93316fbf6301108ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa9eb2851d78b0867e7d887c8293f2e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa9eb2851d78b0867e7d887c8293f2e4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (BatchPermutation, <a class="el" href="classcaffe2_1_1_get_batch_permutation_gradient.html">GetBatchPermutationGradient</a>)</td></tr>
<tr class="separator:afa9eb2851d78b0867e7d887c8293f2e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90c97146bde25c2f926851ff74243a98"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90c97146bde25c2f926851ff74243a98"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GroupSpatialSoftmax, <a class="el" href="classcaffe2_1_1_group_spatial_softmax_op.html">GroupSpatialSoftmaxOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a90c97146bde25c2f926851ff74243a98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a815415bc1ff4a49974a3544ed65eb86c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a815415bc1ff4a49974a3544ed65eb86c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (GroupSpatialSoftmaxGradient, <a class="el" href="classcaffe2_1_1_group_spatial_softmax_gradient_op.html">GroupSpatialSoftmaxGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a815415bc1ff4a49974a3544ed65eb86c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1973896ad27b9662177a275c47de3370"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1973896ad27b9662177a275c47de3370"></a>
number of classes in each softmax group&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;scores&quot;,&quot;4D tensor of softmax inputs (called 'scores' or 'logits') with shape &quot;&quot;(N, C, H, W), where C = num_anchors * num_classes defines num_anchors &quot;&quot;groups of contiguous num_classes softmax inputs.&quot;).Output(0</td></tr>
<tr class="separator:a1973896ad27b9662177a275c47de3370"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace36496eb7f47d0796d35f6301da28f8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ace36496eb7f47d0796d35f6301da28f8"></a>
See GroupSpatialSoftmax&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;d_probabilities&quot;,&quot;Gradient of forward output 0 (probabilities).&quot;).Output(0</td></tr>
<tr class="separator:ace36496eb7f47d0796d35f6301da28f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0b90052b204ce8384b1ac45307e5bcd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa0b90052b204ce8384b1ac45307e5bcd"></a>
See GroupSpatialSoftmax Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>input</b> (scores).&quot;)</td></tr>
<tr class="separator:aa0b90052b204ce8384b1ac45307e5bcd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a224ffd10bbfd86472315b4ad1d01a130"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a224ffd10bbfd86472315b4ad1d01a130"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (GroupSpatialSoftmax, <a class="el" href="classcaffe2_1_1_get_group_spatial_softmax_gradient.html">GetGroupSpatialSoftmaxGradient</a>)</td></tr>
<tr class="separator:a224ffd10bbfd86472315b4ad1d01a130"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a788ed0673e098a2b8af50ac7e3493363"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a788ed0673e098a2b8af50ac7e3493363"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PSRoIPool, <a class="el" href="classcaffe2_1_1_p_s_ro_i_pool_op.html">PSRoIPoolOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a788ed0673e098a2b8af50ac7e3493363"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2daa6b7d123ec6bd8ce2cd31436a5584"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2daa6b7d123ec6bd8ce2cd31436a5584"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (PSRoIPoolGradient, <a class="el" href="classcaffe2_1_1_p_s_ro_i_pool_gradient_op.html">PSRoIPoolGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a2daa6b7d123ec6bd8ce2cd31436a5584"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85c9465f9ddd2a5ca2b45eaae97b15eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a85c9465f9ddd2a5ca2b45eaae97b15eb"></a>
Spatial scale of the input feature map X relative to the input image <a class="el" href="struct_e.html">E</a> if X has a stride of w r t the input image&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;group_size&quot;,&quot;(int) default 1; pooled_h = pooled_w = group_size where pooled_{h,w} &quot;&quot;is the pooled output Y's height and width, respectively.&quot;).Arg(&quot;output_dim&quot;</td></tr>
<tr class="separator:a85c9465f9ddd2a5ca2b45eaae97b15eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72114556592a2a580890dfb40ccb7275"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a72114556592a2a580890dfb40ccb7275"></a>
number of channels in the pooled which might be the number of classes is used for classification or if used for class agnostic bounding box regression&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;4D position sensitive feature map input of shape (N, C, H, W), where &quot;&quot;C = group_size**2 * output_dim.&quot;).Input(1</td></tr>
<tr class="separator:a72114556592a2a580890dfb40ccb7275"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68fba055e322a02f230ec321c9b25ecc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a68fba055e322a02f230ec321c9b25ecc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RoIPoolF, <a class="el" href="classcaffe2_1_1_ro_i_pool_f_op.html">RoIPoolFOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a68fba055e322a02f230ec321c9b25ecc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac41073fb5661c63562cf557d908e0608"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac41073fb5661c63562cf557d908e0608"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (RoIPoolFGradient, <a class="el" href="classcaffe2_1_1_ro_i_pool_f_gradient_op.html">RoIPoolFGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac41073fb5661c63562cf557d908e0608"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ffca9272e89396435d88d2aff1a5f11"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8ffca9272e89396435d88d2aff1a5f11"></a>
Pooled output Y s width&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (0,&quot;X&quot;,&quot;4D feature map input of shape (N, C, H, W).&quot;).Input(1</td></tr>
<tr class="separator:a8ffca9272e89396435d88d2aff1a5f11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf3f33f630d6cdd61839f03971f0e93d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaf3f33f630d6cdd61839f03971f0e93d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SampleAs, <a class="el" href="classcaffe2_1_1_sample_as_op.html">SampleAsOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aaf3f33f630d6cdd61839f03971f0e93d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7a0e8b0c7c1029585126c5b630a9269"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7a0e8b0c7c1029585126c5b630a9269"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SampleAsGradient, <a class="el" href="classcaffe2_1_1_sample_as_gradient_op.html">SampleAsGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac7a0e8b0c7c1029585126c5b630a9269"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82a7ab07bfd416c848e69dbe62c76b98"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a82a7ab07bfd416c848e69dbe62c76b98"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of at least&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (N,...).&quot;) .Input( 1</td></tr>
<tr class="separator:a82a7ab07bfd416c848e69dbe62c76b98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3843b22da2f0eab2d648ded3eeedfa4c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3843b22da2f0eab2d648ded3eeedfa4c"></a>
See SampleAs&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;labels&quot;,&quot;See SampleAs.&quot;).Input(2</td></tr>
<tr class="separator:a3843b22da2f0eab2d648ded3eeedfa4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c45f32d1588a2fc3ad183a61d050af1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c45f32d1588a2fc3ad183a61d050af1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SampleAs, <a class="el" href="classcaffe2_1_1_get_sample_as_gradient.html">GetSampleAsGradient</a>)</td></tr>
<tr class="separator:a1c45f32d1588a2fc3ad183a61d050af1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a711ebcb62a132724de7ad4ace8f82c24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a711ebcb62a132724de7ad4ace8f82c24"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SelectSmoothL1Loss, <a class="el" href="classcaffe2_1_1_select_smooth_l1_loss_op.html">SelectSmoothL1LossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a711ebcb62a132724de7ad4ace8f82c24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb34c0080fee79e0c74b2ac7e1f7f3ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeb34c0080fee79e0c74b2ac7e1f7f3ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SelectSmoothL1LossGradient, <a class="el" href="classcaffe2_1_1_select_smooth_l1_loss_gradient_op.html">SelectSmoothL1LossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aeb34c0080fee79e0c74b2ac7e1f7f3ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec16d812ba602247ac91bf9bb5d0d196"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec16d812ba602247ac91bf9bb5d0d196"></a>
L2 to L1 transition point&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;scale&quot;,&quot;(float) default 1.0; multiply the loss by this scale factor.&quot;).Input(0</td></tr>
<tr class="separator:aec16d812ba602247ac91bf9bb5d0d196"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeac40c0116bfdc0b0c53d94f2e4909fc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeac40c0116bfdc0b0c53d94f2e4909fc"></a>
L2 to L1 transition point tensor of bounding box regression predictions with&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (N, 4 *num_bbox_classes *num_anchors, H, W).&quot;) .Input( 1</td></tr>
<tr class="separator:aeac40c0116bfdc0b0c53d94f2e4909fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5948b578ab7b8b92e21d813eaabed7b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af5948b578ab7b8b92e21d813eaabed7b"></a>
L2 to L1 transition point tensor of bounding box regression predictions with tensor of labels&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (<a class="el" href="struct_m.html">M</a>, 4) for 4 contiguous channels starting&quot; &quot;at each of the <a class="el" href="struct_m.html">M</a> locations selected by the locations input.&quot;) .Input( 2</td></tr>
<tr class="separator:af5948b578ab7b8b92e21d813eaabed7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e248f8de75b327ca1516eadc44bb561"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7e248f8de75b327ca1516eadc44bb561"></a>
L2 to L1 transition point tensor of bounding box regression predictions with tensor of labels tensor of shape(<a class="el" href="struct_m.html">M</a>, 4) that identifies <a class="el" href="struct_m.html">M</a> 'select'locations&quot; &quot;encoded by the four colums the loss is divided by&#160;</td><td class="memItemRight" valign="bottom"><b>max</b> (1, normalizer).&quot;) .Output( 0</td></tr>
<tr class="separator:a7e248f8de75b327ca1516eadc44bb561"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd30ff796d30d266fbba7e252712f350"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abd30ff796d30d266fbba7e252712f350"></a>
See SelectSmoothL1Loss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;Y&quot;,&quot;See SelectSmoothL1Loss.&quot;).Input(2</td></tr>
<tr class="separator:abd30ff796d30d266fbba7e252712f350"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a949959c95c643b3431a497834689e471"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a949959c95c643b3431a497834689e471"></a>
See SelectSmoothL1Loss See SelectSmoothL1Loss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;normalizer&quot;,&quot;See SelectSmoothL1Loss.&quot;).Input(4</td></tr>
<tr class="separator:a949959c95c643b3431a497834689e471"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a877ef62eb82a29223ff013a9264bebba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a877ef62eb82a29223ff013a9264bebba"></a>
See SelectSmoothL1Loss See SelectSmoothL1Loss Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>output</b> (loss).&quot;) .Output( 0</td></tr>
<tr class="separator:a877ef62eb82a29223ff013a9264bebba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8415f2e392acc597d4ed63553dc37a31"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8415f2e392acc597d4ed63553dc37a31"></a>
See SelectSmoothL1Loss See SelectSmoothL1Loss Gradient of forward Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>input</b> (Y_hat).&quot;)</td></tr>
<tr class="separator:a8415f2e392acc597d4ed63553dc37a31"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade0ceca2cf0296fcf89ec7c4cf872390"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade0ceca2cf0296fcf89ec7c4cf872390"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SelectSmoothL1Loss, <a class="el" href="classcaffe2_1_1_get_select_smooth_l1_loss_gradient.html">GetSelectSmoothL1LossGradient</a>)</td></tr>
<tr class="separator:ade0ceca2cf0296fcf89ec7c4cf872390"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86e9367429f62e5cd61f5d7ee9975211"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86e9367429f62e5cd61f5d7ee9975211"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SigmoidCrossEntropyLoss, <a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_loss_op.html">SigmoidCrossEntropyLossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a86e9367429f62e5cd61f5d7ee9975211"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac17e12cfbd16282bd46aae67a9f0cb86"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac17e12cfbd16282bd46aae67a9f0cb86"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SigmoidCrossEntropyLossGradient, <a class="el" href="classcaffe2_1_1_sigmoid_cross_entropy_loss_gradient_op.html">SigmoidCrossEntropyLossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ac17e12cfbd16282bd46aae67a9f0cb86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb678dbb5eeafb7649de7851ca1aaa38"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acb678dbb5eeafb7649de7851ca1aaa38"></a>
multiply the loss by this scale factor&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;normalize&quot;,&quot;(int) default 1; if true, divide the loss by the number of targets &gt; &quot;&quot;-1.&quot;).Input(0</td></tr>
<tr class="separator:acb678dbb5eeafb7649de7851ca1aaa38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a768a6a8cc259b72f6a8eb79150c22920"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a768a6a8cc259b72f6a8eb79150c22920"></a>
multiply the loss by this scale factor <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of predicted&#160;</td><td class="memItemRight" valign="bottom"><b>logits</b> (shape must be at least 1D).&quot;) .Input( 1</td></tr>
<tr class="separator:a768a6a8cc259b72f6a8eb79150c22920"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9053a992d9f256cb63a3daa367f39160"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9053a992d9f256cb63a3daa367f39160"></a>
multiply the loss by this scale factor <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of predicted <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of targets of type int and same shape as logits X&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;loss&quot;,&quot;<a class="el" href="classc10_1_1_scalar.html">Scalar</a> loss.&quot;)</td></tr>
<tr class="separator:a9053a992d9f256cb63a3daa367f39160"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ccfca8a826fad70e49764edce235da1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ccfca8a826fad70e49764edce235da1"></a>
See SigmoidCrossEntropyLoss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;targets&quot;,&quot;See SigmoidCrossEntropyLoss.&quot;).Input(2</td></tr>
<tr class="separator:a5ccfca8a826fad70e49764edce235da1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea66cee584c22eb4732a5b9701118674"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aea66cee584c22eb4732a5b9701118674"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SigmoidCrossEntropyLoss, <a class="el" href="classcaffe2_1_1_get_sigmoid_cross_entropy_loss_gradient.html">GetSigmoidCrossEntropyLossGradient</a>)</td></tr>
<tr class="separator:aea66cee584c22eb4732a5b9701118674"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae35cc48380697571474ff70dcef71550"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae35cc48380697571474ff70dcef71550"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SigmoidFocalLoss, <a class="el" href="classcaffe2_1_1_sigmoid_focal_loss_op.html">SigmoidFocalLossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae35cc48380697571474ff70dcef71550"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa96bcc23e944812089c7335781eb7f0f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa96bcc23e944812089c7335781eb7f0f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SigmoidFocalLossGradient, <a class="el" href="classcaffe2_1_1_sigmoid_focal_loss_gradient_op.html">SigmoidFocalLossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:aa96bcc23e944812089c7335781eb7f0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37cf47dfea18c3b1ba665d8159a5bd3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a37cf47dfea18c3b1ba665d8159a5bd3e"></a>
where N is the number of elements in the H and W are the height and and each of length num_classes For the binary form of Focal num_classes does not include the background category(So, for COCO, num_classes=80, not 81.) The binary form of focal loss is multiply the loss by this scale factor&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;alpha&quot;,&quot;(float) default 0.25; Focal Loss's alpha hyper-parameter.&quot;).Arg(&quot;gamma&quot;</td></tr>
<tr class="separator:a37cf47dfea18c3b1ba665d8159a5bd3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa72f655a6e52ae3c448efbb00c8318ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa72f655a6e52ae3c448efbb00c8318ad"></a>
Focal Loss s gamma hyper parameter&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;num_classes&quot;,&quot;(int) default 80; number of classes (excluding background).&quot;).Input(0</td></tr>
<tr class="separator:aa72f655a6e52ae3c448efbb00c8318ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0f5258173f1875bbf78401f3545513a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac0f5258173f1875bbf78401f3545513a"></a>
Focal Loss s gamma hyper parameter tensor of sigmoid&#160;</td><td class="memItemRight" valign="bottom"><b>inputs</b> (called 'scores'or 'logits') with shape&quot; &quot;(N</td></tr>
<tr class="separator:ac0f5258173f1875bbf78401f3545513a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8405c53fe63a80b778c99883ae8a2a37"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8405c53fe63a80b778c99883ae8a2a37"></a>
See SigmoidFocalLoss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;labels&quot;,&quot;See SigmoidFocalLoss.&quot;).Input(2</td></tr>
<tr class="separator:a8405c53fe63a80b778c99883ae8a2a37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f54cd71752cad0abea5ed0528232075"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8f54cd71752cad0abea5ed0528232075"></a>
See SigmoidFocalLoss See SigmoidFocalLoss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;d_loss&quot;,&quot;Gradient of forward output 0 (loss)&quot;).Output(0</td></tr>
<tr class="separator:a8f54cd71752cad0abea5ed0528232075"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d45aee18386cbb2cc33a5f9a595d48f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d45aee18386cbb2cc33a5f9a595d48f"></a>
See SigmoidFocalLoss See SigmoidFocalLoss Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>input</b> (logits)&quot;)</td></tr>
<tr class="separator:a1d45aee18386cbb2cc33a5f9a595d48f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add77fe9d2b75981ce67de50f4ef17612"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="add77fe9d2b75981ce67de50f4ef17612"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SigmoidFocalLoss, <a class="el" href="classcaffe2_1_1_get_sigmoid_focal_loss_gradient.html">GetSigmoidFocalLossGradient</a>)</td></tr>
<tr class="separator:add77fe9d2b75981ce67de50f4ef17612"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a202fee4948fc05b25a551c4c5ca1684e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a202fee4948fc05b25a551c4c5ca1684e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SmoothL1Loss, <a class="el" href="classcaffe2_1_1_smooth_l1_loss_op.html">SmoothL1LossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a202fee4948fc05b25a551c4c5ca1684e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada5dae30627e5ff1b253660c91f1c23b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada5dae30627e5ff1b253660c91f1c23b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SmoothL1LossGradient, <a class="el" href="classcaffe2_1_1_smooth_l1_loss_gradient_op.html">SmoothL1LossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ada5dae30627e5ff1b253660c91f1c23b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b07f215c1c93b38220ecd2cf5a3dc08"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1b07f215c1c93b38220ecd2cf5a3dc08"></a>
NumInputs(4).NumOutputs(1).SetDoc(R&quot;DOC( Smooth L1 Loss is a minor variation of Huber loss in which the point of transition between L2 loss and L1 loss is adjustable by a hyper-parameter beta L2 to L1 transition point <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of&#160;</td><td class="memItemRight" valign="bottom"><b>predictions</b> (at least 1D).&quot;) .Input( 1</td></tr>
<tr class="separator:a1b07f215c1c93b38220ecd2cf5a3dc08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bdd7dd674979b3b15852928bf4455a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4bdd7dd674979b3b15852928bf4455a4"></a>
NumInputs(4).NumOutputs(1).SetDoc(R&quot;DOC( Smooth L1 Loss is a minor variation of Huber loss in which the point of transition between L2 loss and L1 loss is adjustable by a hyper-parameter beta L2 to L1 transition point <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of labels with the same shape as Y_hat&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (2,&quot;alpha_in&quot;,&quot;<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of inside weights with the same shape as Y.&quot;).Input(3</td></tr>
<tr class="separator:a4bdd7dd674979b3b15852928bf4455a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b0c7fe16d0f4660f0b89b0c9a3a1c82"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6b0c7fe16d0f4660f0b89b0c9a3a1c82"></a>
See SmoothL1Loss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;Y&quot;,&quot;See SmoothL1Loss.&quot;).Input(2</td></tr>
<tr class="separator:a6b0c7fe16d0f4660f0b89b0c9a3a1c82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab76b8d308b1909504e25ae001acda79f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab76b8d308b1909504e25ae001acda79f"></a>
See SmoothL1Loss See SmoothL1Loss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;alpha_out&quot;,&quot;See SmoothL1Loss.&quot;).Input(4</td></tr>
<tr class="separator:ab76b8d308b1909504e25ae001acda79f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96c8e265edc8afdfd87ada051b95f3d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96c8e265edc8afdfd87ada051b95f3d4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SmoothL1Loss, <a class="el" href="classcaffe2_1_1_get_smooth_l1_loss_gradient.html">GetSmoothL1LossGradient</a>)</td></tr>
<tr class="separator:a96c8e265edc8afdfd87ada051b95f3d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8209dbeb5bd8494ad5fc7bc77d1d6fa4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8209dbeb5bd8494ad5fc7bc77d1d6fa4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SoftmaxFocalLoss, <a class="el" href="classcaffe2_1_1_softmax_focal_loss_op.html">SoftmaxFocalLossOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a8209dbeb5bd8494ad5fc7bc77d1d6fa4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ae7b9026c4e5f057324915f289f74ec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4ae7b9026c4e5f057324915f289f74ec"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SoftmaxFocalLossGradient, <a class="el" href="classcaffe2_1_1_softmax_focal_loss_gradient_op.html">SoftmaxFocalLossGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a4ae7b9026c4e5f057324915f289f74ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06416b98e998410ae88b3e58e15da987"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a06416b98e998410ae88b3e58e15da987"></a>
where N is the number of elements in the H and W are the height and and where t is the&#160;</td><td class="memItemRight" valign="bottom"><b>target</b> (ground truth) class</td></tr>
<tr class="separator:a06416b98e998410ae88b3e58e15da987"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5f42bd20cf2f0601d922d6b6c27df93"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab5f42bd20cf2f0601d922d6b6c27df93"></a>
Focal Loss s gamma hyper parameter&#160;</td><td class="memItemRight" valign="bottom"><b>Arg</b> (&quot;num_classes&quot;,&quot;(int) default 81; number of classes in each softmax group.&quot;).Input(0</td></tr>
<tr class="separator:ab5f42bd20cf2f0601d922d6b6c27df93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56d32188bccdca5375000ac51a5ea590"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a56d32188bccdca5375000ac51a5ea590"></a>
the loss is normalized by <a class="el" href="classc10_1_1_scalar.html">Scalar</a> loss&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (1,&quot;probabilities&quot;,&quot;4D tensor of softmax probabilities with shape (N, C, H, W), where &quot;&quot;C = num_anchors * num_classes, and softmax was applied to each of the &quot;&quot;num_anchors groups; within a group the num_classes values sum to 1.&quot;)</td></tr>
<tr class="separator:a56d32188bccdca5375000ac51a5ea590"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c1068532430dac02f7bf4ee392e2a97"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c1068532430dac02f7bf4ee392e2a97"></a>
See SoftmaxFocalLoss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;labels&quot;,&quot;See SoftmaxFocalLoss.&quot;).Input(2</td></tr>
<tr class="separator:a9c1068532430dac02f7bf4ee392e2a97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af48bbee1f4ef86a1a191137b2edb886f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af48bbee1f4ef86a1a191137b2edb886f"></a>
See SoftmaxFocalLoss See SoftmaxFocalLoss&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;probabilities&quot;,&quot;Output 1 from SoftmaxFocalLoss; See SoftmaxFocalLoss.&quot;).Input(4</td></tr>
<tr class="separator:af48bbee1f4ef86a1a191137b2edb886f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa556516d4f1ec44adf674465da942e39"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa556516d4f1ec44adf674465da942e39"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SoftmaxFocalLoss, <a class="el" href="classcaffe2_1_1_get_softmax_focal_loss_gradient.html">GetSoftmaxFocalLossGradient</a>)</td></tr>
<tr class="separator:aa556516d4f1ec44adf674465da942e39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02525550680bda57f43686ffac7bb5fe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02525550680bda57f43686ffac7bb5fe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (SpatialNarrowAs, <a class="el" href="classcaffe2_1_1_spatial_narrow_as_op.html">SpatialNarrowAsOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a02525550680bda57f43686ffac7bb5fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f25cffca303af8aa788207effb65f65"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f25cffca303af8aa788207effb65f65"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (<a class="el" href="classcaffe2_1_1_spatial_narrow_as_gradient.html">SpatialNarrowAsGradient</a>, <a class="el" href="classcaffe2_1_1_spatial_narrow_as_gradient_op.html">SpatialNarrowAsGradientOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:a1f25cffca303af8aa788207effb65f65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a875b024a56c9029c750115ab7e63cc47"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a875b024a56c9029c750115ab7e63cc47"></a>
or input of&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (N, H0, W0) or(N</td></tr>
<tr class="separator:a875b024a56c9029c750115ab7e63cc47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0561e19bf037dba5b0dd602b6147e614"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0561e19bf037dba5b0dd602b6147e614"></a>
or input of W0&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;B&quot;,&quot;3D or 4D input of shape (N, H1, W1) or (N, C, H1, W1), where H1 &lt;= H0 &quot;&quot;and W1 &lt;= W0.&quot;).Output(0</td></tr>
<tr class="separator:a0561e19bf037dba5b0dd602b6147e614"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a374f5ff364caef872440ce7b72f45895"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a374f5ff364caef872440ce7b72f45895"></a>
or input of W0 Sub window of <a class="el" href="struct_a.html">A</a> containing&#160;</td><td class="memItemRight" valign="bottom"><b>rows</b> (inclusive) and columns&quot; &quot;[0</td></tr>
<tr class="separator:a374f5ff364caef872440ce7b72f45895"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d4379bb119b45ac564166718748e059"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d4379bb119b45ac564166718748e059"></a>
or input of W0 Sub window of <a class="el" href="struct_a.html">A</a> containing&#160;</td><td class="memItemRight" valign="bottom"><b>W1</b> (inclusive).&quot;)</td></tr>
<tr class="separator:a9d4379bb119b45ac564166718748e059"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87e9af7937fab61148cc79256e74e195"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a87e9af7937fab61148cc79256e74e195"></a>
See SpatialNarrowAs&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (1,&quot;B&quot;,&quot;See SpatialNarrowAs.&quot;).Input(2</td></tr>
<tr class="separator:a87e9af7937fab61148cc79256e74e195"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc1325d2eecf85bdec3ea2a138e8aa3d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc1325d2eecf85bdec3ea2a138e8aa3d"></a>
See SpatialNarrowAs Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>output</b> (<a class="el" href="struct_c.html">C</a>).&quot;) .Output( 0</td></tr>
<tr class="separator:abc1325d2eecf85bdec3ea2a138e8aa3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0fded5fcd6f114d80a798004c520d69"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af0fded5fcd6f114d80a798004c520d69"></a>
See SpatialNarrowAs Gradient of forward Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>input</b> (<a class="el" href="struct_a.html">A</a>)&quot;)</td></tr>
<tr class="separator:af0fded5fcd6f114d80a798004c520d69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0f07e0e85ac4e367c22655a9692876d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad0f07e0e85ac4e367c22655a9692876d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (SpatialNarrowAs, <a class="el" href="classcaffe2_1_1_spatial_narrow_as_gradient.html">SpatialNarrowAsGradient</a>)</td></tr>
<tr class="separator:ad0f07e0e85ac4e367c22655a9692876d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7b1d0492fc29ef12ab7653b21032c7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab7b1d0492fc29ef12ab7653b21032c7f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UpsampleNearest, <a class="el" href="classcaffe2_1_1_upsample_nearest_op.html">UpsampleNearestOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ab7b1d0492fc29ef12ab7653b21032c7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6ddd08c04881f2ab0e6390d2b3d1915"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6ddd08c04881f2ab0e6390d2b3d1915"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (UpsampleNearestGradient, <a class="el" href="classcaffe2_1_1_upsample_nearest_gradient_op.html">UpsampleNearestGradientOp</a>&lt; float, <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt;)</td></tr>
<tr class="separator:ae6ddd08c04881f2ab0e6390d2b3d1915"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd87a334413c7660b34b49aa3c9dd70f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abd87a334413c7660b34b49aa3c9dd70f"></a>
integer upsampling factor feature map of&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b> (N, <a class="el" href="struct_c.html">C</a>, scale *H, scale *W)</td></tr>
<tr class="separator:abd87a334413c7660b34b49aa3c9dd70f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9cd96258d2158fdf204c238356cc0efe"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9cd96258d2158fdf204c238356cc0efe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_GRADIENT</b> (UpsampleNearest, <a class="el" href="classcaffe2_1_1_get_upsample_nearest_gradient.html">GetUpsampleNearestGradient</a>)</td></tr>
<tr class="separator:a9cd96258d2158fdf204c238356cc0efe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8063a225139b51b5c3201af38cd13227"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8063a225139b51b5c3201af38cd13227"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CPU_OPERATOR</b> (Caffe2ModuleTestDynamicDummy, <a class="el" href="classcaffe2_1_1_caffe2_module_test_dynamic_dummy_op.html">Caffe2ModuleTestDynamicDummyOp</a>)</td></tr>
<tr class="separator:a8063a225139b51b5c3201af38cd13227"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0282f7845ed6da9bc1aa5c7020ec891d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0282f7845ed6da9bc1aa5c7020ec891d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OPERATOR_SCHEMA</b> (Caffe2ModuleTestDynamicDummy)</td></tr>
<tr class="separator:a0282f7845ed6da9bc1aa5c7020ec891d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8393f86fde8654be20e31a8cf1518bc7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8393f86fde8654be20e31a8cf1518bc7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>REGISTER_CAFFE2_EARLY_INIT_FUNCTION</b> (registerGlobalPerfNetObserverCreator,&amp;registerGlobalPerfNetObserverCreator,&quot;Caffe2 net global observer creator&quot;)</td></tr>
<tr class="separator:a8393f86fde8654be20e31a8cf1518bc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05774c4bb6d041d0e1239c8ed4ead519"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a05774c4bb6d041d0e1239c8ed4ead519"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE2_MODULE</b> (caffe2_rocksdb,&quot;RocksDB implementation for caffe2::DB.&quot;)</td></tr>
<tr class="separator:a05774c4bb6d041d0e1239c8ed4ead519"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a4f6e311adf01f96656be7a6e92c61b39"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4f6e311adf01f96656be7a6e92c61b39"></a>
DoRunWithOtherType2 typedef <a class="el" href="classc10_1_1_registry.html">c10::Registry</a>&lt; std::string, std::unique_ptr&lt; <a class="el" href="classcaffe2_1_1_operator_base.html">OperatorBase</a> &gt;, const OperatorDef &amp;, <a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> * &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>OperatorRegistry</b></td></tr>
<tr class="separator:a4f6e311adf01f96656be7a6e92c61b39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0319f6f160afcb5114d1df3a04634c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad0319f6f160afcb5114d1df3a04634c3"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kCIFARSize</b> = 32</td></tr>
<tr class="separator:ad0319f6f160afcb5114d1df3a04634c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c5f94b53611e57244dafb85926cc9c2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5c5f94b53611e57244dafb85926cc9c2"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kCIFARImageNBytes</b> = kCIFARSize * kCIFARSize * 3</td></tr>
<tr class="separator:a5c5f94b53611e57244dafb85926cc9c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aede5fd30af8dddc4d3f43207260b26ec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aede5fd30af8dddc4d3f43207260b26ec"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kCIFAR10BatchSize</b> = 10000</td></tr>
<tr class="separator:aede5fd30af8dddc4d3f43207260b26ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af05867c998628fbf970478572f32a462"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af05867c998628fbf970478572f32a462"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kCIFAR10TestDataSize</b> = 10000</td></tr>
<tr class="separator:af05867c998628fbf970478572f32a462"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6eb02b581f40e6c2107cff354f93b46d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6eb02b581f40e6c2107cff354f93b46d"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kCIFAR10TrainBatches</b> = 5</td></tr>
<tr class="separator:a6eb02b581f40e6c2107cff354f93b46d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acee608401867021e057c71576582c2eb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acee608401867021e057c71576582c2eb"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kCIFAR100TrainDataSize</b> = 50000</td></tr>
<tr class="separator:acee608401867021e057c71576582c2eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86b349deb32a7b5137e31d6297c6f28c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86b349deb32a7b5137e31d6297c6f28c"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kCIFAR100TestDataSize</b> = 10000</td></tr>
<tr class="separator:a86b349deb32a7b5137e31d6297c6f28c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17803cefcc839e9256e5bf815f5d71b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a17803cefcc839e9256e5bf815f5d71b4"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>kTensorBlobType</b> = &quot;Tensor&quot;</td></tr>
<tr class="separator:a17803cefcc839e9256e5bf815f5d71b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3cd3212f419650a9034f155fdea6298"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac3cd3212f419650a9034f155fdea6298"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>kChunkIdSeparator</b> = &quot;#%&quot;</td></tr>
<tr class="separator:ac3cd3212f419650a9034f155fdea6298"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad56c01cfb9873b89810de07f3d09023c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad56c01cfb9873b89810de07f3d09023c"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>kDefaultChunkSize</b> = -1</td></tr>
<tr class="separator:ad56c01cfb9873b89810de07f3d09023c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1900bca08da42b6be306f413ccd2182"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad1900bca08da42b6be306f413ccd2182"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>kNoChunking</b> = 0</td></tr>
<tr class="separator:ad1900bca08da42b6be306f413ccd2182"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3dd5d4fba7c9642de6fc45c88f84b16"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab3dd5d4fba7c9642de6fc45c88f84b16"></a>
std::atomic&lt; bool &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>g_caffe2_has_cuda_linked</b> {false}</td></tr>
<tr class="separator:ab3dd5d4fba7c9642de6fc45c88f84b16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a801490c488f8299da22b0feb61cb4bee"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a801490c488f8299da22b0feb61cb4bee"></a>
std::atomic&lt; bool &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>g_caffe2_has_hip_linked</b> {false}</td></tr>
<tr class="separator:a801490c488f8299da22b0feb61cb4bee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a016b982f98fda42e3e49f9553ad75231"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a016b982f98fda42e3e49f9553ad75231"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_CUDA_NUM_THREADS</b> = 128</td></tr>
<tr class="separator:a016b982f98fda42e3e49f9553ad75231"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a400d93bbfdf69e3f815c2bb419f6c15d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a400d93bbfdf69e3f815c2bb419f6c15d"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_CUDA_NUM_THREADS_2D_DIMX</b> = 16</td></tr>
<tr class="separator:a400d93bbfdf69e3f815c2bb419f6c15d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7b058bf3b6c4b034f721915589df0bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad7b058bf3b6c4b034f721915589df0bd"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_CUDA_NUM_THREADS_2D_DIMY</b> = 16</td></tr>
<tr class="separator:ad7b058bf3b6c4b034f721915589df0bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27fa97d7f04b319de6c9fe8ef11b8b6b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a27fa97d7f04b319de6c9fe8ef11b8b6b"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_MAXIMUM_NUM_BLOCKS</b> = 4096</td></tr>
<tr class="separator:a27fa97d7f04b319de6c9fe8ef11b8b6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a505c2b33c51513881181ff25f7063878"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a505c2b33c51513881181ff25f7063878"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_MAXIMUM_NUM_BLOCKS_2D_DIMX</b> = 128</td></tr>
<tr class="separator:a505c2b33c51513881181ff25f7063878"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8e41cd16e139418b73b704d43cedc24"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae8e41cd16e139418b73b704d43cedc24"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>CAFFE_MAXIMUM_NUM_BLOCKS_2D_DIMY</b> = 128</td></tr>
<tr class="separator:ae8e41cd16e139418b73b704d43cedc24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac32ede39066211986d015364aa0ea8a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac32ede39066211986d015364aa0ea8a0"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>kCUDAGridDimMaxX</b> = 2147483647</td></tr>
<tr class="separator:ac32ede39066211986d015364aa0ea8a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84b0c7e1513ca3b98432f7d2a51fc87a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a84b0c7e1513ca3b98432f7d2a51fc87a"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>kCUDAGridDimMaxY</b> = 65535</td></tr>
<tr class="separator:a84b0c7e1513ca3b98432f7d2a51fc87a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab706d7984b4edb13128fb3331972a38f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab706d7984b4edb13128fb3331972a38f"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>kCUDAGridDimMaxZ</b> = 65535</td></tr>
<tr class="separator:ab706d7984b4edb13128fb3331972a38f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf79cc66cc27cafd7c0859287d62daa2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adf79cc66cc27cafd7c0859287d62daa2"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>kCUDATensorMaxDims</b> = 8</td></tr>
<tr class="separator:adf79cc66cc27cafd7c0859287d62daa2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abdeeef5246d6c9fc520df422e59c93b5"><td class="memItemLeft" align="right" valign="top">constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>MaxDeviceTypes</b></td></tr>
<tr class="separator:abdeeef5246d6c9fc520df422e59c93b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a124d67f7deb27266569d7ffb3447414e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a124d67f7deb27266569d7ffb3447414e"></a>
class CAFFE2_API&#160;</td><td class="memItemRight" valign="bottom"><b>OperatorBase</b></td></tr>
<tr class="separator:a124d67f7deb27266569d7ffb3447414e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f308b1e218da746bab941419af4f6bd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f308b1e218da746bab941419af4f6bd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>DoRunWithType2</b></td></tr>
<tr class="separator:a1f308b1e218da746bab941419af4f6bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2169ccbd47ef3a2c06f65f7405e8e0e6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2169ccbd47ef3a2c06f65f7405e8e0e6"></a>
std::function&lt; void(const OperatorDef &amp;)&gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetOperatorLogger</b> ()</td></tr>
<tr class="separator:a2169ccbd47ef3a2c06f65f7405e8e0e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2f0010e56a40c6f4c187301bcf8e226"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae2f0010e56a40c6f4c187301bcf8e226"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>kCannotComputeNumOutputs</b> = -1</td></tr>
<tr class="separator:ae2f0010e56a40c6f4c187301bcf8e226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabea76bd2be0a4ea36a880f7c77d5cba"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabea76bd2be0a4ea36a880f7c77d5cba"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>kQTensorBlobQType</b> = &quot;QTensor&quot;</td></tr>
<tr class="separator:aabea76bd2be0a4ea36a880f7c77d5cba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec9be0984306127d39c1a342c501ba83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec9be0984306127d39c1a342c501ba83"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>k_limit_default_</b> = 1000</td></tr>
<tr class="separator:aec9be0984306127d39c1a342c501ba83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac3127d3b8cfbde2f82b33d431e57c95"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aac3127d3b8cfbde2f82b33d431e57c95"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>kBlobName</b> = &quot;blob_name&quot;</td></tr>
<tr class="separator:aac3127d3b8cfbde2f82b33d431e57c95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1c220ef38476c32d4208f2f45381313"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae1c220ef38476c32d4208f2f45381313"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>kAddValue</b> = &quot;add_value&quot;</td></tr>
<tr class="separator:ae1c220ef38476c32d4208f2f45381313"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01abe48ef568bf9479aab89ad5f253c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01abe48ef568bf9479aab89ad5f253c3"></a>
alternative key for the&#160;</td><td class="memItemRight" valign="bottom"><b>handler</b></td></tr>
<tr class="separator:a01abe48ef568bf9479aab89ad5f253c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80364a916c39ee481a9c29d7f5ae53d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a80364a916c39ee481a9c29d7f5ae53d9"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>CONV_ALGORITHM_AUTO</b> = 0</td></tr>
<tr class="separator:a80364a916c39ee481a9c29d7f5ae53d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a5c1b2276b10fc1ce05b5b3c9d45272"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a5c1b2276b10fc1ce05b5b3c9d45272"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>CONV_ALGORITHM_WINOGRAD</b> = 1</td></tr>
<tr class="separator:a4a5c1b2276b10fc1ce05b5b3c9d45272"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a643ab84639eae709e248a8f7c7e55849"><td class="memItemLeft" align="right" valign="top">const char *&#160;</td><td class="memItemRight" valign="bottom"><b>kConvFusionDoc</b></td></tr>
<tr class="separator:a643ab84639eae709e248a8f7c7e55849"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94447f9d5a18549f5d83895f93a9b449"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a94447f9d5a18549f5d83895f93a9b449"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>cpu_blob</b></td></tr>
<tr class="separator:a94447f9d5a18549f5d83895f93a9b449"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a7aea3987eaeed3e8efb879d271c818"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a7aea3987eaeed3e8efb879d271c818"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>ideep_blob</b></td></tr>
<tr class="separator:a5a7aea3987eaeed3e8efb879d271c818"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a534d618b697f29dbf3d1c2509f5c1309"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a534d618b697f29dbf3d1c2509f5c1309"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the Whether or not to do color jitter Defaults to Image brightness scale used in color jittering Defaults to Whether or not to do color lighting Defaults to&#160;</td><td class="memItemRight" valign="bottom"><b>Type</b></td></tr>
<tr class="separator:a534d618b697f29dbf3d1c2509f5c1309"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a569493bf1694a2e38495aac43789e98e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a569493bf1694a2e38495aac43789e98e"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the Whether or not to do color jitter Defaults to Image brightness scale used in color jittering Defaults to Whether or not to do color lighting Defaults to Scale the size of the smallest dimension of the image to this Scale and minsize are mutually exclusive Must be larger than crop&#160;</td><td class="memItemRight" valign="bottom"><b>If</b></td></tr>
<tr class="separator:a569493bf1694a2e38495aac43789e98e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6739031634080ced488a2712ad530b09"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6739031634080ced488a2712ad530b09"></a>
INT_MAX batch_size images will be processed GPUs can optionally be used for part of the processing The following transformations are applied to the image <a class="el" href="struct_a.html">A</a> bounding box is applied to the initial Number of images to output for each run of the Whether or not to do color jitter Defaults to Image brightness scale used in color jittering Defaults to Whether or not to do color lighting Defaults to Scale the size of the smallest dimension of the image to this Scale and minsize are mutually exclusive Must be larger than crop both dimensions of the image will be set to minsize or&#160;</td><td class="memItemRight" valign="bottom"><b>scale</b></td></tr>
<tr class="separator:a6739031634080ced488a2712ad530b09"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a126d858d0b52cbf02dd08f5c218ce9d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a126d858d0b52cbf02dd08f5c218ce9d2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>otherwise</b></td></tr>
<tr class="separator:a126d858d0b52cbf02dd08f5c218ce9d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb88eb7761c4b2d4970a2b98e0d70afb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adb88eb7761c4b2d4970a2b98e0d70afb"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to Name of the <a class="el" href="structc10_1_1_type.html">Type</a> of The sizes of any outputs besides the data and shortest side desired for image resize Defaults to[-1,-1] or no random resize desired&#160;</td><td class="memItemRight" valign="bottom"><b>data</b> = in[0]</td></tr>
<tr class="separator:adb88eb7761c4b2d4970a2b98e0d70afb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02628998426ae02ef9c6e4764eee4142"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02628998426ae02ef9c6e4764eee4142"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to Name of the <a class="el" href="structc10_1_1_type.html">Type</a> of The sizes of any outputs besides the data and shortest side desired for image resize Defaults to[-1,-1] or no random resize desired <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> containing the images additional&#160;</td><td class="memItemRight" valign="bottom"><b>outputs</b></td></tr>
<tr class="separator:a02628998426ae02ef9c6e4764eee4142"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42e25dec086376cc33e6a0f4199c96d1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42e25dec086376cc33e6a0f4199c96d1"></a>
the other dimension is proportionally scaled Defaults to Whether or not to mirror the image Defaults to Vector of means per color Standard deviation by which to normalize color channels Defaults to Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults Bounding box coordinate Defaults if the input is in Caffe format Defaults to Number of CPU decode transform threads Defaults to Name of the <a class="el" href="structc10_1_1_type.html">Type</a> of The sizes of any outputs besides the data and shortest side desired for image resize Defaults to[-1,-1] or no random resize desired <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> containing the images additional Any outputs after the first will be Tensors read from the input&#160;</td><td class="memItemRight" valign="bottom"><b>TensorProtos</b></td></tr>
<tr class="separator:a42e25dec086376cc33e6a0f4199c96d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9343f2b93099fd08c702c02ca9a67067"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9343f2b93099fd08c702c02ca9a67067"></a>
const char *const&#160;</td><td class="memItemRight" valign="bottom"><b>snpe_ffi_so</b> = &quot;libsnpe_ffi.so&quot;</td></tr>
<tr class="separator:a9343f2b93099fd08c702c02ca9a67067"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f26c8e49cc5d96b7dc00e5389c436f0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f26c8e49cc5d96b7dc00e5389c436f0"></a>
constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><b>k2b1bXBits</b> = 2</td></tr>
<tr class="separator:a7f26c8e49cc5d96b7dc00e5389c436f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95c357882dcf28f5100862bb0c47bb11"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a95c357882dcf28f5100862bb0c47bb11"></a>
constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><b>kL1CacheSizeBytes</b> = 16 * 1024</td></tr>
<tr class="separator:a95c357882dcf28f5100862bb0c47bb11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a675c192414204207a8fbe65cc25a53bb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a675c192414204207a8fbe65cc25a53bb"></a>
constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><b>kGEMMTileSize</b> = 64</td></tr>
<tr class="separator:a675c192414204207a8fbe65cc25a53bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec79aadd2f986b41f0e9e1eaf3c4ec96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec79aadd2f986b41f0e9e1eaf3c4ec96"></a>
constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><b>kGEMMTileDepthBytes</b> = 16</td></tr>
<tr class="separator:aec79aadd2f986b41f0e9e1eaf3c4ec96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9727e1099416b7634e8502ea834a91a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9727e1099416b7634e8502ea834a91a1"></a>
element wise Github&#160;</td><td class="memItemRight" valign="bottom"><b>Links</b></td></tr>
<tr class="separator:a9727e1099416b7634e8502ea834a91a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae33e5e712c84972a4ee6363f01b4dbd8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae33e5e712c84972a4ee6363f01b4dbd8"></a>
we add to&#160;</td><td class="memItemRight" valign="bottom"><b>it</b></td></tr>
<tr class="separator:ae33e5e712c84972a4ee6363f01b4dbd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa60bb1ecfdbe7cf126c0dda627e6a64a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa60bb1ecfdbe7cf126c0dda627e6a64a"></a>
we first initialize the output tensor to all&#160;</td><td class="memItemRight" valign="bottom"><b>zeros</b></td></tr>
<tr class="separator:aa60bb1ecfdbe7cf126c0dda627e6a64a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa31b459803870398792f0d1fbcf40451"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa31b459803870398792f0d1fbcf40451"></a>
we first initialize the output tensor to all and then do accumulation Any further calls to the&#160;</td><td class="memItemRight" valign="bottom"><b>input</b></td></tr>
<tr class="separator:aa31b459803870398792f0d1fbcf40451"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5678988ca67cc3c59b7ba9d64aa91857"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5678988ca67cc3c59b7ba9d64aa91857"></a>
we first initialize the output tensor to all and then do accumulation Any further calls to the The input tensor that has to be accumulated to the output tensor If the output size is not the same as input&#160;</td><td class="memItemRight" valign="bottom"><b>size</b> = 1</td></tr>
<tr class="separator:a5678988ca67cc3c59b7ba9d64aa91857"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ba29b97f6823d9ed5883d821873234e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ba29b97f6823d9ed5883d821873234e"></a>
we first initialize the output tensor to all and then do accumulation Any further calls to the The input tensor that has to be accumulated to the output tensor If the output size is not the same as input the output tensor is first reshaped and initialized to&#160;</td><td class="memItemRight" valign="bottom"><b>zero</b></td></tr>
<tr class="separator:a5ba29b97f6823d9ed5883d821873234e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c76ef55e49cc26412c5c8d03a357a38"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5c76ef55e49cc26412c5c8d03a357a38"></a>
we first initialize the output tensor to all and then do accumulation Any further calls to the The input tensor that has to be accumulated to the output tensor If the output size is not the same as input the output tensor is first reshaped and initialized to and only&#160;</td><td class="memItemRight" valign="bottom"><b>then</b></td></tr>
<tr class="separator:a5c76ef55e49cc26412c5c8d03a357a38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a874a9ae2d0b766057b51924dd6afc7ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a874a9ae2d0b766057b51924dd6afc7ad"></a>
element wise DOC&#160;</td><td class="memItemRight" valign="bottom"><b>output</b> = 1.0</td></tr>
<tr class="separator:a874a9ae2d0b766057b51924dd6afc7ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1c38163b6e5be871e034083c4eae694"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1c38163b6e5be871e034083c4eae694"></a>
element wise DOC The arccosine of the input tensor computed element&#160;</td><td class="memItemRight" valign="bottom"><b>wise</b></td></tr>
<tr class="separator:ab1c38163b6e5be871e034083c4eae694"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac78b395a3c5bc4c7d1b0b409186295b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac78b395a3c5bc4c7d1b0b409186295b2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>RealBatchSizeIn</b></td></tr>
<tr class="separator:ac78b395a3c5bc4c7d1b0b409186295b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a583f8a167994486be789a3af021d1142"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a583f8a167994486be789a3af021d1142"></a>
Real batch size&#160;</td><td class="memItemRight" valign="bottom"><b>RealBatchSizeOut</b></td></tr>
<tr class="separator:a583f8a167994486be789a3af021d1142"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1be78cf917075b9274ac4282e32194c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae1be78cf917075b9274ac4282e32194c"></a>
Real batch size Real batah size it will adjust the batch size according to max_batch_size argument In this&#160;</td><td class="memItemRight" valign="bottom"><b>case</b></td></tr>
<tr class="separator:ae1be78cf917075b9274ac4282e32194c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd78016643d21586a096af8d8dde327d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd78016643d21586a096af8d8dde327d"></a>
Real batch size Real batah size it will adjust the batch size according to max_batch_size argument In this in&#160;</td><td class="memItemRight" valign="bottom"><b>addition</b></td></tr>
<tr class="separator:afd78016643d21586a096af8d8dde327d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0efa4ede07f3852f506f974ae6bc276b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0efa4ede07f3852f506f974ae6bc276b"></a>
Real batch size Real batah size it will adjust the batch size according to max_batch_size argument In this in if it has two it will record the input batch size and record it to the second output When we have&#160;</td><td class="memItemRight" valign="bottom"><b>inputs</b></td></tr>
<tr class="separator:a0efa4ede07f3852f506f974ae6bc276b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc4915704cb8323a7767a70a700d183f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adc4915704cb8323a7767a70a700d183f"></a>
Real batch size Real batah size it will adjust the batch size according to max_batch_size argument In this in if it has two it will record the input batch size and record it to the second output When we have it expects the seocnd input contains the batch size to adjust&#160;</td><td class="memItemRight" valign="bottom"><b>to</b></td></tr>
<tr class="separator:adc4915704cb8323a7767a70a700d183f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b8760abd825f0c98fc16dae30030eb3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9b8760abd825f0c98fc16dae30030eb3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>X</b> = in[0]</td></tr>
<tr class="separator:a9b8760abd825f0c98fc16dae30030eb3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a42384bd701f06b88ef25095814d725"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5a42384bd701f06b88ef25095814d725"></a>
Feature map input with order NCHW or NHWC&#160;</td><td class="memItemRight" valign="bottom"><b>bias</b></td></tr>
<tr class="separator:a5a42384bd701f06b88ef25095814d725"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84e9aac7255302feac18b3cd49a3a05e"><td class="memItemLeft" align="right" valign="top">returns a tensor containing the indices of the largest element along the given axis If the keepdims arg is *True *&#160;</td><td class="memItemRight" valign="bottom"><b>default</b></td></tr>
<tr class="separator:a84e9aac7255302feac18b3cd49a3a05e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7af5ad1a7f68f8957aeef5a71becc392"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7af5ad1a7f68f8957aeef5a71becc392"></a>
returns a tensor containing the indices of the largest element along the given axis If the keepdims arg is *True the shape of the output tensor matches the input tensor except the axis dimension equals&#160;</td><td class="memItemRight" valign="bottom"><b>Else</b></td></tr>
<tr class="separator:a7af5ad1a7f68f8957aeef5a71becc392"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a0648524653d767b8f353b763cdc504"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a0648524653d767b8f353b763cdc504"></a>
returns a tensor containing the indices of the largest element along the given axis If the keepdims arg is *True the shape of the output tensor matches the input tensor except the axis dimension equals the axis dimension of the output tensor is removed Github&#160;</td><td class="memItemRight" valign="bottom"><b>axis</b> =2</td></tr>
<tr class="separator:a9a0648524653d767b8f353b763cdc504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa0bc5cba69ce29821f122015be60eb1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa0bc5cba69ce29821f122015be60eb1"></a>
*int *long or *long long *and checks if all values are True when coerced into a boolean In other&#160;</td><td class="memItemRight" valign="bottom"><b>words</b></td></tr>
<tr class="separator:afa0bc5cba69ce29821f122015be60eb1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae27c15ea70dd24144b1562e0611c6d48"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae27c15ea70dd24144b1562e0611c6d48"></a>
*int *long or *long long *and checks if all values are True when coerced into a boolean In other for non bool types this asserts that all values in the tensor are non zero If a value is False after coerced into a&#160;</td><td class="memItemRight" valign="bottom"><b>boolean</b></td></tr>
<tr class="separator:ae27c15ea70dd24144b1562e0611c6d48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed020b5f0b3d2bfb6bfab750924d9dd2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed020b5f0b3d2bfb6bfab750924d9dd2"></a>
and <a class="el" href="struct_d.html">D</a> is the feature_dim The indices is a tensor containing the indices of the features that need to be bucketized The lengths is a tensor that splits the following boundaries argument The boundaries is a tensor containing the border list for each feature With in each&#160;</td><td class="memItemRight" valign="bottom"><b>batch</b></td></tr>
<tr class="separator:aed020b5f0b3d2bfb6bfab750924d9dd2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5047db535c5c98e93d4fb2de9f42cdb2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5047db535c5c98e93d4fb2de9f42cdb2"></a>
and <a class="el" href="struct_d.html">D</a> is the feature_dim The indices is a tensor containing the indices of the features that need to be bucketized The lengths is a tensor that splits the following boundaries argument The boundaries is a tensor containing the border list for each feature With in each indices should not have duplicate&#160;</td><td class="memItemRight" valign="bottom"><b>number</b></td></tr>
<tr class="separator:a5047db535c5c98e93d4fb2de9f42cdb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d5b3eb35251a192390274e25f9a87a4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d5b3eb35251a192390274e25f9a87a4"></a>
and <a class="el" href="struct_d.html">D</a> is the feature_dim The indices is a tensor containing the indices of the features that need to be bucketized The lengths is a tensor that splits the following boundaries argument The boundaries is a tensor containing the border list for each feature With in each indices should not have duplicate and the number of elements in indices should be less than or euqal to <a class="el" href="struct_d.html">D</a> Each element in lengths the first sub border list&#160;</td><td class="memItemRight" valign="bottom"><b>is</b> [0.5, 1.0]</td></tr>
<tr class="separator:a7d5b3eb35251a192390274e25f9a87a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e20361269928187b6a5625204805051"><td class="memItemLeft" align="right" valign="top">const vector&lt; TensorShape &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>in</b></td></tr>
<tr class="separator:a6e20361269928187b6a5625204805051"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a361340ae951d832bd229b551db6d686c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a361340ae951d832bd229b551db6d686c"></a>
<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a>&#160;</td><td class="memItemRight" valign="bottom"><b>helper</b> (def)</td></tr>
<tr class="separator:a361340ae951d832bd229b551db6d686c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33ba257bf31ceca956d71205df79f53c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a33ba257bf31ceca956d71205df79f53c"></a>
const auto &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>data_dims</b> = GetDimsVector(in[0])</td></tr>
<tr class="separator:a33ba257bf31ceca956d71205df79f53c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad960afee248a027651483f33a368ec46"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad960afee248a027651483f33a368ec46"></a>
const auto &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>indices_dims</b> = GetDimsVector(in[1])</td></tr>
<tr class="separator:ad960afee248a027651483f33a368ec46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a821f8391013a3a007990bc7ac6772f2a"><td class="memItemLeft" align="right" valign="top">vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>output_dims</b></td></tr>
<tr class="separator:a821f8391013a3a007990bc7ac6772f2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48262a78819cac51ddd04a6d020a0baa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a48262a78819cac51ddd04a6d020a0baa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>out</b> [0] = CreateTensorShape(output_dims, TensorProto::FLOAT)</td></tr>
<tr class="separator:a48262a78819cac51ddd04a6d020a0baa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb7b0d087a3411220cc5422d2361f7e7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abb7b0d087a3411220cc5422d2361f7e7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>DATA</b></td></tr>
<tr class="separator:abb7b0d087a3411220cc5422d2361f7e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af04e8baeca5dcb4f675a99f815264363"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of rank&#160;</td><td class="memItemRight" valign="bottom"><b>r</b></td></tr>
<tr class="separator:af04e8baeca5dcb4f675a99f815264363"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78f811e6ab0b987945d660f473e439d8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a78f811e6ab0b987945d660f473e439d8"></a>
indices&#160;</td><td class="memItemRight" valign="bottom"><b>vector</b></td></tr>
<tr class="separator:a78f811e6ab0b987945d660f473e439d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5af61885359c14ef12bf13313a245852"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5af61885359c14ef12bf13313a245852"></a>
indices and values vector Each element in lengths indices should not have duplicate number For&#160;</td><td class="memItemRight" valign="bottom"><b>example</b></td></tr>
<tr class="separator:a5af61885359c14ef12bf13313a245852"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a11eb071486461d2526bb04ee3e827b"><td class="memItemLeft" align="right" valign="top">with the size where&#160;</td><td class="memItemRight" valign="bottom"><b>num_feature</b></td></tr>
<tr class="separator:a1a11eb071486461d2526bb04ee3e827b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2eceb09f260a313a6490f36792c13873"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2eceb09f260a313a6490f36792c13873"></a>
with the size where we also need additional information regarding the feature value distribution There are several vectors to keep data to percentile mappping information as arguments(context) the interpolation is apply&#160;</td><td class="memItemRight" valign="bottom"><b>R_2</b> = [0.3, 1.2]</td></tr>
<tr class="separator:a2eceb09f260a313a6490f36792c13873"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad01a9efe72340b4cbc19f4b50f99fafd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad01a9efe72340b4cbc19f4b50f99fafd"></a>
We will build&#160;</td><td class="memItemRight" valign="bottom"><b>R</b> = [0.1, 0.4, 0.5, 0.3, 1.2]</td></tr>
<tr class="separator:ad01a9efe72340b4cbc19f4b50f99fafd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5d863158b12a8509d502d100bc76518"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa5d863158b12a8509d502d100bc76518"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>besides</b></td></tr>
<tr class="separator:aa5d863158b12a8509d502d100bc76518"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3ec10da341226fbe34f94b36cda614a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3ec10da341226fbe34f94b36cda614a"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>__pad0__</b></td></tr>
<tr class="separator:ad3ec10da341226fbe34f94b36cda614a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa16dc11234a60ac548ba1efa93e7c28b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa16dc11234a60ac548ba1efa93e7c28b"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>mask</b></td></tr>
<tr class="separator:aa16dc11234a60ac548ba1efa93e7c28b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7902a5e138e702cc5a8e58f919048156"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7902a5e138e702cc5a8e58f919048156"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Tensor</b></td></tr>
<tr class="separator:a7902a5e138e702cc5a8e58f919048156"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a248040d946d6717a58c350eee8a73892"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a248040d946d6717a58c350eee8a73892"></a>
same shape as data&#160;</td><td class="memItemRight" valign="bottom"><b>masked_indices</b></td></tr>
<tr class="separator:a248040d946d6717a58c350eee8a73892"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af414c251ce4da8ff38f5355a092635e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af414c251ce4da8ff38f5355a092635e1"></a>
const float&#160;</td><td class="memItemRight" valign="bottom"><b>minf</b> = -1.0f * std::numeric_limits&lt;float&gt;::infinity()</td></tr>
<tr class="separator:af414c251ce4da8ff38f5355a092635e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b7467b205e56056c9121e40bfff213f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6b7467b205e56056c9121e40bfff213f"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive&#160;</td><td class="memItemRight" valign="bottom"><b>False</b></td></tr>
<tr class="separator:a6b7467b205e56056c9121e40bfff213f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11c1b5f26f85c316d813e2b572f889c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a11c1b5f26f85c316d813e2b572f889c1"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive&#160;</td><td class="memItemRight" valign="bottom"><b>True</b></td></tr>
<tr class="separator:a11c1b5f26f85c316d813e2b572f889c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74ba8e47d6a968bb7ef37228eb2ea48d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a74ba8e47d6a968bb7ef37228eb2ea48d"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False&#160;</td><td class="memItemRight" valign="bottom"><b>values1</b> = 1.0</td></tr>
<tr class="separator:a74ba8e47d6a968bb7ef37228eb2ea48d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1ce822052940b564fe8a18b36043a46"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad1ce822052940b564fe8a18b36043a46"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False&#160;</td><td class="memItemRight" valign="bottom"><b>mask2</b> = False</td></tr>
<tr class="separator:ad1ce822052940b564fe8a18b36043a46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff768241374a251f1193b7a1c68419b1"><td class="memItemLeft" align="right" valign="top">reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False&#160;</td><td class="memItemRight" valign="bottom"><b>values2</b></td></tr>
<tr class="separator:aff768241374a251f1193b7a1c68419b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8243c546a33a687ac9b0b5065c40b7c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8243c546a33a687ac9b0b5065c40b7c9"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True&#160;</td><td class="memItemRight" valign="bottom"><b>values3</b> = 4.0</td></tr>
<tr class="separator:a8243c546a33a687ac9b0b5065c40b7c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3f58537928e93ce4dea86b12e17980d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3f58537928e93ce4dea86b12e17980d"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct&#160;</td><td class="memItemRight" valign="bottom"><b>by</b></td></tr>
<tr class="separator:ad3f58537928e93ce4dea86b12e17980d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3518699eb3c6de62fc0804d8bf4d35ab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3518699eb3c6de62fc0804d8bf4d35ab"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct&#160;</td><td class="memItemRight" valign="bottom"><b>mask3</b></td></tr>
<tr class="separator:a3518699eb3c6de62fc0804d8bf4d35ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f30c5159e60c741917da1572d69831c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5f30c5159e60c741917da1572d69831c"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct Note that for all mask&#160;</td><td class="memItemRight" valign="bottom"><b>positions</b></td></tr>
<tr class="separator:a5f30c5159e60c741917da1572d69831c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2057204d94ca64707d7093f80e497c96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2057204d94ca64707d7093f80e497c96"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct Note that for all mask there must be at least one True This is not&#160;</td><td class="memItemRight" valign="bottom"><b>allowed</b></td></tr>
<tr class="separator:a2057204d94ca64707d7093f80e497c96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43e420bb37460bbc38f3ba88bb83379c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a43e420bb37460bbc38f3ba88bb83379c"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct Note that for all mask there must be at least one True This is not False False we accept the first&#160;</td><td class="memItemRight" valign="bottom"><b>value</b></td></tr>
<tr class="separator:a43e420bb37460bbc38f3ba88bb83379c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08aaffbe2c21a3733b5a44d5e0ec1ddc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a08aaffbe2c21a3733b5a44d5e0ec1ddc"></a>
reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct Note that for all mask there must be at least one True This is not False False we accept the first and no longer expect a value for that&#160;</td><td class="memItemRight" valign="bottom"><b>location</b></td></tr>
<tr class="separator:a08aaffbe2c21a3733b5a44d5e0ec1ddc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26af102a075a7eeb3e90e643f8b90ac4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a26af102a075a7eeb3e90e643f8b90ac4"></a>
*&#160;</td><td class="memItemRight" valign="bottom"><b>type</b></td></tr>
<tr class="separator:a26af102a075a7eeb3e90e643f8b90ac4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a726982682691269ef900b03784b3431f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><b>Y</b></td></tr>
<tr class="separator:a726982682691269ef900b03784b3431f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc83acec950979e55215b3ead8ff3c93"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afc83acec950979e55215b3ead8ff3c93"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation&#160;</td><td class="memItemRight" valign="bottom"><b>Typically</b></td></tr>
<tr class="separator:afc83acec950979e55215b3ead8ff3c93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa7ee5ca45d083c80de818b3b666a25e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afa7ee5ca45d083c80de818b3b666a25e"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation the results of this op are subsequently reduced over multiple devices to obtain statistics over a larger batch size in cases where the batch size for a single model copy is too low to yield the full benefit of batch normalization The resulting bias and scale can then be plugged back into SpatialBNGradient to get results over the larger batch size DOC&#160;</td><td class="memItemRight" valign="bottom"><b>mean</b> =2.0</td></tr>
<tr class="separator:afa7ee5ca45d083c80de818b3b666a25e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13f6a72d88af45a62ebade1938f893bc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a13f6a72d88af45a62ebade1938f893bc"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation the results of this op are subsequently reduced over multiple devices to obtain statistics over a larger batch size in cases where the batch size for a single model copy is too low to yield the full benefit of batch normalization The resulting bias and scale can then be plugged back into SpatialBNGradient to get results over the larger batch size DOC The mean saved from the forward pass as a dimensional tensor of size <a class="el" href="struct_c.html">C</a>&#160;</td><td class="memItemRight" valign="bottom"><b>output_grad</b></td></tr>
<tr class="separator:a13f6a72d88af45a62ebade1938f893bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd996a69d304ea7be28941b23e9b9228"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd996a69d304ea7be28941b23e9b9228"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation the results of this op are subsequently reduced over multiple devices to obtain statistics over a larger batch size in cases where the batch size for a single model copy is too low to yield the full benefit of batch normalization The resulting bias and scale can then be plugged back into SpatialBNGradient to get results over the larger batch size DOC The mean saved from the forward pass as a dimensional tensor of size <a class="el" href="struct_c.html">C</a> Gradient for the output layer of&#160;</td><td class="memItemRight" valign="bottom"><b>SpatialBN</b></td></tr>
<tr class="separator:afd996a69d304ea7be28941b23e9b9228"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f5b30a4606edd5458f6676a4067b86c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6f5b30a4606edd5458f6676a4067b86c"></a>
the gradient for the output of SpatialBN and the per channel mean and inverse std var vectors for the computes the per channel bias and scale gradient to be used during the backward pass for subsequent spatial batch normalization gradient calculation the results of this op are subsequently reduced over multiple devices to obtain statistics over a larger batch size in cases where the batch size for a single model copy is too low to yield the full benefit of batch normalization The resulting bias and scale can then be plugged back into SpatialBNGradient to get results over the larger batch size DOC The mean saved from the forward pass as a dimensional tensor of size <a class="el" href="struct_c.html">C</a> Gradient for the output layer of here used as input because we are on the backward pass&#160;</td><td class="memItemRight" valign="bottom"><b>bias_grad</b></td></tr>
<tr class="separator:a6f5b30a4606edd5458f6676a4067b86c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2e47ce24a2b32b1c654120108c3b858"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2e47ce24a2b32b1c654120108c3b858"></a>
computes the sum of all elements per channel and the sum of all elements squared per channel These values can be reduced across multiple batches and used to obtain the mean and variance across the full set of batches Using the new mean and variance as input to SpatialBN has the effect of changing the batch size over which SpatialBN is applied DOC&#160;</td><td class="memItemRight" valign="bottom"><b>sum</b></td></tr>
<tr class="separator:ac2e47ce24a2b32b1c654120108c3b858"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2069850bb2c06fd98dd2142a18e0441"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2069850bb2c06fd98dd2142a18e0441"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>kv_handler</b></td></tr>
<tr class="separator:ac2069850bb2c06fd98dd2142a18e0441"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e00679abaa908d00e7c8fc71e0499cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2e00679abaa908d00e7c8fc71e0499cf"></a>
Key value handler for&#160;</td><td class="memItemRight" valign="bottom"><b>comm_world</b></td></tr>
<tr class="separator:a2e00679abaa908d00e7c8fc71e0499cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae9c1871d705fa9e8aa558644f102386"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aae9c1871d705fa9e8aa558644f102386"></a>
Key value handler for <a class="el" href="struct_a.html">A</a> common world for collective operations int rank of this node in the common&#160;</td><td class="memItemRight" valign="bottom"><b>world</b></td></tr>
<tr class="separator:aae9c1871d705fa9e8aa558644f102386"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20774c05b863ca8fbda1b27507e18d11"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a20774c05b863ca8fbda1b27507e18d11"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>existing_comm_world</b></td></tr>
<tr class="separator:a20774c05b863ca8fbda1b27507e18d11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4131b6de924c49ed98ffacf3f4e387b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae4131b6de924c49ed98ffacf3f4e387b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>common_world</b></td></tr>
<tr class="separator:ae4131b6de924c49ed98ffacf3f4e387b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae95bc248f963a13dfcca20bd71e88995"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae95bc248f963a13dfcca20bd71e88995"></a>
The common world to be&#160;</td><td class="memItemRight" valign="bottom"><b>destroyed</b></td></tr>
<tr class="separator:ae95bc248f963a13dfcca20bd71e88995"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af22a34562d580125c148133482def750"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af22a34562d580125c148133482def750"></a>
The common world The reduced result on&#160;</td><td class="memItemRight" valign="bottom"><b>root</b></td></tr>
<tr class="separator:af22a34562d580125c148133482def750"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5c2844d0eb15de0d902da4d79a9ef88"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad5c2844d0eb15de0d902da4d79a9ef88"></a>
The common world The allreduced&#160;</td><td class="memItemRight" valign="bottom"><b>tensor</b></td></tr>
<tr class="separator:ad5c2844d0eb15de0d902da4d79a9ef88"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a977aabc758f9d7a2b65c796fbf433d83"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a977aabc758f9d7a2b65c796fbf433d83"></a>
The common world The allreduced same on all&#160;</td><td class="memItemRight" valign="bottom"><b>nodes</b></td></tr>
<tr class="separator:a977aabc758f9d7a2b65c796fbf433d83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad24fa41c4f9a7caf2045720dec1ab894"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad24fa41c4f9a7caf2045720dec1ab894"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>dst</b></td></tr>
<tr class="separator:ad24fa41c4f9a7caf2045720dec1ab894"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4100b31fea680091fc72ee3c63a3356"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4100b31fea680091fc72ee3c63a3356"></a>
The common world An int CPUtensor of size specifying the rank If&#160;</td><td class="memItemRight" valign="bottom"><b>given</b></td></tr>
<tr class="separator:aa4100b31fea680091fc72ee3c63a3356"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ec0c3ada1f730fc97a3fd46174cc53f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9ec0c3ada1f730fc97a3fd46174cc53f"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the to argument of the op The rank to send the tensor to bool if&#160;</td><td class="memItemRight" valign="bottom"><b>set</b></td></tr>
<tr class="separator:a9ec0c3ada1f730fc97a3fd46174cc53f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ca87e17a9274257b1f0cc98eacdf2a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6ca87e17a9274257b1f0cc98eacdf2a0"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the to argument of the op The rank to send the tensor to bool if only send the content and assume that the receiver has already known the tensor s shape and&#160;</td><td class="memItemRight" valign="bottom"><b>information</b></td></tr>
<tr class="separator:a6ca87e17a9274257b1f0cc98eacdf2a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8b6d7036f64365eb3a654735bc5f1b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad8b6d7036f64365eb3a654735bc5f1b2"></a>
The common world&#160;</td><td class="memItemRight" valign="bottom"><b>src</b></td></tr>
<tr class="separator:ad8b6d7036f64365eb3a654735bc5f1b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d1641229ee1edeff1d9d378be9dceb4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d1641229ee1edeff1d9d378be9dceb4"></a>
The common world An int CPUtensor of size specifying the rank If this overrides the from argument of the op The received tensor&#160;</td><td class="memItemRight" valign="bottom"><b>tag</b></td></tr>
<tr class="separator:a9d1641229ee1edeff1d9d378be9dceb4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e294375191043415c67aa7dc5a9b489"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7e294375191043415c67aa7dc5a9b489"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>split</b></td></tr>
<tr class="separator:a7e294375191043415c67aa7dc5a9b489"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab28c42219190741e69d228cc12689986"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab28c42219190741e69d228cc12689986"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>int</b></td></tr>
<tr class="separator:ab28c42219190741e69d228cc12689986"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c6cd95ddd1f216469176c36c82f004b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4c6cd95ddd1f216469176c36c82f004b"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>legnths</b></td></tr>
<tr class="separator:a4c6cd95ddd1f216469176c36c82f004b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a554c333c437b4388f4d5ad4218f37bac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a554c333c437b4388f4d5ad4218f37bac"></a>
INT_MAX The tensor l_i indicates the logic block of input Either NHWC or&#160;</td><td class="memItemRight" valign="bottom"><b>NCWH</b></td></tr>
<tr class="separator:a554c333c437b4388f4d5ad4218f37bac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26f51cf0e7a7c3688d879508f69477aa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a26f51cf0e7a7c3688d879508f69477aa"></a>
INT_MAX The tensor l_i indicates the logic block of input Either NHWC or will split on <a class="el" href="struct_c.html">C</a> defaults to NCHW given a lengths along the specified axis If K outputs are&#160;</td><td class="memItemRight" valign="bottom"><b>provided</b></td></tr>
<tr class="separator:a26f51cf0e7a7c3688d879508f69477aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0489286b5b37e795f5465cdf33c71233"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0489286b5b37e795f5465cdf33c71233"></a>
apply conditional&#160;</td><td class="memItemRight" valign="bottom"><b>DataT</b></td></tr>
<tr class="separator:a0489286b5b37e795f5465cdf33c71233"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad07ea3a223f8cadbeae2e6e1c7bc43d7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad07ea3a223f8cadbeae2e6e1c7bc43d7"></a>
apply conditional <a class="el" href="classnom_1_1repr_1_1_data.html">Data</a> to use when True&#160;</td><td class="memItemRight" valign="bottom"><b>DataO</b></td></tr>
<tr class="separator:ad07ea3a223f8cadbeae2e6e1c7bc43d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78596a07b45c07102b67cab1fb848247"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a78596a07b45c07102b67cab1fb848247"></a>
const char&#160;</td><td class="memItemRight" valign="bottom"><b>kConvDoc</b> []</td></tr>
<tr class="separator:a78596a07b45c07102b67cab1fb848247"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d62363e2abb26265634ff2fa39f20a9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d62363e2abb26265634ff2fa39f20a9"></a>
an input weight tensor&#160;</td><td class="memItemRight" valign="bottom"><b>$filter</b></td></tr>
<tr class="separator:a1d62363e2abb26265634ff2fa39f20a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe1f42b96e01292b15ad28c02bd1adb4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abe1f42b96e01292b15ad28c02bd1adb4"></a>
an input weight tensor and optionally an input bias tensor $bias It then computes the transposed&#160;</td><td class="memItemRight" valign="bottom"><b>convolution</b></td></tr>
<tr class="separator:abe1f42b96e01292b15ad28c02bd1adb4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02c97bed9e795921f8ea0a6d272b3456"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02c97bed9e795921f8ea0a6d272b3456"></a>
an input weight tensor and optionally an input bias tensor $bias It then computes the transposed sometimes referred to as&#160;</td><td class="memItemRight" valign="bottom"><b>deconvolution</b></td></tr>
<tr class="separator:a02c97bed9e795921f8ea0a6d272b3456"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79aecb88bfb1a552248da253b56dbc96"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79aecb88bfb1a552248da253b56dbc96"></a>
an input weight tensor and optionally an input bias tensor $bias It then computes the transposed sometimes referred to as and produces a single output tensor $Y The hyperparameters of the op such as kernel&#160;</td><td class="memItemRight" valign="bottom"><b>stride</b> =2</td></tr>
<tr class="separator:a79aecb88bfb1a552248da253b56dbc96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1be774967eedd652a2175782242c22e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac1be774967eedd652a2175782242c22e"></a>
an input weight tensor and optionally an input bias tensor $bias It then computes the transposed sometimes referred to as and produces a single output tensor $Y The hyperparameters of the op such as kernel and padding are specified as args At each the filter is deconvolved with a subset of $X and the $bias is added This is done throughout the input data until the output computation is complete The output shapes are computed as follows The number of channels in the output feature map is the number of kernels specified in the filter blob The spatial height and width are computed&#160;</td><td class="memItemRight" valign="bottom"><b>as</b></td></tr>
<tr class="separator:ac1be774967eedd652a2175782242c22e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af21916d06a331826256ed48f651d1226"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af21916d06a331826256ed48f651d1226"></a>
an input weight tensor and optionally an input bias tensor $bias It then computes the transposed sometimes referred to as and produces a single output tensor $Y The hyperparameters of the op such as kernel and padding are specified as args At each the filter is deconvolved with a subset of $X and the $bias is added This is done throughout the input data until the output computation is complete The output shapes are computed as follows The number of channels in the output feature map is the number of kernels specified in the filter blob The spatial height and width are computed which is why they are separate files&#160;</td><td class="memItemRight" valign="bottom"><b>Also</b></td></tr>
<tr class="separator:af21916d06a331826256ed48f651d1226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a441e9ef50971c213c28777dea092cae2"><td class="memItemLeft" align="right" valign="top">const char *&#160;</td><td class="memItemRight" valign="bottom"><b>githubLinks</b></td></tr>
<tr class="separator:a441e9ef50971c213c28777dea092cae2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38613bac22c06a85e6764539c6103ec5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38613bac22c06a85e6764539c6103ec5"></a>
const char *&#160;</td><td class="memItemRight" valign="bottom"><b>kCountExample</b></td></tr>
<tr class="separator:a38613bac22c06a85e6764539c6103ec5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7026acab05a17cb8d768dae95f0434aa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7026acab05a17cb8d768dae95f0434aa"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>counter</b></td></tr>
<tr class="separator:a7026acab05a17cb8d768dae95f0434aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bc60a5d359d05aa9077867f0464214c"><td class="memItemLeft" align="right" valign="top">default must&#160;</td><td class="memItemRight" valign="bottom"><b>be</b></td></tr>
<tr class="separator:a3bc60a5d359d05aa9077867f0464214c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac94227580fff8ec550ddab6fbd27a328"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac94227580fff8ec550ddab6fbd27a328"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>previous_count</b></td></tr>
<tr class="separator:ac94227580fff8ec550ddab6fbd27a328"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a247515d56285ef271b73a5aef587e2b3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a247515d56285ef271b73a5aef587e2b3"></a>
Input tensor which is almost always the result of a softmax operation $X is a array of size&#160;</td><td class="memItemRight" valign="bottom"><b>$NxD</b></td></tr>
<tr class="separator:a247515d56285ef271b73a5aef587e2b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a125bb08b4fb3ac367f25d56407945e71"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a125bb08b4fb3ac367f25d56407945e71"></a>
R&#160;</td><td class="memItemRight" valign="bottom"><b>logits</b> = in[0]</td></tr>
<tr class="separator:a125bb08b4fb3ac367f25d56407945e71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50b260eccc1ad0af8c8238b91bb3e1f7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a50b260eccc1ad0af8c8238b91bb3e1f7"></a>
R matrix of logits for each example and class&#160;</td><td class="memItemRight" valign="bottom"><b>xentropy</b></td></tr>
<tr class="separator:a50b260eccc1ad0af8c8238b91bb3e1f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26538ce8b849e2eb1d6f0639c681463c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a26538ce8b849e2eb1d6f0639c681463c"></a>
matrix of logits for each example and class&#160;</td><td class="memItemRight" valign="bottom"><b>weights</b></td></tr>
<tr class="separator:a26538ce8b849e2eb1d6f0639c681463c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad89ef6ca1004570a92d57df67ae3b925"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad89ef6ca1004570a92d57df67ae3b925"></a>
Maximum number of candidates to carry over to next activation step&#160;</td><td class="memItemRight" valign="bottom"><b>INPUTS</b></td></tr>
<tr class="separator:ad89ef6ca1004570a92d57df67ae3b925"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d6462f911f1af4ad87a36e7cb9b38ab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7d6462f911f1af4ad87a36e7cb9b38ab"></a>
Maximum number of candidates to carry over to next activation step float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_activation_length, batch_size, alphabet_size] of network&#160;</td><td class="memItemRight" valign="bottom"><b>SEQ_LEN</b></td></tr>
<tr class="separator:a7d6462f911f1af4ad87a36e7cb9b38ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad88e3171d9002bb911dc07c92fe849f7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad88e3171d9002bb911dc07c92fe849f7"></a>
Maximum number of candidates to carry over to next activation step float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_activation_length, batch_size, alphabet_size] of network <a class="el" href="classc10_1_1optional.html">optional</a> int vector containing sequence&#160;</td><td class="memItemRight" valign="bottom"><b>lengths</b></td></tr>
<tr class="separator:ad88e3171d9002bb911dc07c92fe849f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a3a988f70f4491fd6a9228b5017cf6e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a3a988f70f4491fd6a9228b5017cf6e"></a>
Maximum number of candidates to carry over to next activation step float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_activation_length, batch_size, alphabet_size] of network <a class="el" href="classc10_1_1optional.html">optional</a> int vector containing sequence having size[batch_size] seq_len will be set to max_time if not provided&#160;</td><td class="memItemRight" valign="bottom"><b>VALUES</b></td></tr>
<tr class="separator:a4a3a988f70f4491fd6a9228b5017cf6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe227faccd1ee13a1fc73cea53dcb7dd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe227faccd1ee13a1fc73cea53dcb7dd"></a>
When merge_repeated is&#160;</td><td class="memItemRight" valign="bottom"><b>true</b></td></tr>
<tr class="separator:afe227faccd1ee13a1fc73cea53dcb7dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57d6828aca83123e1d35b710899ed34b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a57d6828aca83123e1d35b710899ed34b"></a>
When merge_repeated is merge repeated classes in output float <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> sized[max_time, batch_size, num_classes]&#160;</td><td class="memItemRight" valign="bottom"><b>OUTPUT_LEN</b></td></tr>
<tr class="separator:a57d6828aca83123e1d35b710899ed34b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addb0697a8c7a31db09034b492c3926f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="addb0697a8c7a31db09034b492c3926f6"></a>
as well as can tie together different blobs in a data dependency&#160;</td><td class="memItemRight" valign="bottom"><b>DOC</b></td></tr>
<tr class="separator:addb0697a8c7a31db09034b492c3926f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e84d76cd6fb8c90b44f5fe5913183a1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e84d76cd6fb8c90b44f5fe5913183a1"></a>
or input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>Z</b></td></tr>
<tr class="separator:a4e84d76cd6fb8c90b44f5fe5913183a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a670980437aa26d14148d2e1d5aa3be04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a670980437aa26d14148d2e1d5aa3be04"></a>
Y with different shapes and produces one output float tensor of the dot product between X and Y We currently support two kinds of strategies to achieve this Before doing normal dot_product pad the smaller Y must be equal Only the second dimension of X or Y can be padded DOC or input tensor whether to replicate the smaller tensor or&#160;</td><td class="memItemRight" valign="bottom"><b>not</b></td></tr>
<tr class="separator:a670980437aa26d14148d2e1d5aa3be04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ebfa6140fad930b6448092a77cc4d95"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9ebfa6140fad930b6448092a77cc4d95"></a>
INT_MAX Subnet with blob bindings Indices of corresponding outer workspace&#160;</td><td class="memItemRight" valign="bottom"><b>blobs</b></td></tr>
<tr class="separator:a9ebfa6140fad930b6448092a77cc4d95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb2a34a424811068acf175bd0272749c"><td class="memItemLeft" align="right" valign="top">INT_MAX Subnet with blob bindings Indices of corresponding outer workspace in&#160;</td><td class="memItemRight" valign="bottom"><b>order</b></td></tr>
<tr class="separator:afb2a34a424811068acf175bd0272749c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45c572cb5522ce6bbfdd93781bdcac5b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a45c572cb5522ce6bbfdd93781bdcac5b"></a>
INT_MAX Subnet with blob bindings Indices of corresponding outer workspace in List of blobs from the forward Do int out&#160;</td><td class="memItemRight" valign="bottom"><b>bool</b> { return true</td></tr>
<tr class="separator:a45c572cb5522ce6bbfdd93781bdcac5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa65868e3ebf153459a7dc65217a7bad9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa65868e3ebf153459a7dc65217a7bad9"></a>
<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a>&#160;</td><td class="memItemRight" valign="bottom"><b>argsHelper</b> (def)</td></tr>
<tr class="separator:aa65868e3ebf153459a7dc65217a7bad9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9607dd607d4171cc05659548eeddb6f5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9607dd607d4171cc05659548eeddb6f5"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>__pad1__</b></td></tr>
<tr class="separator:a9607dd607d4171cc05659548eeddb6f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a942bd0c8983407b943d3ef8caa0ad372"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a942bd0c8983407b943d3ef8caa0ad372"></a>
default perform dropout If non signifying which elements are dropped out If is_test is&#160;</td><td class="memItemRight" valign="bottom"><b>nonzero</b></td></tr>
<tr class="separator:a942bd0c8983407b943d3ef8caa0ad372"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22028ef1f7df3ab6e4694c21389787f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a22028ef1f7df3ab6e4694c21389787f6"></a>
the op takes an input tensor $X of shape a weight vector $w of length&#160;</td><td class="memItemRight" valign="bottom"><b>$D</b></td></tr>
<tr class="separator:a22028ef1f7df3ab6e4694c21389787f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa412914b0d4b09dd4f6ced188facf53c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa412914b0d4b09dd4f6ced188facf53c"></a>
the op takes an input tensor $X of shape a weight vector $w of length and a bias vector $b of length $<a class="el" href="struct_d.html">D</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Here</b></td></tr>
<tr class="separator:aa412914b0d4b09dd4f6ced188facf53c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe066ec6da806b59611b405c02c27344"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe066ec6da806b59611b405c02c27344"></a>
the op takes an input tensor $X of shape a weight vector $w of length and a bias vector $b of length $<a class="el" href="struct_d.html">D</a> $N represents the batch size and $<a class="el" href="struct_d.html">D</a> represents the length of the feature vectors The&#160;</td><td class="memItemRight" valign="bottom"><b>$Y</b></td></tr>
<tr class="separator:afe066ec6da806b59611b405c02c27344"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef1ef66a792fed13fe6454eb54ae529a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aef1ef66a792fed13fe6454eb54ae529a"></a>
the op takes an input tensor $X of shape a weight vector $w of length and a bias vector $b of length $<a class="el" href="struct_d.html">D</a> $N represents the batch size and $<a class="el" href="struct_d.html">D</a> represents the length of the feature vectors The is a tensor of shape $NxD and is calculated as&#160;</td><td class="memItemRight" valign="bottom"><b>$$Y_</b> {ij} = X_{ij}w_j + b_j \ for \ i\in{N}</td></tr>
<tr class="separator:aef1ef66a792fed13fe6454eb54ae529a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed04d2da4a15e653d4ca2bf0e1398c43"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed04d2da4a15e653d4ca2bf0e1398c43"></a>
and the dimensions of the second input is the contiguous subset of the dimensions of the first For the following tensor shapes are&#160;</td><td class="memItemRight" valign="bottom"><b>supported</b></td></tr>
<tr class="separator:aed04d2da4a15e653d4ca2bf0e1398c43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09c7c3441df93b9b4bf12cd42360adb1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a09c7c3441df93b9b4bf12cd42360adb1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>param</b></td></tr>
<tr class="separator:a09c7c3441df93b9b4bf12cd42360adb1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22b2361594237f0e46c48218e03999df"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a22b2361594237f0e46c48218e03999df"></a>
Parameters to be normalized&#160;</td><td class="memItemRight" valign="bottom"><b>grad</b></td></tr>
<tr class="separator:a22b2361594237f0e46c48218e03999df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98ae3dd5ea569ef46e36533d47481c06"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a98ae3dd5ea569ef46e36533d47481c06"></a>
Parameters to be normalized Gradient&#160;</td><td class="memItemRight" valign="bottom"><b>computed</b></td></tr>
<tr class="separator:a98ae3dd5ea569ef46e36533d47481c06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab35bb5aa6e43f41faebd3dd919939e6a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab35bb5aa6e43f41faebd3dd919939e6a"></a>
element wise This operation can be done in an in place fashion&#160;</td><td class="memItemRight" valign="bottom"><b>too</b></td></tr>
<tr class="separator:ab35bb5aa6e43f41faebd3dd919939e6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d03f1d9ba942a7952e612c5c273a984"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0d03f1d9ba942a7952e612c5c273a984"></a>
element wise This operation can be done in an in place fashion by providing the same input and output blobs Github&#160;</td><td class="memItemRight" valign="bottom"><b>Link</b></td></tr>
<tr class="separator:a0d03f1d9ba942a7952e612c5c273a984"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91d735e45ac0e0eae5fc5a9884810ced"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a91d735e45ac0e0eae5fc5a9884810ced"></a>
NumInputs(2).NumOutputs(1).SetDoc(R&quot;DOC( Broadcast the input tensor to a materialized new tensor using given shape. Broadcast rule is similar to &quot;numpy.array(input)*numpy.ones(shape)&quot; Two corresponding dimensions must have the same or one of them equals to In order to align with PyTorch s&#160;</td><td class="memItemRight" valign="bottom"><b>expand</b></td></tr>
<tr class="separator:a91d735e45ac0e0eae5fc5a9884810ced"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48d01cee0c09a2e0298f716ea9d7d303"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a48d01cee0c09a2e0298f716ea9d7d303"></a>
NumInputs(2).NumOutputs(1).SetDoc(R&quot;DOC( Broadcast the input tensor to a materialized new tensor using given shape. Broadcast rule is similar to &quot;numpy.array(input)*numpy.ones(shape)&quot; Two corresponding dimensions must have the same or one of them equals to In order to align with PyTorch s shape is allowed to have entries equal which means to preserve the size of the corresponding dimension in&#160;</td><td class="memItemRight" valign="bottom"><b>shape</b></td></tr>
<tr class="separator:a48d01cee0c09a2e0298f716ea9d7d303"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa03f0da1dff8bce378f1fff2a6395d69"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa03f0da1dff8bce378f1fff2a6395d69"></a>
*and produces a single output tensor *expanded *The op also takes an argument *dims *with a list of dimensions for where to add the single dimensional entries If the same blob is provided as input and the operation is copy free This is the exact inverse operation of *Squeeze *Github&#160;</td><td class="memItemRight" valign="bottom"><b>dims</b> =[0,1]</td></tr>
<tr class="separator:aa03f0da1dff8bce378f1fff2a6395d69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa602c3e7ee0c909720e0b7fda2498713"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa602c3e7ee0c909720e0b7fda2498713"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>originalSize</b> = dims.size()</td></tr>
<tr class="separator:aa602c3e7ee0c909720e0b7fda2498713"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1b902924fb69a8694427f8a967a820e"><td class="memItemLeft" align="right" valign="top">std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>newDims</b></td></tr>
<tr class="separator:ac1b902924fb69a8694427f8a967a820e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96adb1d51fc9f403bcd2c76e1c2afd2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96adb1d51fc9f403bcd2c76e1c2afd2f"></a>
the data types supported are *float *int32 *int64 and *bool *If the dtype argument is not the data type of value is used The output tensor shape is either specified by the shape argument or will match the shape of the input tensor if one is the input should be a tensor containing the desired output use the integer keys from the *DataType *enum in&#160;</td><td class="memItemRight" valign="bottom"><b>TensorProto</b></td></tr>
<tr class="separator:a96adb1d51fc9f403bcd2c76e1c2afd2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a5d709852b528f13c91000ff9a2fc78"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a5d709852b528f13c91000ff9a2fc78"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>FLOAT</b> = 1</td></tr>
<tr class="separator:a9a5d709852b528f13c91000ff9a2fc78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a273ee25c97147555a8963a69e39d506b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a273ee25c97147555a8963a69e39d506b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>INT32</b> = 2</td></tr>
<tr class="separator:a273ee25c97147555a8963a69e39d506b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42c10371987ad7cc93b588a530213197"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a42c10371987ad7cc93b588a530213197"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>BYTE</b> = 3</td></tr>
<tr class="separator:a42c10371987ad7cc93b588a530213197"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f393a572bc90e4c4488de9baacab356"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3f393a572bc90e4c4488de9baacab356"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>STRING</b> = 4</td></tr>
<tr class="separator:a3f393a572bc90e4c4488de9baacab356"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af77e12014663bd74a7a091eae4e20676"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af77e12014663bd74a7a091eae4e20676"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>BOOL</b> = 5</td></tr>
<tr class="separator:af77e12014663bd74a7a091eae4e20676"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af461974036b19e2456f1c38b5b52f170"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af461974036b19e2456f1c38b5b52f170"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>UINT8</b> = 6</td></tr>
<tr class="separator:af461974036b19e2456f1c38b5b52f170"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2cd9ac9739b22dc56d89d97fd23edd0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af2cd9ac9739b22dc56d89d97fd23edd0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>INT8</b> = 7</td></tr>
<tr class="separator:af2cd9ac9739b22dc56d89d97fd23edd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27c49ba917a1bc7025b0b84a335f89b3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a27c49ba917a1bc7025b0b84a335f89b3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>UINT16</b> = 8</td></tr>
<tr class="separator:a27c49ba917a1bc7025b0b84a335f89b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d076c5b58e1323f58702d4215e63d7d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1d076c5b58e1323f58702d4215e63d7d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>INT16</b> = 9</td></tr>
<tr class="separator:a1d076c5b58e1323f58702d4215e63d7d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f51332eb21b3ef9cd98cf83a874989a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3f51332eb21b3ef9cd98cf83a874989a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>INT64</b> = 10</td></tr>
<tr class="separator:a3f51332eb21b3ef9cd98cf83a874989a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa9db81c770a3f96afdf0a6d29c12516"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa9db81c770a3f96afdf0a6d29c12516"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>FLOAT16</b> = 12</td></tr>
<tr class="separator:aaa9db81c770a3f96afdf0a6d29c12516"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f8817388dd4ac982ba8e60ad571edcb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7f8817388dd4ac982ba8e60ad571edcb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>DOUBLE</b> = 13</td></tr>
<tr class="separator:a7f8817388dd4ac982ba8e60ad571edcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad78339bb265b9706d20a8dc7c9c1c7a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aad78339bb265b9706d20a8dc7c9c1c7a"></a>
shape input must be in CPU context&#160;</td><td class="memItemRight" valign="bottom"><b>min</b></td></tr>
<tr class="separator:aad78339bb265b9706d20a8dc7c9c1c7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf0a63db344299b542e0925101997d49"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abf0a63db344299b542e0925101997d49"></a>
max The range can be defined either by arguments or input blobs min and max are inclusive If the range is given by input you also need to give the shape as input When the range is given as&#160;</td><td class="memItemRight" valign="bottom"><b>arguments</b></td></tr>
<tr class="separator:abf0a63db344299b542e0925101997d49"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a232cee0f633d85ba6a1f302196cbd183"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a232cee0f633d85ba6a1f302196cbd183"></a>
its elements will be excluded from uniform sampling Using the second input will require you to provide shape via the first input DOC Maximum inclusive The shape of the output tensor Cannot set the shape argument and pass in an input at the same time tensor containing the desired output shape First input must be in CPU context&#160;</td><td class="memItemRight" valign="bottom"><b>avoid</b></td></tr>
<tr class="separator:a232cee0f633d85ba6a1f302196cbd183"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c3106fc05ed5c5d24fed2f9a08cb024"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c3106fc05ed5c5d24fed2f9a08cb024"></a>
if *input_as_shape *is set to *true then the *input *should be a tensor containing the desired output the *shape *argument should **not **be set *&#160;</td><td class="memItemRight" valign="bottom"><b>Note</b></td></tr>
<tr class="separator:a1c3106fc05ed5c5d24fed2f9a08cb024"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb35f7b3bb97822c1fc4a1a54b21e10e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adb35f7b3bb97822c1fc4a1a54b21e10e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>index</b></td></tr>
<tr class="separator:adb35f7b3bb97822c1fc4a1a54b21e10e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48184f626f27c032d0422bf8cbf662b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a48184f626f27c032d0422bf8cbf662b4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>query</b></td></tr>
<tr class="separator:a48184f626f27c032d0422bf8cbf662b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21ec1480e326f9bb7c54968127c5eb07"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a21ec1480e326f9bb7c54968127c5eb07"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>d_1</b></td></tr>
<tr class="separator:a21ec1480e326f9bb7c54968127c5eb07"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41432e174c316325bbff8153416d24ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a41432e174c316325bbff8153416d24ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>scale_bias_quantized_input</b></td></tr>
<tr class="separator:a41432e174c316325bbff8153416d24ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a618d0a8eacad49616dfb223e1bf5f574"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a618d0a8eacad49616dfb223e1bf5f574"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>bitwidth</b> = helper.GetSingleArgument&lt;int32_t&gt;(&quot;bitwidth&quot;, 8)</td></tr>
<tr class="separator:a618d0a8eacad49616dfb223e1bf5f574"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad175ed63638d0e619c5ad9bc4a9147a2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad175ed63638d0e619c5ad9bc4a9147a2"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><b>data_per_byte</b> = 8 / bitwidth</td></tr>
<tr class="separator:ad175ed63638d0e619c5ad9bc4a9147a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac08b30025c0b261115bbe5b29c5deed3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac08b30025c0b261115bbe5b29c5deed3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>quantized_input</b></td></tr>
<tr class="separator:ac08b30025c0b261115bbe5b29c5deed3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a651dcda2b97877111c70ae67faf39fc7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a651dcda2b97877111c70ae67faf39fc7"></a>
Fused&#160;</td><td class="memItemRight" valign="bottom"><b>tail</b></td></tr>
<tr class="separator:a651dcda2b97877111c70ae67faf39fc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d15ce97d784d0f058e0e4e8918a096b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9d15ce97d784d0f058e0e4e8918a096b"></a>
but operating on bit rowwise quantized matrices with fused uint8 tensor with rank obtained with&#160;</td><td class="memItemRight" valign="bottom"><b>OUTPUT</b></td></tr>
<tr class="separator:a9d15ce97d784d0f058e0e4e8918a096b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61505d0227fd9e5aa8ff89574a50440d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a61505d0227fd9e5aa8ff89574a50440d"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated&#160;</td><td class="memItemRight" valign="bottom"><b>boxes</b></td></tr>
<tr class="separator:a61505d0227fd9e5aa8ff89574a50440d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa387555929f783931a3daae73258f6a3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa387555929f783931a3daae73258f6a3"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi]&#160;</td><td class="memItemRight" valign="bottom"><b>scores</b></td></tr>
<tr class="separator:aa387555929f783931a3daae73258f6a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d9a6e8fd840dd3b73a424af28ae21a9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3d9a6e8fd840dd3b73a424af28ae21a9"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv&#160;</td><td class="memItemRight" valign="bottom"><b>layer</b></td></tr>
<tr class="separator:a3d9a6e8fd840dd3b73a424af28ae21a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f313fbecca7f6c6bb322357c323ddb2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1f313fbecca7f6c6bb322357c323ddb2"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv&#160;</td><td class="memItemRight" valign="bottom"><b>bbox_deltas</b></td></tr>
<tr class="separator:a1f313fbecca7f6c6bb322357c323ddb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f3297a2ee43eab9573a914561a4b9e4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f3297a2ee43eab9573a914561a4b9e4"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv&#160;</td><td class="memItemRight" valign="bottom"><b>im_info</b></td></tr>
<tr class="separator:a9f3297a2ee43eab9573a914561a4b9e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad29c13b7f40a60a67ed926087bae3094"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad29c13b7f40a60a67ed926087bae3094"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image&#160;</td><td class="memItemRight" valign="bottom"><b>info</b></td></tr>
<tr class="separator:ad29c13b7f40a60a67ed926087bae3094"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0416758737683535601832004392c108"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0416758737683535601832004392c108"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image&#160;</td><td class="memItemRight" valign="bottom"><b>anchors</b></td></tr>
<tr class="separator:a0416758737683535601832004392c108"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67eda2f21f59c5b7af3223c55519bcdf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a67eda2f21f59c5b7af3223c55519bcdf"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box&#160;</td><td class="memItemRight" valign="bottom"><b>rois</b></td></tr>
<tr class="separator:a67eda2f21f59c5b7af3223c55519bcdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac129a146337ac56a3bf187ba38f3ff22"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac129a146337ac56a3bf187ba38f3ff22"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box&#160;</td><td class="memItemRight" valign="bottom"><b>Proposals</b></td></tr>
<tr class="separator:ac129a146337ac56a3bf187ba38f3ff22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b22e1ac123bfdcc0ec84099f2a738ae"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6b22e1ac123bfdcc0ec84099f2a738ae"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box&#160;</td><td class="memItemRight" valign="bottom"><b>rois_probs</b></td></tr>
<tr class="separator:a6b22e1ac123bfdcc0ec84099f2a738ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52ec935b2e2696497ce9721cb21b2216"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a52ec935b2e2696497ce9721cb21b2216"></a>
bounding box regression result deltas as well as predefined bounding box shapes anchors Greedy non maximum suppression is applied to generate the final bounding boxes DOC int RPN_PRE_NMS_TOP_N float RPN_NMS_THRESH for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] for rotated angle is normalized to be within[angle_bound_lo, angle_bound_hi] Scores from conv Bounding box deltas from conv Image Bounding box scores of&#160;</td><td class="memItemRight" valign="bottom"><b>proposals</b></td></tr>
<tr class="separator:a52ec935b2e2696497ce9721cb21b2216"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa23aaba871f4578781eb651a109a2fd2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa23aaba871f4578781eb651a109a2fd2"></a>
*type depends on&#160;</td><td class="memItemRight" valign="bottom"><b>dtype</b></td></tr>
<tr class="separator:aa23aaba871f4578781eb651a109a2fd2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f6983994631763a3136899aae48027a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0f6983994631763a3136899aae48027a"></a>
in a sequence length aware fashion&#160;</td><td class="memItemRight" valign="bottom"><b>Concretely</b></td></tr>
<tr class="separator:a0f6983994631763a3136899aae48027a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79bbf8f3ec52ccd3913154c386b75a9e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79bbf8f3ec52ccd3913154c386b75a9e"></a>
in a sequence length aware fashion given the previous hidden and the sequence computes the GRU&#160;</td><td class="memItemRight" valign="bottom"><b>activations</b></td></tr>
<tr class="separator:a79bbf8f3ec52ccd3913154c386b75a9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5dd7a0d505d35c0cdeceae6e72bbf668"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5dd7a0d505d35c0cdeceae6e72bbf668"></a>
in a sequence length aware fashion given the previous hidden and the sequence computes the GRU avoiding computation if the input is Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length&#160;</td><td class="memItemRight" valign="bottom"><b>hidden</b></td></tr>
<tr class="separator:a5dd7a0d505d35c0cdeceae6e72bbf668"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4de84d17dee51f14a129bf538f6e5c95"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4de84d17dee51f14a129bf538f6e5c95"></a>
When&#160;</td><td class="memItemRight" valign="bottom"><b>false</b></td></tr>
<tr class="separator:a4de84d17dee51f14a129bf538f6e5c95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfe7a7bcf1a3cee70ba27814d3bd7ed7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abfe7a7bcf1a3cee70ba27814d3bd7ed7"></a>
When the sequence lengths input is left and all following inputs are shifted left by&#160;</td><td class="memItemRight" valign="bottom"><b>one</b></td></tr>
<tr class="separator:abfe7a7bcf1a3cee70ba27814d3bd7ed7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75af76b9adf6d15343f3c87937d96132"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a75af76b9adf6d15343f3c87937d96132"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed when condition is true&#160;</td><td class="memItemRight" valign="bottom"><b>condition</b></td></tr>
<tr class="separator:a75af76b9adf6d15343f3c87937d96132"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a847eef798ef168ce9c6d72fad07090f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a847eef798ef168ce9c6d72fad07090f3"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>pad</b> = helper.GetSingleArgument&lt;int&gt;(&quot;pad&quot;, 0)</td></tr>
<tr class="separator:a847eef798ef168ce9c6d72fad07090f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2b9abe1c69fb306a265046144f3c385"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><b>kernel_h</b></td></tr>
<tr class="separator:ac2b9abe1c69fb306a265046144f3c385"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaaed860c253cc3623218f5e049f56807"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><b>kernel_w</b></td></tr>
<tr class="separator:aaaed860c253cc3623218f5e049f56807"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6813549291034e22b8c23512190e36e1"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><b>dilation_h</b></td></tr>
<tr class="separator:a6813549291034e22b8c23512190e36e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a8bd7d72a9b3c36434015674bc13cd7"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><b>dilation_w</b></td></tr>
<tr class="separator:a0a8bd7d72a9b3c36434015674bc13cd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a433ab69df61deb5e78008f2017514433"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><b>stride_h</b></td></tr>
<tr class="separator:a433ab69df61deb5e78008f2017514433"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28f24cb994d9da9475e824cc5715772d"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><b>stride_w</b></td></tr>
<tr class="separator:a28f24cb994d9da9475e824cc5715772d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af099ee4ee7c78151eb49c18aa60795b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af099ee4ee7c78151eb49c18aa60795b4"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>N</b> = 0</td></tr>
<tr class="separator:af099ee4ee7c78151eb49c18aa60795b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e26b92169288a3179d57605789ac6c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0e26b92169288a3179d57605789ac6c3"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>C</b> = 0</td></tr>
<tr class="separator:a0e26b92169288a3179d57605789ac6c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a137953ba6204f3e8fd74ec54e2939c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a137953ba6204f3e8fd74ec54e2939c"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>H</b> = 0</td></tr>
<tr class="separator:a3a137953ba6204f3e8fd74ec54e2939c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18b3cae1f95c037dc6731761f8c960d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a18b3cae1f95c037dc6731761f8c960d4"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>W</b> = 0</td></tr>
<tr class="separator:a18b3cae1f95c037dc6731761f8c960d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1967cf82937108e793eb54b0b67f21b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1967cf82937108e793eb54b0b67f21b0"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>dkernel_h</b> = dilation_h * (kernel_h - 1) + 1</td></tr>
<tr class="separator:a1967cf82937108e793eb54b0b67f21b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af15994695a9f9cdadf3630c54ad6b80b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af15994695a9f9cdadf3630c54ad6b80b"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>dkernel_w</b> = dilation_w * (kernel_w - 1) + 1</td></tr>
<tr class="separator:af15994695a9f9cdadf3630c54ad6b80b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac949bdc75720d6d87772574ddfa39974"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac949bdc75720d6d87772574ddfa39974"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>out_h</b> = (H + 2 * pad - dkernel_h) / stride_h + 1</td></tr>
<tr class="separator:ac949bdc75720d6d87772574ddfa39974"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0262e3344411b113a3733e7bc902e2e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae0262e3344411b113a3733e7bc902e2e"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>out_w</b> = (W + 2 * pad - dkernel_w) / stride_w + 1</td></tr>
<tr class="separator:ae0262e3344411b113a3733e7bc902e2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4163bdb6c6ed9c3f5ca8a54ae7af557"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac4163bdb6c6ed9c3f5ca8a54ae7af557"></a>
Max number of&#160;</td><td class="memItemRight" valign="bottom"><b>elements</b></td></tr>
<tr class="separator:ac4163bdb6c6ed9c3f5ca8a54ae7af557"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c0a29cc27c9bbf99aa8d8f6676f5879"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1c0a29cc27c9bbf99aa8d8f6676f5879"></a>
return an Int tensor of same shape containing the indices for each of the keys If the index is&#160;</td><td class="memItemRight" valign="bottom"><b>frozen</b></td></tr>
<tr class="separator:a1c0a29cc27c9bbf99aa8d8f6676f5879"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96b458a9c12db9cd3c46e7dc915fa127"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96b458a9c12db9cd3c46e7dc915fa127"></a>
return an Int tensor of same shape containing the indices for each of the keys If the index is unknown entries are given index&#160;</td><td class="memItemRight" valign="bottom"><b>Otherwise</b></td></tr>
<tr class="separator:a96b458a9c12db9cd3c46e7dc915fa127"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32d2691bcb314721c42ac8efbf00d542"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32d2691bcb314721c42ac8efbf00d542"></a>
return an Int tensor of same shape containing the indices for each of the keys If the index is unknown entries are given index new entries are added into the index If an insert is necessary but max_elements has been&#160;</td><td class="memItemRight" valign="bottom"><b>reached</b></td></tr>
<tr class="separator:a32d2691bcb314721c42ac8efbf00d542"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add92182063935ff83c56d664bebe6cc6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="add92182063935ff83c56d664bebe6cc6"></a>
return an Int tensor of same shape containing the indices for each of the keys If the index is unknown entries are given index new entries are added into the index If an insert is necessary but max_elements has been fail DOC&#160;</td><td class="memItemRight" valign="bottom"><b>keys</b></td></tr>
<tr class="separator:add92182063935ff83c56d664bebe6cc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69b22611ea21528b9c509b99a53125d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a69b22611ea21528b9c509b99a53125d9"></a>
return an Int tensor of same shape containing the indices for each of the keys If the index is unknown entries are given index new entries are added into the index If an insert is necessary but max_elements has been fail DOC <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of keys to be looked up Output(0,&quot;indices&quot;,&quot;Indices for each of the keys.&quot;).ScalarType(TensorProto disallowing creation of new index entries Should not be called concurrently with IndexGet DOC&#160;</td><td class="memItemRight" valign="bottom"><b>handle</b></td></tr>
<tr class="separator:a69b22611ea21528b9c509b99a53125d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bd5f74034dd7155bb25a22d33d17f23"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4bd5f74034dd7155bb25a22d33d17f23"></a>
Pointer to an <a class="el" href="structcaffe2_1_1_index.html">Index</a> instance The input handle If skips the first entry of the tensor This allows to load tensors that are aligned with an&#160;</td><td class="memItemRight" valign="bottom"><b>embedding</b></td></tr>
<tr class="separator:a4bd5f74034dd7155bb25a22d33d17f23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7960ab3a5bdbf445c0cc1ea8bc90bb6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac7960ab3a5bdbf445c0cc1ea8bc90bb6"></a>
the first element of the output tensor will be element of index DOC&#160;</td><td class="memItemRight" valign="bottom"><b>items</b></td></tr>
<tr class="separator:ac7960ab3a5bdbf445c0cc1ea8bc90bb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af745269a12adbef5b49b2a3fdb4d8833"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af745269a12adbef5b49b2a3fdb4d8833"></a>
array of probabilities for prediction&#160;</td><td class="memItemRight" valign="bottom"><b>L</b></td></tr>
<tr class="separator:af745269a12adbef5b49b2a3fdb4d8833"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acaf33db75d197b55ae0da48da1e4cde0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acaf33db75d197b55ae0da48da1e4cde0"></a>
array of probabilities for prediction array of JSD&#160;</td><td class="memItemRight" valign="bottom"><b>losses</b></td></tr>
<tr class="separator:acaf33db75d197b55ae0da48da1e4cde0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96c21a1fa027620da6bc066dfabde121"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96c21a1fa027620da6bc066dfabde121"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>INT_MAX</b></td></tr>
<tr class="separator:a96c21a1fa027620da6bc066dfabde121"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6875db97deb54ba11f0eea9b6ef95a84"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6875db97deb54ba11f0eea9b6ef95a84"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>input_dims_long</b> = GetDimsVector(in[0])</td></tr>
<tr class="separator:a6875db97deb54ba11f0eea9b6ef95a84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a833087f682593970e7914e0992e5d3df"><td class="memItemLeft" align="right" valign="top">const auto&#160;</td><td class="memItemRight" valign="bottom"><b>canonical_axis</b></td></tr>
<tr class="separator:a833087f682593970e7914e0992e5d3df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a911530d63403fd44caea8f537859fe11"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a911530d63403fd44caea8f537859fe11"></a>
default and produces one output tensor $Y of the same shape as $X The op performs the element wise leaky relu&#160;</td><td class="memItemRight" valign="bottom"><b>operation</b></td></tr>
<tr class="separator:a911530d63403fd44caea8f537859fe11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e67c8232891b780cc64ca7be7d1bd45"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8e67c8232891b780cc64ca7be7d1bd45"></a>
default and produces one output tensor $Y of the same shape as $X The op performs the element wise leaky relu defined as&#160;</td><td class="memItemRight" valign="bottom"><b>$$y</b></td></tr>
<tr class="separator:a8e67c8232891b780cc64ca7be7d1bd45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a851ffcb82bd8d747c0b35f206204096a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a851ffcb82bd8d747c0b35f206204096a"></a>
default and produces one output tensor $Y of the same shape as $X The op performs the element wise leaky relu defined as calculated as described&#160;</td><td class="memItemRight" valign="bottom"><b>above</b></td></tr>
<tr class="separator:a851ffcb82bd8d747c0b35f206204096a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a235ebb5556d3d43af388e63a961e9451"><td class="memItemLeft" align="right" valign="top">and LENGTHS tensor of&#160;</td><td class="memItemRight" valign="bottom"><b>rank</b></td></tr>
<tr class="separator:a235ebb5556d3d43af388e63a961e9451"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89f1e357cdb07194593060cafe463b6b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a89f1e357cdb07194593060cafe463b6b"></a>
and LENGTHS tensor of pad each segment in DATA with so that each segment s length is target_length If will&#160;</td><td class="memItemRight" valign="bottom"><b>throw</b></td></tr>
<tr class="separator:a89f1e357cdb07194593060cafe463b6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41a0db4af58de5f768499e496ab7a29c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a41a0db4af58de5f768499e496ab7a29c"></a>
and LENGTHS tensor of pad each segment in DATA with so that each segment s length is target_length If will if there is segment of length larger than target_length&#160;</td><td class="memItemRight" valign="bottom"><b>Example</b></td></tr>
<tr class="separator:a41a0db4af58de5f768499e496ab7a29c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad15db7db5c2b5cf0082bdcbeefcc1bad"><td class="memItemLeft" align="right" valign="top">and LENGTHS tensor of pad each segment in DATA with so that each segment s length is target_length If will if there is segment of length larger than target_length&#160;</td><td class="memItemRight" valign="bottom"><b>LENGTHS</b></td></tr>
<tr class="separator:ad15db7db5c2b5cf0082bdcbeefcc1bad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace4229baf718cdcd2b521072b76e6d20"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ace4229baf718cdcd2b521072b76e6d20"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>where</b></td></tr>
<tr class="separator:ace4229baf718cdcd2b521072b76e6d20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66bb3ba7ee844f730e23652a0ca2709b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a66bb3ba7ee844f730e23652a0ca2709b"></a>
for each&#160;</td><td class="memItemRight" valign="bottom"><b>row</b></td></tr>
<tr class="separator:a66bb3ba7ee844f730e23652a0ca2709b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68dee1f813e0a2b14f01b798c73ae7ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a68dee1f813e0a2b14f01b798c73ae7ad"></a>
for each weights are accessed by&#160;</td><td class="memItemRight" valign="bottom"><b>indices</b> [0..L-1]</td></tr>
<tr class="separator:a68dee1f813e0a2b14f01b798c73ae7ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac41f13aba2e12c4803893511e03fc1ee"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac41f13aba2e12c4803893511e03fc1ee"></a>
for each weights are accessed by where L is the length of given row This is basically a fused&#160;</td><td class="memItemRight" valign="bottom"><b>WEIGHT</b></td></tr>
<tr class="separator:ac41f13aba2e12c4803893511e03fc1ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c9e2f0278e53e88e0f348c494ebc8cf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c9e2f0278e53e88e0f348c494ebc8cf"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;::LENGTHS uint8 tensor obtained with&#160;</td><td class="memItemRight" valign="bottom"><b>INDICES</b></td></tr>
<tr class="separator:a9c9e2f0278e53e88e0f348c494ebc8cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91c2dfe5a9d8de6c3b2fd3ca57dd3332"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a91c2dfe5a9d8de6c3b2fd3ca57dd3332"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;::LENGTHS uint8 tensor obtained with Integer vector containing indices of the first dimension of DATA for the slices that are being aggregated&#160;</td><td class="memItemRight" valign="bottom"><b>scale_bias</b></td></tr>
<tr class="separator:a91c2dfe5a9d8de6c3b2fd3ca57dd3332"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af09be0e596aea8ce09cb0099750d191c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af09be0e596aea8ce09cb0099750d191c"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;::LENGTHS uint8 tensor obtained with Integer vector containing indices of the first dimension of DATA for the slices that are being aggregated Matrix of&#160;</td><td class="memItemRight" valign="bottom"><b>floats</b></td></tr>
<tr class="separator:af09be0e596aea8ce09cb0099750d191c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b040cfcb4ddc8e0c69f9c98af9ef30a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8b040cfcb4ddc8e0c69f9c98af9ef30a"></a>
NumInputs(4).NumOutputs(1).ValueLengthInputFillers(<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; <a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1 &gt;::LENGTHS uint8 tensor obtained with Integer vector containing indices of the first dimension of DATA for the slices that are being aggregated Matrix of each row r_i of which stores a pair&#160;</td><td class="memItemRight" valign="bottom"><b>s_i</b></td></tr>
<tr class="separator:a8b040cfcb4ddc8e0c69f9c98af9ef30a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a646ea3bb5dade3085048a79112314374"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a646ea3bb5dade3085048a79112314374"></a>
<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 0, 1 &gt;::LENGTHS&#160;</td><td class="memItemRight" valign="bottom"><b>SetDoc</b> (R&quot;DOC(
Variation of SparseLengthsMean operator, where DATA is
stored using 8bits. DATA was quantized with 8Bit row-wise
quantization (see doc to FloatToRowwiseQuantized8Bits operator). To
restore DATA from 8Bit, we use additional input that stores scales
and biases.
)DOC&quot;).Input(0</td></tr>
<tr class="separator:a646ea3bb5dade3085048a79112314374"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada0d014fd88f397e697620159dbab2c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada0d014fd88f397e697620159dbab2c1"></a>
<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 0, 1 &gt;::LENGTHS uint8 tensor obtained with&#160;</td><td class="memItemRight" valign="bottom"><b>operator FloatToRowwiseQuantized8Bits&quot;) .Input</b> (1,&quot;INDICES&quot;,&quot;Integer vector containing indices of the first &quot;&quot;dimension of DATA for the slices that are being aggregated&quot;).Input(2</td></tr>
<tr class="separator:ada0d014fd88f397e697620159dbab2c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2cdb178e8438b60a42ea3e7d77f1d61e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2cdb178e8438b60a42ea3e7d77f1d61e"></a>
<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 0, 1 &gt;::LENGTHS uint8 tensor obtained with Vector with the same sum of elements as the first dimension of DATA&#160;</td><td class="memItemRight" valign="bottom"><b>Input</b> (3,&quot;scale_bias&quot;,&quot;Matrix of floats, each row r_i of which stores a pair &quot;&quot;s_i, b_i -- scale and bias for i-th row&quot;).Output(0</td></tr>
<tr class="separator:a2cdb178e8438b60a42ea3e7d77f1d61e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc4641f8f2900f3433237c2a8a4b2c56"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afc4641f8f2900f3433237c2a8a4b2c56"></a>
<a class="el" href="classcaffe2_1_1_sparse_lengths8_bits_rowwise_op.html">SparseLengths8BitsRowwiseOp</a>&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a>, 1, 1 &gt;::LENGTHS uint8 tensor obtained with Integer vector containing indices of the first dimension of DATA for the slices that are being aggregated Matrix of each row r_i of which stores a pair b_i scale and bias for i th row&#160;</td><td class="memItemRight" valign="bottom"><b>Output</b> (0,&quot;output&quot;,&quot;output&quot;)</td></tr>
<tr class="separator:afc4641f8f2900f3433237c2a8a4b2c56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af87e96d4c7b59961d67e39a6b1c8b84c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af87e96d4c7b59961d67e39a6b1c8b84c"></a>
where segments are defined by their and concatenate them in an output tensor of the output value will be padded and the corresponding output indices will be padded by DOC <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of int32 lengths of rank&#160;</td><td class="memItemRight" valign="bottom"><b>TopKIndices</b></td></tr>
<tr class="separator:af87e96d4c7b59961d67e39a6b1c8b84c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60c0409f42dded674f448d39a4ab5403"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a60c0409f42dded674f448d39a4ab5403"></a>
default save the db directly to the path specified by the db arg If not prepend the path of the current root folder of the workspace to the path specified by the db arg characters that precede strip_prefix will be removed Useful for removing device scope from blob names&#160;</td><td class="memItemRight" valign="bottom"><b>leveldb</b></td></tr>
<tr class="separator:a60c0409f42dded674f448d39a4ab5403"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23178e219ebb5c0c71a6c83f8b7c2484"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a23178e219ebb5c0c71a6c83f8b7c2484"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>__pad2__</b></td></tr>
<tr class="separator:a23178e219ebb5c0c71a6c83f8b7c2484"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5f5fe4728e1b8a42ff90c79dbb7c11a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad5f5fe4728e1b8a42ff90c79dbb7c11a"></a>
but allows one to save to db every few&#160;</td><td class="memItemRight" valign="bottom"><b>iterations</b></td></tr>
<tr class="separator:ad5f5fe4728e1b8a42ff90c79dbb7c11a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b114b4d3dc83a14ff4a3772128120cd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8b114b4d3dc83a14ff4a3772128120cd"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>__pad3__</b></td></tr>
<tr class="separator:a8b114b4d3dc83a14ff4a3772128120cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73c61110ed40d8c2df55eeb60b4f7e7a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a73c61110ed40d8c2df55eeb60b4f7e7a"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>__pad4__</b></td></tr>
<tr class="separator:a73c61110ed40d8c2df55eeb60b4f7e7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a506c9d08d68a046d4184263c7add9075"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a506c9d08d68a046d4184263c7add9075"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>Y_scale</b></td></tr>
<tr class="separator:a506c9d08d68a046d4184263c7add9075"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae70c28fcaca447577f627519c386d10c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae70c28fcaca447577f627519c386d10c"></a>
stride&#160;</td><td class="memItemRight" valign="bottom"><b>sizes</b></td></tr>
<tr class="separator:ae70c28fcaca447577f627519c386d10c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a904decf29795a6e42dbc64d5c7d7f5bc"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a904decf29795a6e42dbc64d5c7d7f5bc"></a>
stride pad lengths and dilation $L_p pooling consists of taking the $L_p norm of a subset of the input tensor according to the kernel size and downsampling the data into the output blob for further processing Pooling layers reduce the spatial dimensionality of the input blob Each of the output blob s dimensions will reduce according&#160;</td><td class="memItemRight" valign="bottom"><b>kernel</b> =2</td></tr>
<tr class="separator:a904decf29795a6e42dbc64d5c7d7f5bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c2ecff80474db82c9f0560c13dd9dc4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6c2ecff80474db82c9f0560c13dd9dc4"></a>
stride pad lengths and dilation $L_p pooling consists of taking the $L_p norm of a subset of the input tensor according to the kernel size and downsampling the data into the output blob for further processing Pooling layers reduce the spatial dimensionality of the input blob Each of the output blob s dimensions will reduce according&#160;</td><td class="memItemRight" valign="bottom"><b>p</b></td></tr>
<tr class="separator:a6c2ecff80474db82c9f0560c13dd9dc4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f4e1dcf835af307ea11384652dabf66"><td class="memItemLeft" align="right" valign="top">and label is applied to the tensor elementwise If&#160;</td><td class="memItemRight" valign="bottom"><b>y</b></td></tr>
<tr class="separator:a4f4e1dcf835af307ea11384652dabf66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a332cb22714eba8bb0fdef14c34030d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7a332cb22714eba8bb0fdef14c34030d"></a>
<a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a>&#160;</td><td class="memItemRight" valign="bottom"><b>arg_helper</b> (def)</td></tr>
<tr class="separator:a7a332cb22714eba8bb0fdef14c34030d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdbc7a0971315979347ee50dd9b153b2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afdbc7a0971315979347ee50dd9b153b2"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>axis_a</b> = arg_helper.GetSingleArgument&lt;int&gt;(&quot;axis_a&quot;, 1)</td></tr>
<tr class="separator:afdbc7a0971315979347ee50dd9b153b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a974f589c507849a1391d7dc6d652795d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a974f589c507849a1391d7dc6d652795d"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>axis_b</b> = arg_helper.GetSingleArgument&lt;int&gt;(&quot;axis_b&quot;, 1)</td></tr>
<tr class="separator:a974f589c507849a1391d7dc6d652795d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebecc3bf57cafeb8faa1a924893b6e3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aebecc3bf57cafeb8faa1a924893b6e3e"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>trans_a</b> = arg_helper.GetSingleArgument&lt;bool&gt;(&quot;trans_a&quot;, false)</td></tr>
<tr class="separator:aebecc3bf57cafeb8faa1a924893b6e3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7cae62b6a05427609c18f31bde7b452a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7cae62b6a05427609c18f31bde7b452a"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>trans_b</b> = arg_helper.GetSingleArgument&lt;bool&gt;(&quot;trans_b&quot;, false)</td></tr>
<tr class="separator:a7cae62b6a05427609c18f31bde7b452a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88a445908fa33836b816544f0bf3c4c1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a88a445908fa33836b816544f0bf3c4c1"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>canonical_axis_a</b> = canonical_axis_index_(axis_a, in[0].dims().size())</td></tr>
<tr class="separator:a88a445908fa33836b816544f0bf3c4c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29606596277dd30518b88d66b63c4979"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29606596277dd30518b88d66b63c4979"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>canonical_axis_b</b> = canonical_axis_index_(axis_b, in[0].dims().size())</td></tr>
<tr class="separator:a29606596277dd30518b88d66b63c4979"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4e2e5c8558cda69f8bafb2036237910"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4e2e5c8558cda69f8bafb2036237910"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>M</b> = size_to_dim_(canonical_axis_a, GetDimsVector(in[0]))</td></tr>
<tr class="separator:aa4e2e5c8558cda69f8bafb2036237910"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2644f95545e21d24eb935c9dff1b5892"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2644f95545e21d24eb935c9dff1b5892"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>A</b></td></tr>
<tr class="separator:a2644f95545e21d24eb935c9dff1b5892"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a331b75476c82799af066b8ee184f602e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a331b75476c82799af066b8ee184f602e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>B</b></td></tr>
<tr class="separator:a331b75476c82799af066b8ee184f602e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94a5e77e784c19120ec7c2da8b59429b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a94a5e77e784c19120ec7c2da8b59429b"></a>
then the resulted tensor have the reduced dimension pruned DOC Keep the reduced default True keeps the reduced An input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>variance</b></td></tr>
<tr class="separator:a94a5e77e784c19120ec7c2da8b59429b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a972833e2089ab4cb0b33f5e9d43b7e3c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a972833e2089ab4cb0b33f5e9d43b7e3c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>prediction</b></td></tr>
<tr class="separator:a972833e2089ab4cb0b33f5e9d43b7e3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a594cf996b8817ed8d72c760e8e9c804b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a594cf996b8817ed8d72c760e8e9c804b"></a>
<a class="el" href="struct_d.html">D</a> float i&#160;</td><td class="memItemRight" valign="bottom"><b>e</b></td></tr>
<tr class="separator:a594cf996b8817ed8d72c760e8e9c804b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b699a0901714ff53746bce0243dd643"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1b699a0901714ff53746bce0243dd643"></a>
<a class="el" href="struct_d.html">D</a> float i batch size <a class="el" href="struct_d.html">D</a> is number of possible classes labels&#160;</td><td class="memItemRight" valign="bottom"><b>accuracies</b></td></tr>
<tr class="separator:a1b699a0901714ff53746bce0243dd643"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bcd9c1d66f538e1000206e7b9b26574"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8bcd9c1d66f538e1000206e7b9b26574"></a>
axis to&#160;</td><td class="memItemRight" valign="bottom"><b>normalize</b></td></tr>
<tr class="separator:a8bcd9c1d66f538e1000206e7b9b26574"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4a042f321e9ae055cd8f23e049c306f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af4a042f321e9ae055cd8f23e049c306f"></a>
The input tensor&#160;</td><td class="memItemRight" valign="bottom"><b>tiled_data</b></td></tr>
<tr class="separator:af4a042f321e9ae055cd8f23e049c306f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2d8e2afab331be309bb4e0558eda875"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2d8e2afab331be309bb4e0558eda875"></a>
bucketize it based on the boundary values and then do one hot encoding The lengths specifies the number of boundary values for each column The final number of buckets is this number plus This would also be the expanded feature size boundaries specifies all the boundary values Note that each bucket is right inclusive That given boundary&#160;</td><td class="memItemRight" valign="bottom"><b>values</b> [b1, b2, b3]</td></tr>
<tr class="separator:ac2d8e2afab331be309bb4e0558eda875"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a063d5c012a746ae3f0607cd8e9918d6f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a063d5c012a746ae3f0607cd8e9918d6f"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed on each iteration Whether to use the condition input Do not create new scopes Use this only if you re certain there will be no name&#160;</td><td class="memItemRight" valign="bottom"><b>collision</b></td></tr>
<tr class="separator:a063d5c012a746ae3f0607cd8e9918d6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3922066fe591721dca3dfe765afecb6d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3922066fe591721dca3dfe765afecb6d"></a>
INT_MAX <a class="el" href="struct_net.html">Net</a> executed on each iteration Whether to use the condition input Do not create new scopes Use this only if you re certain there will be no name for example if you re converting from a fully SSA IR&#160;</td><td class="memItemRight" valign="bottom"><b>max_trip_count</b></td></tr>
<tr class="separator:a3922066fe591721dca3dfe765afecb6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6c795ac7b5679d106913d1e43f1ede8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af6c795ac7b5679d106913d1e43f1ede8"></a>
d int long tensor contains the length in each of the output&#160;</td><td class="memItemRight" valign="bottom"><b>packed_tensor</b></td></tr>
<tr class="separator:af6c795ac7b5679d106913d1e43f1ede8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d058cb2d3aecab8aa693b25b1e7ab33"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d058cb2d3aecab8aa693b25b1e7ab33"></a>
d int long tensor contains the length in each of the output N dim <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> where&#160;</td><td class="memItemRight" valign="bottom"><b>presence_mask</b></td></tr>
<tr class="separator:a4d058cb2d3aecab8aa693b25b1e7ab33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a582a59c237d9eb43bcbf72d14b26269e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a582a59c237d9eb43bcbf72d14b26269e"></a>
d int long tensor contains the length in each of the output N dim <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> where dim boolean false where packed_tensor is&#160;</td><td class="memItemRight" valign="bottom"><b>padded</b></td></tr>
<tr class="separator:a582a59c237d9eb43bcbf72d14b26269e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e0590dbfdc9979736726c12dc0f86f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1e0590dbfdc9979736726c12dc0f86f4"></a>
d int long tensor contains the length in each of the output N dim <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> where dim boolean false where packed_tensor is true otherwise Padding number in the packed segments Use true to pad&#160;</td><td class="memItemRight" valign="bottom"><b>infinity</b></td></tr>
<tr class="separator:a1e0590dbfdc9979736726c12dc0f86f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae44dcb44f4ea48621f7963d6e79a4e86"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae44dcb44f4ea48621f7963d6e79a4e86"></a>
CPUContext::PadTensorInference Input data tensor from the previous&#160;</td><td class="memItemRight" valign="bottom"><b>operator</b></td></tr>
<tr class="separator:ae44dcb44f4ea48621f7963d6e79a4e86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba0a98ae5bc51ac68c5fecf74846a08d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aba0a98ae5bc51ac68c5fecf74846a08d"></a>
dimensions depend on whether the NCHW or NHWC operators are being used For in the&#160;</td><td class="memItemRight" valign="bottom"><b>former</b></td></tr>
<tr class="separator:aba0a98ae5bc51ac68c5fecf74846a08d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c7c833e2736e911486d1edf12767063"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c7c833e2736e911486d1edf12767063"></a>
dimensions depend on whether the NCHW or NHWC operators are being used For in the the input has where N is the batch <a class="el" href="struct_c.html">C</a> is the number of&#160;</td><td class="memItemRight" valign="bottom"><b>channels</b></td></tr>
<tr class="separator:a3c7c833e2736e911486d1edf12767063"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa1f4eca0104e94278a74f4ef8e73e3f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa1f4eca0104e94278a74f4ef8e73e3f"></a>
given a sample set of raw labeled with their corresponding percentiles from the same distribution In&#160;</td><td class="memItemRight" valign="bottom"><b>particular</b></td></tr>
<tr class="separator:aaa1f4eca0104e94278a74f4ef8e73e3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a781301c4e85af233a6284cd73a386a90"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a781301c4e85af233a6284cd73a386a90"></a>
given a sample set of raw labeled with their corresponding percentiles from the same distribution In this&#160;</td><td class="memItemRight" valign="bottom"><b>value_to_pct</b></td></tr>
<tr class="separator:a781301c4e85af233a6284cd73a386a90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a000385437867c1c3d0c350bb31799f8a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a000385437867c1c3d0c350bb31799f8a"></a>
given a sample set of raw labeled with their corresponding percentiles from the same distribution In this Sorted with columns Each element in the first column is a float representing the raw value of a sample Its corresponding element in the next column represents the percentile it maps to&#160;</td><td class="memItemRight" valign="bottom"><b>percentile_values</b></td></tr>
<tr class="separator:a000385437867c1c3d0c350bb31799f8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed6e93b181e5889e7dcc8f3c9de22d97"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed6e93b181e5889e7dcc8f3c9de22d97"></a>
given a sample set of raw labeled with their corresponding percentiles from the same distribution In this Sorted with columns Each element in the first column is a float representing the raw value of a sample Its corresponding element in the next column represents the percentile it maps to tensor of with the same dimensions as the flattened input tensor Each element of this corresponds to the percentile calculated for&#160;</td><td class="memItemRight" valign="bottom"><b>original_values</b> [i]</td></tr>
<tr class="separator:aed6e93b181e5889e7dcc8f3c9de22d97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06e77cee7ed8c180ee4ac48a93e6af07"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a06e77cee7ed8c180ee4ac48a93e6af07"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>probabilities</b></td></tr>
<tr class="separator:a06e77cee7ed8c180ee4ac48a93e6af07"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaeb88ea06e7c7786f7fccf89856c939b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaeb88ea06e7c7786f7fccf89856c939b"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x&#160;</td><td class="memItemRight" valign="bottom"><b>prediction_dimensions</b></td></tr>
<tr class="separator:aaeb88ea06e7c7786f7fccf89856c939b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe0dd04e683afcc83fca64b8cdb7f2d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe0dd04e683afcc83fca64b8cdb7f2d4"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each&#160;</td><td class="memItemRight" valign="bottom"><b>piece</b></td></tr>
<tr class="separator:afe0dd04e683afcc83fca64b8cdb7f2d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae07067d0cf60007501b36e4723269c04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae07067d0cf60007501b36e4723269c04"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each low bound is excluded while high bound is included Also the piecewise linear function must be continuous Notes If the input is binary set the binary arg to true so that one group of piecewise linear functions is&#160;</td><td class="memItemRight" valign="bottom"><b>slopes</b></td></tr>
<tr class="separator:ae07067d0cf60007501b36e4723269c04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae44d0d1acf67e19a840413070a7ff482"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae44d0d1acf67e19a840413070a7ff482"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each low bound is excluded while high bound is included Also the piecewise linear function must be continuous Notes If the input is binary set the binary arg to true so that one group of piecewise linear functions is intercepts can be passed either through args or through input blobs If we have multiple groups of piecewise linear&#160;</td><td class="memItemRight" valign="bottom"><b>functions</b></td></tr>
<tr class="separator:ae44d0d1acf67e19a840413070a7ff482"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c055b4bef5e52acb925112a7e4bae8d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5c055b4bef5e52acb925112a7e4bae8d"></a>
a <a class="el" href="struct_d.html">D</a> or <a class="el" href="struct_d.html">D</a> slopes and intercepts The output tensor has the same shape of input predictions and contains the predictions transformed by the piecewise linear functions Each column of predictions has its own piecewise linear transformation functions Therefore the size of piecewise function parameters are pieces x except for binary predictions where only the positive prediction needs them Note that in each low bound is excluded while high bound is included Also the piecewise linear function must be continuous Notes If the input is binary set the binary arg to true so that one group of piecewise linear functions is intercepts can be passed either through args or through input blobs If we have multiple groups of piecewise linear each group has the same number of pieces If a prediction is out of the&#160;</td><td class="memItemRight" valign="bottom"><b>bounds</b></td></tr>
<tr class="separator:a5c055b4bef5e52acb925112a7e4bae8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bfed66a4f3b0f3f07c77461837e1865"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3bfed66a4f3b0f3f07c77461837e1865"></a>
constexpr char&#160;</td><td class="memItemRight" valign="bottom"><b>kAveragePoolDoc</b> []</td></tr>
<tr class="separator:a3bfed66a4f3b0f3f07c77461837e1865"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee13b107bf2340cf21eee84ef7193bb8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aee13b107bf2340cf21eee84ef7193bb8"></a>
constexpr char&#160;</td><td class="memItemRight" valign="bottom"><b>kMaxPoolDoc</b> []</td></tr>
<tr class="separator:aee13b107bf2340cf21eee84ef7193bb8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10f13eb8a80fdc489841c30ff4130079"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a10f13eb8a80fdc489841c30ff4130079"></a>
an input slope tensor&#160;</td><td class="memItemRight" valign="bottom"><b>$slope</b></td></tr>
<tr class="separator:a10f13eb8a80fdc489841c30ff4130079"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab38622f3a117a3be97d277a6f396756"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aab38622f3a117a3be97d277a6f396756"></a>
Size of the dimension to prepend&#160;</td><td class="memItemRight" valign="bottom"><b>reshaped</b></td></tr>
<tr class="separator:aab38622f3a117a3be97d277a6f396756"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbe907919cbfb48b8da725092d98d93d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adbe907919cbfb48b8da725092d98d93d"></a>
Output tensor quantization offset First&#160;</td><td class="memItemRight" valign="bottom"><b>operand</b></td></tr>
<tr class="separator:adbe907919cbfb48b8da725092d98d93d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53f27d89a4b3456a96d1161906f4bc2f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a53f27d89a4b3456a96d1161906f4bc2f"></a>
Output tensor quantization offset First should share the type with the second operand&#160;</td><td class="memItemRight" valign="bottom"><b>Result</b></td></tr>
<tr class="separator:a53f27d89a4b3456a96d1161906f4bc2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5494970aaaedf6895222529c8afdd60"><td class="memItemLeft" align="right" valign="top">const char&#160;</td><td class="memItemRight" valign="bottom"><b>kAveragePoolDoc_int8</b> []</td></tr>
<tr class="separator:af5494970aaaedf6895222529c8afdd60"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adaddb3f06a9d40edcac2a7081435cfda"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adaddb3f06a9d40edcac2a7081435cfda"></a>
Output tensor quantization offset Pass to add the axis specified in arg axis to all input tensors&#160;</td><td class="memItemRight" valign="bottom"><b>concat_result</b></td></tr>
<tr class="separator:adaddb3f06a9d40edcac2a7081435cfda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac92a1dd732464903fd5fd2171374ae94"><td class="memItemLeft" align="right" valign="top">const char&#160;</td><td class="memItemRight" valign="bottom"><b>kConvDoc_int8</b> []</td></tr>
<tr class="separator:ac92a1dd732464903fd5fd2171374ae94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5df8dca841b47b03838cde5f92c5eea1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5df8dca841b47b03838cde5f92c5eea1"></a>
Output tensor quantization scale the filter&#160;</td><td class="memItemRight" valign="bottom"><b>blob</b></td></tr>
<tr class="separator:a5df8dca841b47b03838cde5f92c5eea1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92f0a5042f1b1d6acad1cb2f0cb8f833"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92f0a5042f1b1d6acad1cb2f0cb8f833"></a>
Output tensor quantization scale the filter and the bias and computes the output Note that other&#160;</td><td class="memItemRight" valign="bottom"><b>parameters</b></td></tr>
<tr class="separator:a92f0a5042f1b1d6acad1cb2f0cb8f833"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9cdda7a6dc791abcb72daa0a81cb9414"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9cdda7a6dc791abcb72daa0a81cb9414"></a>
Output tensor quantization scale the filter and the bias and computes the output Note that other such as the stride and kernel or the pads sizes in each direction are not necessary for input because they are provided by the ConvTransposeUnpoolOpBase&#160;</td><td class="memItemRight" valign="bottom"><b>operator.Various dimension checks are done
implicitly, and the sizes are specified in the Input docs for this operator.As is expected, the filter is deconvolved with a subset of the
image and the bias is added</b></td></tr>
<tr class="separator:a9cdda7a6dc791abcb72daa0a81cb9414"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afef7c7e01c62304c3bf69c8a3e290385"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afef7c7e01c62304c3bf69c8a3e290385"></a>
this is done throughout the image data and the output is computed As a side note on the implementation&#160;</td><td class="memItemRight" valign="bottom"><b>layout</b></td></tr>
<tr class="separator:afef7c7e01c62304c3bf69c8a3e290385"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adabbb26e87550ec50e4874868f1df0ff"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="adabbb26e87550ec50e4874868f1df0ff"></a>
this is done throughout the image data and the output is computed As a side note on the implementation which is why they are separate files DOC&#160;</td><td class="memItemRight" valign="bottom"><b>filter</b></td></tr>
<tr class="separator:adabbb26e87550ec50e4874868f1df0ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2ab97ebf48d649cd50b121b6890658b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af2ab97ebf48d649cd50b121b6890658b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>qX</b></td></tr>
<tr class="separator:af2ab97ebf48d649cd50b121b6890658b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16c2439e693d3e6737478637555ac966"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a16c2439e693d3e6737478637555ac966"></a>
Coefficient of&#160;</td><td class="memItemRight" valign="bottom"><b>leakage</b></td></tr>
<tr class="separator:a16c2439e693d3e6737478637555ac966"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af831fa1c3d4b8a60be92d0cda9f24e22"><td class="memItemLeft" align="right" valign="top">const char&#160;</td><td class="memItemRight" valign="bottom"><b>kMaxPoolDoc_int8</b> []</td></tr>
<tr class="separator:af831fa1c3d4b8a60be92d0cda9f24e22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab66e575cd397fee1dd78bd1a4e79923d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab66e575cd397fee1dd78bd1a4e79923d"></a>
New shape Output tensor quantization offset&#160;</td><td class="memItemRight" valign="bottom"><b>new_shape</b></td></tr>
<tr class="separator:ab66e575cd397fee1dd78bd1a4e79923d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e8336f10b0e17aea02bd93bfe2ceb2c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e8336f10b0e17aea02bd93bfe2ceb2c"></a>
New shape Output tensor quantization offset New shape&#160;</td><td class="memItemRight" valign="bottom"><b>old_shape</b></td></tr>
<tr class="separator:a4e8336f10b0e17aea02bd93bfe2ceb2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8abb08815ed2b537572b7770bfbef4d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae8abb08815ed2b537572b7770bfbef4d"></a>
Spatial scale of the input feature map X relative to the input image <a class="el" href="struct_e.html">E</a>&#160;</td><td class="memItemRight" valign="bottom"><b>g</b></td></tr>
<tr class="separator:ae8abb08815ed2b537572b7770bfbef4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9115771c8c914cda9be537c1ec39e402"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9115771c8c914cda9be537c1ec39e402"></a>
Pooled output Y s width Int8 <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> feature map input of&#160;</td><td class="memItemRight" valign="bottom"><b>RoIs</b></td></tr>
<tr class="separator:a9115771c8c914cda9be537c1ec39e402"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af96894028253b5436881789e477c8a8d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af96894028253b5436881789e477c8a8d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>rather</b></td></tr>
<tr class="separator:af96894028253b5436881789e477c8a8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a077430ccb977be73e84c36d8b748b997"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a077430ccb977be73e84c36d8b748b997"></a>
it will be coerced into one For an arbitrary n dimensional tensor X in[a_0, a_1,..., a_{k-1}, a_k,..., a_{n-1}] and k is the axis then X will be coerced into a dimensional tensor with dimensions[a_0 *...*a_{k-1}, a_k *...*a_{n-1}] For the default case where this means the X tensor will be coerced into a tensor of&#160;</td><td class="memItemRight" valign="bottom"><b>dimensions</b> [a_0, a_1 *...*a_{n-1}] =1</td></tr>
<tr class="separator:a077430ccb977be73e84c36d8b748b997"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa831d9779cdb324a6b77fb25fb81a7c3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa831d9779cdb324a6b77fb25fb81a7c3"></a>
it will be coerced into one For an arbitrary n dimensional tensor X in[a_0, a_1,..., a_{k-1}, a_k,..., a_{n-1}] and k is the axis then X will be coerced into a dimensional tensor with dimensions[a_0 *...*a_{k-1}, a_k *...*a_{n-1}] For the default case where this means the X tensor will be coerced into a tensor of where a_0 is often the batch size In this&#160;</td><td class="memItemRight" valign="bottom"><b>situation</b></td></tr>
<tr class="separator:aa831d9779cdb324a6b77fb25fb81a7c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34174f2652b1ceed8b21e82dc5401de4"><td class="memItemLeft" align="right" valign="top">it will be coerced into one For an arbitrary n dimensional tensor X in[a_0, a_1,..., a_{k-1}, a_k,..., a_{n-1}] and k is the axis then X will be coerced into a dimensional tensor with dimensions[a_0 *...*a_{k-1}, a_k *...*a_{n-1}] For the default case where this means the X tensor will be coerced into a tensor of where a_0 is often the batch size In this we must have&#160;</td><td class="memItemRight" valign="bottom"><b>a_0</b></td></tr>
<tr class="separator:a34174f2652b1ceed8b21e82dc5401de4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac23c1c4df253d068261b0432516b2697"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac23c1c4df253d068261b0432516b2697"></a>
int can be&#160;</td><td class="memItemRight" valign="bottom"><b>passed</b></td></tr>
<tr class="separator:ac23c1c4df253d068261b0432516b2697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8aa00a8803f6fa1a99346beb2aadd17c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8aa00a8803f6fa1a99346beb2aadd17c"></a>
dimension For example if&#160;</td><td class="memItemRight" valign="bottom"><b>$X</b> = [[1,5,2,9],[4,1,8,2],[2,7,0,3]]$ and $lengths = [2,3,1,2]$</td></tr>
<tr class="separator:a8aa00a8803f6fa1a99346beb2aadd17c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6e158113975cc2149d06aa986868935"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae6e158113975cc2149d06aa986868935"></a>
then the axes dimensions are pruned Github&#160;</td><td class="memItemRight" valign="bottom"><b>axes</b> =(0,1)</td></tr>
<tr class="separator:ae6e158113975cc2149d06aa986868935"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38a1b11a35f6c10b6a84a59522220774"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38a1b11a35f6c10b6a84a59522220774"></a>
of shape&#160;</td><td class="memItemRight" valign="bottom"><b>$BxMxN</b></td></tr>
<tr class="separator:a38a1b11a35f6c10b6a84a59522220774"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ddf0c7251c28e4641db489f6cd94763"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ddf0c7251c28e4641db489f6cd94763"></a>
of shape where $<a class="el" href="struct_b.html">B</a> is the batch $<a class="el" href="struct_m.html">M</a> is number of&#160;</td><td class="memItemRight" valign="bottom"><b>rows</b></td></tr>
<tr class="separator:a5ddf0c7251c28e4641db489f6cd94763"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55c92b9ccc6225c8ac73a268ed9568af"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55c92b9ccc6225c8ac73a268ed9568af"></a>
of shape where $<a class="el" href="struct_b.html">B</a> is the batch $<a class="el" href="struct_m.html">M</a> is number of and $N is number of columns The output of this is a matrix of shape&#160;</td><td class="memItemRight" valign="bottom"><b>$BxM</b></td></tr>
<tr class="separator:a55c92b9ccc6225c8ac73a268ed9568af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed098459630802109ed29afd323aec5b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aed098459630802109ed29afd323aec5b"></a>
the value to replace&#160;</td><td class="memItemRight" valign="bottom"><b>NaN</b></td></tr>
<tr class="separator:aed098459630802109ed29afd323aec5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a873d61b7001d72065b6aa1e703c9cce5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a873d61b7001d72065b6aa1e703c9cce5"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>actualNewShape</b> = helper.GetRepeatedArgument&lt;int64_t&gt;(&quot;shape&quot;)</td></tr>
<tr class="separator:a873d61b7001d72065b6aa1e703c9cce5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37a806608620d39e6b1ecaf34a1b255b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a37a806608620d39e6b1ecaf34a1b255b"></a>
int64_t&#160;</td><td class="memItemRight" valign="bottom"><b>totalSize</b> = 1</td></tr>
<tr class="separator:a37a806608620d39e6b1ecaf34a1b255b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8eb85f525131e24b7d5b2eb229911f7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8eb85f525131e24b7d5b2eb229911f7f"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>unknownIdx</b> = -1</td></tr>
<tr class="separator:a8eb85f525131e24b7d5b2eb229911f7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc042919e612ec50e763098e9a6a10c4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><b>else</b></td></tr>
<tr class="separator:abc042919e612ec50e763098e9a6a10c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3398bd4207d1a0cae41a0709ca8bf19a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3398bd4207d1a0cae41a0709ca8bf19a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>segments</b></td></tr>
<tr class="separator:a3398bd4207d1a0cae41a0709ca8bf19a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade68c67fc2c092431b76e601447c8a10"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade68c67fc2c092431b76e601447c8a10"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>embeddings</b></td></tr>
<tr class="separator:ade68c67fc2c092431b76e601447c8a10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabf414ec5335b860871be92441009791"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aabf414ec5335b860871be92441009791"></a>
Prefix string to prepend extracted blobs&#160;</td><td class="memItemRight" valign="bottom"><b>blob_names</b></td></tr>
<tr class="separator:aabf414ec5335b860871be92441009791"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6063e6bcaed3c21cfc5ba2a2d4a42db"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6063e6bcaed3c21cfc5ba2a2d4a42db"></a>
Prefix string to prepend extracted blobs tensor of strings containing extracted blob&#160;</td><td class="memItemRight" valign="bottom"><b>names</b></td></tr>
<tr class="separator:ad6063e6bcaed3c21cfc5ba2a2d4a42db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affc85df67937009da8c9b40f8e200a67"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="affc85df67937009da8c9b40f8e200a67"></a>
the implementation takes an the hidden state the cell and a weight&#160;</td><td class="memItemRight" valign="bottom"><b>TxNxD</b></td></tr>
<tr class="separator:affc85df67937009da8c9b40f8e200a67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dc4cd73d7a27e1f7a87b8472166f860"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dc4cd73d7a27e1f7a87b8472166f860"></a>
the implementation takes an the hidden state the cell and a weight the final hidden cell&#160;</td><td class="memItemRight" valign="bottom"><b>bidirectional</b></td></tr>
<tr class="separator:a3dc4cd73d7a27e1f7a87b8472166f860"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a265eb912ecfd3e936faaa35ffc48fe5a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a265eb912ecfd3e936faaa35ffc48fe5a"></a>
the implementation takes an the hidden state the cell and a weight the final hidden cell&#160;</td><td class="memItemRight" valign="bottom"><b>num_layers</b></td></tr>
<tr class="separator:a265eb912ecfd3e936faaa35ffc48fe5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1a14739188d2f98346f4b2fe102fcf0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab1a14739188d2f98346f4b2fe102fcf0"></a>
the implementation takes an the hidden state the cell and a weight the final hidden cell&#160;</td><td class="memItemRight" valign="bottom"><b>rnn_mode</b></td></tr>
<tr class="separator:ab1a14739188d2f98346f4b2fe102fcf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4fb5b511557f03896c001185e3672999"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4fb5b511557f03896c001185e3672999"></a>
R recurrent or input R&#160;</td><td class="memItemRight" valign="bottom"><b>all_params</b></td></tr>
<tr class="separator:a4fb5b511557f03896c001185e3672999"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73ffdee20b31f06da7a5ad73418913da"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a73ffdee20b31f06da7a5ad73418913da"></a>
See RoIPoolF&#160;</td><td class="memItemRight" valign="bottom"><b>dY</b></td></tr>
<tr class="separator:a73ffdee20b31f06da7a5ad73418913da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa359d2095f6c54a1076ff23f33fedfd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa359d2095f6c54a1076ff23f33fedfd"></a>
See RoIPoolF Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>dX</b></td></tr>
<tr class="separator:aaa359d2095f6c54a1076ff23f33fedfd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92f1546edffed1e9aba557b776054b41"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a92f1546edffed1e9aba557b776054b41"></a>
there are multiple output&#160;</td><td class="memItemRight" valign="bottom"><b>cases</b></td></tr>
<tr class="separator:a92f1546edffed1e9aba557b776054b41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1673d636a4169926d6a3f898b19dc380"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1673d636a4169926d6a3f898b19dc380"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>float</b></td></tr>
<tr class="separator:a1673d636a4169926d6a3f898b19dc380"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a894bce6c1cc63d0c81412c6b226c5507"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a894bce6c1cc63d0c81412c6b226c5507"></a>
default the scale to&#160;</td><td class="memItemRight" valign="bottom"><b>apply</b></td></tr>
<tr class="separator:a894bce6c1cc63d0c81412c6b226c5507"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f8801adf2e37b349b39eeff046baff9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9f8801adf2e37b349b39eeff046baff9"></a>
an argument&#160;</td><td class="memItemRight" valign="bottom"><b>$alpha</b></td></tr>
<tr class="separator:a9f8801adf2e37b349b39eeff046baff9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b4b515b73ad2c1eaeccac9044c038d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5b4b515b73ad2c1eaeccac9044c038d4"></a>
an argument an argument&#160;</td><td class="memItemRight" valign="bottom"><b>$scale</b></td></tr>
<tr class="separator:a5b4b515b73ad2c1eaeccac9044c038d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76dde945e8c293e42578695bb73fa128"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a76dde945e8c293e42578695bb73fa128"></a>
affects the activation function itself This should go with the weight initialization in the paper See&#160;</td><td class="memItemRight" valign="bottom"><b>https</b></td></tr>
<tr class="separator:a76dde945e8c293e42578695bb73fa128"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9bcf3fada0e9ffba9872945b48942f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac9bcf3fada0e9ffba9872945b48942f6"></a>
will use same as padding_width&#160;</td><td class="memItemRight" valign="bottom"><b>start_padding</b></td></tr>
<tr class="separator:ac9bcf3fada0e9ffba9872945b48942f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9812e4f620c5648f6daa7f6c109c7cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae9812e4f620c5648f6daa7f6c109c7cb"></a>
will use same as padding_width D_n&#160;</td><td class="memItemRight" valign="bottom"><b>data_out</b></td></tr>
<tr class="separator:ae9812e4f620c5648f6daa7f6c109c7cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a682a06d162fd568a7873754f98c4cf17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a682a06d162fd568a7873754f98c4cf17"></a>
will use same as padding_width D_n&#160;</td><td class="memItemRight" valign="bottom"><b>D_1</b></td></tr>
<tr class="separator:a682a06d162fd568a7873754f98c4cf17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20d540a1732732c70753b404d4e4e715"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a20d540a1732732c70753b404d4e4e715"></a>
will use same as padding_width considers all data as a single segment&#160;</td><td class="memItemRight" valign="bottom"><b>lengths_out</b></td></tr>
<tr class="separator:a20d540a1732732c70753b404d4e4e715"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64e0ab7bd353bf53fdb04b239c3ec035"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a64e0ab7bd353bf53fdb04b239c3ec035"></a>
Outer size of padding present around each range&#160;</td><td class="memItemRight" valign="bottom"><b>data_in</b></td></tr>
<tr class="separator:a64e0ab7bd353bf53fdb04b239c3ec035"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a074c9a0e8cde128f1ec5dc8087e66917"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a074c9a0e8cde128f1ec5dc8087e66917"></a>
Outer size of padding present around each range <a class="el" href="struct_t.html">T</a>&lt; N, D1..., Dn &gt; Padded input data&#160;</td><td class="memItemRight" valign="bottom"><b>padding_sum</b></td></tr>
<tr class="separator:a074c9a0e8cde128f1ec5dc8087e66917"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a955f20693c31916293168aa86432578f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a955f20693c31916293168aa86432578f"></a>
Outer size of padding present around each range <a class="el" href="struct_t.html">T</a>&lt; N, D1..., Dn &gt; Padded input data <a class="el" href="class_sum.html">Sum</a> of all start&#160;</td><td class="memItemRight" valign="bottom"><b>paddings</b></td></tr>
<tr class="separator:a955f20693c31916293168aa86432578f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a343762a275de83eb56507048c729cbe3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a343762a275de83eb56507048c729cbe3"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>starts</b> = helper.GetRepeatedArgument&lt;int&gt;(&quot;starts&quot;, vector&lt;int&gt;())</td></tr>
<tr class="separator:a343762a275de83eb56507048c729cbe3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07509b1a06b67850fa18bb40a8acaaa0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a07509b1a06b67850fa18bb40a8acaaa0"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>ends</b> = helper.GetRepeatedArgument&lt;int&gt;(&quot;ends&quot;, vector&lt;int&gt;())</td></tr>
<tr class="separator:a07509b1a06b67850fa18bb40a8acaaa0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30f0470d37c539ccf7a87013b62faadd"><td class="memItemLeft" align="right" valign="top">return&#160;</td><td class="memItemRight" valign="bottom"><b>vector&lt; TensorShape &gt;</b></td></tr>
<tr class="separator:a30f0470d37c539ccf7a87013b62faadd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a740cd076fdf40bd78a4a80ba11170b42"><td class="memItemLeft" align="right" valign="top">it will be coerced into one For an arbitrary n dimensional tensor X where k is the axis then X will be coerced into a dimensional tensor with dimensions[(a_0 *...*a_{k-1}),(a_k *...*a_{n-1})] For the default case where the X tensor will be coerced into a tensor of where $a_0 is often the batch size In this we must hav&#160;</td><td class="memItemRight" valign="bottom"><b>$a_0</b> )</td></tr>
<tr class="separator:a740cd076fdf40bd78a4a80ba11170b42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac905ba11e842b05d79645781591665b9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac905ba11e842b05d79645781591665b9"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>labels</b> = in[1]</td></tr>
<tr class="separator:ac905ba11e842b05d79645781591665b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addad4c4cf84d667f963d2f34365f3fd4"><td class="memItemLeft" align="right" valign="top">const int&#160;</td><td class="memItemRight" valign="bottom"><b>batch_size</b></td></tr>
<tr class="separator:addad4c4cf84d667f963d2f34365f3fd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22ec3d8b4f17b4e26fdfd0f339e64089"><td class="memItemLeft" align="right" valign="top">const int&#160;</td><td class="memItemRight" valign="bottom"><b>num_classes</b></td></tr>
<tr class="separator:a22ec3d8b4f17b4e26fdfd0f339e64089"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa469f4d6a64b3c06be07c93816218588"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa469f4d6a64b3c06be07c93816218588"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>weight_tensor</b></td></tr>
<tr class="separator:aa469f4d6a64b3c06be07c93816218588"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f5feb41a376710e51d64cee1162d257"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8f5feb41a376710e51d64cee1162d257"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>softmax</b></td></tr>
<tr class="separator:a8f5feb41a376710e51d64cee1162d257"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a767cf78651f26ed6df6a8aeb5f1b5d40"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a767cf78651f26ed6df6a8aeb5f1b5d40"></a>
default&#160;</td><td class="memItemRight" valign="bottom"><b>loss</b></td></tr>
<tr class="separator:a767cf78651f26ed6df6a8aeb5f1b5d40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01d5960d4de088a68ab3e1d95106a67b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01d5960d4de088a68ab3e1d95106a67b"></a>
where the softplus&#160;</td><td class="memItemRight" valign="bottom"><b>function</b></td></tr>
<tr class="separator:a01d5960d4de088a68ab3e1d95106a67b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a10753664d8a0fc9b5a2e4509b2db6a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8a10753664d8a0fc9b5a2e4509b2db6a"></a>
where the softplus&#160;</td><td class="memItemRight" valign="bottom"><b>$y</b> = ln(e^x + 1)$</td></tr>
<tr class="separator:a8a10753664d8a0fc9b5a2e4509b2db6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fdf8abbf0736f2fa5bd0e75ffc1a40f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0fdf8abbf0736f2fa5bd0e75ffc1a40f"></a>
this op outputs a copy of the input tensor where values from the height and width dimensions are moved to the batch dimension After the zero padding is according to the pad&#160;</td><td class="memItemRight" valign="bottom"><b>argument</b></td></tr>
<tr class="separator:a0fdf8abbf0736f2fa5bd0e75ffc1a40f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a02153d276223fef9c3078199432411"><td class="memItemLeft" align="right" valign="top">this op outputs a copy of the input tensor where values from the height and width dimensions are moved to the batch dimension After the zero padding is according to the pad both height and width of the input must be divisible by the block_size Only NCHW order is currently supported Github&#160;</td><td class="memItemRight" valign="bottom"><b>block_size</b></td></tr>
<tr class="separator:a8a02153d276223fef9c3078199432411"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc109e6351665ebf886eff4bff7615ef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc109e6351665ebf886eff4bff7615ef"></a>
followed by cropping This is the reverse transformation of SpaceToBatch More&#160;</td><td class="memItemRight" valign="bottom"><b>specifically</b></td></tr>
<tr class="separator:abc109e6351665ebf886eff4bff7615ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2506c69ffc53d2e96b8bdea9b074175c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2506c69ffc53d2e96b8bdea9b074175c"></a>
Parameters to be normalized Gradient computed <a class="el" href="struct_a.html">A</a> bool variable to control whether to use max norm or constant norm When&#160;</td><td class="memItemRight" valign="bottom"><b>use_max_norm</b> = false</td></tr>
<tr class="separator:a2506c69ffc53d2e96b8bdea9b074175c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43af402778303cefcff606cf59b2ed3a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a43af402778303cefcff606cf59b2ed3a"></a>
Parameters to be normalized Gradient computed <a class="el" href="struct_a.html">A</a> bool variable to control whether to use max norm or constant norm When constant norm is used so that all the embedding vectors are scaled to have a L2 norm equals to max norm is used so that embedding is scaled so that its l2 norm is no larger than <a class="el" href="struct_a.html">A</a> If an embedding s norm is less than <a class="el" href="struct_a.html">A</a>&#160;</td><td class="memItemRight" valign="bottom"><b>originally</b></td></tr>
<tr class="separator:a43af402778303cefcff606cf59b2ed3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba52d668a5c39be0b91bfd82e26cda62"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aba52d668a5c39be0b91bfd82e26cda62"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>is_test</b> = helper.GetSingleArgument&lt;int&gt;(OpSchema::Arg_IsTest, 0)</td></tr>
<tr class="separator:aba52d668a5c39be0b91bfd82e26cda62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4be1ab1fabce46dbaab702a7d6d7ebb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa4be1ab1fabce46dbaab702a7d6d7ebb"></a>
default where $N is batch $<a class="el" href="struct_c.html">C</a> is number of $H is spatial&#160;</td><td class="memItemRight" valign="bottom"><b>height</b></td></tr>
<tr class="separator:aa4be1ab1fabce46dbaab702a7d6d7ebb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8ac53eae620f81c22719195b35a1593"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af8ac53eae620f81c22719195b35a1593"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output&#160;</td><td class="memItemRight" valign="bottom"><b>var</b></td></tr>
<tr class="separator:af8ac53eae620f81c22719195b35a1593"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a543cfef67c8cf2d63c93bc44caada2ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a543cfef67c8cf2d63c93bc44caada2ad"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output The running&#160;</td><td class="memItemRight" valign="bottom"><b>sums</b></td></tr>
<tr class="separator:a543cfef67c8cf2d63c93bc44caada2ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8168b69b39192f6b33801e8c68ceb37"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad8168b69b39192f6b33801e8c68ceb37"></a>
default The input dimensional tensor of shape $NCHW or $NHWC depending on the order parameter The bias as a dimensional tensor of size $<a class="el" href="struct_c.html">C</a> to be applied to the output The running *<a class="el" href="classc10_1_1optional.html">optional</a> *Per channel sums of elements to be used to determine the mean and variance for this batch The output dimensional tensor of the same shape as $X The running variance after the spatial BN&#160;</td><td class="memItemRight" valign="bottom"><b>saved_var</b></td></tr>
<tr class="separator:ad8168b69b39192f6b33801e8c68ceb37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8de4b212a0e77899730111b72a268394"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8de4b212a0e77899730111b72a268394"></a>
Unscaled log probabilities Optional blob to be used to weight the samples for the loss With spatial weighting is by&#160;</td><td class="memItemRight" valign="bottom"><b>x</b></td></tr>
<tr class="separator:a8de4b212a0e77899730111b72a268394"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaea2db89e5ced97847aea14ff2699ae6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaea2db89e5ced97847aea14ff2699ae6"></a>
<a class="el" href="struct_a.html">A</a> <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> pointing to the newly created&#160;</td><td class="memItemRight" valign="bottom"><b>StatRegistry</b></td></tr>
<tr class="separator:aaea2db89e5ced97847aea14ff2699ae6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12d30c53af125f5297c370ca526670c0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a12d30c53af125f5297c370ca526670c0"></a>
If export values from given <a class="el" href="classcaffe2_1_1_stat_registry.html">StatRegistry</a> export values from the global singleton <a class="el" href="classcaffe2_1_1_stat_registry.html">StatRegistry</a> int64 tensor with exported values default true Whether to atomically reset the counters&#160;</td><td class="memItemRight" valign="bottom"><b>afterwards</b></td></tr>
<tr class="separator:a12d30c53af125f5297c370ca526670c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63e477122797f7dc2f2116ca82122dfb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a63e477122797f7dc2f2116ca82122dfb"></a>
returning a scalar tensor containing a pointer to it The timer is stopped by calling **TimerEnd **Github&#160;</td><td class="memItemRight" valign="bottom"><b>str</b></td></tr>
<tr class="separator:a63e477122797f7dc2f2116ca82122dfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac293f6f7b62d52cad76bd452f4713427"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac293f6f7b62d52cad76bd452f4713427"></a>
stops the timer publishing a CAFFE_EVENT Github&#160;</td><td class="memItemRight" valign="bottom"><b>timerget_op</b></td></tr>
<tr class="separator:ac293f6f7b62d52cad76bd452f4713427"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06d0b15aa19a08fce87e5fb608109476"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a06d0b15aa19a08fce87e5fb608109476"></a>
tensor of float&#160;</td><td class="memItemRight" valign="bottom"><b>Index_High</b></td></tr>
<tr class="separator:a06d0b15aa19a08fce87e5fb608109476"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46a63043bc4c891fd5bf4541f9c6059e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46a63043bc4c891fd5bf4541f9c6059e"></a>
default flag to indicate if the summarized statistics have to be written to a log file <a class="el" href="struct_d.html">D</a>&#160;</td><td class="memItemRight" valign="bottom"><b>max</b></td></tr>
<tr class="separator:a46a63043bc4c891fd5bf4541f9c6059e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd265702e7a42e4caf263cf1764ddb1e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afd265702e7a42e4caf263cf1764ddb1e"></a>
default flag to indicate if the summarized statistics have to be written to a log file <a class="el" href="struct_d.html">D</a> mean and standard&#160;</td><td class="memItemRight" valign="bottom"><b>deviation</b></td></tr>
<tr class="separator:afd265702e7a42e4caf263cf1764ddb1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95cfbc8efd5c995523881c02ef435780"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a95cfbc8efd5c995523881c02ef435780"></a>
constexpr char&#160;</td><td class="memItemRight" valign="bottom"><b>kSummaryzeOpExtension</b> [] = &quot;.summary&quot;</td></tr>
<tr class="separator:a95cfbc8efd5c995523881c02ef435780"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd46e25adda028ba1513751fa49a20a6"><td class="memItemLeft" align="right" valign="top">const std::int32_t&#160;</td><td class="memItemRight" valign="bottom"><b>tiles</b></td></tr>
<tr class="separator:acd46e25adda028ba1513751fa49a20a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab53314f2b366d81bbb445275ad724a22"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab53314f2b366d81bbb445275ad724a22"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>a_2</b></td></tr>
<tr class="separator:ab53314f2b366d81bbb445275ad724a22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3b7483ea444fbc48ff4b73f4062c583"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac3b7483ea444fbc48ff4b73f4062c583"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>a_n</b></td></tr>
<tr class="separator:ac3b7483ea444fbc48ff4b73f4062c583"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e8ddcda9f75a80dfa630faafc917c81"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e8ddcda9f75a80dfa630faafc917c81"></a>
r and integer argument&#160;</td><td class="memItemRight" valign="bottom"><b>k</b></td></tr>
<tr class="separator:a6e8ddcda9f75a80dfa630faafc917c81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45b77424afcbc65c3b1971194b6c5e84"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><b>valid_axes</b></td></tr>
<tr class="separator:a45b77424afcbc65c3b1971194b6c5e84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c9b81a4bc415e962478d27e1e4bfdf7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7c9b81a4bc415e962478d27e1e4bfdf7"></a>
tensor of int32 or int64 indices&#160;</td><td class="memItemRight" valign="bottom"><b>remapping</b></td></tr>
<tr class="separator:a7c9b81a4bc415e962478d27e1e4bfdf7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3294f46f45a52ac75939d3e6239c9021"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3294f46f45a52ac75939d3e6239c9021"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>time</b></td></tr>
<tr class="separator:a3294f46f45a52ac75939d3e6239c9021"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64a9a81af86f2fc412c0a0260bac35f6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a64a9a81af86f2fc412c0a0260bac35f6"></a>
The time in&#160;</td><td class="memItemRight" valign="bottom"><b>nanoseconds</b></td></tr>
<tr class="separator:a64a9a81af86f2fc412c0a0260bac35f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aade73067b9ad02d9b13ecacbc0ed4fbb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aade73067b9ad02d9b13ecacbc0ed4fbb"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>if</b></td></tr>
<tr class="separator:aade73067b9ad02d9b13ecacbc0ed4fbb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93ff253c52b3d44ad91706a0c24aeea4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a93ff253c52b3d44ad91706a0c24aeea4"></a>
bool saves contents to the root folder of the current&#160;</td><td class="memItemRight" valign="bottom"><b>workspace</b></td></tr>
<tr class="separator:a93ff253c52b3d44ad91706a0c24aeea4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d06086ac8ff6ede90d0b42dad0812ce"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d06086ac8ff6ede90d0b42dad0812ce"></a>
const char&#160;</td><td class="memItemRight" valign="bottom"><b>kPrintFileExtension</b> [] = &quot;.log&quot;</td></tr>
<tr class="separator:a4d06086ac8ff6ede90d0b42dad0812ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa03ec354315c7cd6f4105cfaab761172"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa03ec354315c7cd6f4105cfaab761172"></a>
const <a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a>&#160;</td><td class="memItemRight" valign="bottom"><b>args</b> (def)</td></tr>
<tr class="separator:aa03ec354315c7cd6f4105cfaab761172"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ecb9de2e3cdf593d3742e73af7fa8d8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ecb9de2e3cdf593d3742e73af7fa8d8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>sampling_cdf</b></td></tr>
<tr class="separator:a5ecb9de2e3cdf593d3742e73af7fa8d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae99537decdb041bd333ba6a56a371350"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae99537decdb041bd333ba6a56a371350"></a>
An <a class="el" href="classc10_1_1optional.html">optional</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> Input cumulative sampling all values in sampling_cdf will be scaled by this number&#160;</td><td class="memItemRight" valign="bottom"><b>sampled_indexes</b></td></tr>
<tr class="separator:ae99537decdb041bd333ba6a56a371350"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a496eed23a8db93ec6c2fe45c5af8ce33"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a496eed23a8db93ec6c2fe45c5af8ce33"></a>
an index is randomly sampled from the distribution given by the weights of the corresponding batch The output is a <a class="el" href="struct_d.html">D</a>&#160;</td><td class="memItemRight" valign="bottom"><b>sampling_weights</b></td></tr>
<tr class="separator:a496eed23a8db93ec6c2fe45c5af8ce33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa76eb18ddf3ce22304ae72a04d1c6f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa76eb18ddf3ce22304ae72a04d1c6f9"></a>
an index is randomly sampled from the distribution given by the weights of the corresponding batch The output is a <a class="el" href="struct_d.html">D</a> <a class="el" href="struct_a.html">A</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of&#160;</td><td class="memItemRight" valign="bottom"><b>sampling_values</b></td></tr>
<tr class="separator:aaa76eb18ddf3ce22304ae72a04d1c6f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73fb263964dfa799dbc08e0b0fff54ce"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a73fb263964dfa799dbc08e0b0fff54ce"></a>
an index is randomly sampled from the distribution given by the weights of the corresponding batch The output is a <a class="el" href="struct_d.html">D</a> <a class="el" href="struct_a.html">A</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of An <a class="el" href="classc10_1_1optional.html">optional</a> <a class="el" href="struct_d.html">D</a> <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of The output tensor contains&#160;</td><td class="memItemRight" valign="bottom"><b>sampled_values</b></td></tr>
<tr class="separator:a73fb263964dfa799dbc08e0b0fff54ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a195c1200dae10f7315d12353e6049b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a195c1200dae10f7315d12353e6049b"></a>
decltype(adagrad_update__base)&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update__avx_f16c</b></td></tr>
<tr class="separator:a4a195c1200dae10f7315d12353e6049b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94c708c4959b740c12530a3dd970a06a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a94c708c4959b740c12530a3dd970a06a"></a>
decltype(adagrad_update_prefetch__base)&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_update_prefetch__avx_f16c</b></td></tr>
<tr class="separator:a94c708c4959b740c12530a3dd970a06a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d0f91656bbb833d67a25c3f62a0d839"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0d0f91656bbb833d67a25c3f62a0d839"></a>
decltype(adagrad_fp16_update_prefetch__base)&#160;</td><td class="memItemRight" valign="bottom"><b>adagrad_fp16_update_prefetch__avx_f16c</b></td></tr>
<tr class="separator:a0d0f91656bbb833d67a25c3f62a0d839"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97fe00fefd2ff0c2e7ad97bb8f4c0942"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a97fe00fefd2ff0c2e7ad97bb8f4c0942"></a>
decltype(rowwise_adagrad_update__base)&#160;</td><td class="memItemRight" valign="bottom"><b>rowwise_adagrad_update__avx_f16c</b></td></tr>
<tr class="separator:a97fe00fefd2ff0c2e7ad97bb8f4c0942"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c14025f4c10663e67b5e0b62023b580"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c14025f4c10663e67b5e0b62023b580"></a>
decltype(sparse_adagrad_int32_t__base)&#160;</td><td class="memItemRight" valign="bottom"><b>sparse_adagrad_int32_t__avx_f16c</b></td></tr>
<tr class="separator:a9c14025f4c10663e67b5e0b62023b580"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8146a6996001c3dc24b691a7e0df781a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8146a6996001c3dc24b691a7e0df781a"></a>
decltype(sparse_adagrad_int64_t__base)&#160;</td><td class="memItemRight" valign="bottom"><b>sparse_adagrad_int64_t__avx_f16c</b></td></tr>
<tr class="separator:a8146a6996001c3dc24b691a7e0df781a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab91f4437ccee8d774da51f865a59784b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab91f4437ccee8d774da51f865a59784b"></a>
decltype(TypedAxpyHalffloat__base)&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpyHalffloat__avx2_fma</b></td></tr>
<tr class="separator:ab91f4437ccee8d774da51f865a59784b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b344800e68d6950af83cc840a3863f3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7b344800e68d6950af83cc840a3863f3"></a>
decltype(TypedAxpyHalffloat__base)&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpyHalffloat__avx_f16c</b></td></tr>
<tr class="separator:a7b344800e68d6950af83cc840a3863f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39b50b2f3d3705194e199d76f9207f78"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39b50b2f3d3705194e199d76f9207f78"></a>
decltype(TypedAxpy_uint8_float__base)&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpy_uint8_float__avx2_fma</b></td></tr>
<tr class="separator:a39b50b2f3d3705194e199d76f9207f78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae18af2164d350680320943e7ce57966c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae18af2164d350680320943e7ce57966c"></a>
decltype(TypedAxpy_uint8_float__base)&#160;</td><td class="memItemRight" valign="bottom"><b>TypedAxpy_uint8_float__avx_f16c</b></td></tr>
<tr class="separator:ae18af2164d350680320943e7ce57966c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c11fd39ff969cdceed1f9b2abf86356"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2c11fd39ff969cdceed1f9b2abf86356"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>CPU</b> = DeviceType::CPU</td></tr>
<tr class="separator:a2c11fd39ff969cdceed1f9b2abf86356"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53b0ebf880464a2bac2d5a96f30085fa"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a53b0ebf880464a2bac2d5a96f30085fa"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>CUDA</b> = DeviceType::CUDA</td></tr>
<tr class="separator:a53b0ebf880464a2bac2d5a96f30085fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3de9143feb0ce212025b0ed87d3d2d94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3de9143feb0ce212025b0ed87d3d2d94"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>OPENGL</b> = DeviceType::OPENGL</td></tr>
<tr class="separator:a3de9143feb0ce212025b0ed87d3d2d94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfa07870aa515f9474eeae1b94f00f51"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abfa07870aa515f9474eeae1b94f00f51"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>OPENCL</b> = DeviceType::OPENCL</td></tr>
<tr class="separator:abfa07870aa515f9474eeae1b94f00f51"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8edd92ac440ca9cdda35075f9e88ae9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab8edd92ac440ca9cdda35075f9e88ae9"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>MKLDNN</b> = DeviceType::MKLDNN</td></tr>
<tr class="separator:ab8edd92ac440ca9cdda35075f9e88ae9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55b38ad9efaab6a720553f54e3975b53"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a55b38ad9efaab6a720553f54e3975b53"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>IDEEP</b> = DeviceType::IDEEP</td></tr>
<tr class="separator:a55b38ad9efaab6a720553f54e3975b53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46f5149fa42f8069e53fed363595b4c5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a46f5149fa42f8069e53fed363595b4c5"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>HIP</b> = DeviceType::HIP</td></tr>
<tr class="separator:a46f5149fa42f8069e53fed363595b4c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc0e9e0832cf223c6e83fcd68296b742"><td class="memItemLeft" align="right" valign="top">constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>COMPILE_TIME_MAX_DEVICE_TYPES</b></td></tr>
<tr class="separator:acc0e9e0832cf223c6e83fcd68296b742"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c50614194f4e844b731b9db6cc5aebf"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8c50614194f4e844b731b9db6cc5aebf"></a>
constexpr DeviceType&#160;</td><td class="memItemRight" valign="bottom"><b>ONLY_FOR_TEST</b> = DeviceType::ONLY_FOR_TEST</td></tr>
<tr class="separator:a8c50614194f4e844b731b9db6cc5aebf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f7f63133167d59328c15c4ce234b50a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4f7f63133167d59328c15c4ce234b50a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>data_0</b></td></tr>
<tr class="separator:a4f7f63133167d59328c15c4ce234b50a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ac5a014129013215a5387a2816fe366"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2ac5a014129013215a5387a2816fe366"></a>
Weight tensor in KRSC layout&#160;</td><td class="memItemRight" valign="bottom"><b>W_q</b></td></tr>
<tr class="separator:a2ac5a014129013215a5387a2816fe366"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a713bca195433bb091043f737f7591c47"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a713bca195433bb091043f737f7591c47"></a>
Weight tensor in KRSC layout Weight bias tensor in a packed&#160;</td><td class="memItemRight" valign="bottom"><b>format</b></td></tr>
<tr class="separator:a713bca195433bb091043f737f7591c47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d8acb9c94dd491e1780d9b2dd992ca0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d8acb9c94dd491e1780d9b2dd992ca0"></a>
constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>nlines_log</b> = 10000</td></tr>
<tr class="separator:a4d8acb9c94dd491e1780d9b2dd992ca0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7413dcb9a1fabf1a7cec4c9404bd7396"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7413dcb9a1fabf1a7cec4c9404bd7396"></a>
Timeout in&#160;</td><td class="memItemRight" valign="bottom"><b>secs</b></td></tr>
<tr class="separator:a7413dcb9a1fabf1a7cec4c9404bd7396"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73c354f476240f392ab010204294ec95"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a73c354f476240f392ab010204294ec95"></a>
Timeout in&#160;</td><td class="memItemRight" valign="bottom"><b>queue</b></td></tr>
<tr class="separator:a73c354f476240f392ab010204294ec95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7edb91da059b55443b1e1da62ede5d8e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7edb91da059b55443b1e1da62ede5d8e"></a>
The shared pointer for the&#160;</td><td class="memItemRight" valign="bottom"><b>BlobsQueue</b></td></tr>
<tr class="separator:a7edb91da059b55443b1e1da62ede5d8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95d0e7956b663833f254e29316fd8937"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a95d0e7956b663833f254e29316fd8937"></a>
the output status will be set to true which can be used as exit criteria for execution step The input is the queue and the last output is the status The rest are data blobs DOC The shared pointer for the <a class="el" href="classcaffe2_1_1_blobs_queue.html">BlobsQueue</a>&#160;</td><td class="memItemRight" valign="bottom"><b>status</b></td></tr>
<tr class="separator:a95d0e7956b663833f254e29316fd8937"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29f8a500a75314ea467a2106a53c34cb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29f8a500a75314ea467a2106a53c34cb"></a>
the output status will be set to true which can be used as exit criteria for execution step The input is the queue and the last output is the status The rest are data blobs DOC The shared pointer for the <a class="el" href="classcaffe2_1_1_blobs_queue.html">BlobsQueue</a> Is set to depending on the success of&#160;</td><td class="memItemRight" valign="bottom"><b>dequeue</b></td></tr>
<tr class="separator:a29f8a500a75314ea467a2106a53c34cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee26a4898a0db5ed8ca026e97990bbab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aee26a4898a0db5ed8ca026e97990bbab"></a>
Parameters to be updated&#160;</td><td class="memItemRight" valign="bottom"><b>moment_delta</b></td></tr>
<tr class="separator:aee26a4898a0db5ed8ca026e97990bbab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a273ccf387f0345956ca0c2d5f89fe673"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a273ccf387f0345956ca0c2d5f89fe673"></a>
Parameters to be updated Average of squared parameter updates&#160;</td><td class="memItemRight" valign="bottom"><b>lr</b></td></tr>
<tr class="separator:a273ccf387f0345956ca0c2d5f89fe673"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab579c68e9d0206dc164615dff8510ff8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab579c68e9d0206dc164615dff8510ff8"></a>
Parameters to be updated Average of squared parameter updates Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>output_moment</b></td></tr>
<tr class="separator:ab579c68e9d0206dc164615dff8510ff8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc790fea4330bd79d05c6beb2be30a7f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abc790fea4330bd79d05c6beb2be30a7f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>moment</b></td></tr>
<tr class="separator:abc790fea4330bd79d05c6beb2be30a7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76351eacbd2e27f4c16e4f8c8cc0ad27"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a76351eacbd2e27f4c16e4f8c8cc0ad27"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates Gradient computed&#160;</td><td class="memItemRight" valign="bottom"><b>output_param</b></td></tr>
<tr class="separator:a76351eacbd2e27f4c16e4f8c8cc0ad27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4135a536bdb0db2fdd08bae14b9c585a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4135a536bdb0db2fdd08bae14b9c585a"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates Gradient computed Updated parameters&#160;</td><td class="memItemRight" valign="bottom"><b>output_moment_delta</b></td></tr>
<tr class="separator:a4135a536bdb0db2fdd08bae14b9c585a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01901aa5cc1f26b6ca38d9af5d19f752"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a01901aa5cc1f26b6ca38d9af5d19f752"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates Gradient computed Updated parameters Updated average of squared parameter updates&#160;</td><td class="memItemRight" valign="bottom"><b>Default</b></td></tr>
<tr class="separator:a01901aa5cc1f26b6ca38d9af5d19f752"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5522b9e969392e7ca4c8ea03f74860d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5522b9e969392e7ca4c8ea03f74860d2"></a>
runs the dense AdaDelta update and Parameters to be updated Average of squared parameter updates Gradient computed Updated parameters Updated average of squared parameter updates the squared gradient sum is decayed by this&#160;</td><td class="memItemRight" valign="bottom"><b>factor</b></td></tr>
<tr class="separator:a5522b9e969392e7ca4c8ea03f74860d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03dd84a062642ec91cb5e9ead4992387"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a03dd84a062642ec91cb5e9ead4992387"></a>
Parameters to be updated&#160;</td><td class="memItemRight" valign="bottom"><b>moment_2</b></td></tr>
<tr class="separator:a03dd84a062642ec91cb5e9ead4992387"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a548bcf4b59d94dc8812c4d734f166a67"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a548bcf4b59d94dc8812c4d734f166a67"></a>
Parameters to be updated Second moment history learning rate Updated parameters&#160;</td><td class="memItemRight" valign="bottom"><b>output_moment_2</b></td></tr>
<tr class="separator:a548bcf4b59d94dc8812c4d734f166a67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab72ab057fde2a72d05cdd79b35c2d399"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab72ab057fde2a72d05cdd79b35c2d399"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>moment1</b></td></tr>
<tr class="separator:ab72ab057fde2a72d05cdd79b35c2d399"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a193565e3db19a64866b963c54ebca322"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a193565e3db19a64866b963c54ebca322"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>moment2</b></td></tr>
<tr class="separator:a193565e3db19a64866b963c54ebca322"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdd625f01c006adbc78187fd0e9e6c43"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="acdd625f01c006adbc78187fd0e9e6c43"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>iter</b></td></tr>
<tr class="separator:acdd625f01c006adbc78187fd0e9e6c43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad063181d7718c1aaf6657a3a6017008b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad063181d7718c1aaf6657a3a6017008b"></a>
runs the dense Adam&#160;</td><td class="memItemRight" valign="bottom"><b>new_moment1</b></td></tr>
<tr class="separator:ad063181d7718c1aaf6657a3a6017008b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a67fb60750d5c0d3cebb76c8a093409"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1a67fb60750d5c0d3cebb76c8a093409"></a>
runs the dense Adam new_moment2 as in dense case DOC&#160;</td><td class="memItemRight" valign="bottom"><b>moment_1</b></td></tr>
<tr class="separator:a1a67fb60750d5c0d3cebb76c8a093409"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e3fc7d0769e0f7d89dfefc55647209f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3e3fc7d0769e0f7d89dfefc55647209f"></a>
runs the Adam update&#160;</td><td class="memItemRight" valign="bottom"><b>new_moment2</b></td></tr>
<tr class="separator:a3e3fc7d0769e0f7d89dfefc55647209f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad245dfe6cdb3e86167608f294ea0d02d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad245dfe6cdb3e86167608f294ea0d02d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>input_tensor</b></td></tr>
<tr class="separator:ad245dfe6cdb3e86167608f294ea0d02d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c0a174357fcc86c67562a7d04e93b73"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0c0a174357fcc86c67562a7d04e93b73"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of floats to be clipped&#160;</td><td class="memItemRight" valign="bottom"><b>additional_threshold</b></td></tr>
<tr class="separator:a0c0a174357fcc86c67562a7d04e93b73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abaa79577cca416cf81dfdc100ba72aad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abaa79577cca416cf81dfdc100ba72aad"></a>
<a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of floats to be clipped An <a class="el" href="classc10_1_1optional.html">optional</a> additonal threshold to scale the orignal threshold&#160;</td><td class="memItemRight" valign="bottom"><b>clipped</b></td></tr>
<tr class="separator:abaa79577cca416cf81dfdc100ba72aad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32eefe979dd1aa0a3bcffe5bae25b2e3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32eefe979dd1aa0a3bcffe5bae25b2e3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>mutex</b></td></tr>
<tr class="separator:a32eefe979dd1aa0a3bcffe5bae25b2e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf733448c75ed082167df02c63481b83"><td class="memItemLeft" align="right" valign="top">given a parameter tensor X and its gradient the local learning rate for X will be&#160;</td><td class="memItemRight" valign="bottom"><b>local_lr</b></td></tr>
<tr class="separator:adf733448c75ed082167df02c63481b83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02fa825ee826bff4602fb32d08869898"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a02fa825ee826bff4602fb32d08869898"></a>
given a parameter tensor X and its gradient the local learning rate for X will be where offset is a preset hyper parameter to avoid numerical issue and trust indicates how much we trust the layer to change its parameters during one update In this&#160;</td><td class="memItemRight" valign="bottom"><b>implementation</b></td></tr>
<tr class="separator:a02fa825ee826bff4602fb32d08869898"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad8f78cc4d7f108fe2d5c1a2ecb43ff0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aad8f78cc4d7f108fe2d5c1a2ecb43ff0"></a>
given a parameter tensor X and its gradient the local learning rate for X will be where offset is a preset hyper parameter to avoid numerical issue and trust indicates how much we trust the layer to change its parameters during one update In this we uses l2 norm and the computed local learning rate is clipped based on the upper bound lr_max and the lower bound&#160;</td><td class="memItemRight" valign="bottom"><b>lr_min</b></td></tr>
<tr class="separator:aad8f78cc4d7f108fe2d5c1a2ecb43ff0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad48faa575f192bdbe73264d5f05ae22b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad48faa575f192bdbe73264d5f05ae22b"></a>
the learning rate for performing gradient descent on learning rate lr Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>effgrad</b></td></tr>
<tr class="separator:ad48faa575f192bdbe73264d5f05ae22b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff5c1997a586b412366282e3d5c36ed8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aff5c1997a586b412366282e3d5c36ed8"></a>
given&#160;</td><td class="memItemRight" valign="bottom"><b>nesterov</b></td></tr>
<tr class="separator:aff5c1997a586b412366282e3d5c36ed8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d580ff9f43830a1a4910e1374df359e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3d580ff9f43830a1a4910e1374df359e"></a>
given&#160;</td><td class="memItemRight" valign="bottom"><b>computes</b></td></tr>
<tr class="separator:a3d580ff9f43830a1a4910e1374df359e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83d84a24ebe7bd6eb94a08f04bc6f5d5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a83d84a24ebe7bd6eb94a08f04bc6f5d5"></a>
given&#160;</td><td class="memItemRight" valign="bottom"><b>adjusted_gradient</b></td></tr>
<tr class="separator:a83d84a24ebe7bd6eb94a08f04bc6f5d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a983f6c0370710aa3fee309be4042f2de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a983f6c0370710aa3fee309be4042f2de"></a>
given param&#160;</td><td class="memItemRight" valign="bottom"><b>momentum</b></td></tr>
<tr class="separator:a983f6c0370710aa3fee309be4042f2de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1f18bb49a8ab18db4eb71615e96ce71"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad1f18bb49a8ab18db4eb71615e96ce71"></a>
given param parameter Note the difference to&#160;</td><td class="memItemRight" valign="bottom"><b>MomentumSGD</b></td></tr>
<tr class="separator:ad1f18bb49a8ab18db4eb71615e96ce71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9e753c4409d91d8b8b316a4a3740105"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa9e753c4409d91d8b8b316a4a3740105"></a>
GradientSlice with gradients for updated indices Learning rate Adjusted gradient Updated parameter boolean Whether to use Nesterov Accelerated&#160;</td><td class="memItemRight" valign="bottom"><b>Gradient</b></td></tr>
<tr class="separator:aa9e753c4409d91d8b8b316a4a3740105"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7122aa4ca0f9404d6371137d86062608"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7122aa4ca0f9404d6371137d86062608"></a>
Parameters to be updated Learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>curv_win</b></td></tr>
<tr class="separator:a7122aa4ca0f9404d6371137d86062608"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07a9855e8d5726f19a8cb00c750a2785"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a07a9855e8d5726f19a8cb00c750a2785"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges&#160;</td><td class="memItemRight" valign="bottom"><b>g2_avg</b></td></tr>
<tr class="separator:a07a9855e8d5726f19a8cb00c750a2785"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e124b5cc6833c47766b8591badedcac"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4e124b5cc6833c47766b8591badedcac"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated&#160;</td><td class="memItemRight" valign="bottom"><b>output_lr</b></td></tr>
<tr class="separator:a4e124b5cc6833c47766b8591badedcac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad634dc96d52b1398e9a9962f54f90999"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad634dc96d52b1398e9a9962f54f90999"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated Output learning rate&#160;</td><td class="memItemRight" valign="bottom"><b>output_curv_win</b></td></tr>
<tr class="separator:ad634dc96d52b1398e9a9962f54f90999"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26e9a5a40ec5af5f25ebed9ccf8cdab6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a26e9a5a40ec5af5f25ebed9ccf8cdab6"></a>
Parameters to be updated Learning rate Memory for latest curvature ranges Moving average of squared gradient Gradient computed Parameters to be updated Output learning rate Output memory for latest curvature ranges&#160;</td><td class="memItemRight" valign="bottom"><b>output_g2_avg</b></td></tr>
<tr class="separator:a26e9a5a40ec5af5f25ebed9ccf8cdab6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad52ad980b4534788ecf0b74ccb620cd9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad52ad980b4534788ecf0b74ccb620cd9"></a>
INT_MAX&#160;</td><td class="memItemRight" valign="bottom"><b>compressed</b></td></tr>
<tr class="separator:ad52ad980b4534788ecf0b74ccb620cd9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6628a6811afecb701315bbe9f4f69a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad6628a6811afecb701315bbe9f4f69a0"></a>
constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><b>kDefaultMinWorkSize</b> = 1</td></tr>
<tr class="separator:ad6628a6811afecb701315bbe9f4f69a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2fda0a33e913bd4c1b4b8eba8ca6d0c8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2fda0a33e913bd4c1b4b8eba8ca6d0c8"></a>
constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><b>kCacheLineSize</b> = 64</td></tr>
<tr class="separator:a2fda0a33e913bd4c1b4b8eba8ca6d0c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d07a4973050cd3d4b5cc90e0b1c422b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4d07a4973050cd3d4b5cc90e0b1c422b"></a>
constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><b>kGEMMLOWPCacheLineSize</b> = 64</td></tr>
<tr class="separator:a4d07a4973050cd3d4b5cc90e0b1c422b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac01c330ff817b47ce5d3f2af7860c9ca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac01c330ff817b47ce5d3f2af7860c9ca"></a>
const int&#160;</td><td class="memItemRight" valign="bottom"><b>kMaxBusyWaitNOPs</b> = 32 * 1000 * 1000</td></tr>
<tr class="separator:ac01c330ff817b47ce5d3f2af7860c9ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeaca74207e0950141b4065f4d3edd356"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeaca74207e0950141b4065f4d3edd356"></a>
where N is the number of elements in the H and W are the height and&#160;</td><td class="memItemRight" valign="bottom"><b>width</b></td></tr>
<tr class="separator:aeaca74207e0950141b4065f4d3edd356"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6c10ab5fa385762978454077dea15e3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af6c10ab5fa385762978454077dea15e3"></a>
where N is the number of elements in the H and W are the height and and each of length num_classes The softmax is applied to each group independently&#160;</td><td class="memItemRight" valign="bottom"><b>See</b></td></tr>
<tr class="separator:af6c10ab5fa385762978454077dea15e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae66d51642dae6860e4466d02f638f6f4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae66d51642dae6860e4466d02f638f6f4"></a>
number of classes in each softmax group tensor of softmax probabilities with where and softmax was applied to each of the num_anchors&#160;</td><td class="memItemRight" valign="bottom"><b>groups</b></td></tr>
<tr class="separator:ae66d51642dae6860e4466d02f638f6f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2dabcd58efcb03a5854ddc2ced520955"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2dabcd58efcb03a5854ddc2ced520955"></a>
See GroupSpatialSoftmax&#160;</td><td class="memItemRight" valign="bottom"><b>d_scores</b></td></tr>
<tr class="separator:a2dabcd58efcb03a5854ddc2ced520955"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa896509ba020db78e177d62b08e853ab"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa896509ba020db78e177d62b08e853ab"></a>
L2 to L1 transition point&#160;</td><td class="memItemRight" valign="bottom"><b>Y_hat</b></td></tr>
<tr class="separator:aa896509ba020db78e177d62b08e853ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0000b1506a25ba86106e1206b320bd9f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0000b1506a25ba86106e1206b320bd9f"></a>
L2 to L1 transition point tensor of bounding box regression predictions with tensor of labels&#160;</td><td class="memItemRight" valign="bottom"><b>locations</b></td></tr>
<tr class="separator:a0000b1506a25ba86106e1206b320bd9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a9ac9ac239dc6258625e39c593f4017"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6a9ac9ac239dc6258625e39c593f4017"></a>
See SelectSmoothL1Loss See SelectSmoothL1Loss&#160;</td><td class="memItemRight" valign="bottom"><b>d_loss</b></td></tr>
<tr class="separator:a6a9ac9ac239dc6258625e39c593f4017"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2de71de1541a14734d46a8850369932"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2de71de1541a14734d46a8850369932"></a>
See SelectSmoothL1Loss See SelectSmoothL1Loss Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>d_Y_hat</b></td></tr>
<tr class="separator:ac2de71de1541a14734d46a8850369932"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33b67d7c8ded06316eb76184a46bd2b1"><td class="memItemLeft" align="right" valign="top">where indicates that the corresponding sample should be ignored&#160;</td><td class="memItemRight" valign="bottom"><b>and</b></td></tr>
<tr class="separator:a33b67d7c8ded06316eb76184a46bd2b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a845d0ba21848e422be4315ee22951e05"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a845d0ba21848e422be4315ee22951e05"></a>
multiply the loss by this scale factor <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of predicted&#160;</td><td class="memItemRight" valign="bottom"><b>targets</b></td></tr>
<tr class="separator:a845d0ba21848e422be4315ee22951e05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86a0093200964db0cdd407849b3ded00"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a86a0093200964db0cdd407849b3ded00"></a>
where N is the number of elements in the H and W are the height and and each of length num_classes For the binary form of Focal&#160;</td><td class="memItemRight" valign="bottom"><b>Loss</b></td></tr>
<tr class="separator:a86a0093200964db0cdd407849b3ded00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9050fa7b2067de6640cd2c7582fe9dfb"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9050fa7b2067de6640cd2c7582fe9dfb"></a>
See SigmoidFocalLoss&#160;</td><td class="memItemRight" valign="bottom"><b>normalizer</b></td></tr>
<tr class="separator:a9050fa7b2067de6640cd2c7582fe9dfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b523ee5c505573455d567eb142dd6ec"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b523ee5c505573455d567eb142dd6ec"></a>
See SigmoidFocalLoss See SigmoidFocalLoss&#160;</td><td class="memItemRight" valign="bottom"><b>d_logits</b></td></tr>
<tr class="separator:a3b523ee5c505573455d567eb142dd6ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11f05925c5b640ee38bd2547e89d25b0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a11f05925c5b640ee38bd2547e89d25b0"></a>
NumInputs(4).NumOutputs(1).SetDoc(R&quot;DOC( Smooth L1 Loss is a minor variation of Huber loss in which the point of transition between L2 loss and L1 loss is adjustable by a hyper-parameter beta L2 to L1 transition point <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of <a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of labels with the same shape as Y_hat&#160;</td><td class="memItemRight" valign="bottom"><b>alpha_out</b></td></tr>
<tr class="separator:a11f05925c5b640ee38bd2547e89d25b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4da563a35f7a8295c1688b7523d5cd8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab4da563a35f7a8295c1688b7523d5cd8"></a>
See SmoothL1Loss&#160;</td><td class="memItemRight" valign="bottom"><b>alpha_in</b></td></tr>
<tr class="separator:ab4da563a35f7a8295c1688b7523d5cd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3b64378cf5baeca5dbbe14b6551fa04"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad3b64378cf5baeca5dbbe14b6551fa04"></a>
where N is the number of elements in the H and W are the height and and where&#160;</td><td class="memItemRight" valign="bottom"><b>p_i</b> = exp(s_i) / sum_j exp(s_j)</td></tr>
<tr class="separator:ad3b64378cf5baeca5dbbe14b6551fa04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3df2618bd4ee692a16513ca45ed324d2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3df2618bd4ee692a16513ca45ed324d2"></a>
or input of&#160;</td><td class="memItemRight" valign="bottom"><b>H0</b></td></tr>
<tr class="separator:a3df2618bd4ee692a16513ca45ed324d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3b58c36c510f86dbb5f4b58f3ee2c69"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae3b58c36c510f86dbb5f4b58f3ee2c69"></a>
See SpatialNarrowAs&#160;</td><td class="memItemRight" valign="bottom"><b>dC</b></td></tr>
<tr class="separator:ae3b58c36c510f86dbb5f4b58f3ee2c69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a459559d278a69f3d8669f8b246a19f01"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a459559d278a69f3d8669f8b246a19f01"></a>
See SpatialNarrowAs Gradient of forward&#160;</td><td class="memItemRight" valign="bottom"><b>dA</b></td></tr>
<tr class="separator:a459559d278a69f3d8669f8b246a19f01"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> global dictionary that holds information about what Caffe2 modules have been loaded in the current runtime, and also utility functions to load modules. </p>
<p>Copyright (c) 2016, NVIDIA CORPORATION, All rights reserved.</p>
<p>Copyright (c) 2016-present, Facebook, Inc.</p>
<p>Copyright 2016 Facebook.</p>
<dl class="section author"><dt>Author</dt><dd>Tudor Bosman (<a href="#" onclick="location.href='mai'+'lto:'+'tud'+'or'+'b@f'+'b.'+'com'; return false;">tudor<span style="display: none;">.nosp@m.</span>b@fb<span style="display: none;">.nosp@m.</span>.com</a>)</dd></dl>
<p>Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at </p><pre class="fragment">http://www.apache.org/licenses/LICENSE-2.0
</pre><p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>
<p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p>
<ol type="1">
<li>Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.</li>
<li>Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.</li>
</ol>
<p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR <a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. </p>
</div><h2 class="groupheader">Function Documentation</h2>
<a class="anchor" id="a882a6d5eb5b21f3f19113c171b8a276f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API void caffe2::addBlobDeviceOptions </td>
          <td>(</td>
          <td class="paramtype">std::map&lt; std::string, caffe2::DeviceOption &gt;&#160;</td>
          <td class="paramname"><em>blobMap</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a> *&#160;</td>
          <td class="paramname"><em>nn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Helpers for the convertToNNModule for use if you already have an NNModule. </p>
<p>You probably don't want to use these if you can use convertToNNModule instead. </p>

<p>Definition at line <a class="el" href="distributed_8cc_source.html#l00016">16</a> of file <a class="el" href="distributed_8cc_source.html">distributed.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a4f6369bbf216f45519638f9aceb22773"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_CUDA_API int caffe2::CaffeCudaGetDevice </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the current GPU id. </p>
<p>This is a simple wrapper around cudaGetDevice(). </p>

<p>Definition at line <a class="el" href="common__gpu_8cc_source.html#l00096">96</a> of file <a class="el" href="common__gpu_8cc_source.html">common_gpu.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ae5ded10391eee674b0aaa6d61353e0ab"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_CUDA_API void caffe2::CaffeCudaSetDevice </td>
          <td>(</td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>id</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the current GPU id. </p>
<p>This is a simple wrapper around cudaGetDevice(). </p>

<p>Definition at line <a class="el" href="common__gpu_8cc_source.html#l00102">102</a> of file <a class="el" href="common__gpu_8cc_source.html">common_gpu.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a8b29e6c380745c1fe5cd12d9ad712a75"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a> caffe2::convertToNNModule </td>
          <td>(</td>
          <td class="paramtype">const caffe2::NetDef &amp;&#160;</td>
          <td class="paramname"><em>net</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>strict</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classnom_1_1_node.html">repr::NNGraph::NodeRef</a> &gt; *&#160;</td>
          <td class="paramname"><em>opNodeVec</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Ingest a <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> protobuf model and output an NNModule. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">net</td><td>The <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> protobuf NetDef </td></tr>
  </table>
  </dd>
</dl>
<p>We keep track of the producer of the blob. Because Caffe2 Nets are really just ordered operations we can just keep track of the most recent producer of a blob and draw and edge from that to any consumer we come by. If a new operator produces the blob we simply replace it in this map.</p>
<p>For the construction of the control flow graph we keep track of a current basic block, which we split up as we come accross control flow operations such as if and while. </p>

<p>Definition at line <a class="el" href="converter_8cc_source.html#l00301">301</a> of file <a class="el" href="converter_8cc_source.html">converter.cc</a>.</p>

</div>
</div>
<a class="anchor" id="aa622473d4ffc538d61f14a134ad03e20"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API <a class="el" href="structnom_1_1repr_1_1_n_n_module.html">nom::repr::NNModule</a> caffe2::convertToNNModule </td>
          <td>(</td>
          <td class="paramtype">caffe2::NetDef &amp;&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::map&lt; std::string, caffe2::DeviceOption &gt;&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Convert to an NNModule and apply a mapping of tensor names to DeviceOptions to it. </p>
<p>This <em>only</em> applies the map to Declare/Export nodes, which are representationally equivalent to external_input/external_output in <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> NetDefs.</p>
<p>Throws an exception if the passed in blobMap contains blobs that are not present in the NNModule. </p>

<p>Definition at line <a class="el" href="distributed_8cc_source.html#l00103">103</a> of file <a class="el" href="distributed_8cc_source.html">distributed.cc</a>.</p>

</div>
</div>
<a class="anchor" id="af932547d95616517ff8fe091eb3ba698"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structnom_1_1repr_1_1_n_n_module.html">repr::NNModule</a> caffe2::convertToNNModule </td>
          <td>(</td>
          <td class="paramtype">const caffe2::NetDef &amp;&#160;</td>
          <td class="paramname"><em>net</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>strict</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classnom_1_1_node.html">repr::NNGraph::NodeRef</a> &gt; *&#160;</td>
          <td class="paramname"><em>opNodeVec</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Ingest a <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> protobuf model and output an NNModule. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">net</td><td>The <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> protobuf NetDef </td></tr>
  </table>
  </dd>
</dl>
<p>We keep track of the producer of the blob. Because Caffe2 Nets are really just ordered operations we can just keep track of the most recent producer of a blob and draw and edge from that to any consumer we come by. If a new operator produces the blob we simply replace it in this map.</p>
<p>For the construction of the control flow graph we keep track of a current basic block, which we split up as we come accross control flow operations such as if and while. </p>

<p>Definition at line <a class="el" href="converter_8cc_source.html#l00301">301</a> of file <a class="el" href="converter_8cc_source.html">converter.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ab3d440e0ce95795f9d5b9f035073195e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API unique_ptr&lt; <a class="el" href="classcaffe2_1_1_net_base.html">NetBase</a> &gt; caffe2::CreateNet </td>
          <td>(</td>
          <td class="paramtype">const NetDef &amp;&#160;</td>
          <td class="paramname"><em>net_def</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *&#160;</td>
          <td class="paramname"><em>ws</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Creates a network, accessing / creating blobs in the given workspace. </p>
<p>Note that this is different from <a class="el" href="classcaffe2_1_1_workspace.html#ac8c465ceb6cecbd5a2311f3d5bf4c35e" title="Creates a network with the given NetDef, and returns the pointer to the network. ">Workspace::CreateNet</a>. The latter adds the created net object to the workspace's net map, while this function returns a standalone net object. </p>

<p>Definition at line <a class="el" href="net_8cc_source.html#l00151">151</a> of file <a class="el" href="net_8cc_source.html">net.cc</a>.</p>

</div>
</div>
<a class="anchor" id="af626e8bd4defd97004472e4618071467"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::unique_ptr&lt;<a class="el" href="classcaffe2_1_1_recurrent_network_executor_base.html">RecurrentNetworkExecutorBase</a>&gt; caffe2::createRNNExecutor&lt; <a class="el" href="classcaffe2_1_1_c_p_u_context.html">CPUContext</a> &gt; </td>
          <td>(</td>
          <td class="paramtype">const NetDef &amp;&#160;</td>
          <td class="paramname"><em>step_net_def</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::map&lt; string, string &gt; &amp;&#160;</td>
          <td class="paramname"><em>recurrent_input_map</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>timestep_blob</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcaffe2_1_1_argument_helper.html">ArgumentHelper</a>&#160;</td>
          <td class="paramname"><em>rnn_args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implementation of RecurrentNetworkExecutor that uses thread pool for multithreaded execution of RNNs. </p>
<p>Used with CPU. </p>

<p>Definition at line <a class="el" href="recurrent__network__executor_8cc_source.html#l00013">13</a> of file <a class="el" href="recurrent__network__executor_8cc_source.html">recurrent_network_executor.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a5bab26d8f00817d54cb0d975ea633123"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Context &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void caffe2::createSharedBuffer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcaffe2_1_1_workspace.html">Workspace</a> *&#160;</td>
          <td class="paramname"><em>ws</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Creates a mutex and shared buffer in the workspace. </p>
<p>Not thread-safe, must be called from the constructor. </p>

</div>
</div>
<a class="anchor" id="a3cdcb7acfd41aedb349910afd55eb5a8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API const CaffeMap&lt; string, const <a class="el" href="classcaffe2_1_1_module_schema.html">ModuleSchema</a> * &gt; &amp; caffe2::CurrentModules </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Current Modules present in the Caffe2 runtime. </p>
<p>Returns: map: a map of modules and (optionally) their description. The key is the module name, and the value is the description for that module. The module name is recommended to be the part that constitutes the trunk of the dynamic library: for example, a module called libcaffe2_db_rocksdb.so should have the name "caffe2_db_rocksdb". The reason we do not use "lib" is because it's somewhat redundant, and the reason we do not include ".so" is for cross-platform compatibility on platforms like mac os. </p>

<p>Definition at line <a class="el" href="module_8cc_source.html#l00027">27</a> of file <a class="el" href="module_8cc_source.html">module.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a6b05dd11e7a9e3d8318df5c99008fb46"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API void caffe2::DeserializeBlob </td>
          <td>(</td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>content</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcaffe2_1_1_blob.html">Blob</a> *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Deserializes from a string containing either BlobProto or TensorProto. </p>
<p>If the deserialization fails, the content in the blob should no longer be trusted. </p>

<p>Definition at line <a class="el" href="blob__serialization_8cc_source.html#l00362">362</a> of file <a class="el" href="blob__serialization_8cc_source.html">blob_serialization.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a069c8118feb23c3b2ad89f3e10b8198d"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename IndexType , typename InType , typename OutType , bool IS_WEIGHT_POSITIONAL = false&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void caffe2::EmbeddingLookup </td>
          <td>(</td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>block_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>output_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>index_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>data_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const InType *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const IndexType *&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int *&#160;</td>
          <td class="paramname"><em>lengths</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>scale_bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>normalize_by_lengths</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutType *&#160;</td>
          <td class="paramname"><em>out</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Embedding lookup with reduction. </p>
<p><code>input</code> of size data_size * block_size <code>indices</code> of size index_size <code>lengths</code> of size output_size <code>weights</code> nullptr or array of size index_size <code>out</code> of size output_size * block_size sum(lengths[i]) == index_size</p>
<p>Behavior is roughly equivalent to pseudocode:</p>
<p>pos = 0 for (i = 0..index_size-1) for (k = 0..block_size-1) out[i*block_size + k] = 0 for (j = 0..lengths[i]-1) for (k = 0..block_size-1) out[i*block_size + k] += input[indices[pos]*block_size + k] * (weights ? weights[IS_WEIGHT_POSITIONAL ? j : pos] : 1.0) pos += 1 if (normalize_weights &amp;&amp; lengths[i] &gt; 0) for (k = 0..block_size-1) out[i*block_size + k] /= lengths[i] </p>

</div>
</div>
<a class="anchor" id="a598eb1dd260a469dd6432b292697ebf5"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">fbgemm::CompressedSparseColumn* caffe2::ExtractOutlierMatrix </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>groups</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>kernel_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>M</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbits_in_non_outlier</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; std::int8_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>W_quantized</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W_quantized</td><td>input quantized weight that is not packed yet </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a75e437e39d446084ae41c0ba6afad2a2"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename IndexType , typename InType , typename OutType , bool IS_WEIGHT_POSITIONAL = false&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void caffe2::Fused8BitRowwiseEmbeddingLookup </td>
          <td>(</td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>block_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>output_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>index_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::int64_t&#160;</td>
          <td class="paramname"><em>data_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const InType *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const IndexType *&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int *&#160;</td>
          <td class="paramname"><em>lengths</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>normalize_by_lengths</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutType *&#160;</td>
          <td class="paramname"><em>out</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Embedding lookup with reduction. </p>
<p><code>input</code> of size data_size * (block_size + 8B) <code>indices</code> of size index_size <code>lengths</code> of size output_size <code>weights</code> nullptr or array of size index_size <code>out</code> of size output_size * block_size sum(lengths[i]) == index_size</p>
<p>Note that block_size should be the number of quantized values per row in the data, i.e. excluding the scale and bias. The total (fused) block size is assumed to be this block_size, plus 4 bytes for scale and 4 bytes for bias.</p>
<p>Behavior is roughly equivalent to pseudocode:</p>
<p>pos = 0 fused_block_size = block_size + 8B // quantized values and scale and bias for (i = 0..index_size-1) for (k = 0..block_size-1) out[i*block_size + k] = 0 for (j = 0..lengths[i]-1) for (k = 0..block_size-1) out[i*block_size + k] += input[indices[pos]*(fused_block_size) + k] * (weights ? weights[IS_WEIGHT_POSITIONAL ? j : pos] : 1.0) pos += 1 if (normalize_weights &amp;&amp; lengths[i] &gt; 0) for (k = 0..block_size-1) out[i*block_size + k] /= lengths[i] </p>

</div>
</div>
<a class="anchor" id="acc9c70f728fa0ccd1bca146cd1d282ae"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void caffe2::Get1DPartitionOf2D </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nthreads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>thread_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>m_begin</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>m_end</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>n_begin</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>n_end</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n_align</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>1D-partition m x n 2D work. </p>
<p>First try partitioning m if m &gt;= nthreads. Otherwise, each row is partitioned by multiple threads. In this case, each thread only works on a single row. Optionally, we can force the number of columns assigned per thread is a multiple of n_align. </p>

<p>Definition at line <a class="el" href="dnnlowp__partition_8cc_source.html#l00020">20</a> of file <a class="el" href="dnnlowp__partition_8cc_source.html">dnnlowp_partition.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ab645e4c1c84a791406d55a16f31a7e80"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_CUDA_API CudaMemoryPoolType caffe2::GetCudaMemoryPoolType </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the current memory pool type used by Caffe2. </p>
<p>The memory pool is set up during <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a>'s global initialization time. </p>

</div>
</div>
<a class="anchor" id="a8e1e6fbe09090c25f04ce1bdacc9f030"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_CUDA_API bool caffe2::GetCudaPeerAccessPattern </td>
          <td>(</td>
          <td class="paramtype">vector&lt; vector&lt; bool &gt;&gt; *&#160;</td>
          <td class="paramname"><em>pattern</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Return a peer access pattern by returning a matrix (in the format of a nested vector) of boolean values specifying whether peer access is possible. </p>
<p>This function returns false if anything wrong happens during the query of the GPU access pattern. </p>

</div>
</div>
<a class="anchor" id="aa7078d33f22df2864a57ac382257afec"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_CUDA_API const cudaDeviceProp &amp; caffe2::GetDeviceProperty </td>
          <td>(</td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>device</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the device property for the given device. </p>
<p>This function is thread safe. </p>

<p>Definition at line <a class="el" href="common__gpu_8cc_source.html#l00139">139</a> of file <a class="el" href="common__gpu_8cc_source.html">common_gpu.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ae9b241203d1057494c9eefcde409a05e"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename ACC_T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;fbgemm::PackBMatrix&lt;int8_t, ACC_T&gt; &gt; caffe2::GetOrCreateFbgemmPackBMatrix </td>
          <td>(</td>
          <td class="paramtype">fbgemm::matrix_op_t&#160;</td>
          <td class="paramname"><em>trans</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::int32_t&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::int32_t&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>orig_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::int8_t *&#160;</td>
          <td class="paramname"><em>quantized_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::int32_t&#160;</td>
          <td class="paramname"><em>ld</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>If there's an existing packed matrix for the same matrix, reuse it. </p>
<p>Create a new one otherwise. This can save memory usage if many threads are sharing the same weight. </p>

</div>
</div>
<a class="anchor" id="a34ee9caa2ba0f16d7573ca9173803931"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API bool caffe2::GlobalInit </td>
          <td>(</td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>pargc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char ***&#160;</td>
          <td class="paramname"><em>argv</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialize the global environment of <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a>. </p>
<p>Caffe2 uses a registration pattern for initialization functions. Custom initialization functions should take the signature bool (<em>func)(int</em>, char***) where the pointers to argc and argv are passed in. Caffe2 then runs the initialization in three phases: (1) Functions registered with REGISTER_CAFFE2_EARLY_INIT_FUNCTION. Note that since it is possible the logger is not initialized yet, any logging in such early init functions may not be printed correctly. (2) Parses Caffe-specific commandline flags, and initializes caffe logging. (3) Functions registered with REGISTER_CAFFE2_INIT_FUNCTION. If there is something wrong at each stage, the function returns false. If the global initialization has already been run, the function returns false as well.</p>
<p>GlobalInit is re-entrant safe; a re-entrant call will no-op and exit.</p>
<p>GlobalInit is safe to call multiple times but not idempotent; successive calls will parse flags and re-set <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> logging levels from flags as needed, but NOT re-run early init and init functions.</p>
<p>GlobalInit is also thread-safe and can be called concurrently. </p>

<p>Definition at line <a class="el" href="init_8cc_source.html#l00044">44</a> of file <a class="el" href="init_8cc_source.html">init.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ac1d8febf62e5b0a60614a4ce5754d373"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API bool caffe2::GlobalInit </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialize the global environment without command line arguments. </p>
<p>This is a version of the GlobalInit where no argument is passed in. On mobile devices, use this global init, since we cannot pass the command line options to <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a>, no arguments are passed. </p>

<p>Definition at line <a class="el" href="init_8cc_source.html#l00093">93</a> of file <a class="el" href="init_8cc_source.html">init.cc</a>.</p>

</div>
</div>
<a class="anchor" id="aa32a2d15d30c2bff23d742e401ee0841"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API MPI_Comm caffe2::GlobalMPIComm </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the global MPI communicator used by Caffe2. </p>
<p>In default, this is MPI_COMM_WORLD unless you call <a class="el" href="namespacecaffe2.html#a438633cd31c7c1685fcc95cf03a7f7cf" title="Sets the global MPI communicator. ">SetGlobalMPIComm()</a>. </p>

<p>Definition at line <a class="el" href="mpi__common_8cc_source.html#l00020">20</a> of file <a class="el" href="mpi__common_8cc_source.html">mpi_common.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a48638afbef9a25309bf7ef40a6e97919"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool caffe2::HasCudaGPU </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Check if the current running session has a cuda gpu present. </p>
<p>Note that this is different from having <a class="el" href="namespacecaffe2.html" title="A global dictionary that holds information about what Caffe2 modules have been loaded in the current ...">caffe2</a> built with cuda. Building Caffe2 with cuda only guarantees that this function exists. If there are no cuda gpus present in the machine, or there are hardware configuration problems like an insufficient driver, this function will still return false, meaning that there is no usable GPU present.</p>
<p>In the open source build, it is possible that Caffe2's GPU code is dynamically loaded, and as a result a library could be only linked to the CPU code, but want to test if cuda is later available or not. In this case, one should use HasCudaRuntime() from common.h. </p>

<p>Definition at line <a class="el" href="common__gpu_8h_source.html#l00149">149</a> of file <a class="el" href="common__gpu_8h_source.html">common_gpu.h</a>.</p>

</div>
</div>
<a class="anchor" id="a5c2e21acb51df80158e5644031314050"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API void caffe2::LoadModule </td>
          <td>(</td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>filename</em> = <code>&quot;&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a module. </p>
<p>Inputs: name: a module name or a path name. It is recommended that you use the name of the module, and leave the full path option to only experimental modules. filename: (optional) a filename that serves as a hint to load the module. </p>

<p>Definition at line <a class="el" href="module_8cc_source.html#l00052">52</a> of file <a class="el" href="module_8cc_source.html">module.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a0ca6146615d44e0893a020304848c3d1"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename F &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcaffe2_1_1detail_1_1_scope_guard_impl.html">detail::ScopeGuardImplDecay</a>&lt;F&gt; caffe2::MakeGuard </td>
          <td>(</td>
          <td class="paramtype">F &amp;&amp;&#160;</td>
          <td class="paramname"><em>f</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>ScopeGuard is a general implementation of the "Initialization is
Resource Acquisition" idiom. </p>
<p>Basically, it guarantees that a function is executed upon leaving the currrent scope unless otherwise told.</p>
<p>The <a class="el" href="namespacecaffe2.html#a0ca6146615d44e0893a020304848c3d1" title="ScopeGuard is a general implementation of the &quot;Initialization is Resource Acquisition&quot; idiom...">MakeGuard()</a> function is used to create a new ScopeGuard object. It can be instantiated with a lambda function, a std::function&lt;void()&gt;, a functor, or a void(*)() function pointer.</p>
<p>Usage example: <a class="el" href="class_add.html">Add</a> a friend to memory iff it is also added to the db.</p>
<p>void User::addFriend(User&amp; newFriend) { // add the friend to memory friends_.push_back(&amp;newFriend);</p>
<p>// If the db insertion that follows fails, we should // remove it from memory. auto guard = MakeGuard([&amp;] { friends_.pop_back(); });</p>
<p>// this will throw an exception upon error, which // makes the ScopeGuard execute UserCont::pop_back() // once the Guard's destructor is called. db_-&gt;addFriend(GetName(), newFriend.GetName());</p>
<p>// an exception was not thrown, so don't execute // the Guard. guard.dismiss(); }</p>
<p>Examine ScopeGuardTest.cpp for some more sample usage.</p>
<p>Stolen from: Andrei's and Petru Marginean's CUJ article: <a href="http://drdobbs.com/184403758">http://drdobbs.com/184403758</a> and the loki library: <a href="http://loki-lib.sourceforge.net/index.php?n=Idioms.ScopeGuardPointer">http://loki-lib.sourceforge.net/index.php?n=Idioms.ScopeGuardPointer</a> and triendl.kj article: <a href="http://www.codeproject.com/KB/cpp/scope_guard.aspx">http://www.codeproject.com/KB/cpp/scope_guard.aspx</a> </p>

<p>Definition at line <a class="el" href="scope__guard_8h_source.html#l00153">153</a> of file <a class="el" href="scope__guard_8h_source.html">scope_guard.h</a>.</p>

</div>
</div>
<a class="anchor" id="a7105376fca14f67a44e669947c9300b0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API bool caffe2::MatchStrings </td>
          <td>(</td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>s</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This allows for the use of * and | to match operator types, engines, or any other property that is represented by strings. </p>
<p>For example, if we wanted to match an operator to <a class="el" href="class_conv.html">Conv</a> or <a class="el" href="class_f_c.html">FC</a>, we can give: "Conv|FC" as the type() of that op. </p>

<p>Definition at line <a class="el" href="graph_8cc_source.html#l00214">214</a> of file <a class="el" href="graph_8cc_source.html">graph.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a4dc2404153d4045abf87562f016a7fa4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void caffe2::MPISetupPeers </td>
          <td>(</td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>replicas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>role</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>job_path</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><a class="el" href="class_a.html" title="does bound shape inference given a C2 net. ">A</a> function used to perform peer setup so one does not need to use mpirun / mpiexec to run the binary. </p>
<p>Note that if you use mpirun or mpiexec to set up the common world, do not use this function - MPI_Init would have already set that up.</p>
<p>This also assumes that you have a common path (like NFS) that multiple instances can read from.</p>
<p>Inputs: replicas (int): the number of replicas that mpi will run with. role (string): the role of this process, "server" or "client". job_path (string): a file name that the server will write its port into and the clients will read the server's port from. </p>

<p>Definition at line <a class="el" href="mpi__common_8cc_source.html#l00094">94</a> of file <a class="el" href="mpi__common_8cc_source.html">mpi_common.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ac7f0e8205348ebe02da420eca59a942f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API void caffe2::SerializeBlob </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;&#160;</td>
          <td class="paramname"><em>blob</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">BlobSerializerBase::SerializationAcceptor&#160;</td>
          <td class="paramname"><em>acceptor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>chunk_size</em> = <code>kDefaultChunkSize</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Serializes the given blob, if possible. </p>
<p>Note that this serialization uses the registration mechanism and one has to implement specific serialization approaches for specific classes. Acceptor should take care of writing data to the actual storage. </p>

<p>Definition at line <a class="el" href="blob__serialization_8cc_source.html#l00092">92</a> of file <a class="el" href="blob__serialization_8cc_source.html">blob_serialization.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ac88344ce83b47dcf2290d09f0f500164"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API string caffe2::SerializeBlob </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcaffe2_1_1_blob.html">Blob</a> &amp;&#160;</td>
          <td class="paramname"><em>blob</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>name</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Convenience function to serialize a blob to a string. </p>
<p>This is a conveinence function to serialize small Blobs that produce manageable serialized strings. To serialize big blobs such as large sparse tensors, use the fully-functional interface in <a class="el" href="blob__serializer__base_8h_source.html">blob_serializer_base.h</a>.</p>
<p>NOTE: this function doesn't do chunking and might break with big tensors. </p>

<p>Definition at line <a class="el" href="blob__serialization_8cc_source.html#l00100">100</a> of file <a class="el" href="blob__serialization_8cc_source.html">blob_serialization.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a438633cd31c7c1685fcc95cf03a7f7cf"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">CAFFE2_API void caffe2::SetGlobalMPIComm </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>new_comm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the global MPI communicator. </p>
<p>Caffe2 takes over the ownership of the passed in communicator. </p>

<p>Definition at line <a class="el" href="mpi__common_8cc_source.html#l00024">24</a> of file <a class="el" href="mpi__common_8cc_source.html">mpi_common.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a9004d4d17e6bab9445bcb231d4b097ef"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename SIndex &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int caffe2::sparse_adagrad </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>block_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::uint64_t&#160;</td>
          <td class="paramname"><em>param_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>g</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SIndex *&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>nw</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>nh</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>lr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>num_rows if succeeds otherwise return the row idx where we pass the boundary of param_size </dd></dl>

</div>
</div>
<a class="anchor" id="a4109386aaa76859aba7efd3465d30106"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> caffe2::TensorCPUFromValues </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classc10_1_1_array_ref.html">at::IntArrayRef</a>&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classc10_1_1_array_ref.html">at::ArrayRef</a>&lt; <a class="el" href="struct_t.html">T</a> &gt;&#160;</td>
          <td class="paramname"><em>values</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Creates a CPU tensor, and fills its contents with the given values. </p>
<p>Values are copied in </p>

<p>Definition at line <a class="el" href="caffe2_2core_2tensor_8h_source.html#l00663">663</a> of file <a class="el" href="caffe2_2core_2tensor_8h_source.html">tensor.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a class="anchor" id="a740cd076fdf40bd78a4a80ba11170b42"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">it will be coerced into one For an arbitrary n dimensional tensor X where k is the axis then X will be coerced into a dimensional tensor with dimensions [(a_0 * ... * a_{k-1}), (a_k * ... * a_{n-1})] For the default case where the X tensor will be coerced into a tensor of where $a_0 is often the batch size In this we must hav caffe2::$a_0) </td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= N$ and $a_1 * ... * a_{n-1} = <a class="code" href="struct_d.html">D</a>$. Each of these</div><div class="line">dimensions must be matched correctly</div><div class="ttc" id="struct_d_html"><div class="ttname"><a href="struct_d.html">D</a></div><div class="ttdef"><b>Definition:</b> <a href="static_8cpp_source.html#l00070">static.cpp:70</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="softmax__op_8cc_source.html#l00123">123</a> of file <a class="el" href="softmax__op_8cc_source.html">softmax_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a34174f2652b1ceed8b21e82dc5401de4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">it will be coerced into one For an arbitrary n dimensional tensor X in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is the axis then X will be coerced into a dimensional tensor with dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}] For the default case where this means the X tensor will be coerced into a tensor of where a_0 is often the batch size In this we must have caffe2::a_0</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= N and a_1 * ... * a_{n-1} = <a class="code" href="struct_d.html">D</a>.</div><div class="line">Each of these dimensions must be matched correctly</div><div class="ttc" id="struct_d_html"><div class="ttname"><a href="struct_d.html">D</a></div><div class="ttdef"><b>Definition:</b> <a href="static_8cpp_source.html#l00070">static.cpp:70</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="int8__softmax__op_8cc_source.html#l00026">26</a> of file <a class="el" href="int8__softmax__op_8cc_source.html">int8_softmax_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a33b67d7c8ded06316eb76184a46bd2b1"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">where indicates that the corresponding sample should be ignored caffe2::and</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{0, 1} correspond to the binary classes 0 and 1. By</div><div class="line"><span class="keywordflow">default</span> the loss is divided by the number of targets &gt; -1 and then multiplied by</div><div class="line">the `scale` op argument. The divisive normalization may be disable by setting</div><div class="line">the op argument `normalize` to 0 (the multiplication by `scale` still takes</div><div class="line">effect).</div><div class="line"></div><div class="line">This op fuses sigmoid and cross entropy <span class="keywordflow">for</span> numerical stability in both forward</div><div class="line">and gradient computation.</div><div class="line">)DOC<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Arg(</span></div><div class="line"><span class="stringliteral">        &quot;</span>scale<span class="stringliteral">&quot;,</span></div><div class="line"><span class="stringliteral">        &quot;</span>(float) <span class="keywordflow">default</span> 1.0</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="sigmoid__cross__entropy__loss__op_8cc_source.html#l00034">34</a> of file <a class="el" href="sigmoid__cross__entropy__loss__op_8cc_source.html">sigmoid_cross_entropy_loss_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="addad4c4cf84d667f963d2f34365f3fd4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::batch_size</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">              size_to_dim_(canonical_axis, GetDimsVector(logits))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="softmax__with__loss__op_8cc_source.html#l00026">26</a> of file <a class="el" href="softmax__with__loss__op_8cc_source.html">softmax_with_loss_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a3bc60a5d359d05aa9077867f0464214c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">default must must caffe2::be</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= 0.<span class="stringliteral">&quot;);</span></div><div class="line"><span class="stringliteral"></span></div><div class="line"><span class="stringliteral"></span></div><div class="line"><span class="stringliteral">    .NumInputs(1)</span></div><div class="line"><span class="stringliteral">    .NumOutputs(0, 1)</span></div><div class="line"><span class="stringliteral">    .SetDoc(R&quot;</span>DOC(</div><div class="line">Resets a count-down counter with initial value specified by the `init_count`</div><div class="line">argument.</div><div class="line">)DOC<span class="stringliteral">&quot; + (string) githubLinks + (string) kCountExample)</span></div><div class="line"><span class="stringliteral">    .Input(</span></div><div class="line"><span class="stringliteral">        0,</span></div><div class="line"><span class="stringliteral">        &quot;</span>counter<span class="stringliteral">&quot;,</span></div><div class="line"><span class="stringliteral">        &quot;</span>*(type: <a class="code" href="struct_tensor.html">Tensor</a>`&lt;ptr&gt;`)* <a class="code" href="struct_a.html">A</a> blob pointing to an instance of a counter.<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Output(</span></div><div class="line"><span class="stringliteral">        0,</span></div><div class="line"><span class="stringliteral">        &quot;</span>previous_value<span class="stringliteral">&quot;,</span></div><div class="line"><span class="stringliteral">        &quot;</span>*(type: <span class="keywordtype">int</span>)* [OPTIONAL] count value BEFORE <span class="keyword">this</span> operation.<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Arg(</span></div><div class="line"><span class="stringliteral">        &quot;</span>init_count<span class="stringliteral">&quot;,</span></div><div class="line"><span class="stringliteral">        &quot;</span>*(type: int; <span class="keywordflow">default</span>: 0)* Resets counter to <span class="keyword">this</span> value</div><div class="ttc" id="struct_a_html"><div class="ttname"><a href="struct_a.html">A</a></div><div class="ttdef"><b>Definition:</b> <a href="static_8cpp_source.html#l00052">static.cpp:52</a></div></div>
<div class="ttc" id="struct_tensor_html"><div class="ttname"><a href="struct_tensor.html">Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="ios__caffe__predictor_8h_source.html#l00009">ios_caffe_predictor.h:9</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="counter__ops_8cc_source.html#l00210">210</a> of file <a class="el" href="counter__ops_8cc_source.html">counter_ops.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a8a02153d276223fef9c3078199432411"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">this op outputs a copy of the input tensor where values from the height and width dimensions are moved to the batch dimension After the zero padding is according to the pad both height and width of the input must be divisible by the block_size Only NCHW order is currently supported Github caffe2::block_size</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=3</div><div class="line">)</div><div class="line"></div><div class="line">workspace.FeedBlob(<span class="stringliteral">&quot;X&quot;</span>, np.random.rand(1,3,5,5).astype(np.float32))</div><div class="line">print(<span class="stringliteral">&quot;X.shape:&quot;</span>, workspace.FetchBlob(<span class="stringliteral">&quot;X&quot;</span>).shape)</div><div class="line">workspace.RunOperatorOnce(op)</div><div class="line">print(<span class="stringliteral">&quot;Y.shape:&quot;</span>, workspace.FetchBlob(<span class="stringliteral">&quot;Y&quot;</span>).shape)</div><div class="line"></div><div class="line">```</div><div class="line"></div><div class="line">**Result**</div><div class="line"></div><div class="line">```</div><div class="line"></div><div class="line">X.shape: (1, 3, 5, 5)</div><div class="line">Y.shape: (9, 3, 3, 3)</div><div class="line"></div><div class="line">```</div><div class="line"></div><div class="line">&lt;/details&gt;</div><div class="line"></div><div class="line">)DOC<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Arg(&quot;</span>pad<span class="stringliteral">&quot;,&quot;</span>(*<span class="keywordtype">int</span>*): exclusive axis that divides the first and second dimension of matrix `<a class="code" href="struct_a.html">A</a>` (<span class="keywordflow">default</span>=0)<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Arg(&quot;</span>block_size<span class="stringliteral">&quot;,&quot;</span>(*<span class="keywordtype">int</span>*): height/width of spatial blocks to be moved (<span class="keywordflow">default</span>=2)<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Arg(&quot;</span>order<span class="stringliteral">&quot;,&quot;</span>(*<span class="keywordtype">string</span>*): order of dimensions of input and output blobs</div><div class="ttc" id="struct_a_html"><div class="ttname"><a href="struct_a.html">A</a></div><div class="ttdef"><b>Definition:</b> <a href="static_8cpp_source.html#l00052">static.cpp:52</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="space__batch__op_8cc_source.html#l00027">27</a> of file <a class="el" href="space__batch__op_8cc_source.html">space_batch_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a833087f682593970e7914e0992e5d3df"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const auto caffe2::canonical_axis</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">          canonical_axis_index_(axis, in[0].dims().size())</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="layer__norm__op_8cc_source.html#l00147">147</a> of file <a class="el" href="layer__norm__op_8cc_source.html">layer_norm_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="acc0e9e0832cf223c6e83fcd68296b742"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">constexpr DeviceType caffe2::COMPILE_TIME_MAX_DEVICE_TYPES</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">    DeviceType::COMPILE_TIME_MAX_DEVICE_TYPES</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="caffe2__pb_8h_source.html#l00016">16</a> of file <a class="el" href="caffe2__pb_8h_source.html">caffe2_pb.h</a>.</p>

</div>
</div>
<a class="anchor" id="a84e9aac7255302feac18b3cd49a3a05e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int caffe2::default</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=\<span class="stringliteral">&quot;\&quot;) Serialized ONNX model to be converted to backend representation&quot;</span>)</div><div class="line">    .Arg(</div><div class="line">        <span class="stringliteral">&quot;initializers&quot;</span>,</div><div class="line">        <span class="stringliteral">&quot;Initialization pair indicating the mapping of the name between NetDef and ONNX model&quot;</span>)</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="arg__ops_8cc_source.html#l00103">103</a> of file <a class="el" href="arg__ops_8cc_source.html">arg_ops.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a6813549291034e22b8c23512190e36e1"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::dilation_h</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(</div><div class="line">              <span class="stringliteral">&quot;dilation_h&quot;</span>, helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;dilation&quot;</span>, 1))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="im2col__op_8cc_source.html#l00040">40</a> of file <a class="el" href="im2col__op_8cc_source.html">im2col_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a0a8bd7d72a9b3c36434015674bc13cd7"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::dilation_w</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(</div><div class="line">              <span class="stringliteral">&quot;dilation_w&quot;</span>, helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;dilation&quot;</span>, 1))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="im2col__op_8cc_source.html#l00042">42</a> of file <a class="el" href="im2col__op_8cc_source.html">im2col_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="abc042919e612ec50e763098e9a6a10c4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">given param caffe2::else</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div><div class="line">            CAFFE_ENFORCE_EQ(</div><div class="line">                totalSize,</div><div class="line">                size,</div><div class="line">                <span class="stringliteral">&quot;Argument `shape` does not agree with the input data.&quot;</span>,</div><div class="line">                <span class="stringliteral">&quot; (&quot;</span>,</div><div class="line">                totalSize,</div><div class="line">                <span class="stringliteral">&quot; != &quot;</span>,</div><div class="line">                size,</div><div class="line">                <span class="stringliteral">&quot;)&quot;</span>)</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="operators_2reshape__op_8cc_source.html#l00088">88</a> of file <a class="el" href="operators_2reshape__op_8cc_source.html">reshape_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a441e9ef50971c213c28777dea092cae2"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const char* caffe2::githubLinks</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= R<span class="stringliteral">&quot;DOC(</span></div><div class="line"><span class="stringliteral">  Github Links:</span></div><div class="line"><span class="stringliteral">  - https://github.com/pytorch/pytorch/blob/master/caffe2/operators/counter_ops.cc</span></div><div class="line"><span class="stringliteral"></span></div><div class="line"><span class="stringliteral">)DOC&quot;</span></div></div><!-- fragment -->
<p>Definition at line <a class="el" href="counter__ops_8cc_source.html#l00006">6</a> of file <a class="el" href="counter__ops_8cc_source.html">counter_ops.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a6e20361269928187b6a5625204805051"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const vector&lt; TensorShape &gt; &amp; caffe2::in</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div><div class="line">      vector&lt;TensorShape&gt; out(1)</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="batch__gather__ops_8cc_source.html#l00012">12</a> of file <a class="el" href="batch__gather__ops_8cc_source.html">batch_gather_ops.cc</a>.</p>

</div>
</div>
<a class="anchor" id="af5494970aaaedf6895222529c8afdd60"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const char caffe2::kAveragePoolDoc_int8[]</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= R<span class="stringliteral">&quot;DOC(</span></div><div class="line"><span class="stringliteral">consumes an input blob X and applies average pooling across the</span></div><div class="line"><span class="stringliteral">the blob according to kernel sizes, stride sizes, and pad lengths defined by the</span></div><div class="line"><span class="stringliteral">ConvPoolOpBase operator. Average pooling consisting of averaging all values of a</span></div><div class="line"><span class="stringliteral">subset of the input tensor according to the kernel size and downsampling the</span></div><div class="line"><span class="stringliteral">data into the output blob Y for further processing.</span></div><div class="line"><span class="stringliteral">)DOC&quot;</span></div></div><!-- fragment -->
<p>Definition at line <a class="el" href="int8__average__pool__op_8cc_source.html#l00012">12</a> of file <a class="el" href="int8__average__pool__op_8cc_source.html">int8_average_pool_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ac92a1dd732464903fd5fd2171374ae94"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const char caffe2::kConvDoc_int8[]</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= R<span class="stringliteral">&quot;DOC(</span></div><div class="line"><span class="stringliteral">[Only NHWC order is supported now]Note that other parameters, such as the stride and</span></div><div class="line"><span class="stringliteral">kernel size, or the pads&#39; sizes in each direction are not necessary for input</span></div><div class="line"><span class="stringliteral">because they are provided by the ConvPoolOpBase operator. Various dimension</span></div><div class="line"><span class="stringliteral">checks are done implicitly, and the sizes are specified in the Input docs for</span></div><div class="line"><span class="stringliteral">this operator. As is expected, the filter is convolved with a subset of the</span></div><div class="line"><span class="stringliteral">image and the bias is added; this is done throughout the image data and the</span></div><div class="line"><span class="stringliteral">output is computed. As a side note on the implementation layout:</span></div><div class="line"><span class="stringliteral">conv_op_impl.h is the templated implementation of the conv_op.h file, which is</span></div><div class="line"><span class="stringliteral">why they are separate files.</span></div><div class="line"><span class="stringliteral">)DOC&quot;</span></div></div><!-- fragment -->
<p>Definition at line <a class="el" href="int8__conv__op_8cc_source.html#l00007">7</a> of file <a class="el" href="int8__conv__op_8cc_source.html">int8_conv_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a643ab84639eae709e248a8f7c7e55849"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const char* caffe2::kConvFusionDoc</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= R<span class="stringliteral">&quot;DOC(</span></div><div class="line"><span class="stringliteral">Note that other parameters, such as the stride and</span></div><div class="line"><span class="stringliteral">kernel size, or the pads&#39; sizes in each direction are not necessary for input</span></div><div class="line"><span class="stringliteral">because they are provided by the ConvPoolOpBase operator. Various dimension</span></div><div class="line"><span class="stringliteral">checks are done implicitly, and the sizes are specified in the Input docs for</span></div><div class="line"><span class="stringliteral">this operator. As is expected, the filter is convolved with a subset of the</span></div><div class="line"><span class="stringliteral">image and the bias is added; this is done throughout the image data and the</span></div><div class="line"><span class="stringliteral">output is computed. As a side note on the implementation layout:</span></div><div class="line"><span class="stringliteral">conv_op_impl.h is the templated implementation of the conv_op.h file, which is</span></div><div class="line"><span class="stringliteral">why they are separate files.</span></div><div class="line"><span class="stringliteral">)DOC&quot;</span></div></div><!-- fragment -->
<p>Definition at line <a class="el" href="conv__fusion__op_8cc_source.html#l00151">151</a> of file <a class="el" href="conv__fusion__op_8cc_source.html">conv_fusion_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ac2b9abe1c69fb306a265046144f3c385"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::kernel_h</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(</div><div class="line">              <span class="stringliteral">&quot;kernel_h&quot;</span>, helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;kernel&quot;</span>, 0))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="im2col__op_8cc_source.html#l00036">36</a> of file <a class="el" href="im2col__op_8cc_source.html">im2col_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="aaaed860c253cc3623218f5e049f56807"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::kernel_w</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(</div><div class="line">              <span class="stringliteral">&quot;kernel_w&quot;</span>, helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;kernel&quot;</span>, 0))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="im2col__op_8cc_source.html#l00038">38</a> of file <a class="el" href="im2col__op_8cc_source.html">im2col_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="af831fa1c3d4b8a60be92d0cda9f24e22"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const char caffe2::kMaxPoolDoc_int8[]</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= R<span class="stringliteral">&quot;DOC(</span></div><div class="line"><span class="stringliteral">consumes an input blob X and applies max pooling across the</span></div><div class="line"><span class="stringliteral">the blob according to kernel sizes, stride sizes, and pad lengths defined by the</span></div><div class="line"><span class="stringliteral">ConvPoolOpBase operator. Max pooling consisting of taking the maximum value of a</span></div><div class="line"><span class="stringliteral">subset of the input tensor according to the kernel size and downsampling the</span></div><div class="line"><span class="stringliteral">data into the output blob Y for further processing.</span></div><div class="line"><span class="stringliteral">)DOC&quot;</span></div></div><!-- fragment -->
<p>Definition at line <a class="el" href="int8__max__pool__op_8cc_source.html#l00010">10</a> of file <a class="el" href="int8__max__pool__op_8cc_source.html">int8_max_pool_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="ad15db7db5c2b5cf0082bdcbeefcc1bad"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">where segments are defined by their and concatenate them in an output tensor of the output value will be padded and the corresponding output indices will be padded by DOC caffe2::LENGTHS</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= [0, 1, 1, 1]</div><div class="line">  and target_length = 2</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="lengths__pad__op_8cc_source.html#l00020">20</a> of file <a class="el" href="lengths__pad__op_8cc_source.html">lengths_pad_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="adf733448c75ed082167df02c63481b83"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">given a parameter tensor X and its gradient the local learning rate for X will be caffe2::local_lr</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= trust * norm(X) / ( norm(dX) + wd * norm(X) + offset * norm(X) )</div><div class="line"></div><div class="line">      = trust / ( norm(dX) / norm(X) + wd + offset )</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="lars__op_8cc_source.html#l00033">33</a> of file <a class="el" href="lars__op_8cc_source.html">lars_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="abdeeef5246d6c9fc520df422e59c93b5"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">constexpr int caffe2::MaxDeviceTypes</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">    DeviceTypeProto::PROTO_COMPILE_TIME_MAX_DEVICE_TYPES</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="event_8h_source.html#l00013">13</a> of file <a class="el" href="event_8h_source.html">event.h</a>.</p>

</div>
</div>
<a class="anchor" id="ac1b902924fb69a8694427f8a967a820e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;int&gt; caffe2::newDims</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">          SqueezeOp&lt;CPUContext&gt;::ComputeDims(GetDimsVector(in[0]), dims)</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="operators_2expand__squeeze__dims__op_8cc_source.html#l00125">125</a> of file <a class="el" href="operators_2expand__squeeze__dims__op_8cc_source.html">expand_squeeze_dims_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a22ec3d8b4f17b4e26fdfd0f339e64089"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::num_classes</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">              <a class="code" href="namespacec10.html#a77eb9df108ba3aaac4963465630706b6">size_from_dim_</a>(canonical_axis, GetDimsVector(logits))</div><div class="ttc" id="namespacec10_html_a77eb9df108ba3aaac4963465630706b6"><div class="ttname"><a href="namespacec10.html#a77eb9df108ba3aaac4963465630706b6">c10::size_from_dim_</a></div><div class="ttdeci">int64_t size_from_dim_(int k, IntArrayRef dims)</div><div class="ttdoc">Return product of all dimensions starting from k. </div><div class="ttdef"><b>Definition:</b> <a href="_tensor_impl_8h_source.html#l00053">TensorImpl.h:53</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="softmax__with__loss__op_8cc_source.html#l00028">28</a> of file <a class="el" href="softmax__with__loss__op_8cc_source.html">softmax_with_loss_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a1a11eb071486461d2526bb04ee3e827b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">with the size where caffe2::num_feature</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= F (F &gt;= 1).</div><div class="line"></div><div class="line">    For each feature</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="bisect__percentile__op_8cc_source.html#l00014">14</a> of file <a class="el" href="bisect__percentile__op_8cc_source.html">bisect_percentile_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="afb2a34a424811068acf175bd0272749c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::order</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= StringToStorageOrder(</div><div class="line">              helper.GetSingleArgument&lt;<span class="keywordtype">string</span>&gt;(<span class="stringliteral">&quot;order&quot;</span>, <span class="stringliteral">&quot;NCHW&quot;</span>))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="do__op_8cc_source.html#l00017">17</a> of file <a class="el" href="do__op_8cc_source.html">do_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a821f8391013a3a007990bc7ac6772f2a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; int64_t &gt; caffe2::output_dims</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">          caffe2::gather_helper::calc_output_shape_vector&lt;int&gt;(</div><div class="line">              data_dims, indices_dims, 1)</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="batch__gather__ops_8cc_source.html#l00018">18</a> of file <a class="el" href="batch__gather__ops_8cc_source.html">batch_gather_ops.cc</a>.</p>

</div>
</div>
<a class="anchor" id="af04e8baeca5dcb4f675a99f815264363"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classnom_1_1repr_1_1_tensor.html">Tensor</a> of rank caffe2::r</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= 2.<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Input(1, &quot;</span>INDICES<span class="stringliteral">&quot;, &quot;</span><a class="code" href="struct_tensor.html">Tensor</a> of int32/int64 indices</div><div class="ttc" id="struct_tensor_html"><div class="ttname"><a href="struct_tensor.html">Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="ios__caffe__predictor_8h_source.html#l00009">ios_caffe_predictor.h:9</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="batch__gather__ops_8cc_source.html#l00025">25</a> of file <a class="el" href="batch__gather__ops_8cc_source.html">batch_gather_ops.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a235ebb5556d3d43af388e63a961e9451"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">d_n then the output will have <a class="el" href="struct_a.html">A</a> Int8 tensor of caffe2::rank</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= axis.<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Output(</span></div><div class="line"><span class="stringliteral">        0,</span></div><div class="line"><span class="stringliteral">        &quot;</span>output<span class="stringliteral">&quot;,</span></div><div class="line"><span class="stringliteral">        &quot;</span><a class="code" href="struct_a.html">A</a> 2<a class="code" href="struct_d.html">D</a> Int8 tensor with the contents of the input tensor</div><div class="ttc" id="struct_a_html"><div class="ttname"><a href="struct_a.html">A</a></div><div class="ttdef"><b>Definition:</b> <a href="static_8cpp_source.html#l00052">static.cpp:52</a></div></div>
<div class="ttc" id="struct_d_html"><div class="ttname"><a href="struct_d.html">D</a></div><div class="ttdef"><b>Definition:</b> <a href="static_8cpp_source.html#l00070">static.cpp:70</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="lengths__pad__op_8cc_source.html#l00010">10</a> of file <a class="el" href="lengths__pad__op_8cc_source.html">lengths_pad_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a433ab69df61deb5e78008f2017514433"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::stride_h</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(</div><div class="line">              <span class="stringliteral">&quot;stride_h&quot;</span>, helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;stride&quot;</span>, 1))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="im2col__op_8cc_source.html#l00044">44</a> of file <a class="el" href="im2col__op_8cc_source.html">im2col_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a28f24cb994d9da9475e824cc5715772d"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::stride_w</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(</div><div class="line">              <span class="stringliteral">&quot;stride_w&quot;</span>, helper.GetSingleArgument&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;stride&quot;</span>, 1))</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="im2col__op_8cc_source.html#l00046">46</a> of file <a class="el" href="im2col__op_8cc_source.html">im2col_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="acd46e25adda028ba1513751fa49a20a6"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int caffe2::tiles</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">          helper.GetSingleArgument&lt;std::int32_t&gt;(<span class="stringliteral">&quot;tiles&quot;</span>, 1)</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="tile__op_8cc_source.html#l00094">94</a> of file <a class="el" href="tile__op_8cc_source.html">tile_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a45b77424afcbc65c3b1971194b6c5e84"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">auto caffe2::valid_axes</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div><div class="line">            std::all_of(axes.begin(), axes.end(), [&amp;tensor_size](<span class="keywordtype">int</span>&amp; axis) {</div><div class="line">              <span class="keywordflow">return</span> axis &gt;= 0 &amp;&amp; axis &lt; tensor_size;</div><div class="line">            })</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="transpose__op_8cc_source.html#l00024">24</a> of file <a class="el" href="transpose__op_8cc_source.html">transpose_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="aff768241374a251f1193b7a1c68419b1"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">reconstruct values together according to masks <a class="el" href="struct_a.html">A</a> comprehensive False False True Reconstruct Note that for all mask there must be at least one True This is not False False we accept the first and no longer expect a value for that False True caffe2::values2</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= 2.0</div><div class="line">mask3   = False</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="boolean__unmask__ops_8cc_source.html#l00067">67</a> of file <a class="el" href="boolean__unmask__ops_8cc_source.html">boolean_unmask_ops.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a30f0470d37c539ccf7a87013b62faadd"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">return caffe2::vector&lt; TensorShape &gt;</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">{</div><div class="line">          CreateTensorShape(dst_sizes, data.data_type())}</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="slice__op_8cc_source.html#l00109">109</a> of file <a class="el" href="slice__op_8cc_source.html">slice_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a4f4e1dcf835af307ea11384652dabf66"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">the cap of output caffe2::y</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">== 1 then it assumed the first input should be ranked higher</div><div class="line">(have a larger value) than the second input</div></div><!-- fragment -->
<p>Definition at line <a class="el" href="margin__ranking__criterion__op_8cc_source.html#l00079">79</a> of file <a class="el" href="margin__ranking__criterion__op_8cc_source.html">margin_ranking_criterion_op.cc</a>.</p>

</div>
</div>
<a class="anchor" id="a726982682691269ef900b03784b3431f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">integer upsampling factor caffe2::Y</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= X.<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Input(0, &quot;</span>X<span class="stringliteral">&quot;, &quot;</span>*(type: <a class="code" href="struct_tensor.html">Tensor</a>`&lt;<span class="keywordtype">float</span>&gt;`)* Input data tensor.<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Output(0, &quot;</span>Y<span class="stringliteral">&quot;, &quot;</span>*(type: <a class="code" href="struct_tensor.html">Tensor</a>`&lt;<span class="keywordtype">float</span>&gt;`)* Output tensor.<span class="stringliteral">&quot;)</span></div><div class="line"><span class="stringliteral">    .Output(</span></div><div class="line"><span class="stringliteral">        1,</span></div><div class="line"><span class="stringliteral">        &quot;</span>mask<span class="stringliteral">&quot;,</span></div><div class="line"><span class="stringliteral">        &quot;</span>*(type: <a class="code" href="struct_tensor.html">Tensor</a>`&lt;<span class="keywordtype">bool</span>&gt;`)* The output mask containing <span class="keywordtype">boolean</span> values <span class="keywordflow">for</span><span class="stringliteral">&quot;</span></div><div class="line"><span class="stringliteral">        &quot;</span>each element</div><div class="ttc" id="struct_tensor_html"><div class="ttname"><a href="struct_tensor.html">Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="ios__caffe__predictor_8h_source.html#l00009">ios_caffe_predictor.h:9</a></div></div>
</div><!-- fragment -->
<p>Definition at line <a class="el" href="cast__op_8cc_source.html#l00119">119</a> of file <a class="el" href="cast__op_8cc_source.html">cast_op.cc</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- HTML footer for doxygen 1.8.14-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Mar 22 2019 13:07:00 for Caffe2 - C++ API by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
<div class="footerContainer">
  <div id="footer_wrap" class="wrapper footerWrapper">
    <div class="footerBlocks">
      <div id="fb_oss" class="footerSection fbOpenSourceFooter">
          <svg class="facebookOSSLogoSvg" viewBox="0 0 1133.9 1133.9" x="0px" y="0px" height=50 width=50>
            <g>
              <path class="logoRing outerRing" d="M 498.3 3.7 c 153.6 88.9 307.3 177.7 461.1 266.2 c 7.6 4.4 10.3 9.1 10.3 17.8 c -0.3 179.1 -0.2 358.3 0 537.4 c 0 8.1 -2.4 12.8 -9.7 17.1 c -154.5 88.9 -308.8 178.1 -462.9 267.5 c -9 5.2 -15.5 5.3 -24.6 0.1 c -153.9 -89.2 -307.9 -178 -462.1 -266.8 C 3 838.8 0 833.9 0 825.1 c 0.3 -179.1 0.2 -358.3 0 -537.4 c 0 -8.6 2.6 -13.6 10.2 -18 C 164.4 180.9 318.4 92 472.4 3 C 477 -1.5 494.3 -0.7 498.3 3.7 Z M 48.8 555.3 c 0 79.9 0.2 159.9 -0.2 239.8 c -0.1 10 3 15.6 11.7 20.6 c 137.2 78.8 274.2 157.8 411 237.3 c 9.9 5.7 17 5.7 26.8 0.1 c 137.5 -79.8 275.2 -159.2 412.9 -238.5 c 7.4 -4.3 10.5 -8.9 10.5 -17.8 c -0.3 -160.2 -0.3 -320.5 0 -480.7 c 0 -8.8 -2.8 -13.6 -10.3 -18 C 772.1 218 633.1 137.8 494.2 57.4 c -6.5 -3.8 -11.5 -4.5 -18.5 -0.5 C 336.8 137.4 197.9 217.7 58.8 297.7 c -7.7 4.4 -10.2 9.2 -10.2 17.9 C 48.9 395.5 48.8 475.4 48.8 555.3 Z" />
              <path class="logoRing middleRing" d="M 184.4 555.9 c 0 -33.3 -1 -66.7 0.3 -100 c 1.9 -48 24.1 -86 64.7 -110.9 c 54.8 -33.6 110.7 -65.5 167 -96.6 c 45.7 -25.2 92.9 -24.7 138.6 1 c 54.4 30.6 108.7 61.5 162.2 93.7 c 44 26.5 67.3 66.8 68 118.4 c 0.9 63.2 0.9 126.5 0 189.7 c -0.7 50.6 -23.4 90.7 -66.6 116.9 c -55 33.4 -110.8 65.4 -167.1 96.5 c -43.4 24 -89 24.2 -132.3 0.5 c -57.5 -31.3 -114.2 -64 -170 -98.3 c -41 -25.1 -62.9 -63.7 -64.5 -112.2 C 183.5 621.9 184.3 588.9 184.4 555.9 Z M 232.9 556.3 c 0 29.5 0.5 59.1 -0.1 88.6 c -0.8 39.2 16.9 67.1 50.2 86.2 c 51.2 29.4 102.2 59.2 153.4 88.4 c 31.4 17.9 63.6 18.3 95 0.6 c 53.7 -30.3 107.1 -61.2 160.3 -92.5 c 29.7 -17.5 45 -44.5 45.3 -78.8 c 0.6 -61.7 0.5 -123.5 0 -185.2 c -0.3 -34.4 -15.3 -61.5 -44.9 -79 C 637.7 352.6 583 320.8 527.9 290 c -27.5 -15.4 -57.2 -16.1 -84.7 -0.7 c -56.9 31.6 -113.4 64 -169.1 97.6 c -26.4 15.9 -40.7 41.3 -41.1 72.9 C 232.6 491.9 232.9 524.1 232.9 556.3 Z" />
              <path class="logoRing innerRing" d="M 484.9 424.4 c 69.8 -2.8 133.2 57.8 132.6 132 C 617 630 558.5 688.7 484.9 689.1 c -75.1 0.4 -132.6 -63.6 -132.7 -132.7 C 352.1 485 413.4 421.5 484.9 424.4 Z M 401.3 556.7 c -3.4 37.2 30.5 83.6 83 84.1 c 46.6 0.4 84.8 -37.6 84.9 -84 c 0.1 -46.6 -37.2 -84.4 -84.2 -84.6 C 432.2 472.1 397.9 518.3 401.3 556.7 Z" />
            </g>
          </svg>
        <h2>Facebook Open Source</h2>
      </div>
      <div class="footerSection">
        <a class="footerLink" href="https://code.facebook.com/projects/" target="_blank">Open Source Projects</a>
        <a class="footerLink" href="https://github.com/facebook/" target="_blank">GitHub</a>
        <a class="footerLink" href="https://twitter.com/fbOpenSource" target="_blank">Twitter</a>
      </div>
      <div class="footerSection rightAlign">
        <a class="footerLink" href="https://github.com/caffe2/caffe2" target="_blank">Contribute to this project on GitHub</a>
      </div>
    </div>
  </div>
</div>
<script type="text/javascript" src="/js/jekyll-link-anchors.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', '{{ site.gacode }}', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
