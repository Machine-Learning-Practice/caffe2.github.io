<!-- HTML header for doxygen 1.8.14-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Caffe2 - Python API: torch/onnx/utils.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="/static/favicon.png" type="image/x-icon">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" />
<link href="main.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo" width="56"><a href="/"><img alt="Logo" src="Caffe2-with-name-55-tall.png"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Caffe2 - Python API
   </div>
   <div id="projectbrief">A deep learning, cross platform ML framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="namespaces.html"><span>Packages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li><a href="/doxygen-c/html/classes.html"><span>C++&#160;API</span></a></li>
      <li><a href="/doxygen-python/html/annotated.html"><span>Python&#160;API</span></a></li>
      <li><a href="https://github.com/caffe2/caffe2"><span>GitHub</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_e164125afd4f8f52f497b29f866a4ef6.html">torch</a></li><li class="navelem"><a class="el" href="dir_4edc9c8c8a3539550c3dbba3386d4114.html">onnx</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">utils.py</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="stringliteral">r&quot;&quot;&quot;</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="stringliteral">The torch.onnx module contains functions to export models into the ONNX</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="stringliteral">IR format.  These models can be loaded with the ONNX library and then</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="stringliteral">converted to models which run on other deep learning frameworks.</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="keyword">import</span> torch</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="keyword">import</span> <a class="code" href="namespacetorch_1_1jit.html">torch.jit</a></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="keyword">import</span> <a class="code" href="namespacetorch_1_1autograd.html">torch.autograd</a></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="keyword">import</span> <a class="code" href="namespacetorch_1_1serialization.html">torch.serialization</a></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="keyword">import</span> re</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1__six.html">torch._six</a> <span class="keyword">import</span> container_abcs</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="keyword">import</span> contextlib</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="keyword">import</span> numbers</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="keyword">import</span> warnings</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="keyword">import</span> functools</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="keyword">import</span> types</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1__six.html">torch._six</a> <span class="keyword">import</span> string_classes</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1autograd.html">torch.autograd</a> <span class="keyword">import</span> Function, function</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1jit.html">torch.jit</a> <span class="keyword">import</span> _unique_state_dict</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1onnx.html">torch.onnx</a> <span class="keyword">import</span> ONNX_ARCHIVE_MODEL_PROTO_NAME, ExportTypes, OperatorExportTypes</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1___c.html">torch._C</a> <span class="keyword">import</span> ListType</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;@contextlib.contextmanager</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="keyword">def </span>set_training(model, mode):</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;    <span class="stringliteral">r&quot;&quot;&quot;</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="stringliteral">    A context manager to temporarily set the training mode of &#39;model&#39;</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="stringliteral">    to &#39;mode&#39;, resetting it when we exit the with-block.  A no-op if</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="stringliteral">    mode is None.</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    <span class="keywordflow">if</span> mode <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;        <span class="keywordflow">yield</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;        <span class="keywordflow">return</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;    old_mode = model.training</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;    <span class="keywordflow">if</span> old_mode != mode:</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;        model.train(mode)</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;    <span class="keywordflow">try</span>:</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;        <span class="keywordflow">yield</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;    <span class="keywordflow">finally</span>:</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;        <span class="keywordflow">if</span> old_mode != mode:</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;            model.train(old_mode)</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="keyword">def </span>export(model, args, f, export_params=True, verbose=False, training=False,</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;           input_names=<span class="keywordtype">None</span>, output_names=<span class="keywordtype">None</span>, aten=<span class="keyword">False</span>, export_raw_ir=<span class="keyword">False</span>,</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;           operator_export_type=<span class="keywordtype">None</span>, opset_version=<span class="keywordtype">None</span>):</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    <span class="stringliteral">r&quot;&quot;&quot;</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="stringliteral">    Export a model into ONNX format.  This exporter runs your model</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="stringliteral">    once in order to get a trace of its execution to be exported;</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="stringliteral">    at the moment, it supports a limited set of dynamic models (e.g., RNNs.)</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="stringliteral">    See also: :ref:`onnx-export`</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="stringliteral">    Arguments:</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="stringliteral">        model (torch.nn.Module): the model to be exported.</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="stringliteral">        args (tuple of arguments): the inputs to</span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="stringliteral">            the model, e.g., such that ``model(*args)`` is a valid</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="stringliteral">            invocation of the model.  Any non-Tensor arguments will</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="stringliteral">            be hard-coded into the exported model; any Tensor arguments</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="stringliteral">            will become inputs of the exported model, in the order they</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="stringliteral">            occur in args.  If args is a Tensor, this is equivalent</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="stringliteral">            to having called it with a 1-ary tuple of that Tensor.</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="stringliteral">            (Note: passing keyword arguments to the model is not currently</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="stringliteral">            supported.  Give us a shout if you need it.)</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="stringliteral">        f: a file-like object (has to implement fileno that returns a file descriptor)</span></div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="stringliteral">            or a string containing a file name.  A binary Protobuf will be written</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="stringliteral">            to this file.</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="stringliteral">        export_params (bool, default True): if specified, all parameters will</span></div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="stringliteral">            be exported.  Set this to False if you want to export an untrained model.</span></div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="stringliteral">            In this case, the exported model will first take all of its parameters</span></div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="stringliteral">            as arguments, the ordering as specified by ``model.state_dict().values()``</span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="stringliteral">        verbose (bool, default False): if specified, we will print out a debug</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="stringliteral">            description of the trace being exported.</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="stringliteral">        training (bool, default False): export the model in training mode.  At</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="stringliteral">            the moment, ONNX is oriented towards exporting models for inference</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="stringliteral">            only, so you will generally not need to set this to True.</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="stringliteral">        input_names(list of strings, default empty list): names to assign to the</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="stringliteral">            input nodes of the graph, in order</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="stringliteral">        output_names(list of strings, default empty list): names to assign to the</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="stringliteral">            output nodes of the graph, in order</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="stringliteral">        aten (bool, default False): [DEPRECATED. use operator_export_type] export the</span></div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="stringliteral">            model in aten mode. If using aten mode, all the ops original exported</span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="stringliteral">            by the functions in symbolic.py are exported as ATen ops.</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="stringliteral">        export_raw_ir (bool, default False): [DEPRECATED. use operator_export_type]</span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="stringliteral">            export the internal IR directly instead of converting it to ONNX ops.</span></div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="stringliteral">        operator_export_type (enum, default OperatorExportTypes.ONNX):</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="stringliteral">            OperatorExportTypes.ONNX: all ops are exported as regular ONNX ops.</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="stringliteral">            OperatorExportTypes.ONNX_ATEN: all ops are exported as ATen ops.</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="stringliteral">            OperatorExportTypes.ONNX_ATEN_FALLBACK: if symbolic is missing,</span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="stringliteral">                                                    fall back on ATen op.</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="stringliteral">            OperatorExportTypes.RAW: export raw ir.</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="stringliteral">        opset_version (int, default is 9): by default we export the model to the</span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="stringliteral">            opset version of the onnx submodule. Since ONNX&#39;s latest opset may</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="stringliteral">            evolve before next stable release, by default we export to one stable</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="stringliteral">            opset version. Right now, supported stable opset version is 9.</span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="stringliteral">            The opset_version must be _onnx_master_opset or in _onnx_stable_opsets</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="stringliteral">            which are defined in torch/onnx/symbolic.py</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    <span class="keywordflow">if</span> aten <span class="keywordflow">or</span> export_raw_ir:</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        <span class="keyword">assert</span> operator_export_type <span class="keywordflow">is</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        <span class="keyword">assert</span> aten ^ export_raw_ir</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        operator_export_type = OperatorExportTypes.ATEN <span class="keywordflow">if</span> aten <span class="keywordflow">else</span> OperatorExportTypes.RAW</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;    <span class="keywordflow">elif</span> operator_export_type <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        <span class="keywordflow">if</span> torch.onnx.PYTORCH_ONNX_CAFFE2_BUNDLE:</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;            operator_export_type = OperatorExportTypes.ONNX_ATEN_FALLBACK</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;            operator_export_type = OperatorExportTypes.ONNX</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    _export(model, args, f, export_params, verbose, training, input_names, output_names,</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;            operator_export_type=operator_export_type, opset_version=opset_version)</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="comment"># ONNX can&#39;t handle constants that are lists of tensors, which can</span></div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="comment"># get generated in constant prop. So we split them back into prim::ListConstructs</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="keyword">def </span>_split_tensor_list_constants(g, block):</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="keywordflow">for</span> node <span class="keywordflow">in</span> block.nodes():</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;        <span class="keywordflow">for</span> subblock <span class="keywordflow">in</span> node.blocks():</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;            _split_tensor_list_constants(g, subblock)</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;        <span class="keywordflow">if</span> node.kind() == <span class="stringliteral">&quot;prim::Constant&quot;</span>:</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;            output_type = node.output().type()</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;            <span class="keywordflow">if</span> output_type.isSubtypeOf(ListType.ofTensors()):</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;                inputs = [g.create(<span class="stringliteral">&quot;prim::Constant&quot;</span>).t_(<span class="stringliteral">&#39;value&#39;</span>, t)</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                           .insertBefore(node).output()</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;                          <span class="keywordflow">for</span> t <span class="keywordflow">in</span> node[<span class="stringliteral">&#39;value&#39;</span>]]</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;                lc = (g.create(<span class="stringliteral">&quot;prim::ListConstruct&quot;</span>, inputs)</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;                      .insertBefore(node)</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;                      .output()</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;                      .setType(ListType.ofTensors()))</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;                node.output().replaceAllUsesWith(lc)</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="keyword">def </span>_optimize_graph(graph, operator_export_type):</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;    <span class="comment"># Remove fork/wait nodes</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    torch._C._jit_pass_inline_fork_wait(graph)</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    torch._C._jit_pass_dce(graph)</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    torch._C._jit_pass_remove_inplace_ops(graph)</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    <span class="comment"># we record now record some ops like ones/zeros</span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    <span class="comment"># into a trace where we previously recorded constants</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    <span class="comment"># use constant prop to maintain our current level of onnx support</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;    <span class="comment"># without implementing symbolics for all of them</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    torch._C._jit_pass_constant_propagation(graph)</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;    _split_tensor_list_constants(graph, graph)</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;    <span class="comment"># run dce to eliminate dead parts of the graph that might have been</span></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="comment"># left behind by things like symbolic_override</span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    torch._C._jit_pass_dce(graph)</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    torch._C._jit_pass_canonicalize_ops(graph)</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    torch._C._jit_pass_peephole(graph, <span class="keyword">True</span>)</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    <span class="comment"># onnx only supports tensors, but 1 / 2 = 0.5 and tensor(1) / tensor(2) = 0</span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;    torch._C._jit_pass_prepare_division_for_onnx(graph)</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    <span class="comment"># onnx only supports tensors, so we turn all out number types into tensors</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    torch._C._jit_pass_erase_number_types(graph)</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    <span class="comment"># onnx does not support tuples, so try to remove them</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;    torch._C._jit_pass_lower_all_tuples(graph)</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;    torch._C._jit_pass_peephole(graph, <span class="keyword">True</span>)</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;    <span class="keywordflow">if</span> operator_export_type != OperatorExportTypes.RAW:</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;        graph = torch._C._jit_pass_onnx(graph, operator_export_type)</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;        torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;        torch._C._jit_pass_onnx_peephole(graph)</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;    torch._C._jit_pass_dce(graph)</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;    torch._C._jit_pass_fixup_onnx_loops(graph)</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;    graph = torch._C._jit_pass_canonicalize(graph)</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;    torch._C._jit_pass_lint(graph)</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;    <span class="keywordflow">return</span> graph</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="keyword">def </span>_trace(func, args, operator_export_type, return_outs=False):</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;    <span class="comment"># Special case for common case of passing a single Tensor</span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;    <span class="keywordflow">if</span> isinstance(args, torch.Tensor):</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;        args = (args, )</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;    trace, torch_out = <a class="code" href="torch_2jit_2____init_____8py.html#a8f3c6d4f2470a1d678c4da2530e8db9c">torch.jit.get_trace_graph</a>(func, args, _force_outplace=<span class="keyword">True</span>)</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;    trace.set_graph(_optimize_graph(trace.graph(), operator_export_type))</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;    <span class="keywordflow">if</span> return_outs:</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;        <span class="keywordflow">return</span> trace, torch_out</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;    <span class="keywordflow">return</span> trace</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;<span class="keyword">def </span>_trace_and_get_graph_from_model(model, args, training):</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    <span class="comment"># A basic sanity check: make sure the state_dict keys are the same</span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;    <span class="comment"># before and after running the model.  Fail fast!</span></div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;    orig_state_dict_keys = _unique_state_dict(model).keys()</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;    <span class="comment"># By default, training=False, which is good because running a model in</span></div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;    <span class="comment"># training mode could result in internal buffers getting updated, dropout</span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;    <span class="comment"># getting applied, etc.  If you really know what you&#39;re doing, you</span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;    <span class="comment"># can turn training=True (or None, to preserve whatever the original</span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    <span class="comment"># training mode was.)</span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    with set_training(model, training):</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;        trace, torch_out = <a class="code" href="torch_2jit_2____init_____8py.html#a8f3c6d4f2470a1d678c4da2530e8db9c">torch.jit.get_trace_graph</a>(model, args, _force_outplace=<span class="keyword">True</span>)</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;    <span class="keywordflow">if</span> orig_state_dict_keys != _unique_state_dict(model).keys():</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;        <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;state_dict changed after running the tracer; &quot;</span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;                           <span class="stringliteral">&quot;something weird is happening in your model!&quot;</span>)</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;    <span class="keywordflow">return</span> trace.graph(), torch_out</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;<span class="keyword">def </span>_model_to_graph(model, args, f, verbose=False, training=False,</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;                    input_names=<span class="keywordtype">None</span>, output_names=<span class="keywordtype">None</span>,</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;                    operator_export_type=OperatorExportTypes.ONNX,</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;                    example_outputs=<span class="keywordtype">None</span>, propagate=<span class="keyword">False</span>):</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;    <span class="comment"># Special case for common case of passing a single Tensor</span></div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    <span class="keywordflow">if</span> isinstance(args, torch.Tensor):</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        args = (args, )</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;    <span class="keywordflow">if</span> isinstance(model, <a class="code" href="classtorch_1_1jit_1_1_script_module.html">torch.jit.ScriptModule</a>):</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;        torch_out = <span class="keywordtype">None</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;        <span class="keyword">assert</span> example_outputs <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>, <span class="stringliteral">&quot;example_outputs must be provided when exporting a ScriptModule&quot;</span></div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;        <span class="keywordflow">if</span> isinstance(example_outputs, torch.Tensor):</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;            example_outputs = [example_outputs]</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;        <span class="keywordflow">try</span>:</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;            method = model.__getattr__(<span class="stringliteral">&#39;forward&#39;</span>)</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;            graph = method.propagate_and_assign_input_and_output_shapes(</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;                args, example_outputs, <span class="keyword">False</span>, propagate)</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;            <span class="comment"># Erase number types to bring the graph to a pre-NumberType state</span></div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;            params = method.initial_ivalues()</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;        <span class="keywordflow">except</span> AttributeError:</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;            <span class="comment"># TODO: just trace it</span></div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&#39;\&#39;forward\&#39; method must be a script method&#39;</span>)</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;    <span class="keywordflow">else</span>:</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;        graph, torch_out = _trace_and_get_graph_from_model(model, args, training)</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;        params = list(_unique_state_dict(model).values())</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;    graph = _optimize_graph(graph, operator_export_type)</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;    <span class="comment"># NB: ONNX requires complete information about output types, which might be</span></div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;    <span class="comment"># erased by some optimizations, so we need to set it explicitly again.</span></div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;    <span class="keywordflow">if</span> torch_out <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;        output_tensors, _ = torch._C._jit_flatten(torch_out)</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;        <span class="keywordflow">for</span> output, tensor <span class="keywordflow">in</span> zip(graph.outputs(), output_tensors):</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;            output.inferTypeFrom(tensor)</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;    _set_input_and_output_names(graph, input_names, output_names)</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;    <span class="keywordflow">if</span> verbose:</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;        print(graph)</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;    <span class="keywordflow">return</span> graph, params, torch_out</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="keyword">def </span>export_to_pretty_string(model, args, f, export_params=True, verbose=False, training=False,</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;                            input_names=<span class="keywordtype">None</span>, output_names=<span class="keywordtype">None</span>, aten=<span class="keyword">False</span>, export_raw_ir=<span class="keyword">False</span>,</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;                            operator_export_type=<span class="keywordtype">None</span>, export_type=ExportTypes.PROTOBUF_FILE,</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;                            example_outputs=<span class="keywordtype">None</span>, propagate=<span class="keyword">False</span>, google_printer=<span class="keyword">False</span>,</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;                            opset_version=<span class="keywordtype">None</span>):</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;    <span class="keywordflow">if</span> aten <span class="keywordflow">or</span> export_raw_ir:</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;        <span class="keyword">assert</span> operator_export_type <span class="keywordflow">is</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        <span class="keyword">assert</span> aten ^ export_raw_ir</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;        operator_export_type = OperatorExportTypes.ATEN <span class="keywordflow">if</span> aten <span class="keywordflow">else</span> OperatorExportTypes.RAW</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;    <span class="keywordflow">elif</span> operator_export_type <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        operator_export_type = OperatorExportTypes.ONNX</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;    <span class="keywordflow">return</span> _export_to_pretty_string(model, args, f, export_params, verbose, training,</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;                                    input_names, output_names, operator_export_type,</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;                                    export_type, example_outputs, propagate, google_printer,</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;                                    opset_version)</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;<span class="keyword">def </span>_export_to_pretty_string(model, args, f, export_params=True, verbose=False, training=False,</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;                             input_names=<span class="keywordtype">None</span>, output_names=<span class="keywordtype">None</span>, operator_export_type=OperatorExportTypes.ONNX,</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;                             export_type=ExportTypes.PROTOBUF_FILE, example_outputs=<span class="keywordtype">None</span>, propagate=<span class="keyword">False</span>,</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;                             google_printer=<span class="keyword">False</span>, opset_version=<span class="keywordtype">None</span>):</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;    <span class="keyword">from</span> <a class="code" href="namespacetorch_1_1onnx_1_1symbolic.html">torch.onnx.symbolic</a> <span class="keyword">import</span> _default_onnx_opset_version, _set_opset_version</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;    <span class="keywordflow">if</span> opset_version <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;        opset_version = _default_onnx_opset_version</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;    _set_opset_version(opset_version)</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;    graph, params, torch_out = _model_to_graph(model, args, f, verbose,</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;                                               training, input_names,</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;                                               output_names, operator_export_type,</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;                                               example_outputs, propagate)</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;    <span class="keywordflow">return</span> graph._pretty_print_onnx(params, opset_version, <span class="keyword">False</span>, operator_export_type, google_printer)</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;<span class="comment"># NOTE: the output `torch_out` will contain the output tensors resulting from</span></div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;<span class="comment"># the trace of a Module. In the case that a torch.nn.ScriptModule is passed in,</span></div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;<span class="comment"># this output will be None, since we are not doing any tracing but rather</span></div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;<span class="comment"># directly extracting the graph.</span></div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;<span class="keyword">def </span>_export(model, args, f, export_params=True, verbose=False, training=False,</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;            input_names=<span class="keywordtype">None</span>, output_names=<span class="keywordtype">None</span>, operator_export_type=OperatorExportTypes.ONNX,</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;            export_type=ExportTypes.PROTOBUF_FILE, example_outputs=<span class="keywordtype">None</span>, propagate=<span class="keyword">False</span>,</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;            opset_version=<span class="keywordtype">None</span>):</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;    <span class="keyword">from</span> <a class="code" href="namespacetorch_1_1onnx_1_1symbolic.html">torch.onnx.symbolic</a> <span class="keyword">import</span> _default_onnx_opset_version, _set_opset_version</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    <span class="keywordflow">if</span> opset_version <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;        opset_version = _default_onnx_opset_version</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;    _set_opset_version(opset_version)</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;    graph, params, torch_out = _model_to_graph(model, args, f, verbose,</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;                                               training, input_names,</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;                                               output_names, operator_export_type,</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;                                               example_outputs, propagate)</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;    <span class="comment"># TODO: Don&#39;t allocate a in-memory string for the protobuf</span></div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;    defer_weight_export = export_type <span class="keywordflow">is</span> <span class="keywordflow">not</span> ExportTypes.PROTOBUF_FILE</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;    <span class="keywordflow">if</span> export_params:</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;        proto, export_map = graph._export_onnx(params, opset_version, defer_weight_export, operator_export_type)</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    <span class="keywordflow">else</span>:</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;        proto, export_map = graph._export_onnx([], opset_version, <span class="keyword">False</span>, operator_export_type)</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;    <span class="keywordflow">if</span> export_type == ExportTypes.PROTOBUF_FILE:</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;        assert(len(export_map) == 0)</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;        <a class="code" href="serialization_8py.html#a72b9f6bd4e0d145f41204c3250a6b73e">torch.serialization._with_file_like</a>(f, <span class="stringliteral">&quot;wb&quot;</span>, <span class="keyword">lambda</span> f: f.write(proto))</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;    <span class="keywordflow">elif</span> export_type <span class="keywordflow">in</span> [ExportTypes.ZIP_ARCHIVE, ExportTypes.COMPRESSED_ZIP_ARCHIVE]:</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;        <span class="keyword">import</span> zipfile</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;        compression = zipfile.ZIP_DEFLATED \</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;            <span class="keywordflow">if</span> export_type == ExportTypes.COMPRESSED_ZIP_ARCHIVE \</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;            <span class="keywordflow">else</span> zipfile.ZIP_STORED</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;        with zipfile.ZipFile(f, <span class="stringliteral">&#39;w&#39;</span>, compression=compression) <span class="keyword">as</span> z:</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;            z.writestr(ONNX_ARCHIVE_MODEL_PROTO_NAME, proto)</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;            <span class="keywordflow">for</span> k, v <span class="keywordflow">in</span> export_map.items():</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;                z.writestr(k, v)</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;    <span class="keywordflow">elif</span> export_type == ExportTypes.DIRECTORY:</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;        <span class="keyword">import</span> os</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;        <span class="keywordflow">if</span> os.path.exists(f):</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;            assert(os.path.isdir(f))</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;            os.makedirs(f)</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;        model_proto_file = os.path.join(f, ONNX_ARCHIVE_MODEL_PROTO_NAME)</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;        <a class="code" href="serialization_8py.html#a72b9f6bd4e0d145f41204c3250a6b73e">torch.serialization._with_file_like</a>(</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;            model_proto_file, <span class="stringliteral">&quot;wb&quot;</span>, <span class="keyword">lambda</span> f: f.write(proto))</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;        <span class="keywordflow">for</span> k, v <span class="keywordflow">in</span> export_map.items():</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;            weight_proto_file = os.path.join(f, k)</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;            <a class="code" href="serialization_8py.html#a72b9f6bd4e0d145f41204c3250a6b73e">torch.serialization._with_file_like</a>(</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;                weight_proto_file, <span class="stringliteral">&quot;wb&quot;</span>, <span class="keyword">lambda</span> f: f.write(v))</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;    <span class="keywordflow">else</span>:</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;        <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&#39;Unknown export type&#39;</span>)</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;    <span class="keywordflow">return</span> torch_out</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;<span class="keyword">def </span>_set_input_and_output_names(graph, input_names, output_names):</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;    <span class="keyword">def </span>set_names(node_list, name_list, descriptor):</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;        <span class="keywordflow">if</span> name_list <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;            <span class="keywordflow">return</span></div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;        <span class="keywordflow">if</span> len(name_list) &gt; len(node_list):</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;            <span class="keywordflow">raise</span> RuntimeError(</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                <span class="stringliteral">&quot;number of %s names provided (%d) exceeded number of %ss (%d)&quot;</span></div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                % (descriptor, len(name_list), descriptor, len(node_list)))</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;        <span class="keywordflow">for</span> name, node <span class="keywordflow">in</span> zip(name_list, node_list):</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;            <span class="keywordflow">if</span> node.uniqueName() != name:</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;                node.setUniqueName(name)</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;    set_names(list(graph.inputs()), input_names, <span class="stringliteral">&#39;input&#39;</span>)</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;    set_names(list(graph.outputs()), output_names, <span class="stringliteral">&#39;output&#39;</span>)</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;attr_pattern = re.compile(<span class="stringliteral">&quot;^(.+)_([ifstgz])$&quot;</span>)</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;<span class="keyword">def </span>_run_symbolic_method(op_name, symbolic_fn, args):</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    <span class="stringliteral">r&quot;&quot;&quot;</span></div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;<span class="stringliteral">    This trampoline function gets invoked for every symbolic method</span></div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;<span class="stringliteral">    call from C++.</span></div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;    <span class="keywordflow">try</span>:</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;        <span class="keywordflow">return</span> symbolic_fn(*args)</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;    <span class="keywordflow">except</span> TypeError <span class="keyword">as</span> e:</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;        <span class="comment"># Handle the specific case where we didn&#39;t successfully dispatch</span></div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;        <span class="comment"># to symbolic_fn.  Otherwise, the backtrace will have the clues</span></div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;        <span class="comment"># you need.</span></div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;        e.args = (<span class="stringliteral">&quot;{} (occurred when translating {})&quot;</span>.format(e.args[0], op_name), )</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;        <span class="keywordflow">raise</span></div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;<span class="keyword">def </span>_is_onnx_list(value):</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;    <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(value, string_classes) <span class="keywordflow">and</span> \</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;            <span class="keywordflow">not</span> isinstance(value, torch.Tensor) <span class="keywordflow">and</span> \</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;            isinstance(value, container_abcs.Iterable):</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">True</span></div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">False</span></div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;<span class="keyword">def </span>_add_attribute(node, key, value, aten):</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;    <span class="stringliteral">r&quot;&quot;&quot; initializes the right attribute based on type of value &quot;&quot;&quot;</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;    m = attr_pattern.match(key)</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;    <span class="keywordflow">if</span> m <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;        <span class="keywordflow">raise</span> IndexError((</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;            <span class="stringliteral">&quot;Invalid attribute specifier &#39;{}&#39; names &quot;</span> +</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;            <span class="stringliteral">&quot; must be suffixed with type, e.g. &#39;dim_i&#39; or &#39;dims_i&#39;&quot;</span>).format(key))</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;    name, kind = m.group(1), m.group(2)</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;    <span class="keywordflow">if</span> _is_onnx_list(value):</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;        kind += <span class="stringliteral">&quot;s&quot;</span></div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;    <span class="keywordflow">if</span> aten:</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;        <span class="keywordflow">if</span> isinstance(value, torch.Tensor):</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;            <span class="comment"># Caffe2 proto does not support tensor attribute.</span></div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;            <span class="keywordflow">if</span> value.numel() &gt; 1:</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Should not pass tensor attribute&quot;</span>)</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;            value = _scalar(value)</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;            <span class="keywordflow">if</span> isinstance(value, float):</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;                kind = <span class="stringliteral">&quot;f&quot;</span></div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;                kind = <span class="stringliteral">&quot;i&quot;</span></div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;    <span class="keywordflow">return</span> getattr(node, kind + <span class="stringliteral">&quot;_&quot;</span>)(name, value)</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;<span class="keyword">def </span>_scalar(x):</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;Convert a scalar tensor into a Python value.&quot;&quot;&quot;</span></div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;    <span class="keyword">assert</span> x.numel() == 1</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;    <span class="keywordflow">return</span> x[0]</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;<span class="keyword">def </span>_newNode(g, opname, outputs, *args, **kwargs):</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;    <span class="keywordflow">if</span> <span class="stringliteral">&quot;::&quot;</span> <span class="keywordflow">in</span> opname:</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;        aten = <span class="keyword">False</span></div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;        ns_opname = opname</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;    <span class="keywordflow">else</span>:</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;        aten = kwargs.pop(<span class="stringliteral">&quot;aten&quot;</span>, <span class="keyword">False</span>)</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;        ns = <span class="stringliteral">&quot;aten&quot;</span> <span class="keywordflow">if</span> aten <span class="keywordflow">else</span> <span class="stringliteral">&quot;onnx&quot;</span></div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;        ns_opname = ns + <span class="stringliteral">&quot;::&quot;</span> + opname</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;    n = g.create(ns_opname, args, outputs)</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;    <span class="keywordflow">for</span> k, v <span class="keywordflow">in</span> sorted(kwargs.items()):</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;        <span class="comment"># TODO: enable inplace in aten exporting mode.</span></div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;        <span class="keywordflow">if</span> k == <span class="stringliteral">&quot;inplace&quot;</span>:</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;            <span class="keywordflow">continue</span></div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;        _add_attribute(n, k, v, aten=aten)</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;    <span class="keywordflow">return</span> n</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;<span class="keyword">def </span>_graph_op(g, opname, *raw_args, **kwargs):</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;    <span class="stringliteral">r&quot;&quot;&quot;</span></div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;<span class="stringliteral">    Create an ONNX operator &#39;opname&#39;, taking &#39;args&#39; as inputs and attributes</span></div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;<span class="stringliteral">    &#39;kwargs&#39;; returning the node representing the single output of this operator</span></div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;<span class="stringliteral">    (see the `outputs` keyword argument for multi-return nodes).</span></div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;<span class="stringliteral">    The set of operators and the inputs/attributes they take</span></div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;<span class="stringliteral">    is documented at https://github.com/onnx/onnx/blob/master/docs/Operators.md</span></div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;<span class="stringliteral">    This function is monkey-patched onto Graph.</span></div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;<span class="stringliteral">    Arguments:</span></div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;<span class="stringliteral">        opname (string): The ONNX operator name, e.g., `Abs` or `Add`.</span></div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;<span class="stringliteral">        args (Node...): The inputs to the operator; usually provided</span></div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;<span class="stringliteral">            as arguments to the `symbolic` definition.</span></div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;<span class="stringliteral">        kwargs: The attributes of the ONNX operator, with keys named</span></div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;<span class="stringliteral">            according to the following convention: `alpha_f` indicates</span></div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;<span class="stringliteral">            the `alpha` attribute with type `f`.  The valid type specifiers are</span></div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;<span class="stringliteral">            `f` (float), `i` (int), `s` (string) or `t` (Tensor).  An attribute</span></div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;<span class="stringliteral">            specified with type float accepts either a single float, or a</span></div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="stringliteral">            list of floats (e.g., you would say `dims_i` for a `dims` attribute</span></div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;<span class="stringliteral">            that takes a list of integers).</span></div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;<span class="stringliteral">        outputs (int, optional):  The number of outputs this operator returns;</span></div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;<span class="stringliteral">            by default an operator is assumed to return a single output.</span></div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;<span class="stringliteral">            If `outputs` is greater than one, this functions returns a tuple</span></div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;<span class="stringliteral">            of output `Node`, representing each output of the ONNX operator</span></div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;<span class="stringliteral">            in positional.</span></div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;    outputs = kwargs.pop(<span class="stringliteral">&#39;outputs&#39;</span>, 1)</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;    <span class="comment"># Filter out None attributes, this can be convenient client side because</span></div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;    <span class="comment"># now they can pass through None attributes, and have them not show up</span></div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;    kwargs = dict((k, v) <span class="keywordflow">for</span> k, v <span class="keywordflow">in</span> kwargs.items() <span class="keywordflow">if</span> v <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>)</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;    <span class="keyword">def </span>const_if_tensor(arg):</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;        <span class="keywordflow">if</span> arg <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;            <span class="keywordflow">return</span> arg</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;        <span class="keywordflow">elif</span> isinstance(arg, torch._C.Value):</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;            <span class="keywordflow">return</span> arg</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;            <span class="keywordflow">return</span> g.op(<span class="stringliteral">&quot;Constant&quot;</span>, value_z=arg)</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;    args = list(const_if_tensor(arg) <span class="keywordflow">for</span> arg <span class="keywordflow">in</span> raw_args)</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;    n = g.insertNode(_newNode(g, opname, outputs, *args, **kwargs))</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;    <span class="keywordflow">if</span> outputs == 1:</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;        <span class="keywordflow">return</span> n.output()</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;    <span class="keywordflow">return</span> tuple(o <span class="keywordflow">for</span> o <span class="keywordflow">in</span> n.outputs())</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;<span class="comment"># Note [Export inplace]</span></div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;<span class="comment"># ~~~~~~~~~~~~~~~~~~~~~</span></div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;<span class="comment"># In abstract, it would be better for us to export inplace annotations,</span></div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;<span class="comment"># than to not export them, since it is useful information that can</span></div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;<span class="comment"># help the target of an ONNX export export more efficiently.  However,</span></div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;<span class="comment"># ONNX doesn&#39;t currently formalize inplace.  Fortunately, it&#39;s sound to drop</span></div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;<span class="comment"># inplace annotations, but we are losing information this way.</span></div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;</div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;<span class="keyword">def </span>_run_symbolic_function(g, n, inputs, env, operator_export_type=OperatorExportTypes.ONNX):</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;    <span class="comment"># NB: Returning None means the node gets cloned as is into</span></div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;    <span class="comment"># the new graph</span></div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;    <span class="keywordflow">try</span>:</div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;        <span class="keyword">import</span> <a class="code" href="namespacetorch_1_1onnx_1_1symbolic.html">torch.onnx.symbolic</a></div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;</div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;        <span class="comment"># See Note [Export inplace]</span></div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;        <span class="comment"># TODO: I think this is not necessary anymore</span></div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;        <span class="keywordflow">if</span> n.kind().endswith(<span class="stringliteral">&#39;_&#39;</span>):</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;            ns_op_name = n.kind()[:-1]</div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;            ns_op_name = n.kind()</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;        ns, op_name = ns_op_name.split(<span class="stringliteral">&quot;::&quot;</span>)</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;        <span class="keywordflow">if</span> ns == <span class="stringliteral">&quot;onnx&quot;</span>:</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;            <span class="comment"># Use the original node directly</span></div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;            <span class="keywordflow">return</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;        <span class="keywordflow">elif</span> ns == <span class="stringliteral">&quot;aten&quot;</span>:</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;            is_exportable_aten_op = hasattr(<a class="code" href="namespacetorch_1_1onnx_1_1symbolic.html">torch.onnx.symbolic</a>, op_name)</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;            is_onnx_aten_export = operator_export_type == OperatorExportTypes.ONNX_ATEN</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;            is_aten_fallback_export = operator_export_type == OperatorExportTypes.ONNX_ATEN_FALLBACK</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;            <span class="keywordflow">if</span> is_onnx_aten_export <span class="keywordflow">or</span> (<span class="keywordflow">not</span> is_exportable_aten_op <span class="keywordflow">and</span> is_aten_fallback_export):</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;                <span class="comment"># Direct ATen export requested</span></div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;                attrs = {k + <span class="stringliteral">&quot;_&quot;</span> + n.kindOf(k)[0]: n[k] <span class="keywordflow">for</span> k <span class="keywordflow">in</span> n.attributeNames()}</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;                outputs = n.outputsSize()</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;                attrs[<span class="stringliteral">&quot;outputs&quot;</span>] = outputs</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;                <span class="keywordflow">return</span> _graph_at(g, op_name, *inputs, aten=<span class="keyword">True</span>, **attrs)</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;                <span class="comment"># Export it regularly</span></div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;                attrs = {k: n[k] <span class="keywordflow">for</span> k <span class="keywordflow">in</span> n.attributeNames()}</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;                <span class="keywordflow">if</span> <span class="keywordflow">not</span> is_exportable_aten_op:</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;                    warnings.warn(<span class="stringliteral">&quot;ONNX export failed on ATen operator {} because torch.onnx.symbolic.{} does not exist&quot;</span></div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;                                  .format(op_name, op_name))</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;                    <span class="keywordflow">return</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;                fn = getattr(<a class="code" href="namespacetorch_1_1onnx_1_1symbolic.html">torch.onnx.symbolic</a>, op_name)</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;                <span class="keywordflow">return</span> fn(g, *inputs, **attrs)</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;        <span class="keywordflow">elif</span> ns == <span class="stringliteral">&quot;prim&quot;</span>:</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;            <span class="keywordflow">if</span> op_name == <span class="stringliteral">&quot;Constant&quot;</span> <span class="keywordflow">and</span> <span class="keywordflow">not</span> n.mustBeNone():</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;                <span class="keywordflow">if</span> n.kindOf(<span class="stringliteral">&quot;value&quot;</span>) == <span class="stringliteral">&quot;t&quot;</span>:</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;                    <span class="keywordflow">return</span> g.op(<span class="stringliteral">&quot;Constant&quot;</span>, value_t=n[<span class="stringliteral">&quot;value&quot;</span>])</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;                <span class="keywordflow">elif</span> n.kindOf(<span class="stringliteral">&quot;value&quot;</span>) == <span class="stringliteral">&quot;is&quot;</span>:</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;                    value = torch.stack([<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(v) <span class="keywordflow">for</span> v <span class="keywordflow">in</span> n[<span class="stringliteral">&quot;value&quot;</span>]]) <span class="keywordflow">if</span> n[<span class="stringliteral">&quot;value&quot;</span>] <span class="keywordflow">else</span> []</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;                    <span class="keywordflow">return</span> g.op(<span class="stringliteral">&quot;Constant&quot;</span>, value_t=value)</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;                <span class="keywordflow">elif</span> n.output().type().kind() == <span class="stringliteral">&quot;DeviceObjType&quot;</span>:</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;                    <span class="keywordflow">return</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;                <span class="keywordflow">else</span>:</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;                    <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;Unsupported prim::Constant kind: `{}`. Send a bug report.&quot;</span>.format(</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;                        n.kindOf(<span class="stringliteral">&quot;value&quot;</span>)))</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;            <span class="keywordflow">elif</span> n.mustBeNone() <span class="keywordflow">or</span> op_name == <span class="stringliteral">&quot;ListConstruct&quot;</span> <span class="keywordflow">or</span> op_name == <span class="stringliteral">&quot;ListUnpack&quot;</span>:</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;                <span class="comment"># None is not an ONNX operator; keep it as None</span></div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;                <span class="comment"># let the exporter handle finally eliminating these</span></div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;                <span class="comment"># For ListConstruct/ListUnpack, it will be erased in the ONNX peephole pass</span></div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;                <span class="keywordflow">return</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;            <span class="keywordflow">elif</span> op_name == <span class="stringliteral">&#39;Loop&#39;</span> <span class="keywordflow">or</span> op_name == <span class="stringliteral">&#39;If&#39;</span>:</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;                new_op_outputs = g.op(op_name, *inputs, outputs=n.outputsSize())</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;                new_node = new_op_outputs[0].node() <span class="keywordflow">if</span> n.outputsSize() &gt; 1 <span class="keywordflow">else</span> new_op_outputs.node()</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;                <span class="keywordflow">for</span> b <span class="keywordflow">in</span> n.blocks():</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;                    new_block = new_node.addBlock()</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;                    torch._C._jit_pass_onnx_block(b, new_block, operator_export_type, env)</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;                <span class="keywordflow">return</span> new_op_outputs</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;                symbolic_name = <span class="stringliteral">&#39;prim_&#39;</span> + op_name</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;                symbolic_fn = getattr(<a class="code" href="namespacetorch_1_1onnx_1_1symbolic.html">torch.onnx.symbolic</a>, symbolic_name, <span class="keywordtype">None</span>)</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;                <span class="keywordflow">if</span> symbolic_fn <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;                    warnings.warn(<span class="stringliteral">&quot;ONNX export failed on primitive operator {}; please report a bug&quot;</span>.format(op_name))</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;                    <span class="keywordflow">return</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;                attrs = {k: n[k] <span class="keywordflow">for</span> k <span class="keywordflow">in</span> n.attributeNames()}</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;                <span class="keywordflow">return</span> symbolic_fn(g, *inputs, **attrs)</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;            warnings.warn(<span class="stringliteral">&quot;ONNX export failed on an operator with unrecognized namespace {}::{}; &quot;</span></div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;                          <span class="stringliteral">&quot;please report a bug&quot;</span>.format(ns, op_name))</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;            <span class="keywordflow">return</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;    <span class="keywordflow">except</span> TypeError <span class="keyword">as</span> e:</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;        <span class="comment"># Handle the specific case where we didn&#39;t successfully dispatch.</span></div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;        <span class="comment"># Otherwise, the backtrace will have the clues you need.</span></div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;        e.args = (<span class="stringliteral">&quot;{} (occurred when translating {})&quot;</span>.format(e.args[0], op_name), )</div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;        <span class="keywordflow">raise</span></div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;<span class="comment"># Generate an ONNX ATen op node.</span></div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;<span class="keyword">def </span>_graph_at(g, opname, *args, **kwargs):</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;    <span class="keywordflow">return</span> g.op(<span class="stringliteral">&quot;ATen&quot;</span>, *args, operator_s=opname, **kwargs)</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;<span class="comment"># This helper function can create either constant tensor or constant scalar.</span></div><div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;<span class="comment"># If dims is None or 0 or [0], generate a 0-d tensor (scalar).</span></div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;<span class="comment">#</span></div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;<span class="comment"># TODO: We might not need this anymore, since most scalars now show up</span></div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;<span class="comment"># as tensors</span></div><div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;<span class="keyword">def </span>_graph_constant(g, value, dims, type, *args, **kwargs):</div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;    <span class="keyword">assert</span> isinstance(value, numbers.Number)</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;    <span class="keyword">assert</span> type <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;    isscalar = <span class="keyword">False</span></div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;    <span class="keywordflow">if</span> dims <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> dims == 0 <span class="keywordflow">or</span> set(dims) == set([0]):</div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;        dims = [1]</div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;        isscalar = <span class="keyword">True</span></div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;    type = type.lower()</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;    <span class="keywordflow">if</span> type == <span class="stringliteral">&quot;char&quot;</span>:</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;        tensor = torch.CharTensor(*dims)</div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;    <span class="keywordflow">elif</span> type == <span class="stringliteral">&quot;short&quot;</span>:</div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;        tensor = torch.ShortTensor(*dims)</div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;    <span class="keywordflow">elif</span> type == <span class="stringliteral">&quot;int&quot;</span>:</div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;        tensor = torch.IntTensor(*dims)</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;    <span class="keywordflow">elif</span> type == <span class="stringliteral">&quot;long&quot;</span>:</div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;        tensor = torch.LongTensor(*dims)</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;    <span class="keywordflow">elif</span> type == <span class="stringliteral">&quot;half&quot;</span>:</div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;        tensor = torch.HalfTensor(*dims)</div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;    <span class="keywordflow">elif</span> type == <span class="stringliteral">&quot;float&quot;</span>:</div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;        tensor = torch.FloatTensor(*dims)</div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;    <span class="keywordflow">elif</span> type == <span class="stringliteral">&quot;double&quot;</span>:</div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;        tensor = torch.DoubleTensor(*dims)</div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;    <span class="keywordflow">else</span>:</div><div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Unknown type, type should be one of the following strings: &quot;</span></div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;                         <span class="stringliteral">&quot;char, short, int, long, half, float, double&quot;</span>)</div><div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;    tensor.fill_(value)</div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;    <span class="keywordflow">if</span> isscalar:</div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;        <span class="keywordflow">return</span> g.op(<span class="stringliteral">&quot;Constant&quot;</span>, *args, value_z=tensor, **kwargs)</div><div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;    <span class="keywordflow">return</span> g.op(<span class="stringliteral">&quot;Constant&quot;</span>, *args, value_t=tensor, **kwargs)</div><div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;</div><div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;</div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;<span class="keyword">def </span>_node_getitem(self, k):</div><div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;    <span class="stringliteral">r&quot;&quot;&quot;</span></div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;<span class="stringliteral">    Accessor for attributes of a node which is polymorphic over</span></div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;<span class="stringliteral">    return type.</span></div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;<span class="stringliteral">    NB: This is monkey-patched onto Node.</span></div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;    sel = self.kindOf(k)</div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;    <span class="keywordflow">return</span> getattr(self, sel)(k)</div><div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;</div><div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;</div><div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;torch._C.Graph.op = _graph_op</div><div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;torch._C.Graph.at = _graph_at</div><div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;torch._C.Graph.constant = _graph_constant</div><div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;torch._C.Node.__getitem__ = _node_getitem</div><div class="ttc" id="namespacetorch_1_1__six_html"><div class="ttname"><a href="namespacetorch_1_1__six.html">torch._six</a></div><div class="ttdef"><b>Definition:</b> <a href="__six_8py_source.html#l00001">_six.py:1</a></div></div>
<div class="ttc" id="torch_2jit_2____init_____8py_html_a8f3c6d4f2470a1d678c4da2530e8db9c"><div class="ttname"><a href="torch_2jit_2____init_____8py.html#a8f3c6d4f2470a1d678c4da2530e8db9c">torch.jit.get_trace_graph</a></div><div class="ttdeci">def get_trace_graph(f, args=(), kwargs=None, _force_outplace=False, return_inputs=False)</div><div class="ttdef"><b>Definition:</b> <a href="torch_2jit_2____init_____8py_source.html#l00192">__init__.py:192</a></div></div>
<div class="ttc" id="namespacetorch_1_1jit_html"><div class="ttname"><a href="namespacetorch_1_1jit.html">torch.jit</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2jit_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="namespacetorch_1_1autograd_html"><div class="ttname"><a href="namespacetorch_1_1autograd.html">torch.autograd</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2autograd_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="serialization_8py_html_a72b9f6bd4e0d145f41204c3250a6b73e"><div class="ttname"><a href="serialization_8py.html#a72b9f6bd4e0d145f41204c3250a6b73e">torch.serialization._with_file_like</a></div><div class="ttdeci">def _with_file_like(f, mode, body)</div><div class="ttdef"><b>Definition:</b> <a href="serialization_8py_source.html#l00137">serialization.py:137</a></div></div>
<div class="ttc" id="namespacetorch_1_1serialization_html"><div class="ttname"><a href="namespacetorch_1_1serialization.html">torch.serialization</a></div><div class="ttdef"><b>Definition:</b> <a href="serialization_8py_source.html#l00001">serialization.py:1</a></div></div>
<div class="ttc" id="namespacetorch_1_1onnx_1_1symbolic_html"><div class="ttname"><a href="namespacetorch_1_1onnx_1_1symbolic.html">torch.onnx.symbolic</a></div><div class="ttdef"><b>Definition:</b> <a href="symbolic_8py_source.html#l00001">symbolic.py:1</a></div></div>
<div class="ttc" id="namespacetorch_1_1___c_html"><div class="ttname"><a href="namespacetorch_1_1___c.html">_C</a></div></div>
<div class="ttc" id="namespacetorch_1_1onnx_html"><div class="ttname"><a href="namespacetorch_1_1onnx.html">torch.onnx</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2onnx_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="classtorch_1_1jit_1_1_script_module_html"><div class="ttname"><a href="classtorch_1_1jit_1_1_script_module.html">torch.jit.ScriptModule</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2jit_2____init_____8py_source.html#l01013">__init__.py:1013</a></div></div>
<div class="ttc" id="namespacetorch_1_1tensor_html"><div class="ttname"><a href="namespacetorch_1_1tensor.html">torch.tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="tensor_8py_source.html#l00001">tensor.py:1</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.14-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Mar 20 2019 13:07:37 for Caffe2 - Python API by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
<div class="footerContainer">
  <div id="footer_wrap" class="wrapper footerWrapper">
    <div class="footerBlocks">
      <div id="fb_oss" class="footerSection fbOpenSourceFooter">
          <svg class="facebookOSSLogoSvg" viewBox="0 0 1133.9 1133.9" x="0px" y="0px" height=50 width=50>
            <g>
              <path class="logoRing outerRing" d="M 498.3 3.7 c 153.6 88.9 307.3 177.7 461.1 266.2 c 7.6 4.4 10.3 9.1 10.3 17.8 c -0.3 179.1 -0.2 358.3 0 537.4 c 0 8.1 -2.4 12.8 -9.7 17.1 c -154.5 88.9 -308.8 178.1 -462.9 267.5 c -9 5.2 -15.5 5.3 -24.6 0.1 c -153.9 -89.2 -307.9 -178 -462.1 -266.8 C 3 838.8 0 833.9 0 825.1 c 0.3 -179.1 0.2 -358.3 0 -537.4 c 0 -8.6 2.6 -13.6 10.2 -18 C 164.4 180.9 318.4 92 472.4 3 C 477 -1.5 494.3 -0.7 498.3 3.7 Z M 48.8 555.3 c 0 79.9 0.2 159.9 -0.2 239.8 c -0.1 10 3 15.6 11.7 20.6 c 137.2 78.8 274.2 157.8 411 237.3 c 9.9 5.7 17 5.7 26.8 0.1 c 137.5 -79.8 275.2 -159.2 412.9 -238.5 c 7.4 -4.3 10.5 -8.9 10.5 -17.8 c -0.3 -160.2 -0.3 -320.5 0 -480.7 c 0 -8.8 -2.8 -13.6 -10.3 -18 C 772.1 218 633.1 137.8 494.2 57.4 c -6.5 -3.8 -11.5 -4.5 -18.5 -0.5 C 336.8 137.4 197.9 217.7 58.8 297.7 c -7.7 4.4 -10.2 9.2 -10.2 17.9 C 48.9 395.5 48.8 475.4 48.8 555.3 Z" />
              <path class="logoRing middleRing" d="M 184.4 555.9 c 0 -33.3 -1 -66.7 0.3 -100 c 1.9 -48 24.1 -86 64.7 -110.9 c 54.8 -33.6 110.7 -65.5 167 -96.6 c 45.7 -25.2 92.9 -24.7 138.6 1 c 54.4 30.6 108.7 61.5 162.2 93.7 c 44 26.5 67.3 66.8 68 118.4 c 0.9 63.2 0.9 126.5 0 189.7 c -0.7 50.6 -23.4 90.7 -66.6 116.9 c -55 33.4 -110.8 65.4 -167.1 96.5 c -43.4 24 -89 24.2 -132.3 0.5 c -57.5 -31.3 -114.2 -64 -170 -98.3 c -41 -25.1 -62.9 -63.7 -64.5 -112.2 C 183.5 621.9 184.3 588.9 184.4 555.9 Z M 232.9 556.3 c 0 29.5 0.5 59.1 -0.1 88.6 c -0.8 39.2 16.9 67.1 50.2 86.2 c 51.2 29.4 102.2 59.2 153.4 88.4 c 31.4 17.9 63.6 18.3 95 0.6 c 53.7 -30.3 107.1 -61.2 160.3 -92.5 c 29.7 -17.5 45 -44.5 45.3 -78.8 c 0.6 -61.7 0.5 -123.5 0 -185.2 c -0.3 -34.4 -15.3 -61.5 -44.9 -79 C 637.7 352.6 583 320.8 527.9 290 c -27.5 -15.4 -57.2 -16.1 -84.7 -0.7 c -56.9 31.6 -113.4 64 -169.1 97.6 c -26.4 15.9 -40.7 41.3 -41.1 72.9 C 232.6 491.9 232.9 524.1 232.9 556.3 Z" />
              <path class="logoRing innerRing" d="M 484.9 424.4 c 69.8 -2.8 133.2 57.8 132.6 132 C 617 630 558.5 688.7 484.9 689.1 c -75.1 0.4 -132.6 -63.6 -132.7 -132.7 C 352.1 485 413.4 421.5 484.9 424.4 Z M 401.3 556.7 c -3.4 37.2 30.5 83.6 83 84.1 c 46.6 0.4 84.8 -37.6 84.9 -84 c 0.1 -46.6 -37.2 -84.4 -84.2 -84.6 C 432.2 472.1 397.9 518.3 401.3 556.7 Z" />
            </g>
          </svg>
        <h2>Facebook Open Source</h2>
      </div>
      <div class="footerSection">
        <a class="footerLink" href="https://code.facebook.com/projects/" target="_blank">Open Source Projects</a>
        <a class="footerLink" href="https://github.com/facebook/" target="_blank">GitHub</a>
        <a class="footerLink" href="https://twitter.com/fbOpenSource" target="_blank">Twitter</a>
      </div>
      <div class="footerSection rightAlign">
        <a class="footerLink" href="https://github.com/caffe2/caffe2" target="_blank">Contribute to this project on GitHub</a>
      </div>
    </div>
  </div>
</div>
<script type="text/javascript" src="/js/jekyll-link-anchors.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', '{{ site.gacode }}', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
