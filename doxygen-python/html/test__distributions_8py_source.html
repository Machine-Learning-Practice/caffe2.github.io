<!-- HTML header for doxygen 1.8.14-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Caffe2 - Python API: test/test_distributions.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="/static/favicon.png" type="image/x-icon">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" />
<link href="main.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo" width="56"><a href="/"><img alt="Logo" src="Caffe2-with-name-55-tall.png"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Caffe2 - Python API
   </div>
   <div id="projectbrief">A deep learning, cross platform ML framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="namespaces.html"><span>Packages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li><a href="/doxygen-c/html/classes.html"><span>C++&#160;API</span></a></li>
      <li><a href="/doxygen-python/html/annotated.html"><span>Python&#160;API</span></a></li>
      <li><a href="https://github.com/caffe2/caffe2"><span>GitHub</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_13e138d54eb8818da29c3992edef070a.html">test</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">test_distributions.py</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno"><a class="line" href="namespacetest__distributions.html">    1</a></span>&#160;<span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="stringliteral">Note [Randomized statistical tests]</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="stringliteral">-----------------------------------</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="stringliteral">This note describes how to maintain tests in this file as random sources</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="stringliteral">change. This file contains two types of randomized tests:</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="stringliteral">1. The easier type of randomized test are tests that should always pass but are</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="stringliteral">   initialized with random data. If these fail something is wrong, but it&#39;s</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="stringliteral">   fine to use a fixed seed by inheriting from common.TestCase.</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="stringliteral">2. The trickier tests are statistical tests. These tests explicitly call</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="stringliteral">   set_rng_seed(n) and are marked &quot;see Note [Randomized statistical tests]&quot;.</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="stringliteral">   These statistical tests have a known positive failure rate</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="stringliteral">   (we set failure_rate=1e-3 by default). We need to balance strength of these</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="stringliteral">   tests with annoyance of false alarms. One way that works is to specifically</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="stringliteral">   set seeds in each of the randomized tests. When a random generator</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="stringliteral">   occasionally changes (as in #4312 vectorizing the Box-Muller sampler), some</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="stringliteral">   of these statistical tests may (rarely) fail. If one fails in this case,</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="stringliteral">   it&#39;s fine to increment the seed of the failing test (but you shouldn&#39;t need</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="stringliteral">   to increment it more than once; otherwise something is probably actually</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="stringliteral">   wrong).</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="keyword">import</span> math</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="keyword">import</span> numbers</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="keyword">import</span> unittest</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="keyword">from</span> itertools <span class="keyword">import</span> product</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="keyword">from</span> random <span class="keyword">import</span> shuffle</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="keyword">import</span> torch</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1__six.html">torch._six</a> <span class="keyword">import</span> inf</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">from</span> common_utils <span class="keyword">import</span> TestCase, run_tests, set_rng_seed, TEST_WITH_UBSAN, load_tests, skipIfRocm</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="keyword">from</span> common_cuda <span class="keyword">import</span> TEST_CUDA</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1autograd.html">torch.autograd</a> <span class="keyword">import</span> grad, gradcheck</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1distributions.html">torch.distributions</a> <span class="keyword">import</span> (Bernoulli, Beta, Binomial, Categorical,</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;                                 Cauchy, Chi2, Dirichlet, Distribution,</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;                                 Exponential, ExponentialFamily,</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;                                 FisherSnedecor, Gamma, Geometric, Gumbel,</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;                                 HalfCauchy, HalfNormal,</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;                                 Independent, Laplace, LogisticNormal,</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;                                 LogNormal, LowRankMultivariateNormal,</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;                                 Multinomial, MultivariateNormal,</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;                                 NegativeBinomial, Normal, OneHotCategorical, Pareto,</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;                                 Poisson, RelaxedBernoulli, RelaxedOneHotCategorical,</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;                                 StudentT, TransformedDistribution, Uniform,</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;                                 Weibull, constraints, kl_divergence)</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1distributions_1_1constraint__registry.html">torch.distributions.constraint_registry</a> <span class="keyword">import</span> biject_to, transform_to</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1distributions_1_1constraints.html">torch.distributions.constraints</a> <span class="keyword">import</span> Constraint, is_dependent</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1distributions_1_1dirichlet.html">torch.distributions.dirichlet</a> <span class="keyword">import</span> _Dirichlet_backward</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1distributions_1_1kl.html">torch.distributions.kl</a> <span class="keyword">import</span> _kl_expfamily_expfamily</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1distributions_1_1transforms.html">torch.distributions.transforms</a> <span class="keyword">import</span> (AbsTransform, AffineTransform,</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;                                            ComposeTransform, ExpTransform,</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;                                            LowerCholeskyTransform,</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;                                            PowerTransform, SigmoidTransform,</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;                                            SoftmaxTransform,</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;                                            StickBreakingTransform,</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;                                            identity_transform)</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1distributions_1_1utils.html">torch.distributions.utils</a> <span class="keyword">import</span> probs_to_logits, lazy_property</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacetorch_1_1nn_1_1functional.html">torch.nn.functional</a> <span class="keyword">import</span> softmax</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment"># load_tests from common_utils is used to automatically filter tests for</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment"># sharding on sandcastle. This line silences flake warnings</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;load_tests = load_tests</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;TEST_NUMPY = <span class="keyword">True</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="keywordflow">try</span>:</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="keyword">import</span> scipy.stats</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="keyword">import</span> scipy.special</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="keywordflow">except</span> ImportError:</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    TEST_NUMPY = <span class="keyword">False</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;</div><div class="line"><a name="l00076"></a><span class="lineno"><a class="line" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">   76</a></span>&#160;<span class="keyword">def </span><a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Dist, *params):</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="stringliteral">    Creates a pair of distributions `Dist` initialzed to test each element of</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="stringliteral">    param with each other.</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    params1 = [<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([p] * len(p)) <span class="keywordflow">for</span> p <span class="keywordflow">in</span> params]</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    params2 = [p.transpose(0, 1) <span class="keywordflow">for</span> p <span class="keywordflow">in</span> params1]</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;    <span class="keywordflow">return</span> Dist(*params1), Dist(*params2)</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;</div><div class="line"><a name="l00086"></a><span class="lineno"><a class="line" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">   86</a></span>&#160;<span class="keyword">def </span><a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(tensor):</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="stringliteral">    Checks if all entries of a tensor is nan.</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="keywordflow">return</span> (tensor != tensor).all()</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="comment"># Register all distributions for generic tests.</span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;Example = namedtuple(<span class="stringliteral">&#39;Example&#39;</span>, [<span class="stringliteral">&#39;Dist&#39;</span>, <span class="stringliteral">&#39;params&#39;</span>])</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;EXAMPLES = [</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    Example(Bernoulli, [</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.3], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: 0.3},</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        {<span class="stringliteral">&#39;logits&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    ]),</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;    Example(Geometric, [</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.3], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: 0.3},</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    ]),</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;    Example(Beta, [</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;        {</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;            <span class="stringliteral">&#39;concentration1&#39;</span>: torch.randn(2, 3).exp().requires_grad_(),</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;            <span class="stringliteral">&#39;concentration0&#39;</span>: torch.randn(2, 3).exp().requires_grad_(),</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;        },</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;        {</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;            <span class="stringliteral">&#39;concentration1&#39;</span>: torch.randn(4).exp().requires_grad_(),</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;            <span class="stringliteral">&#39;concentration0&#39;</span>: torch.randn(4).exp().requires_grad_(),</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;        },</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    ]),</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    Example(Categorical, [</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;        {<span class="stringliteral">&#39;logits&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.0, 0.0], [0.0, 0.0]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;    ]),</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    Example(Binomial, [</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([10])},</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([10, 8])},</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[10., 8.], [5., 3.]])},</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.)},</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    ]),</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;    Example(NegativeBinomial, [</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.9, 0.0], [0.0, 0.9]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.9, 0.0], [0.0, 0.9]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([10])},</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.9, 0.0], [0.0, 0.9]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([10, 8])},</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.9, 0.0], [0.0, 0.9]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[10., 8.], [5., 3.]])},</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.9, 0.0], [0.0, 0.9]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.)},</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    ]),</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;    Example(Multinomial, [</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>), <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;    ]),</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    Example(Cauchy, [</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;        {<span class="stringliteral">&#39;loc&#39;</span>: 0.0, <span class="stringliteral">&#39;scale&#39;</span>: 1.0},</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        {<span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0]), <span class="stringliteral">&#39;scale&#39;</span>: 1.0},</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;        {<span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.0], [0.0]]),</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;         <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0], [1.0]])}</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;    ]),</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    Example(Chi2, [</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: torch.randn(2, 3).exp().requires_grad_()},</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: torch.randn(1).exp().requires_grad_()},</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    ]),</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    Example(StudentT, [</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: torch.randn(2, 3).exp().requires_grad_()},</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: torch.randn(1).exp().requires_grad_()},</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    ]),</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    Example(Dirichlet, [</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;        {<span class="stringliteral">&#39;concentration&#39;</span>: torch.randn(2, 3).exp().requires_grad_()},</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;        {<span class="stringliteral">&#39;concentration&#39;</span>: torch.randn(4).exp().requires_grad_()},</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;    ]),</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;    Example(Exponential, [</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;        {<span class="stringliteral">&#39;rate&#39;</span>: torch.randn(5, 5).abs().requires_grad_()},</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;        {<span class="stringliteral">&#39;rate&#39;</span>: torch.randn(1).abs().requires_grad_()},</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;    ]),</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    Example(FisherSnedecor, [</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        {</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;            <span class="stringliteral">&#39;df1&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;            <span class="stringliteral">&#39;df2&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        },</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        {</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;            <span class="stringliteral">&#39;df1&#39;</span>: torch.randn(1).abs().requires_grad_(),</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;            <span class="stringliteral">&#39;df2&#39;</span>: torch.randn(1).abs().requires_grad_(),</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;        },</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        {</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;            <span class="stringliteral">&#39;df1&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0]),</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;            <span class="stringliteral">&#39;df2&#39;</span>: 1.0,</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;        }</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;    ]),</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;    Example(Gamma, [</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;        {</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;            <span class="stringliteral">&#39;concentration&#39;</span>: torch.randn(2, 3).exp().requires_grad_(),</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: torch.randn(2, 3).exp().requires_grad_(),</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;        },</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;        {</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;            <span class="stringliteral">&#39;concentration&#39;</span>: torch.randn(1).exp().requires_grad_(),</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: torch.randn(1).exp().requires_grad_(),</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;        },</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    ]),</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;    Example(Gumbel, [</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;        {</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;        },</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;        {</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(1, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(1).abs().requires_grad_(),</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;        },</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    ]),</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    Example(HalfCauchy, [</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: 1.0},</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0], [1.0]])}</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;    ]),</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;    Example(HalfNormal, [</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_()},</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: torch.randn(1).abs().requires_grad_()},</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5], requires_grad=<span class="keyword">True</span>)}</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    ]),</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;    Example(Independent, [</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;        {</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;                                        torch.randn(2, 3).abs().requires_grad_()),</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;            <span class="stringliteral">&#39;reinterpreted_batch_ndims&#39;</span>: 0,</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;        },</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;        {</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;                                        torch.randn(2, 3).abs().requires_grad_()),</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;            <span class="stringliteral">&#39;reinterpreted_batch_ndims&#39;</span>: 1,</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;        },</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;        {</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;                                        torch.randn(2, 3).abs().requires_grad_()),</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;            <span class="stringliteral">&#39;reinterpreted_batch_ndims&#39;</span>: 2,</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;        },</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;        {</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;                                        torch.randn(2, 3, 5).abs().requires_grad_()),</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;            <span class="stringliteral">&#39;reinterpreted_batch_ndims&#39;</span>: 2,</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;        },</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;        {</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;                                        torch.randn(2, 3, 5).abs().requires_grad_()),</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;            <span class="stringliteral">&#39;reinterpreted_batch_ndims&#39;</span>: 3,</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;        },</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;    ]),</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;    Example(Laplace, [</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;        {</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;        },</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;        {</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(1, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(1).abs().requires_grad_(),</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;        },</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;        {</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;        },</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;    ]),</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    Example(LogNormal, [</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;        {</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;        },</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;        {</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(1, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(1).abs().requires_grad_(),</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;        },</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        {</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        },</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;    ]),</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;    Example(LogisticNormal, [</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;        {</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 5).requires_grad_(),</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;        },</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;        {</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(1).requires_grad_(),</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(1).abs().requires_grad_(),</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;        },</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;        {</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;        },</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;    ]),</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;    Example(LowRankMultivariateNormal, [</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;        {</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 2, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;            <span class="stringliteral">&#39;cov_factor&#39;</span>: torch.randn(5, 2, 1, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;            <span class="stringliteral">&#39;cov_diag&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0, 0.25], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;        },</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;        {</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(4, 3, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;            <span class="stringliteral">&#39;cov_factor&#39;</span>: torch.randn(3, 2, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;            <span class="stringliteral">&#39;cov_diag&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([5.0, 1.5, 3.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;        }</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;    ]),</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;    Example(MultivariateNormal, [</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;        {</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 2, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;            <span class="stringliteral">&#39;covariance_matrix&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[2.0, 0.3], [0.3, 0.25]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;        },</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;        {</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(2, 3, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;            <span class="stringliteral">&#39;precision_matrix&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[2.0, 0.1, 0.0],</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;                                              [0.1, 0.25, 0.0],</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;                                              [0.0, 0.0, 0.3]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;        },</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;        {</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 3, 2, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;            <span class="stringliteral">&#39;scale_tril&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[[2.0, 0.0], [-0.5, 0.25]],</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;                                        [[2.0, 0.0], [0.3, 0.25]],</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;                                        [[5.0, 0.0], [-0.5, 1.5]]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;        },</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;        {</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, -1.0]),</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;            <span class="stringliteral">&#39;covariance_matrix&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[5.0, -0.5], [-0.5, 1.5]]),</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;        },</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;    ]),</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;    Example(Normal, [</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;        {</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(5, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;        },</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;        {</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: torch.randn(1, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(1).abs().requires_grad_(),</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;        },</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;        {</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;        },</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;    ]),</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;    Example(OneHotCategorical, [</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;        {<span class="stringliteral">&#39;logits&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.0, 0.0], [0.0, 0.0]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;    ]),</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;    Example(Pareto, [</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;        {</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: 1.0,</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;            <span class="stringliteral">&#39;alpha&#39;</span>: 1.0</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;        },</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;        {</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;            <span class="stringliteral">&#39;alpha&#39;</span>: torch.randn(5, 5).abs().requires_grad_()</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;        },</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;        {</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0]),</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;            <span class="stringliteral">&#39;alpha&#39;</span>: 1.0</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;        }</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;    ]),</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;    Example(Poisson, [</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;        {</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;        },</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;        {</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: torch.randn(3).abs().requires_grad_(),</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;        },</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;        {</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: 0.2,</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;        }</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;    ]),</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;    Example(RelaxedBernoulli, [</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;        {</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;        },</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;        {</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0]),</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.3]),</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;        },</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;        {</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([7.2]),</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;            <span class="stringliteral">&#39;logits&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-2.0, 2.0, 1.0, 5.0])</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;        }</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;    ]),</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;    Example(RelaxedOneHotCategorical, [</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;        {</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2, 0.7], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;        },</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;        {</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0]),</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 1.0]])</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;        },</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;        {</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([7.2]),</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;            <span class="stringliteral">&#39;logits&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-2.0, 2.0], [1.0, 5.0]])</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;        }</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;    ]),</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;    Example(TransformedDistribution, [</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;        {</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;                                        torch.randn(2, 3).abs().requires_grad_()),</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;            <span class="stringliteral">&#39;transforms&#39;</span>: [],</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;        },</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;        {</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;                                        torch.randn(2, 3).abs().requires_grad_()),</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;            <span class="stringliteral">&#39;transforms&#39;</span>: ExpTransform(),</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;        },</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;        {</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;                                        torch.randn(2, 3, 5).abs().requires_grad_()),</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;            <span class="stringliteral">&#39;transforms&#39;</span>: [AffineTransform(torch.randn(3, 5), torch.randn(3, 5)),</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;                           ExpTransform()],</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;        },</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;        {</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(torch.randn(2, 3, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;                                        torch.randn(2, 3, 5).abs().requires_grad_()),</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;            <span class="stringliteral">&#39;transforms&#39;</span>: AffineTransform(1, 2),</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;        },</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;    ]),</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;    Example(Uniform, [</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;        {</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;            <span class="stringliteral">&#39;low&#39;</span>: torch.zeros(5, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;            <span class="stringliteral">&#39;high&#39;</span>: torch.ones(5, 5, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;        },</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;        {</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;            <span class="stringliteral">&#39;low&#39;</span>: torch.zeros(1, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;            <span class="stringliteral">&#39;high&#39;</span>: torch.ones(1, requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;        },</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;        {</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;            <span class="stringliteral">&#39;low&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 1.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;            <span class="stringliteral">&#39;high&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0, 3.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;        },</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;    ]),</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;    Example(Weibull, [</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;        {</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: torch.randn(5, 5).abs().requires_grad_(),</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;            <span class="stringliteral">&#39;concentration&#39;</span>: torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;        }</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;    ])</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;]</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;BAD_EXAMPLES = [</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;    Example(Bernoulli, [</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.1, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-0.5], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: 1.00001},</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;    ]),</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;    Example(Beta, [</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;        {</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;            <span class="stringliteral">&#39;concentration1&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;            <span class="stringliteral">&#39;concentration0&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;        },</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;        {</div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;            <span class="stringliteral">&#39;concentration1&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-1.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;            <span class="stringliteral">&#39;concentration0&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-2.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;        },</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;    ]),</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;    Example(Geometric, [</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.1, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-0.3], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: 1.00000001},</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;    ]),</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;    Example(Categorical, [</div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-0.1, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-1.0, 10.0], [0.0, -1.0]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;    ]),</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;    Example(Binomial, [</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-0.0000001, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 2.0]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;    ]),</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;    Example(NegativeBinomial, [</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-0.0000001, 0.2, 0.3], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, 2.0]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;         <span class="stringliteral">&#39;total_count&#39;</span>: 10},</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;    ]),</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;    Example(Cauchy, [</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;        {<span class="stringliteral">&#39;loc&#39;</span>: 0.0, <span class="stringliteral">&#39;scale&#39;</span>: -1.0},</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;        {<span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0]), <span class="stringliteral">&#39;scale&#39;</span>: 0.0},</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;        {<span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.0], [-2.0]]),</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;         <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-0.000001], [1.0]])}</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;    ]),</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;    Example(Chi2, [</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-2.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;    ]),</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;    Example(StudentT, [</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;        {<span class="stringliteral">&#39;df&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-2.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;    ]),</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;    Example(Dirichlet, [</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;        {<span class="stringliteral">&#39;concentration&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;        {<span class="stringliteral">&#39;concentration&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-2.], requires_grad=<span class="keyword">True</span>)}</div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;    ]),</div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;    Example(Exponential, [</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;        {<span class="stringliteral">&#39;rate&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;        {<span class="stringliteral">&#39;rate&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-2.], requires_grad=<span class="keyword">True</span>)}</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;    ]),</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;    Example(FisherSnedecor, [</div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;        {</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;            <span class="stringliteral">&#39;df1&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;            <span class="stringliteral">&#39;df2&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-1., -100.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;        },</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;        {</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;            <span class="stringliteral">&#39;df1&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;            <span class="stringliteral">&#39;df2&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;        }</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;    ]),</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;    Example(Gamma, [</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;        {</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;            <span class="stringliteral">&#39;concentration&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-1., -100.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;        },</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;        {</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;            <span class="stringliteral">&#39;concentration&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;        }</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;    ]),</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;    Example(Gumbel, [</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;        {</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;        },</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;        {</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., -1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;        },</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;    ]),</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;    Example(HalfCauchy, [</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: -1.0},</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: 0.0},</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-0.000001], [1.0]])}</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;    ]),</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;    Example(HalfNormal, [</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;        {<span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., -1.], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;    ]),</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;    Example(Laplace, [</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;        {</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;        },</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;        {</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., -1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;        },</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;    ]),</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;    Example(LogNormal, [</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;        {</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;        },</div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;        {</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., -1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;        },</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;    ]),</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;    Example(MultivariateNormal, [</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;        {</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;            <span class="stringliteral">&#39;covariance_matrix&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.0, 0.0], [0.0, -2.0]], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;        },</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;    ]),</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;    Example(Normal, [</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;        {</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;        },</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;        {</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., -1.], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;        },</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;        {</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;            <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, -1e-5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;        },</div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;    ]),</div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;    Example(OneHotCategorical, [</div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2, 0.3], [0.1, -10.0, 0.2]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;        {<span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.0, 0.0], [0.0, 0.0]], requires_grad=<span class="keyword">True</span>)},</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;    ]),</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;    Example(Pareto, [</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;        {</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: 0.0,</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;            <span class="stringliteral">&#39;alpha&#39;</span>: 0.0</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;        },</div><div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;        {</div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0, 0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;            <span class="stringliteral">&#39;alpha&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-1e-5, 0.0], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;        },</div><div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;        {</div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0]),</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;            <span class="stringliteral">&#39;alpha&#39;</span>: -1.0</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;        }</div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;    ]),</div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;    Example(Poisson, [</div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;        {</div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;        },</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;        {</div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;            <span class="stringliteral">&#39;rate&#39;</span>: -1.0,</div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;        }</div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;    ]),</div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;    Example(RelaxedBernoulli, [</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;        {</div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;        },</div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;        {</div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0]),</div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-1.0]),</div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;        }</div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;    ]),</div><div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;    Example(RelaxedOneHotCategorical, [</div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;        {</div><div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.5], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-0.1, 0.2, 0.7], [0.5, 0.3, 0.2]], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;        },</div><div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;        {</div><div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;            <span class="stringliteral">&#39;temperature&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0]),</div><div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;            <span class="stringliteral">&#39;probs&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[-1.0, 0.0], [-1.0, 1.1]])</div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;        }</div><div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;    ]),</div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;    Example(TransformedDistribution, [</div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;        {</div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(0, 1),</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;            <span class="stringliteral">&#39;transforms&#39;</span>: <span class="keyword">lambda</span> x: x,</div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;        },</div><div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;        {</div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;            <span class="stringliteral">&#39;base_distribution&#39;</span>: Normal(0, 1),</div><div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;            <span class="stringliteral">&#39;transforms&#39;</span>: [<span class="keyword">lambda</span> x: x],</div><div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;        },</div><div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;    ]),</div><div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;    Example(Uniform, [</div><div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;        {</div><div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;            <span class="stringliteral">&#39;low&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;            <span class="stringliteral">&#39;high&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;        },</div><div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;        {</div><div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;            <span class="stringliteral">&#39;low&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;            <span class="stringliteral">&#39;high&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;        },</div><div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;        {</div><div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;            <span class="stringliteral">&#39;low&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;            <span class="stringliteral">&#39;high&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;        }</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;    ]),</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;    Example(Weibull, [</div><div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;        {</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;            <span class="stringliteral">&#39;concentration&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;        },</div><div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;        {</div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;            <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0], requires_grad=<span class="keyword">True</span>),</div><div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;            <span class="stringliteral">&#39;concentration&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-1.0], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;        }</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;    ])</div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;]</div><div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;</div><div class="line"><a name="l00652"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_distributions.html">  652</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_distributions.html">TestDistributions</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;    _do_cuda_memory_leak_check = <span class="keyword">True</span></div><div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;</div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;    <span class="keyword">def </span>_gradcheck_log_prob(self, dist_ctor, ctor_params):</div><div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;        <span class="comment"># performs gradient checks on log_prob</span></div><div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;        distribution = dist_ctor(*ctor_params)</div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;        s = distribution.sample()</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;        <span class="keywordflow">if</span> s.is_floating_point():</div><div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;            s = s.detach().requires_grad_()</div><div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;</div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;        expected_shape = distribution.batch_shape + distribution.event_shape</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(s.size(), expected_shape)</div><div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;</div><div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;        <span class="keyword">def </span>apply_fn(s, *params):</div><div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;            <span class="keywordflow">return</span> dist_ctor(*params).log_prob(s)</div><div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;</div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;        gradcheck(apply_fn, (s,) + tuple(ctor_params), raise_exception=<span class="keyword">True</span>)</div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;    <span class="keyword">def </span>_check_log_prob(self, dist, asset_fn):</div><div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;        <span class="comment"># checks that the log_prob matches a reference function</span></div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;        s = dist.sample()</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;        log_probs = dist.log_prob(s)</div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;        log_probs_data_flat = log_probs.view(-1)</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;        s_data_flat = s.view(len(log_probs_data_flat), -1)</div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;        <span class="keywordflow">for</span> i, (val, log_prob) <span class="keywordflow">in</span> enumerate(zip(s_data_flat, log_probs_data_flat)):</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;            asset_fn(i, val.squeeze(), log_prob)</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;    <span class="keyword">def </span>_check_sampler_sampler(self, torch_dist, ref_dist, message, multivariate=False,</div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;                               num_samples=10000, failure_rate=1e-3):</div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;        <span class="comment"># Checks that the .sample() method matches a reference function.</span></div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;        torch_samples = torch_dist.sample((num_samples,)).squeeze()</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;        torch_samples = torch_samples.cpu().numpy()</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;        ref_samples = ref_dist.rvs(num_samples).astype(np.float64)</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;        <span class="keywordflow">if</span> multivariate:</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;            <span class="comment"># Project onto a random axis.</span></div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;            axis = np.random.normal(size=torch_samples.shape[-1])</div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;            axis /= np.linalg.norm(axis)</div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;            torch_samples = np.dot(torch_samples, axis)</div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;            ref_samples = np.dot(ref_samples, axis)</div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;        samples = [(x, +1) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> torch_samples] + [(x, -1) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> ref_samples]</div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;        shuffle(samples)  <span class="comment"># necessary to prevent stable sort from making uneven bins for discrete</span></div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;        samples.sort(key=<span class="keyword">lambda</span> x: x[0])</div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;        samples = np.array(samples)[:, 1]</div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;        <span class="comment"># Aggregate into bins filled with roughly zero-mean unit-variance RVs.</span></div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;        num_bins = 10</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;        samples_per_bin = len(samples) // num_bins</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;        bins = samples.reshape((num_bins, samples_per_bin)).mean(axis=1)</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;        stddev = samples_per_bin ** -0.5</div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;        threshold = stddev * scipy.special.erfinv(1 - 2 * failure_rate / num_bins)</div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;        message = <span class="stringliteral">&#39;{}.sample() is biased:\n{}&#39;</span>.format(message, bins)</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;        <span class="keywordflow">for</span> bias <span class="keywordflow">in</span> bins:</div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;            self.assertLess(-threshold, bias, message)</div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;            self.assertLess(bias, threshold, message)</div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;</div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;    <span class="keyword">def </span>_check_sampler_discrete(self, torch_dist, ref_dist, message,</div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;                                num_samples=10000, failure_rate=1e-3):</div><div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;        <span class="stringliteral">&quot;&quot;&quot;Runs a Chi2-test for the support, but ignores tail instead of combining&quot;&quot;&quot;</span></div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;        torch_samples = torch_dist.sample((num_samples,)).squeeze()</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;        torch_samples = torch_samples.cpu().numpy()</div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;        unique, counts = np.unique(torch_samples, return_counts=<span class="keyword">True</span>)</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;        pmf = ref_dist.pmf(unique)</div><div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;        msk = (counts &gt; 5) &amp; ((pmf * num_samples) &gt; 5)</div><div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;        self.assertGreater(pmf[msk].sum(), 0.9, <span class="stringliteral">&quot;Distribution is too sparse for test; try increasing num_samples&quot;</span>)</div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;        chisq, p = scipy.stats.chisquare(counts[msk], pmf[msk] * num_samples)</div><div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;        self.assertGreater(p, failure_rate, message)</div><div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;</div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;    <span class="keyword">def </span>_check_enumerate_support(self, dist, examples):</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;        <span class="keywordflow">for</span> params, expected <span class="keywordflow">in</span> examples:</div><div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;            params = {k: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(v) <span class="keywordflow">for</span> k, v <span class="keywordflow">in</span> params.items()}</div><div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;            expected = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(expected)</div><div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;            d = dist(**params)</div><div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;            actual = d.enumerate_support(expand=<span class="keyword">False</span>)</div><div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual, expected)</div><div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;            actual = d.enumerate_support(expand=<span class="keyword">True</span>)</div><div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;            expected_with_expand = expected.expand((-1,) + d.batch_shape + d.event_shape)</div><div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual, expected_with_expand)</div><div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;</div><div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;    <span class="keyword">def </span>test_repr(self):</div><div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;            <span class="keywordflow">for</span> param <span class="keywordflow">in</span> params:</div><div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;                self.assertTrue(repr(dist).startswith(dist.__class__.__name__))</div><div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;</div><div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;    <span class="keyword">def </span>test_sample_detached(self):</div><div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l00740"></a><span class="lineno">  740</span>&#160;                variable_params = [p <span class="keywordflow">for</span> p <span class="keywordflow">in</span> param.values() <span class="keywordflow">if</span> getattr(p, <span class="stringliteral">&#39;requires_grad&#39;</span>, <span class="keyword">False</span>)]</div><div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;                <span class="keywordflow">if</span> <span class="keywordflow">not</span> variable_params:</div><div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;                sample = dist.sample()</div><div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;                self.assertFalse(sample.requires_grad,</div><div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;                                 msg=<span class="stringliteral">&#39;{} example {}/{}, .sample() is not detached&#39;</span>.format(</div><div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;                                     Dist.__name__, i + 1, len(params)))</div><div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;</div><div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;    <span class="keyword">def </span>test_rsample_requires_grad(self):</div><div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;                <span class="keywordflow">if</span> <span class="keywordflow">not</span> any(getattr(p, <span class="stringliteral">&#39;requires_grad&#39;</span>, <span class="keyword">False</span>) <span class="keywordflow">for</span> p <span class="keywordflow">in</span> param.values()):</div><div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;                <span class="keywordflow">if</span> <span class="keywordflow">not</span> dist.has_rsample:</div><div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;                sample = dist.rsample()</div><div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;                self.assertTrue(sample.requires_grad,</div><div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;                                msg=<span class="stringliteral">&#39;{} example {}/{}, .rsample() does not require grad&#39;</span>.format(</div><div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;                                    Dist.__name__, i + 1, len(params)))</div><div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;</div><div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;    <span class="keyword">def </span>test_enumerate_support_type(self):</div><div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;                    self.assertTrue(type(dist.sample()) <span class="keywordflow">is</span> type(dist.enumerate_support()),</div><div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;                                    msg=(<span class="stringliteral">&#39;{} example {}/{}, return type mismatch between &#39;</span> +</div><div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;                                         <span class="stringliteral">&#39;sample and enumerate_support.&#39;</span>).format(Dist.__name__, i + 1, len(params)))</div><div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;                    <span class="keywordflow">pass</span></div><div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;</div><div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;    <span class="keyword">def </span>test_lazy_property_grad(self):</div><div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;        x = torch.randn(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;</div><div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;        <span class="keyword">class </span>Dummy(object):</div><div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;            @lazy_property</div><div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;            <span class="keyword">def </span>y(self):</div><div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160;                <span class="keywordflow">return</span> x + 1</div><div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;</div><div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;        <span class="keyword">def </span><a class="code" href="namespacetest.html">test</a>():</div><div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;            x.grad = <span class="keywordtype">None</span></div><div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160;            Dummy().y.backward()</div><div class="line"><a name="l00784"></a><span class="lineno">  784</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(x.grad, torch.ones(1))</div><div class="line"><a name="l00785"></a><span class="lineno">  785</span>&#160;</div><div class="line"><a name="l00786"></a><span class="lineno">  786</span>&#160;        <a class="code" href="namespacetest.html">test</a>()</div><div class="line"><a name="l00787"></a><span class="lineno">  787</span>&#160;        with torch.no_grad():</div><div class="line"><a name="l00788"></a><span class="lineno">  788</span>&#160;            <a class="code" href="namespacetest.html">test</a>()</div><div class="line"><a name="l00789"></a><span class="lineno">  789</span>&#160;</div><div class="line"><a name="l00790"></a><span class="lineno">  790</span>&#160;        mean = torch.randn(2)</div><div class="line"><a name="l00791"></a><span class="lineno">  791</span>&#160;        cov = torch.eye(2, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00792"></a><span class="lineno">  792</span>&#160;        distn = MultivariateNormal(mean, cov)</div><div class="line"><a name="l00793"></a><span class="lineno">  793</span>&#160;        with torch.no_grad():</div><div class="line"><a name="l00794"></a><span class="lineno">  794</span>&#160;            distn.scale_tril</div><div class="line"><a name="l00795"></a><span class="lineno">  795</span>&#160;        distn.scale_tril.sum().backward()</div><div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;        self.assertIsNotNone(cov.grad)</div><div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;</div><div class="line"><a name="l00798"></a><span class="lineno">  798</span>&#160;    <span class="keyword">def </span>test_has_examples(self):</div><div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;        distributions_with_examples = {e.Dist <span class="keywordflow">for</span> e <span class="keywordflow">in</span> EXAMPLES}</div><div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;        <span class="keywordflow">for</span> Dist <span class="keywordflow">in</span> globals().values():</div><div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;            <span class="keywordflow">if</span> isinstance(Dist, type) <span class="keywordflow">and</span> issubclass(Dist, Distribution) \</div><div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;                    <span class="keywordflow">and</span> Dist <span class="keywordflow">is</span> <span class="keywordflow">not</span> Distribution <span class="keywordflow">and</span> Dist <span class="keywordflow">is</span> <span class="keywordflow">not</span> ExponentialFamily:</div><div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;                self.assertIn(Dist, distributions_with_examples,</div><div class="line"><a name="l00804"></a><span class="lineno">  804</span>&#160;                              <span class="stringliteral">&quot;Please add {} to the EXAMPLES list in test_distributions.py&quot;</span>.format(Dist.__name__))</div><div class="line"><a name="l00805"></a><span class="lineno">  805</span>&#160;</div><div class="line"><a name="l00806"></a><span class="lineno">  806</span>&#160;    <span class="keyword">def </span>test_distribution_expand(self):</div><div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;        shapes = [torch.Size(), torch.Size((2,)), torch.Size((2, 1))]</div><div class="line"><a name="l00808"></a><span class="lineno">  808</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;            <span class="keywordflow">for</span> param <span class="keywordflow">in</span> params:</div><div class="line"><a name="l00810"></a><span class="lineno">  810</span>&#160;                <span class="keywordflow">for</span> shape <span class="keywordflow">in</span> shapes:</div><div class="line"><a name="l00811"></a><span class="lineno">  811</span>&#160;                    d = Dist(**param)</div><div class="line"><a name="l00812"></a><span class="lineno">  812</span>&#160;                    expanded_shape = shape + d.batch_shape</div><div class="line"><a name="l00813"></a><span class="lineno">  813</span>&#160;                    original_shape = d.batch_shape + d.event_shape</div><div class="line"><a name="l00814"></a><span class="lineno">  814</span>&#160;                    expected_shape = shape + original_shape</div><div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;                    expanded = d.expand(batch_shape=list(expanded_shape))</div><div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;                    sample = expanded.sample()</div><div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;                    actual_shape = expanded.sample().shape</div><div class="line"><a name="l00818"></a><span class="lineno">  818</span>&#160;                    self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expanded.__class__, d.__class__)</div><div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;                    self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(d.sample().shape, original_shape)</div><div class="line"><a name="l00820"></a><span class="lineno">  820</span>&#160;                    self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expanded.log_prob(sample), d.log_prob(sample))</div><div class="line"><a name="l00821"></a><span class="lineno">  821</span>&#160;                    self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual_shape, expected_shape)</div><div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;                    self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expanded.batch_shape, expanded_shape)</div><div class="line"><a name="l00823"></a><span class="lineno">  823</span>&#160;                    <span class="keywordflow">try</span>:</div><div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;                        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expanded.mean,</div><div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;                                         d.mean.expand(expanded_shape + d.event_shape),</div><div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;                                         allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l00827"></a><span class="lineno">  827</span>&#160;                        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expanded.variance,</div><div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;                                         d.variance.expand(expanded_shape + d.event_shape),</div><div class="line"><a name="l00829"></a><span class="lineno">  829</span>&#160;                                         allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l00830"></a><span class="lineno">  830</span>&#160;                    <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l00831"></a><span class="lineno">  831</span>&#160;                        <span class="keywordflow">pass</span></div><div class="line"><a name="l00832"></a><span class="lineno">  832</span>&#160;</div><div class="line"><a name="l00833"></a><span class="lineno">  833</span>&#160;    <span class="keyword">def </span>test_distribution_subclass_expand(self):</div><div class="line"><a name="l00834"></a><span class="lineno">  834</span>&#160;        expand_by = torch.Size((2,))</div><div class="line"><a name="l00835"></a><span class="lineno">  835</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l00836"></a><span class="lineno">  836</span>&#160;</div><div class="line"><a name="l00837"></a><span class="lineno">  837</span>&#160;            <span class="keyword">class </span>SubClass(Dist):</div><div class="line"><a name="l00838"></a><span class="lineno">  838</span>&#160;                <span class="keywordflow">pass</span></div><div class="line"><a name="l00839"></a><span class="lineno">  839</span>&#160;</div><div class="line"><a name="l00840"></a><span class="lineno">  840</span>&#160;            <span class="keywordflow">for</span> param <span class="keywordflow">in</span> params:</div><div class="line"><a name="l00841"></a><span class="lineno">  841</span>&#160;                d = SubClass(**param)</div><div class="line"><a name="l00842"></a><span class="lineno">  842</span>&#160;                expanded_shape = expand_by + d.batch_shape</div><div class="line"><a name="l00843"></a><span class="lineno">  843</span>&#160;                original_shape = d.batch_shape + d.event_shape</div><div class="line"><a name="l00844"></a><span class="lineno">  844</span>&#160;                expected_shape = expand_by + original_shape</div><div class="line"><a name="l00845"></a><span class="lineno">  845</span>&#160;                expanded = d.expand(batch_shape=expanded_shape)</div><div class="line"><a name="l00846"></a><span class="lineno">  846</span>&#160;                sample = expanded.sample()</div><div class="line"><a name="l00847"></a><span class="lineno">  847</span>&#160;                actual_shape = expanded.sample().shape</div><div class="line"><a name="l00848"></a><span class="lineno">  848</span>&#160;                self.assertEqual(expanded.__class__, d.__class__)</div><div class="line"><a name="l00849"></a><span class="lineno">  849</span>&#160;                self.assertEqual(d.sample().shape, original_shape)</div><div class="line"><a name="l00850"></a><span class="lineno">  850</span>&#160;                self.assertEqual(expanded.log_prob(sample), d.log_prob(sample))</div><div class="line"><a name="l00851"></a><span class="lineno">  851</span>&#160;                self.assertEqual(actual_shape, expected_shape)</div><div class="line"><a name="l00852"></a><span class="lineno">  852</span>&#160;</div><div class="line"><a name="l00853"></a><span class="lineno">  853</span>&#160;    <span class="keyword">def </span>test_bernoulli(self):</div><div class="line"><a name="l00854"></a><span class="lineno">  854</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00855"></a><span class="lineno">  855</span>&#160;        r = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00856"></a><span class="lineno">  856</span>&#160;        s = 0.3</div><div class="line"><a name="l00857"></a><span class="lineno">  857</span>&#160;        self.assertEqual(Bernoulli(p).sample((8,)).size(), (8, 3))</div><div class="line"><a name="l00858"></a><span class="lineno">  858</span>&#160;        self.assertFalse(Bernoulli(p).sample().requires_grad)</div><div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;        self.assertEqual(Bernoulli(r).sample((8,)).size(), (8,))</div><div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;        self.assertEqual(Bernoulli(r).sample().size(), ())</div><div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160;        self.assertEqual(Bernoulli(r).sample((3, 2)).size(), (3, 2,))</div><div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;        self.assertEqual(Bernoulli(s).sample().size(), ())</div><div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;        self._gradcheck_log_prob(Bernoulli, (p,))</div><div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160;</div><div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, val, log_prob):</div><div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;            prob = p[idx]</div><div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;            self.assertEqual(log_prob, math.log(prob <span class="keywordflow">if</span> val <span class="keywordflow">else</span> 1 - prob))</div><div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;</div><div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;        self._check_log_prob(Bernoulli(p), ref_log_prob)</div><div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;        self._check_log_prob(Bernoulli(logits=p.log() - (-p).log1p()), ref_log_prob)</div><div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;        self.assertRaises(NotImplementedError, Bernoulli(r).rsample)</div><div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;</div><div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;        <span class="comment"># check entropy computation</span></div><div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;        self.assertEqual(Bernoulli(p).entropy(), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.6108, 0.5004, 0.6730]), prec=1e-4)</div><div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;        self.assertEqual(Bernoulli(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0])).entropy(), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0]))</div><div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;        self.assertEqual(Bernoulli(s).entropy(), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.6108), prec=1e-4)</div><div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;</div><div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160;    <span class="keyword">def </span>test_bernoulli_enumerate_support(self):</div><div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;        examples = [</div><div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [0.1]}, [[0], [1]]),</div><div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [0.1, 0.9]}, [[0], [1]]),</div><div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [[0.1, 0.2], [0.3, 0.4]]}, [[[0]], [[1]]]),</div><div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;        ]</div><div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160;        self._check_enumerate_support(Bernoulli, examples)</div><div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160;</div><div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;    <span class="keyword">def </span>test_bernoulli_3d(self):</div><div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;        p = torch.full((2, 3, 5), 0.5).requires_grad_()</div><div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;        self.assertEqual(Bernoulli(p).sample().size(), (2, 3, 5))</div><div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;        self.assertEqual(Bernoulli(p).sample(sample_shape=(2, 5)).size(),</div><div class="line"><a name="l00890"></a><span class="lineno">  890</span>&#160;                         (2, 5, 2, 3, 5))</div><div class="line"><a name="l00891"></a><span class="lineno">  891</span>&#160;        self.assertEqual(Bernoulli(p).sample((2,)).size(), (2, 2, 3, 5))</div><div class="line"><a name="l00892"></a><span class="lineno">  892</span>&#160;</div><div class="line"><a name="l00893"></a><span class="lineno">  893</span>&#160;    <span class="keyword">def </span>test_geometric(self):</div><div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160;        r = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;        s = 0.3</div><div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;        self.assertEqual(Geometric(p).sample((8,)).size(), (8, 3))</div><div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160;        self.assertEqual(Geometric(1).sample(), 0)</div><div class="line"><a name="l00899"></a><span class="lineno">  899</span>&#160;        self.assertEqual(Geometric(1).log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(1.)), -inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l00900"></a><span class="lineno">  900</span>&#160;        self.assertEqual(Geometric(1).log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.)), 0)</div><div class="line"><a name="l00901"></a><span class="lineno">  901</span>&#160;        self.assertFalse(Geometric(p).sample().requires_grad)</div><div class="line"><a name="l00902"></a><span class="lineno">  902</span>&#160;        self.assertEqual(Geometric(r).sample((8,)).size(), (8,))</div><div class="line"><a name="l00903"></a><span class="lineno">  903</span>&#160;        self.assertEqual(Geometric(r).sample().size(), ())</div><div class="line"><a name="l00904"></a><span class="lineno">  904</span>&#160;        self.assertEqual(Geometric(r).sample((3, 2)).size(), (3, 2))</div><div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160;        self.assertEqual(Geometric(s).sample().size(), ())</div><div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;        self._gradcheck_log_prob(Geometric, (p,))</div><div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;        self.assertRaises(ValueError, <span class="keyword">lambda</span>: Geometric(0))</div><div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;        self.assertRaises(NotImplementedError, Geometric(r).rsample)</div><div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;</div><div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l00911"></a><span class="lineno">  911</span>&#160;    <span class="keyword">def </span>test_geometric_log_prob_and_entropy(self):</div><div class="line"><a name="l00912"></a><span class="lineno">  912</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;        s = 0.3</div><div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;</div><div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, val, log_prob):</div><div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;            prob = p[idx].detach()</div><div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160;            self.assertEqual(log_prob, scipy.stats.geom(prob, loc=-1).logpmf(val))</div><div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;</div><div class="line"><a name="l00919"></a><span class="lineno">  919</span>&#160;        self._check_log_prob(Geometric(p), ref_log_prob)</div><div class="line"><a name="l00920"></a><span class="lineno">  920</span>&#160;        self._check_log_prob(Geometric(logits=p.log() - (-p).log1p()), ref_log_prob)</div><div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160;</div><div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;        <span class="comment"># check entropy computation</span></div><div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160;        self.assertEqual(Geometric(p).entropy(), scipy.stats.geom(p.detach().numpy(), loc=-1).entropy(), prec=1e-3)</div><div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;        self.assertEqual(float(Geometric(s).entropy()), scipy.stats.geom(s, loc=-1).entropy().item(), prec=1e-3)</div><div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;</div><div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160;    <span class="keyword">def </span>test_geometric_sample(self):</div><div class="line"><a name="l00928"></a><span class="lineno">  928</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l00929"></a><span class="lineno">  929</span>&#160;        <span class="keywordflow">for</span> prob <span class="keywordflow">in</span> [0.01, 0.18, 0.8]:</div><div class="line"><a name="l00930"></a><span class="lineno">  930</span>&#160;            self._check_sampler_discrete(Geometric(prob),</div><div class="line"><a name="l00931"></a><span class="lineno">  931</span>&#160;                                         scipy.stats.geom(p=prob, loc=-1),</div><div class="line"><a name="l00932"></a><span class="lineno">  932</span>&#160;                                         <span class="stringliteral">&#39;Geometric(prob={})&#39;</span>.format(prob))</div><div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;</div><div class="line"><a name="l00934"></a><span class="lineno">  934</span>&#160;    <span class="keyword">def </span>test_binomial(self):</div><div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;        p = torch.arange(0.05, 1, 0.1).requires_grad_()</div><div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;        <span class="keywordflow">for</span> total_count <span class="keywordflow">in</span> [1, 2, 10]:</div><div class="line"><a name="l00937"></a><span class="lineno">  937</span>&#160;            self._gradcheck_log_prob(<span class="keyword">lambda</span> p: Binomial(total_count, p), [p])</div><div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;            self._gradcheck_log_prob(<span class="keyword">lambda</span> p: Binomial(total_count, <span class="keywordtype">None</span>, p.log()), [p])</div><div class="line"><a name="l00939"></a><span class="lineno">  939</span>&#160;        self.assertRaises(NotImplementedError, Binomial(10, p).rsample)</div><div class="line"><a name="l00940"></a><span class="lineno">  940</span>&#160;        self.assertRaises(NotImplementedError, Binomial(10, p).entropy)</div><div class="line"><a name="l00941"></a><span class="lineno">  941</span>&#160;</div><div class="line"><a name="l00942"></a><span class="lineno">  942</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l00943"></a><span class="lineno">  943</span>&#160;    <span class="keyword">def </span>test_binomial_log_prob(self):</div><div class="line"><a name="l00944"></a><span class="lineno">  944</span>&#160;        probs = torch.arange(0.05, 1, 0.1)</div><div class="line"><a name="l00945"></a><span class="lineno">  945</span>&#160;        <span class="keywordflow">for</span> total_count <span class="keywordflow">in</span> [1, 2, 10]:</div><div class="line"><a name="l00946"></a><span class="lineno">  946</span>&#160;</div><div class="line"><a name="l00947"></a><span class="lineno">  947</span>&#160;            <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l00948"></a><span class="lineno">  948</span>&#160;                p = probs.view(-1)[idx].item()</div><div class="line"><a name="l00949"></a><span class="lineno">  949</span>&#160;                expected = scipy.stats.binom(total_count, p).logpmf(x)</div><div class="line"><a name="l00950"></a><span class="lineno">  950</span>&#160;                self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l00951"></a><span class="lineno">  951</span>&#160;</div><div class="line"><a name="l00952"></a><span class="lineno">  952</span>&#160;            self._check_log_prob(Binomial(total_count, probs), ref_log_prob)</div><div class="line"><a name="l00953"></a><span class="lineno">  953</span>&#160;            logits = probs_to_logits(probs, is_binary=<span class="keyword">True</span>)</div><div class="line"><a name="l00954"></a><span class="lineno">  954</span>&#160;            self._check_log_prob(Binomial(total_count, logits=logits), ref_log_prob)</div><div class="line"><a name="l00955"></a><span class="lineno">  955</span>&#160;</div><div class="line"><a name="l00956"></a><span class="lineno">  956</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l00957"></a><span class="lineno">  957</span>&#160;    <span class="keyword">def </span>test_binomial_log_prob_vectorized_count(self):</div><div class="line"><a name="l00958"></a><span class="lineno">  958</span>&#160;        probs = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.2, 0.7, 0.9])</div><div class="line"><a name="l00959"></a><span class="lineno">  959</span>&#160;        <span class="keywordflow">for</span> total_count, sample <span class="keywordflow">in</span> [(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([10]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([7., 3., 9.])),</div><div class="line"><a name="l00960"></a><span class="lineno">  960</span>&#160;                                    (<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 2, 10]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1., 9.]))]:</div><div class="line"><a name="l00961"></a><span class="lineno">  961</span>&#160;            log_prob = Binomial(total_count, probs).log_prob(sample)</div><div class="line"><a name="l00962"></a><span class="lineno">  962</span>&#160;            expected = scipy.stats.binom(total_count.cpu().numpy(), probs.cpu().numpy()).logpmf(sample)</div><div class="line"><a name="l00963"></a><span class="lineno">  963</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=4)</div><div class="line"><a name="l00964"></a><span class="lineno">  964</span>&#160;</div><div class="line"><a name="l00965"></a><span class="lineno">  965</span>&#160;    <span class="keyword">def </span>test_binomial_enumerate_support(self):</div><div class="line"><a name="l00966"></a><span class="lineno">  966</span>&#160;        examples = [</div><div class="line"><a name="l00967"></a><span class="lineno">  967</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [0.1], <span class="stringliteral">&quot;total_count&quot;</span>: 2}, [[0], [1], [2]]),</div><div class="line"><a name="l00968"></a><span class="lineno">  968</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [0.1, 0.9], <span class="stringliteral">&quot;total_count&quot;</span>: 2}, [[0], [1], [2]]),</div><div class="line"><a name="l00969"></a><span class="lineno">  969</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [[0.1, 0.2], [0.3, 0.4]], <span class="stringliteral">&quot;total_count&quot;</span>: 3}, [[[0]], [[1]], [[2]], [[3]]]),</div><div class="line"><a name="l00970"></a><span class="lineno">  970</span>&#160;        ]</div><div class="line"><a name="l00971"></a><span class="lineno">  971</span>&#160;        self._check_enumerate_support(Binomial, examples)</div><div class="line"><a name="l00972"></a><span class="lineno">  972</span>&#160;</div><div class="line"><a name="l00973"></a><span class="lineno">  973</span>&#160;    <span class="keyword">def </span>test_binomial_extreme_vals(self):</div><div class="line"><a name="l00974"></a><span class="lineno">  974</span>&#160;        total_count = 100</div><div class="line"><a name="l00975"></a><span class="lineno">  975</span>&#160;        bin0 = Binomial(total_count, 0)</div><div class="line"><a name="l00976"></a><span class="lineno">  976</span>&#160;        self.assertEqual(bin0.sample(), 0)</div><div class="line"><a name="l00977"></a><span class="lineno">  977</span>&#160;        self.assertAlmostEqual(bin0.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.]))[0], 0, places=3)</div><div class="line"><a name="l00978"></a><span class="lineno">  978</span>&#160;        self.assertEqual(float(bin0.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.])).exp()), 0, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l00979"></a><span class="lineno">  979</span>&#160;        bin1 = Binomial(total_count, 1)</div><div class="line"><a name="l00980"></a><span class="lineno">  980</span>&#160;        self.assertEqual(bin1.sample(), total_count)</div><div class="line"><a name="l00981"></a><span class="lineno">  981</span>&#160;        self.assertAlmostEqual(bin1.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([float(total_count)]))[0], 0, places=3)</div><div class="line"><a name="l00982"></a><span class="lineno">  982</span>&#160;        self.assertEqual(float(bin1.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([float(total_count - 1)])).exp()), 0, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l00983"></a><span class="lineno">  983</span>&#160;        zero_counts = torch.zeros(torch.Size((2, 2)))</div><div class="line"><a name="l00984"></a><span class="lineno">  984</span>&#160;        bin2 = Binomial(zero_counts, 1)</div><div class="line"><a name="l00985"></a><span class="lineno">  985</span>&#160;        self.assertEqual(bin2.sample(), zero_counts)</div><div class="line"><a name="l00986"></a><span class="lineno">  986</span>&#160;        self.assertEqual(bin2.log_prob(zero_counts), zero_counts)</div><div class="line"><a name="l00987"></a><span class="lineno">  987</span>&#160;</div><div class="line"><a name="l00988"></a><span class="lineno">  988</span>&#160;    <span class="keyword">def </span>test_binomial_vectorized_count(self):</div><div class="line"><a name="l00989"></a><span class="lineno">  989</span>&#160;        set_rng_seed(0)</div><div class="line"><a name="l00990"></a><span class="lineno">  990</span>&#160;        total_count = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[4, 7], [3, 8]])</div><div class="line"><a name="l00991"></a><span class="lineno">  991</span>&#160;        bin0 = Binomial(total_count, <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(1.))</div><div class="line"><a name="l00992"></a><span class="lineno">  992</span>&#160;        self.assertEqual(bin0.sample(), total_count)</div><div class="line"><a name="l00993"></a><span class="lineno">  993</span>&#160;        bin1 = Binomial(total_count, <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.5))</div><div class="line"><a name="l00994"></a><span class="lineno">  994</span>&#160;        samples = bin1.sample(torch.Size((100000,)))</div><div class="line"><a name="l00995"></a><span class="lineno">  995</span>&#160;        self.assertTrue((samples &lt;= total_count.type_as(samples)).all())</div><div class="line"><a name="l00996"></a><span class="lineno">  996</span>&#160;        self.assertEqual(samples.mean(dim=0), bin1.mean, prec=0.02)</div><div class="line"><a name="l00997"></a><span class="lineno">  997</span>&#160;        self.assertEqual(samples.var(dim=0), bin1.variance, prec=0.02)</div><div class="line"><a name="l00998"></a><span class="lineno">  998</span>&#160;</div><div class="line"><a name="l00999"></a><span class="lineno">  999</span>&#160;    <span class="keyword">def </span>test_negative_binomial(self):</div><div class="line"><a name="l01000"></a><span class="lineno"> 1000</span>&#160;        p = torch.arange(0.05, 1, 0.1).requires_grad_()</div><div class="line"><a name="l01001"></a><span class="lineno"> 1001</span>&#160;        <span class="keywordflow">for</span> total_count <span class="keywordflow">in</span> [1, 2, 10]:</div><div class="line"><a name="l01002"></a><span class="lineno"> 1002</span>&#160;            self._gradcheck_log_prob(<span class="keyword">lambda</span> p: NegativeBinomial(total_count, p), [p])</div><div class="line"><a name="l01003"></a><span class="lineno"> 1003</span>&#160;            self._gradcheck_log_prob(<span class="keyword">lambda</span> p: NegativeBinomial(total_count, <span class="keywordtype">None</span>, p.log()), [p])</div><div class="line"><a name="l01004"></a><span class="lineno"> 1004</span>&#160;        self.assertRaises(NotImplementedError, NegativeBinomial(10, p).rsample)</div><div class="line"><a name="l01005"></a><span class="lineno"> 1005</span>&#160;        self.assertRaises(NotImplementedError, NegativeBinomial(10, p).entropy)</div><div class="line"><a name="l01006"></a><span class="lineno"> 1006</span>&#160;</div><div class="line"><a name="l01007"></a><span class="lineno"> 1007</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01008"></a><span class="lineno"> 1008</span>&#160;    <span class="keyword">def </span>test_negative_binomial_log_prob(self):</div><div class="line"><a name="l01009"></a><span class="lineno"> 1009</span>&#160;        probs = torch.arange(0.05, 1, 0.1)</div><div class="line"><a name="l01010"></a><span class="lineno"> 1010</span>&#160;        <span class="keywordflow">for</span> total_count <span class="keywordflow">in</span> [1, 2, 10]:</div><div class="line"><a name="l01011"></a><span class="lineno"> 1011</span>&#160;</div><div class="line"><a name="l01012"></a><span class="lineno"> 1012</span>&#160;            <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01013"></a><span class="lineno"> 1013</span>&#160;                p = probs.view(-1)[idx].item()</div><div class="line"><a name="l01014"></a><span class="lineno"> 1014</span>&#160;                expected = scipy.stats.nbinom(total_count, 1 - p).logpmf(x)</div><div class="line"><a name="l01015"></a><span class="lineno"> 1015</span>&#160;                self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01016"></a><span class="lineno"> 1016</span>&#160;</div><div class="line"><a name="l01017"></a><span class="lineno"> 1017</span>&#160;            self._check_log_prob(NegativeBinomial(total_count, probs), ref_log_prob)</div><div class="line"><a name="l01018"></a><span class="lineno"> 1018</span>&#160;            logits = probs_to_logits(probs, is_binary=<span class="keyword">True</span>)</div><div class="line"><a name="l01019"></a><span class="lineno"> 1019</span>&#160;            self._check_log_prob(NegativeBinomial(total_count, logits=logits), ref_log_prob)</div><div class="line"><a name="l01020"></a><span class="lineno"> 1020</span>&#160;</div><div class="line"><a name="l01021"></a><span class="lineno"> 1021</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01022"></a><span class="lineno"> 1022</span>&#160;    <span class="keyword">def </span>test_negative_binomial_log_prob_vectorized_count(self):</div><div class="line"><a name="l01023"></a><span class="lineno"> 1023</span>&#160;        probs = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.2, 0.7, 0.9])</div><div class="line"><a name="l01024"></a><span class="lineno"> 1024</span>&#160;        <span class="keywordflow">for</span> total_count, sample <span class="keywordflow">in</span> [(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([10]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([7., 3., 9.])),</div><div class="line"><a name="l01025"></a><span class="lineno"> 1025</span>&#160;                                    (<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 2, 10]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1., 9.]))]:</div><div class="line"><a name="l01026"></a><span class="lineno"> 1026</span>&#160;            log_prob = NegativeBinomial(total_count, probs).log_prob(sample)</div><div class="line"><a name="l01027"></a><span class="lineno"> 1027</span>&#160;            expected = scipy.stats.nbinom(total_count.cpu().numpy(), 1 - probs.cpu().numpy()).logpmf(sample)</div><div class="line"><a name="l01028"></a><span class="lineno"> 1028</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=4)</div><div class="line"><a name="l01029"></a><span class="lineno"> 1029</span>&#160;</div><div class="line"><a name="l01030"></a><span class="lineno"> 1030</span>&#160;    <span class="keyword">def </span>test_multinomial_1d(self):</div><div class="line"><a name="l01031"></a><span class="lineno"> 1031</span>&#160;        total_count = 10</div><div class="line"><a name="l01032"></a><span class="lineno"> 1032</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.1, 0.2, 0.3], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01033"></a><span class="lineno"> 1033</span>&#160;        self.assertEqual(Multinomial(total_count, p).sample().size(), (3,))</div><div class="line"><a name="l01034"></a><span class="lineno"> 1034</span>&#160;        self.assertEqual(Multinomial(total_count, p).sample((2, 2)).size(), (2, 2, 3))</div><div class="line"><a name="l01035"></a><span class="lineno"> 1035</span>&#160;        self.assertEqual(Multinomial(total_count, p).sample((1,)).size(), (1, 3))</div><div class="line"><a name="l01036"></a><span class="lineno"> 1036</span>&#160;        self._gradcheck_log_prob(<span class="keyword">lambda</span> p: Multinomial(total_count, p), [p])</div><div class="line"><a name="l01037"></a><span class="lineno"> 1037</span>&#160;        self._gradcheck_log_prob(<span class="keyword">lambda</span> p: Multinomial(total_count, <span class="keywordtype">None</span>, p.log()), [p])</div><div class="line"><a name="l01038"></a><span class="lineno"> 1038</span>&#160;        self.assertRaises(NotImplementedError, Multinomial(10, p).rsample)</div><div class="line"><a name="l01039"></a><span class="lineno"> 1039</span>&#160;</div><div class="line"><a name="l01040"></a><span class="lineno"> 1040</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01041"></a><span class="lineno"> 1041</span>&#160;    <span class="keyword">def </span>test_multinomial_1d_log_prob(self):</div><div class="line"><a name="l01042"></a><span class="lineno"> 1042</span>&#160;        total_count = 10</div><div class="line"><a name="l01043"></a><span class="lineno"> 1043</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.1, 0.2, 0.3], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01044"></a><span class="lineno"> 1044</span>&#160;        dist = Multinomial(total_count, probs=p)</div><div class="line"><a name="l01045"></a><span class="lineno"> 1045</span>&#160;        x = dist.sample()</div><div class="line"><a name="l01046"></a><span class="lineno"> 1046</span>&#160;        log_prob = dist.log_prob(x)</div><div class="line"><a name="l01047"></a><span class="lineno"> 1047</span>&#160;        expected = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(scipy.stats.multinomial.logpmf(x.numpy(), n=total_count, p=dist.probs.detach().numpy()))</div><div class="line"><a name="l01048"></a><span class="lineno"> 1048</span>&#160;        self.assertEqual(log_prob, expected)</div><div class="line"><a name="l01049"></a><span class="lineno"> 1049</span>&#160;</div><div class="line"><a name="l01050"></a><span class="lineno"> 1050</span>&#160;        dist = Multinomial(total_count, logits=p.log())</div><div class="line"><a name="l01051"></a><span class="lineno"> 1051</span>&#160;        x = dist.sample()</div><div class="line"><a name="l01052"></a><span class="lineno"> 1052</span>&#160;        log_prob = dist.log_prob(x)</div><div class="line"><a name="l01053"></a><span class="lineno"> 1053</span>&#160;        expected = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(scipy.stats.multinomial.logpmf(x.numpy(), n=total_count, p=dist.probs.detach().numpy()))</div><div class="line"><a name="l01054"></a><span class="lineno"> 1054</span>&#160;        self.assertEqual(log_prob, expected)</div><div class="line"><a name="l01055"></a><span class="lineno"> 1055</span>&#160;</div><div class="line"><a name="l01056"></a><span class="lineno"> 1056</span>&#160;    <span class="keyword">def </span>test_multinomial_2d(self):</div><div class="line"><a name="l01057"></a><span class="lineno"> 1057</span>&#160;        total_count = 10</div><div class="line"><a name="l01058"></a><span class="lineno"> 1058</span>&#160;        probabilities = [[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]]</div><div class="line"><a name="l01059"></a><span class="lineno"> 1059</span>&#160;        probabilities_1 = [[1.0, 0.0], [0.0, 1.0]]</div><div class="line"><a name="l01060"></a><span class="lineno"> 1060</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01061"></a><span class="lineno"> 1061</span>&#160;        s = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities_1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01062"></a><span class="lineno"> 1062</span>&#160;        self.assertEqual(Multinomial(total_count, p).sample().size(), (2, 3))</div><div class="line"><a name="l01063"></a><span class="lineno"> 1063</span>&#160;        self.assertEqual(Multinomial(total_count, p).sample(sample_shape=(3, 4)).size(), (3, 4, 2, 3))</div><div class="line"><a name="l01064"></a><span class="lineno"> 1064</span>&#160;        self.assertEqual(Multinomial(total_count, p).sample((6,)).size(), (6, 2, 3))</div><div class="line"><a name="l01065"></a><span class="lineno"> 1065</span>&#160;        set_rng_seed(0)</div><div class="line"><a name="l01066"></a><span class="lineno"> 1066</span>&#160;        self._gradcheck_log_prob(<span class="keyword">lambda</span> p: Multinomial(total_count, p), [p])</div><div class="line"><a name="l01067"></a><span class="lineno"> 1067</span>&#160;        self._gradcheck_log_prob(<span class="keyword">lambda</span> p: Multinomial(total_count, <span class="keywordtype">None</span>, p.log()), [p])</div><div class="line"><a name="l01068"></a><span class="lineno"> 1068</span>&#160;</div><div class="line"><a name="l01069"></a><span class="lineno"> 1069</span>&#160;        <span class="comment"># sample check for extreme value of probs</span></div><div class="line"><a name="l01070"></a><span class="lineno"> 1070</span>&#160;        self.assertEqual(Multinomial(total_count, s).sample(),</div><div class="line"><a name="l01071"></a><span class="lineno"> 1071</span>&#160;                         <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[total_count, 0], [0, total_count]]))</div><div class="line"><a name="l01072"></a><span class="lineno"> 1072</span>&#160;</div><div class="line"><a name="l01073"></a><span class="lineno"> 1073</span>&#160;        <span class="comment"># check entropy computation</span></div><div class="line"><a name="l01074"></a><span class="lineno"> 1074</span>&#160;        self.assertRaises(NotImplementedError, Multinomial(10, p).entropy)</div><div class="line"><a name="l01075"></a><span class="lineno"> 1075</span>&#160;</div><div class="line"><a name="l01076"></a><span class="lineno"> 1076</span>&#160;    <span class="keyword">def </span>test_categorical_1d(self):</div><div class="line"><a name="l01077"></a><span class="lineno"> 1077</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.1, 0.2, 0.3], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01078"></a><span class="lineno"> 1078</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(Categorical(p).mean))</div><div class="line"><a name="l01079"></a><span class="lineno"> 1079</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(Categorical(p).variance))</div><div class="line"><a name="l01080"></a><span class="lineno"> 1080</span>&#160;        self.assertEqual(Categorical(p).sample().size(), ())</div><div class="line"><a name="l01081"></a><span class="lineno"> 1081</span>&#160;        self.assertFalse(Categorical(p).sample().requires_grad)</div><div class="line"><a name="l01082"></a><span class="lineno"> 1082</span>&#160;        self.assertEqual(Categorical(p).sample((2, 2)).size(), (2, 2))</div><div class="line"><a name="l01083"></a><span class="lineno"> 1083</span>&#160;        self.assertEqual(Categorical(p).sample((1,)).size(), (1,))</div><div class="line"><a name="l01084"></a><span class="lineno"> 1084</span>&#160;        self._gradcheck_log_prob(Categorical, (p,))</div><div class="line"><a name="l01085"></a><span class="lineno"> 1085</span>&#160;        self.assertRaises(NotImplementedError, Categorical(p).rsample)</div><div class="line"><a name="l01086"></a><span class="lineno"> 1086</span>&#160;</div><div class="line"><a name="l01087"></a><span class="lineno"> 1087</span>&#160;    <span class="keyword">def </span>test_categorical_2d(self):</div><div class="line"><a name="l01088"></a><span class="lineno"> 1088</span>&#160;        probabilities = [[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]]</div><div class="line"><a name="l01089"></a><span class="lineno"> 1089</span>&#160;        probabilities_1 = [[1.0, 0.0], [0.0, 1.0]]</div><div class="line"><a name="l01090"></a><span class="lineno"> 1090</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01091"></a><span class="lineno"> 1091</span>&#160;        s = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities_1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01092"></a><span class="lineno"> 1092</span>&#160;        self.assertEqual(Categorical(p).mean.size(), (2,))</div><div class="line"><a name="l01093"></a><span class="lineno"> 1093</span>&#160;        self.assertEqual(Categorical(p).variance.size(), (2,))</div><div class="line"><a name="l01094"></a><span class="lineno"> 1094</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(Categorical(p).mean))</div><div class="line"><a name="l01095"></a><span class="lineno"> 1095</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(Categorical(p).variance))</div><div class="line"><a name="l01096"></a><span class="lineno"> 1096</span>&#160;        self.assertEqual(Categorical(p).sample().size(), (2,))</div><div class="line"><a name="l01097"></a><span class="lineno"> 1097</span>&#160;        self.assertEqual(Categorical(p).sample(sample_shape=(3, 4)).size(), (3, 4, 2))</div><div class="line"><a name="l01098"></a><span class="lineno"> 1098</span>&#160;        self.assertEqual(Categorical(p).sample((6,)).size(), (6, 2))</div><div class="line"><a name="l01099"></a><span class="lineno"> 1099</span>&#160;        self._gradcheck_log_prob(Categorical, (p,))</div><div class="line"><a name="l01100"></a><span class="lineno"> 1100</span>&#160;</div><div class="line"><a name="l01101"></a><span class="lineno"> 1101</span>&#160;        <span class="comment"># sample check for extreme value of probs</span></div><div class="line"><a name="l01102"></a><span class="lineno"> 1102</span>&#160;        set_rng_seed(0)</div><div class="line"><a name="l01103"></a><span class="lineno"> 1103</span>&#160;        self.assertEqual(Categorical(s).sample(sample_shape=(2,)),</div><div class="line"><a name="l01104"></a><span class="lineno"> 1104</span>&#160;                         <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0, 1], [0, 1]]))</div><div class="line"><a name="l01105"></a><span class="lineno"> 1105</span>&#160;</div><div class="line"><a name="l01106"></a><span class="lineno"> 1106</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, val, log_prob):</div><div class="line"><a name="l01107"></a><span class="lineno"> 1107</span>&#160;            sample_prob = p[idx][val] / p[idx].sum()</div><div class="line"><a name="l01108"></a><span class="lineno"> 1108</span>&#160;            self.assertEqual(log_prob, math.log(sample_prob))</div><div class="line"><a name="l01109"></a><span class="lineno"> 1109</span>&#160;</div><div class="line"><a name="l01110"></a><span class="lineno"> 1110</span>&#160;        self._check_log_prob(Categorical(p), ref_log_prob)</div><div class="line"><a name="l01111"></a><span class="lineno"> 1111</span>&#160;        self._check_log_prob(Categorical(logits=p.log()), ref_log_prob)</div><div class="line"><a name="l01112"></a><span class="lineno"> 1112</span>&#160;</div><div class="line"><a name="l01113"></a><span class="lineno"> 1113</span>&#160;        <span class="comment"># check entropy computation</span></div><div class="line"><a name="l01114"></a><span class="lineno"> 1114</span>&#160;        self.assertEqual(Categorical(p).entropy(), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0114, 1.0297]), prec=1e-4)</div><div class="line"><a name="l01115"></a><span class="lineno"> 1115</span>&#160;        self.assertEqual(Categorical(s).entropy(), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.0, 0.0]))</div><div class="line"><a name="l01116"></a><span class="lineno"> 1116</span>&#160;</div><div class="line"><a name="l01117"></a><span class="lineno"> 1117</span>&#160;    <span class="keyword">def </span>test_categorical_enumerate_support(self):</div><div class="line"><a name="l01118"></a><span class="lineno"> 1118</span>&#160;        examples = [</div><div class="line"><a name="l01119"></a><span class="lineno"> 1119</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [0.1, 0.2, 0.7]}, [0, 1, 2]),</div><div class="line"><a name="l01120"></a><span class="lineno"> 1120</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [[0.1, 0.9], [0.3, 0.7]]}, [[0], [1]]),</div><div class="line"><a name="l01121"></a><span class="lineno"> 1121</span>&#160;        ]</div><div class="line"><a name="l01122"></a><span class="lineno"> 1122</span>&#160;        self._check_enumerate_support(Categorical, examples)</div><div class="line"><a name="l01123"></a><span class="lineno"> 1123</span>&#160;</div><div class="line"><a name="l01124"></a><span class="lineno"> 1124</span>&#160;    <span class="keyword">def </span>test_one_hot_categorical_1d(self):</div><div class="line"><a name="l01125"></a><span class="lineno"> 1125</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.1, 0.2, 0.3], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01126"></a><span class="lineno"> 1126</span>&#160;        self.assertEqual(OneHotCategorical(p).sample().size(), (3,))</div><div class="line"><a name="l01127"></a><span class="lineno"> 1127</span>&#160;        self.assertFalse(OneHotCategorical(p).sample().requires_grad)</div><div class="line"><a name="l01128"></a><span class="lineno"> 1128</span>&#160;        self.assertEqual(OneHotCategorical(p).sample((2, 2)).size(), (2, 2, 3))</div><div class="line"><a name="l01129"></a><span class="lineno"> 1129</span>&#160;        self.assertEqual(OneHotCategorical(p).sample((1,)).size(), (1, 3))</div><div class="line"><a name="l01130"></a><span class="lineno"> 1130</span>&#160;        self._gradcheck_log_prob(OneHotCategorical, (p,))</div><div class="line"><a name="l01131"></a><span class="lineno"> 1131</span>&#160;        self.assertRaises(NotImplementedError, OneHotCategorical(p).rsample)</div><div class="line"><a name="l01132"></a><span class="lineno"> 1132</span>&#160;</div><div class="line"><a name="l01133"></a><span class="lineno"> 1133</span>&#160;    <span class="keyword">def </span>test_one_hot_categorical_2d(self):</div><div class="line"><a name="l01134"></a><span class="lineno"> 1134</span>&#160;        probabilities = [[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]]</div><div class="line"><a name="l01135"></a><span class="lineno"> 1135</span>&#160;        probabilities_1 = [[1.0, 0.0], [0.0, 1.0]]</div><div class="line"><a name="l01136"></a><span class="lineno"> 1136</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01137"></a><span class="lineno"> 1137</span>&#160;        s = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities_1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01138"></a><span class="lineno"> 1138</span>&#160;        self.assertEqual(OneHotCategorical(p).sample().size(), (2, 3))</div><div class="line"><a name="l01139"></a><span class="lineno"> 1139</span>&#160;        self.assertEqual(OneHotCategorical(p).sample(sample_shape=(3, 4)).size(), (3, 4, 2, 3))</div><div class="line"><a name="l01140"></a><span class="lineno"> 1140</span>&#160;        self.assertEqual(OneHotCategorical(p).sample((6,)).size(), (6, 2, 3))</div><div class="line"><a name="l01141"></a><span class="lineno"> 1141</span>&#160;        self._gradcheck_log_prob(OneHotCategorical, (p,))</div><div class="line"><a name="l01142"></a><span class="lineno"> 1142</span>&#160;</div><div class="line"><a name="l01143"></a><span class="lineno"> 1143</span>&#160;        dist = OneHotCategorical(p)</div><div class="line"><a name="l01144"></a><span class="lineno"> 1144</span>&#160;        x = dist.sample()</div><div class="line"><a name="l01145"></a><span class="lineno"> 1145</span>&#160;        self.assertEqual(dist.log_prob(x), Categorical(p).log_prob(x.max(-1)[1]))</div><div class="line"><a name="l01146"></a><span class="lineno"> 1146</span>&#160;</div><div class="line"><a name="l01147"></a><span class="lineno"> 1147</span>&#160;    <span class="keyword">def </span>test_one_hot_categorical_enumerate_support(self):</div><div class="line"><a name="l01148"></a><span class="lineno"> 1148</span>&#160;        examples = [</div><div class="line"><a name="l01149"></a><span class="lineno"> 1149</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [0.1, 0.2, 0.7]}, [[1, 0, 0], [0, 1, 0], [0, 0, 1]]),</div><div class="line"><a name="l01150"></a><span class="lineno"> 1150</span>&#160;            ({<span class="stringliteral">&quot;probs&quot;</span>: [[0.1, 0.9], [0.3, 0.7]]}, [[[1, 0]], [[0, 1]]]),</div><div class="line"><a name="l01151"></a><span class="lineno"> 1151</span>&#160;        ]</div><div class="line"><a name="l01152"></a><span class="lineno"> 1152</span>&#160;        self._check_enumerate_support(OneHotCategorical, examples)</div><div class="line"><a name="l01153"></a><span class="lineno"> 1153</span>&#160;</div><div class="line"><a name="l01154"></a><span class="lineno"> 1154</span>&#160;    <span class="keyword">def </span>test_poisson_shape(self):</div><div class="line"><a name="l01155"></a><span class="lineno"> 1155</span>&#160;        rate = torch.randn(2, 3).abs().requires_grad_()</div><div class="line"><a name="l01156"></a><span class="lineno"> 1156</span>&#160;        rate_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l01157"></a><span class="lineno"> 1157</span>&#160;        self.assertEqual(Poisson(rate).sample().size(), (2, 3))</div><div class="line"><a name="l01158"></a><span class="lineno"> 1158</span>&#160;        self.assertEqual(Poisson(rate).sample((7,)).size(), (7, 2, 3))</div><div class="line"><a name="l01159"></a><span class="lineno"> 1159</span>&#160;        self.assertEqual(Poisson(rate_1d).sample().size(), (1,))</div><div class="line"><a name="l01160"></a><span class="lineno"> 1160</span>&#160;        self.assertEqual(Poisson(rate_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01161"></a><span class="lineno"> 1161</span>&#160;        self.assertEqual(Poisson(2.0).sample((2,)).size(), (2,))</div><div class="line"><a name="l01162"></a><span class="lineno"> 1162</span>&#160;</div><div class="line"><a name="l01163"></a><span class="lineno"> 1163</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01164"></a><span class="lineno"> 1164</span>&#160;    <span class="keyword">def </span>test_poisson_log_prob(self):</div><div class="line"><a name="l01165"></a><span class="lineno"> 1165</span>&#160;        rate = torch.randn(2, 3).abs().requires_grad_()</div><div class="line"><a name="l01166"></a><span class="lineno"> 1166</span>&#160;        rate_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l01167"></a><span class="lineno"> 1167</span>&#160;</div><div class="line"><a name="l01168"></a><span class="lineno"> 1168</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01169"></a><span class="lineno"> 1169</span>&#160;            l = rate.view(-1)[idx].detach()</div><div class="line"><a name="l01170"></a><span class="lineno"> 1170</span>&#160;            expected = scipy.stats.poisson.logpmf(x, l)</div><div class="line"><a name="l01171"></a><span class="lineno"> 1171</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01172"></a><span class="lineno"> 1172</span>&#160;</div><div class="line"><a name="l01173"></a><span class="lineno"> 1173</span>&#160;        set_rng_seed(0)</div><div class="line"><a name="l01174"></a><span class="lineno"> 1174</span>&#160;        self._check_log_prob(Poisson(rate), ref_log_prob)</div><div class="line"><a name="l01175"></a><span class="lineno"> 1175</span>&#160;        self._gradcheck_log_prob(Poisson, (rate,))</div><div class="line"><a name="l01176"></a><span class="lineno"> 1176</span>&#160;        self._gradcheck_log_prob(Poisson, (rate_1d,))</div><div class="line"><a name="l01177"></a><span class="lineno"> 1177</span>&#160;</div><div class="line"><a name="l01178"></a><span class="lineno"> 1178</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01179"></a><span class="lineno"> 1179</span>&#160;    <span class="keyword">def </span>test_poisson_sample(self):</div><div class="line"><a name="l01180"></a><span class="lineno"> 1180</span>&#160;        set_rng_seed(1)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01181"></a><span class="lineno"> 1181</span>&#160;        <span class="keywordflow">for</span> rate <span class="keywordflow">in</span> [0.1, 1.0, 5.0]:</div><div class="line"><a name="l01182"></a><span class="lineno"> 1182</span>&#160;            self._check_sampler_discrete(Poisson(rate),</div><div class="line"><a name="l01183"></a><span class="lineno"> 1183</span>&#160;                                         scipy.stats.poisson(rate),</div><div class="line"><a name="l01184"></a><span class="lineno"> 1184</span>&#160;                                         <span class="stringliteral">&#39;Poisson(lambda={})&#39;</span>.format(rate),</div><div class="line"><a name="l01185"></a><span class="lineno"> 1185</span>&#160;                                         failure_rate=1e-3)</div><div class="line"><a name="l01186"></a><span class="lineno"> 1186</span>&#160;</div><div class="line"><a name="l01187"></a><span class="lineno"> 1187</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_CUDA, <span class="stringliteral">&quot;CUDA not found&quot;</span>)</div><div class="line"><a name="l01188"></a><span class="lineno"> 1188</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01189"></a><span class="lineno"> 1189</span>&#160;    <span class="keyword">def </span>test_poisson_gpu_sample(self):</div><div class="line"><a name="l01190"></a><span class="lineno"> 1190</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01191"></a><span class="lineno"> 1191</span>&#160;        <span class="keywordflow">for</span> rate <span class="keywordflow">in</span> [0.12, 0.9, 4.0]:</div><div class="line"><a name="l01192"></a><span class="lineno"> 1192</span>&#160;            self._check_sampler_discrete(Poisson(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([rate]).cuda()),</div><div class="line"><a name="l01193"></a><span class="lineno"> 1193</span>&#160;                                         scipy.stats.poisson(rate),</div><div class="line"><a name="l01194"></a><span class="lineno"> 1194</span>&#160;                                         <span class="stringliteral">&#39;Poisson(lambda={}, cuda)&#39;</span>.format(rate),</div><div class="line"><a name="l01195"></a><span class="lineno"> 1195</span>&#160;                                         failure_rate=1e-3)</div><div class="line"><a name="l01196"></a><span class="lineno"> 1196</span>&#160;</div><div class="line"><a name="l01197"></a><span class="lineno"> 1197</span>&#160;    <span class="keyword">def </span>test_relaxed_bernoulli(self):</div><div class="line"><a name="l01198"></a><span class="lineno"> 1198</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.7, 0.2, 0.4], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01199"></a><span class="lineno"> 1199</span>&#160;        r = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01200"></a><span class="lineno"> 1200</span>&#160;        s = 0.3</div><div class="line"><a name="l01201"></a><span class="lineno"> 1201</span>&#160;        temp = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.67, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01202"></a><span class="lineno"> 1202</span>&#160;        self.assertEqual(RelaxedBernoulli(temp, p).sample((8,)).size(), (8, 3))</div><div class="line"><a name="l01203"></a><span class="lineno"> 1203</span>&#160;        self.assertFalse(RelaxedBernoulli(temp, p).sample().requires_grad)</div><div class="line"><a name="l01204"></a><span class="lineno"> 1204</span>&#160;        self.assertEqual(RelaxedBernoulli(temp, r).sample((8,)).size(), (8,))</div><div class="line"><a name="l01205"></a><span class="lineno"> 1205</span>&#160;        self.assertEqual(RelaxedBernoulli(temp, r).sample().size(), ())</div><div class="line"><a name="l01206"></a><span class="lineno"> 1206</span>&#160;        self.assertEqual(RelaxedBernoulli(temp, r).sample((3, 2)).size(), (3, 2,))</div><div class="line"><a name="l01207"></a><span class="lineno"> 1207</span>&#160;        self.assertEqual(RelaxedBernoulli(temp, s).sample().size(), ())</div><div class="line"><a name="l01208"></a><span class="lineno"> 1208</span>&#160;        self._gradcheck_log_prob(RelaxedBernoulli, (temp, p))</div><div class="line"><a name="l01209"></a><span class="lineno"> 1209</span>&#160;        self._gradcheck_log_prob(RelaxedBernoulli, (temp, r))</div><div class="line"><a name="l01210"></a><span class="lineno"> 1210</span>&#160;</div><div class="line"><a name="l01211"></a><span class="lineno"> 1211</span>&#160;        <span class="comment"># test that rsample doesn&#39;t fail</span></div><div class="line"><a name="l01212"></a><span class="lineno"> 1212</span>&#160;        s = RelaxedBernoulli(temp, p).rsample()</div><div class="line"><a name="l01213"></a><span class="lineno"> 1213</span>&#160;        s.backward(torch.ones_like(s))</div><div class="line"><a name="l01214"></a><span class="lineno"> 1214</span>&#160;</div><div class="line"><a name="l01215"></a><span class="lineno"> 1215</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01216"></a><span class="lineno"> 1216</span>&#160;    <span class="keyword">def </span>test_rounded_relaxed_bernoulli(self):</div><div class="line"><a name="l01217"></a><span class="lineno"> 1217</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01218"></a><span class="lineno"> 1218</span>&#160;</div><div class="line"><a name="l01219"></a><span class="lineno"> 1219</span>&#160;        <span class="keyword">class </span>Rounded(object):</div><div class="line"><a name="l01220"></a><span class="lineno"> 1220</span>&#160;            <span class="keyword">def </span>__init__(self, dist):</div><div class="line"><a name="l01221"></a><span class="lineno"> 1221</span>&#160;                self.dist = dist</div><div class="line"><a name="l01222"></a><span class="lineno"> 1222</span>&#160;</div><div class="line"><a name="l01223"></a><span class="lineno"> 1223</span>&#160;            <span class="keyword">def </span>sample(self, *args, **kwargs):</div><div class="line"><a name="l01224"></a><span class="lineno"> 1224</span>&#160;                <span class="keywordflow">return</span> torch.round(self.dist.sample(*args, **kwargs))</div><div class="line"><a name="l01225"></a><span class="lineno"> 1225</span>&#160;</div><div class="line"><a name="l01226"></a><span class="lineno"> 1226</span>&#160;        <span class="keywordflow">for</span> probs, temp <span class="keywordflow">in</span> product([0.1, 0.2, 0.8], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l01227"></a><span class="lineno"> 1227</span>&#160;            self._check_sampler_discrete(Rounded(RelaxedBernoulli(temp, probs)),</div><div class="line"><a name="l01228"></a><span class="lineno"> 1228</span>&#160;                                         scipy.stats.bernoulli(probs),</div><div class="line"><a name="l01229"></a><span class="lineno"> 1229</span>&#160;                                         <span class="stringliteral">&#39;Rounded(RelaxedBernoulli(temp={}, probs={}))&#39;</span>.format(temp, probs),</div><div class="line"><a name="l01230"></a><span class="lineno"> 1230</span>&#160;                                         failure_rate=1e-3)</div><div class="line"><a name="l01231"></a><span class="lineno"> 1231</span>&#160;</div><div class="line"><a name="l01232"></a><span class="lineno"> 1232</span>&#160;        <span class="keywordflow">for</span> probs <span class="keywordflow">in</span> [0.001, 0.2, 0.999]:</div><div class="line"><a name="l01233"></a><span class="lineno"> 1233</span>&#160;            equal_probs = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.5)</div><div class="line"><a name="l01234"></a><span class="lineno"> 1234</span>&#160;            dist = RelaxedBernoulli(1e10, probs)</div><div class="line"><a name="l01235"></a><span class="lineno"> 1235</span>&#160;            s = dist.rsample()</div><div class="line"><a name="l01236"></a><span class="lineno"> 1236</span>&#160;            self.assertEqual(equal_probs, s)</div><div class="line"><a name="l01237"></a><span class="lineno"> 1237</span>&#160;</div><div class="line"><a name="l01238"></a><span class="lineno"> 1238</span>&#160;    <span class="keyword">def </span>test_relaxed_one_hot_categorical_1d(self):</div><div class="line"><a name="l01239"></a><span class="lineno"> 1239</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.1, 0.2, 0.3], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01240"></a><span class="lineno"> 1240</span>&#160;        temp = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.67, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01241"></a><span class="lineno"> 1241</span>&#160;        self.assertEqual(RelaxedOneHotCategorical(probs=p, temperature=temp).sample().size(), (3,))</div><div class="line"><a name="l01242"></a><span class="lineno"> 1242</span>&#160;        self.assertFalse(RelaxedOneHotCategorical(probs=p, temperature=temp).sample().requires_grad)</div><div class="line"><a name="l01243"></a><span class="lineno"> 1243</span>&#160;        self.assertEqual(RelaxedOneHotCategorical(probs=p, temperature=temp).sample((2, 2)).size(), (2, 2, 3))</div><div class="line"><a name="l01244"></a><span class="lineno"> 1244</span>&#160;        self.assertEqual(RelaxedOneHotCategorical(probs=p, temperature=temp).sample((1,)).size(), (1, 3))</div><div class="line"><a name="l01245"></a><span class="lineno"> 1245</span>&#160;        self._gradcheck_log_prob(RelaxedOneHotCategorical, (temp, p))</div><div class="line"><a name="l01246"></a><span class="lineno"> 1246</span>&#160;</div><div class="line"><a name="l01247"></a><span class="lineno"> 1247</span>&#160;    <span class="keyword">def </span>test_relaxed_one_hot_categorical_2d(self):</div><div class="line"><a name="l01248"></a><span class="lineno"> 1248</span>&#160;        probabilities = [[0.1, 0.2, 0.3], [0.5, 0.3, 0.2]]</div><div class="line"><a name="l01249"></a><span class="lineno"> 1249</span>&#160;        probabilities_1 = [[1.0, 0.0], [0.0, 1.0]]</div><div class="line"><a name="l01250"></a><span class="lineno"> 1250</span>&#160;        temp = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([3.0], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01251"></a><span class="lineno"> 1251</span>&#160;        <span class="comment"># The lower the temperature, the more unstable the log_prob gradcheck is</span></div><div class="line"><a name="l01252"></a><span class="lineno"> 1252</span>&#160;        <span class="comment"># w.r.t. the sample. Values below 0.25 empirically fail the default tol.</span></div><div class="line"><a name="l01253"></a><span class="lineno"> 1253</span>&#160;        temp_2 = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.25], requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01254"></a><span class="lineno"> 1254</span>&#160;        p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01255"></a><span class="lineno"> 1255</span>&#160;        s = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(probabilities_1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01256"></a><span class="lineno"> 1256</span>&#160;        self.assertEqual(RelaxedOneHotCategorical(temp, p).sample().size(), (2, 3))</div><div class="line"><a name="l01257"></a><span class="lineno"> 1257</span>&#160;        self.assertEqual(RelaxedOneHotCategorical(temp, p).sample(sample_shape=(3, 4)).size(), (3, 4, 2, 3))</div><div class="line"><a name="l01258"></a><span class="lineno"> 1258</span>&#160;        self.assertEqual(RelaxedOneHotCategorical(temp, p).sample((6,)).size(), (6, 2, 3))</div><div class="line"><a name="l01259"></a><span class="lineno"> 1259</span>&#160;        self._gradcheck_log_prob(RelaxedOneHotCategorical, (temp, p))</div><div class="line"><a name="l01260"></a><span class="lineno"> 1260</span>&#160;        self._gradcheck_log_prob(RelaxedOneHotCategorical, (temp_2, p))</div><div class="line"><a name="l01261"></a><span class="lineno"> 1261</span>&#160;</div><div class="line"><a name="l01262"></a><span class="lineno"> 1262</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01263"></a><span class="lineno"> 1263</span>&#160;    <span class="keyword">def </span>test_argmax_relaxed_categorical(self):</div><div class="line"><a name="l01264"></a><span class="lineno"> 1264</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01265"></a><span class="lineno"> 1265</span>&#160;</div><div class="line"><a name="l01266"></a><span class="lineno"> 1266</span>&#160;        <span class="keyword">class </span>ArgMax(object):</div><div class="line"><a name="l01267"></a><span class="lineno"> 1267</span>&#160;            <span class="keyword">def </span>__init__(self, dist):</div><div class="line"><a name="l01268"></a><span class="lineno"> 1268</span>&#160;                self.dist = dist</div><div class="line"><a name="l01269"></a><span class="lineno"> 1269</span>&#160;</div><div class="line"><a name="l01270"></a><span class="lineno"> 1270</span>&#160;            <span class="keyword">def </span>sample(self, *args, **kwargs):</div><div class="line"><a name="l01271"></a><span class="lineno"> 1271</span>&#160;                s = self.dist.sample(*args, **kwargs)</div><div class="line"><a name="l01272"></a><span class="lineno"> 1272</span>&#160;                _, idx = torch.max(s, -1)</div><div class="line"><a name="l01273"></a><span class="lineno"> 1273</span>&#160;                <span class="keywordflow">return</span> idx</div><div class="line"><a name="l01274"></a><span class="lineno"> 1274</span>&#160;</div><div class="line"><a name="l01275"></a><span class="lineno"> 1275</span>&#160;        <span class="keyword">class </span>ScipyCategorical(object):</div><div class="line"><a name="l01276"></a><span class="lineno"> 1276</span>&#160;            <span class="keyword">def </span>__init__(self, dist):</div><div class="line"><a name="l01277"></a><span class="lineno"> 1277</span>&#160;                self.dist = dist</div><div class="line"><a name="l01278"></a><span class="lineno"> 1278</span>&#160;</div><div class="line"><a name="l01279"></a><span class="lineno"> 1279</span>&#160;            <span class="keyword">def </span>pmf(self, samples):</div><div class="line"><a name="l01280"></a><span class="lineno"> 1280</span>&#160;                new_samples = np.zeros(samples.shape + self.dist.p.shape)</div><div class="line"><a name="l01281"></a><span class="lineno"> 1281</span>&#160;                new_samples[np.arange(samples.shape[0]), samples] = 1</div><div class="line"><a name="l01282"></a><span class="lineno"> 1282</span>&#160;                <span class="keywordflow">return</span> self.dist.pmf(new_samples)</div><div class="line"><a name="l01283"></a><span class="lineno"> 1283</span>&#160;</div><div class="line"><a name="l01284"></a><span class="lineno"> 1284</span>&#160;        <span class="keywordflow">for</span> probs, temp <span class="keywordflow">in</span> product([<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.1, 0.9]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.2, 0.2, 0.6])], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l01285"></a><span class="lineno"> 1285</span>&#160;            self._check_sampler_discrete(ArgMax(RelaxedOneHotCategorical(temp, probs)),</div><div class="line"><a name="l01286"></a><span class="lineno"> 1286</span>&#160;                                         ScipyCategorical(scipy.stats.multinomial(1, probs)),</div><div class="line"><a name="l01287"></a><span class="lineno"> 1287</span>&#160;                                         <span class="stringliteral">&#39;Rounded(RelaxedOneHotCategorical(temp={}, probs={}))&#39;</span>.format(temp, probs),</div><div class="line"><a name="l01288"></a><span class="lineno"> 1288</span>&#160;                                         failure_rate=1e-3)</div><div class="line"><a name="l01289"></a><span class="lineno"> 1289</span>&#160;</div><div class="line"><a name="l01290"></a><span class="lineno"> 1290</span>&#160;        <span class="keywordflow">for</span> probs <span class="keywordflow">in</span> [<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.1, 0.9]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.2, 0.2, 0.6])]:</div><div class="line"><a name="l01291"></a><span class="lineno"> 1291</span>&#160;            equal_probs = torch.ones(probs.size()) / probs.size()[0]</div><div class="line"><a name="l01292"></a><span class="lineno"> 1292</span>&#160;            dist = RelaxedOneHotCategorical(1e10, probs)</div><div class="line"><a name="l01293"></a><span class="lineno"> 1293</span>&#160;            s = dist.rsample()</div><div class="line"><a name="l01294"></a><span class="lineno"> 1294</span>&#160;            self.assertEqual(equal_probs, s)</div><div class="line"><a name="l01295"></a><span class="lineno"> 1295</span>&#160;</div><div class="line"><a name="l01296"></a><span class="lineno"> 1296</span>&#160;    <span class="keyword">def </span>test_uniform(self):</div><div class="line"><a name="l01297"></a><span class="lineno"> 1297</span>&#160;        low = torch.zeros(5, 5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01298"></a><span class="lineno"> 1298</span>&#160;        high = (torch.ones(5, 5) * 3).requires_grad_()</div><div class="line"><a name="l01299"></a><span class="lineno"> 1299</span>&#160;        low_1d = torch.zeros(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01300"></a><span class="lineno"> 1300</span>&#160;        high_1d = (torch.ones(1) * 3).requires_grad_()</div><div class="line"><a name="l01301"></a><span class="lineno"> 1301</span>&#160;        self.assertEqual(Uniform(low, high).sample().size(), (5, 5))</div><div class="line"><a name="l01302"></a><span class="lineno"> 1302</span>&#160;        self.assertEqual(Uniform(low, high).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01303"></a><span class="lineno"> 1303</span>&#160;        self.assertEqual(Uniform(low_1d, high_1d).sample().size(), (1,))</div><div class="line"><a name="l01304"></a><span class="lineno"> 1304</span>&#160;        self.assertEqual(Uniform(low_1d, high_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01305"></a><span class="lineno"> 1305</span>&#160;        self.assertEqual(Uniform(0.0, 1.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01306"></a><span class="lineno"> 1306</span>&#160;</div><div class="line"><a name="l01307"></a><span class="lineno"> 1307</span>&#160;        <span class="comment"># Check log_prob computation when value outside range</span></div><div class="line"><a name="l01308"></a><span class="lineno"> 1308</span>&#160;        uniform = Uniform(low_1d, high_1d)</div><div class="line"><a name="l01309"></a><span class="lineno"> 1309</span>&#160;        above_high = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([4.0])</div><div class="line"><a name="l01310"></a><span class="lineno"> 1310</span>&#160;        below_low = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-1.0])</div><div class="line"><a name="l01311"></a><span class="lineno"> 1311</span>&#160;        self.assertEqual(uniform.log_prob(above_high).item(), -inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l01312"></a><span class="lineno"> 1312</span>&#160;        self.assertEqual(uniform.log_prob(below_low).item(), -inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l01313"></a><span class="lineno"> 1313</span>&#160;</div><div class="line"><a name="l01314"></a><span class="lineno"> 1314</span>&#160;        <span class="comment"># check cdf computation when value outside range</span></div><div class="line"><a name="l01315"></a><span class="lineno"> 1315</span>&#160;        self.assertEqual(uniform.cdf(below_low).item(), 0)</div><div class="line"><a name="l01316"></a><span class="lineno"> 1316</span>&#160;        self.assertEqual(uniform.cdf(above_high).item(), 1)</div><div class="line"><a name="l01317"></a><span class="lineno"> 1317</span>&#160;</div><div class="line"><a name="l01318"></a><span class="lineno"> 1318</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01319"></a><span class="lineno"> 1319</span>&#160;        self._gradcheck_log_prob(Uniform, (low, high))</div><div class="line"><a name="l01320"></a><span class="lineno"> 1320</span>&#160;        self._gradcheck_log_prob(Uniform, (low, 1.0))</div><div class="line"><a name="l01321"></a><span class="lineno"> 1321</span>&#160;        self._gradcheck_log_prob(Uniform, (0.0, high))</div><div class="line"><a name="l01322"></a><span class="lineno"> 1322</span>&#160;</div><div class="line"><a name="l01323"></a><span class="lineno"> 1323</span>&#160;        state = torch.get_rng_state()</div><div class="line"><a name="l01324"></a><span class="lineno"> 1324</span>&#160;        rand = low.new(low.size()).uniform_()</div><div class="line"><a name="l01325"></a><span class="lineno"> 1325</span>&#160;        torch.set_rng_state(state)</div><div class="line"><a name="l01326"></a><span class="lineno"> 1326</span>&#160;        u = Uniform(low, high).rsample()</div><div class="line"><a name="l01327"></a><span class="lineno"> 1327</span>&#160;        u.backward(torch.ones_like(u))</div><div class="line"><a name="l01328"></a><span class="lineno"> 1328</span>&#160;        self.assertEqual(low.grad, 1 - rand)</div><div class="line"><a name="l01329"></a><span class="lineno"> 1329</span>&#160;        self.assertEqual(high.grad, rand)</div><div class="line"><a name="l01330"></a><span class="lineno"> 1330</span>&#160;        low.grad.zero_()</div><div class="line"><a name="l01331"></a><span class="lineno"> 1331</span>&#160;        high.grad.zero_()</div><div class="line"><a name="l01332"></a><span class="lineno"> 1332</span>&#160;</div><div class="line"><a name="l01333"></a><span class="lineno"> 1333</span>&#160;    <span class="keyword">def </span>test_cauchy(self):</div><div class="line"><a name="l01334"></a><span class="lineno"> 1334</span>&#160;        loc = torch.zeros(5, 5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01335"></a><span class="lineno"> 1335</span>&#160;        scale = torch.ones(5, 5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01336"></a><span class="lineno"> 1336</span>&#160;        loc_1d = torch.zeros(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01337"></a><span class="lineno"> 1337</span>&#160;        scale_1d = torch.ones(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01338"></a><span class="lineno"> 1338</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(Cauchy(loc_1d, scale_1d).mean))</div><div class="line"><a name="l01339"></a><span class="lineno"> 1339</span>&#160;        self.assertEqual(Cauchy(loc_1d, scale_1d).variance, inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l01340"></a><span class="lineno"> 1340</span>&#160;        self.assertEqual(Cauchy(loc, scale).sample().size(), (5, 5))</div><div class="line"><a name="l01341"></a><span class="lineno"> 1341</span>&#160;        self.assertEqual(Cauchy(loc, scale).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01342"></a><span class="lineno"> 1342</span>&#160;        self.assertEqual(Cauchy(loc_1d, scale_1d).sample().size(), (1,))</div><div class="line"><a name="l01343"></a><span class="lineno"> 1343</span>&#160;        self.assertEqual(Cauchy(loc_1d, scale_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01344"></a><span class="lineno"> 1344</span>&#160;        self.assertEqual(Cauchy(0.0, 1.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01345"></a><span class="lineno"> 1345</span>&#160;</div><div class="line"><a name="l01346"></a><span class="lineno"> 1346</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01347"></a><span class="lineno"> 1347</span>&#160;        self._gradcheck_log_prob(Cauchy, (loc, scale))</div><div class="line"><a name="l01348"></a><span class="lineno"> 1348</span>&#160;        self._gradcheck_log_prob(Cauchy, (loc, 1.0))</div><div class="line"><a name="l01349"></a><span class="lineno"> 1349</span>&#160;        self._gradcheck_log_prob(Cauchy, (0.0, scale))</div><div class="line"><a name="l01350"></a><span class="lineno"> 1350</span>&#160;</div><div class="line"><a name="l01351"></a><span class="lineno"> 1351</span>&#160;        state = torch.get_rng_state()</div><div class="line"><a name="l01352"></a><span class="lineno"> 1352</span>&#160;        eps = loc.new(loc.size()).cauchy_()</div><div class="line"><a name="l01353"></a><span class="lineno"> 1353</span>&#160;        torch.set_rng_state(state)</div><div class="line"><a name="l01354"></a><span class="lineno"> 1354</span>&#160;        c = Cauchy(loc, scale).rsample()</div><div class="line"><a name="l01355"></a><span class="lineno"> 1355</span>&#160;        c.backward(torch.ones_like(c))</div><div class="line"><a name="l01356"></a><span class="lineno"> 1356</span>&#160;        self.assertEqual(loc.grad, torch.ones_like(scale))</div><div class="line"><a name="l01357"></a><span class="lineno"> 1357</span>&#160;        self.assertEqual(scale.grad, eps)</div><div class="line"><a name="l01358"></a><span class="lineno"> 1358</span>&#160;        loc.grad.zero_()</div><div class="line"><a name="l01359"></a><span class="lineno"> 1359</span>&#160;        scale.grad.zero_()</div><div class="line"><a name="l01360"></a><span class="lineno"> 1360</span>&#160;</div><div class="line"><a name="l01361"></a><span class="lineno"> 1361</span>&#160;    <span class="keyword">def </span>test_halfcauchy(self):</div><div class="line"><a name="l01362"></a><span class="lineno"> 1362</span>&#160;        scale = torch.ones(5, 5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01363"></a><span class="lineno"> 1363</span>&#160;        scale_1d = torch.ones(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01364"></a><span class="lineno"> 1364</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(HalfCauchy(scale_1d).mean))</div><div class="line"><a name="l01365"></a><span class="lineno"> 1365</span>&#160;        self.assertEqual(HalfCauchy(scale_1d).variance, inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l01366"></a><span class="lineno"> 1366</span>&#160;        self.assertEqual(HalfCauchy(scale).sample().size(), (5, 5))</div><div class="line"><a name="l01367"></a><span class="lineno"> 1367</span>&#160;        self.assertEqual(HalfCauchy(scale).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01368"></a><span class="lineno"> 1368</span>&#160;        self.assertEqual(HalfCauchy(scale_1d).sample().size(), (1,))</div><div class="line"><a name="l01369"></a><span class="lineno"> 1369</span>&#160;        self.assertEqual(HalfCauchy(scale_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01370"></a><span class="lineno"> 1370</span>&#160;        self.assertEqual(HalfCauchy(1.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01371"></a><span class="lineno"> 1371</span>&#160;</div><div class="line"><a name="l01372"></a><span class="lineno"> 1372</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01373"></a><span class="lineno"> 1373</span>&#160;        self._gradcheck_log_prob(HalfCauchy, (scale,))</div><div class="line"><a name="l01374"></a><span class="lineno"> 1374</span>&#160;        self._gradcheck_log_prob(HalfCauchy, (1.0,))</div><div class="line"><a name="l01375"></a><span class="lineno"> 1375</span>&#160;</div><div class="line"><a name="l01376"></a><span class="lineno"> 1376</span>&#160;        state = torch.get_rng_state()</div><div class="line"><a name="l01377"></a><span class="lineno"> 1377</span>&#160;        eps = scale.new(scale.size()).cauchy_().abs_()</div><div class="line"><a name="l01378"></a><span class="lineno"> 1378</span>&#160;        torch.set_rng_state(state)</div><div class="line"><a name="l01379"></a><span class="lineno"> 1379</span>&#160;        c = HalfCauchy(scale).rsample()</div><div class="line"><a name="l01380"></a><span class="lineno"> 1380</span>&#160;        c.backward(torch.ones_like(c))</div><div class="line"><a name="l01381"></a><span class="lineno"> 1381</span>&#160;        self.assertEqual(scale.grad, eps)</div><div class="line"><a name="l01382"></a><span class="lineno"> 1382</span>&#160;        scale.grad.zero_()</div><div class="line"><a name="l01383"></a><span class="lineno"> 1383</span>&#160;</div><div class="line"><a name="l01384"></a><span class="lineno"> 1384</span>&#160;    <span class="keyword">def </span>test_halfnormal(self):</div><div class="line"><a name="l01385"></a><span class="lineno"> 1385</span>&#160;        std = torch.randn(5, 5).abs().requires_grad_()</div><div class="line"><a name="l01386"></a><span class="lineno"> 1386</span>&#160;        std_1d = torch.randn(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01387"></a><span class="lineno"> 1387</span>&#160;        std_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5])</div><div class="line"><a name="l01388"></a><span class="lineno"> 1388</span>&#160;        self.assertEqual(HalfNormal(std).sample().size(), (5, 5))</div><div class="line"><a name="l01389"></a><span class="lineno"> 1389</span>&#160;        self.assertEqual(HalfNormal(std).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01390"></a><span class="lineno"> 1390</span>&#160;        self.assertEqual(HalfNormal(std_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01391"></a><span class="lineno"> 1391</span>&#160;        self.assertEqual(HalfNormal(std_1d).sample().size(), (1,))</div><div class="line"><a name="l01392"></a><span class="lineno"> 1392</span>&#160;        self.assertEqual(HalfNormal(.6).sample((1,)).size(), (1,))</div><div class="line"><a name="l01393"></a><span class="lineno"> 1393</span>&#160;        self.assertEqual(HalfNormal(50.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01394"></a><span class="lineno"> 1394</span>&#160;</div><div class="line"><a name="l01395"></a><span class="lineno"> 1395</span>&#160;        <span class="comment"># sample check for extreme value of std</span></div><div class="line"><a name="l01396"></a><span class="lineno"> 1396</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01397"></a><span class="lineno"> 1397</span>&#160;        self.assertEqual(HalfNormal(std_delta).sample(sample_shape=(1, 2)),</div><div class="line"><a name="l01398"></a><span class="lineno"> 1398</span>&#160;                         <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[[0.0, 0.0], [0.0, 0.0]]]),</div><div class="line"><a name="l01399"></a><span class="lineno"> 1399</span>&#160;                         prec=1e-4)</div><div class="line"><a name="l01400"></a><span class="lineno"> 1400</span>&#160;</div><div class="line"><a name="l01401"></a><span class="lineno"> 1401</span>&#160;        self._gradcheck_log_prob(HalfNormal, (std,))</div><div class="line"><a name="l01402"></a><span class="lineno"> 1402</span>&#160;        self._gradcheck_log_prob(HalfNormal, (1.0,))</div><div class="line"><a name="l01403"></a><span class="lineno"> 1403</span>&#160;</div><div class="line"><a name="l01404"></a><span class="lineno"> 1404</span>&#160;        <span class="comment"># check .log_prob() can broadcast.</span></div><div class="line"><a name="l01405"></a><span class="lineno"> 1405</span>&#160;        dist = HalfNormal(torch.ones(2, 1, 4))</div><div class="line"><a name="l01406"></a><span class="lineno"> 1406</span>&#160;        log_prob = dist.log_prob(torch.ones(3, 1))</div><div class="line"><a name="l01407"></a><span class="lineno"> 1407</span>&#160;        self.assertEqual(log_prob.shape, (2, 3, 4))</div><div class="line"><a name="l01408"></a><span class="lineno"> 1408</span>&#160;</div><div class="line"><a name="l01409"></a><span class="lineno"> 1409</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01410"></a><span class="lineno"> 1410</span>&#160;    <span class="keyword">def </span>test_halfnormal_logprob(self):</div><div class="line"><a name="l01411"></a><span class="lineno"> 1411</span>&#160;        std = torch.randn(5, 1).abs().requires_grad_()</div><div class="line"><a name="l01412"></a><span class="lineno"> 1412</span>&#160;</div><div class="line"><a name="l01413"></a><span class="lineno"> 1413</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01414"></a><span class="lineno"> 1414</span>&#160;            s = std.view(-1)[idx].detach()</div><div class="line"><a name="l01415"></a><span class="lineno"> 1415</span>&#160;            expected = scipy.stats.halfnorm(scale=s).logpdf(x)</div><div class="line"><a name="l01416"></a><span class="lineno"> 1416</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01417"></a><span class="lineno"> 1417</span>&#160;</div><div class="line"><a name="l01418"></a><span class="lineno"> 1418</span>&#160;        self._check_log_prob(HalfNormal(std), ref_log_prob)</div><div class="line"><a name="l01419"></a><span class="lineno"> 1419</span>&#160;</div><div class="line"><a name="l01420"></a><span class="lineno"> 1420</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01421"></a><span class="lineno"> 1421</span>&#160;    <span class="keyword">def </span>test_halfnormal_sample(self):</div><div class="line"><a name="l01422"></a><span class="lineno"> 1422</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01423"></a><span class="lineno"> 1423</span>&#160;        <span class="keywordflow">for</span> std <span class="keywordflow">in</span> [0.1, 1.0, 10.0]:</div><div class="line"><a name="l01424"></a><span class="lineno"> 1424</span>&#160;            self._check_sampler_sampler(HalfNormal(std),</div><div class="line"><a name="l01425"></a><span class="lineno"> 1425</span>&#160;                                        scipy.stats.halfnorm(scale=std),</div><div class="line"><a name="l01426"></a><span class="lineno"> 1426</span>&#160;                                        <span class="stringliteral">&#39;HalfNormal(scale={})&#39;</span>.format(std))</div><div class="line"><a name="l01427"></a><span class="lineno"> 1427</span>&#160;</div><div class="line"><a name="l01428"></a><span class="lineno"> 1428</span>&#160;    <span class="keyword">def </span>test_lognormal(self):</div><div class="line"><a name="l01429"></a><span class="lineno"> 1429</span>&#160;        mean = torch.randn(5, 5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01430"></a><span class="lineno"> 1430</span>&#160;        std = torch.randn(5, 5).abs().requires_grad_()</div><div class="line"><a name="l01431"></a><span class="lineno"> 1431</span>&#160;        mean_1d = torch.randn(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01432"></a><span class="lineno"> 1432</span>&#160;        std_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l01433"></a><span class="lineno"> 1433</span>&#160;        mean_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0])</div><div class="line"><a name="l01434"></a><span class="lineno"> 1434</span>&#160;        std_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5])</div><div class="line"><a name="l01435"></a><span class="lineno"> 1435</span>&#160;        self.assertEqual(LogNormal(mean, std).sample().size(), (5, 5))</div><div class="line"><a name="l01436"></a><span class="lineno"> 1436</span>&#160;        self.assertEqual(LogNormal(mean, std).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01437"></a><span class="lineno"> 1437</span>&#160;        self.assertEqual(LogNormal(mean_1d, std_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01438"></a><span class="lineno"> 1438</span>&#160;        self.assertEqual(LogNormal(mean_1d, std_1d).sample().size(), (1,))</div><div class="line"><a name="l01439"></a><span class="lineno"> 1439</span>&#160;        self.assertEqual(LogNormal(0.2, .6).sample((1,)).size(), (1,))</div><div class="line"><a name="l01440"></a><span class="lineno"> 1440</span>&#160;        self.assertEqual(LogNormal(-0.7, 50.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01441"></a><span class="lineno"> 1441</span>&#160;</div><div class="line"><a name="l01442"></a><span class="lineno"> 1442</span>&#160;        <span class="comment"># sample check for extreme value of mean, std</span></div><div class="line"><a name="l01443"></a><span class="lineno"> 1443</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01444"></a><span class="lineno"> 1444</span>&#160;        self.assertEqual(LogNormal(mean_delta, std_delta).sample(sample_shape=(1, 2)),</div><div class="line"><a name="l01445"></a><span class="lineno"> 1445</span>&#160;                         <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[[math.exp(1), 1.0], [math.exp(1), 1.0]]]),</div><div class="line"><a name="l01446"></a><span class="lineno"> 1446</span>&#160;                         prec=1e-4)</div><div class="line"><a name="l01447"></a><span class="lineno"> 1447</span>&#160;</div><div class="line"><a name="l01448"></a><span class="lineno"> 1448</span>&#160;        self._gradcheck_log_prob(LogNormal, (mean, std))</div><div class="line"><a name="l01449"></a><span class="lineno"> 1449</span>&#160;        self._gradcheck_log_prob(LogNormal, (mean, 1.0))</div><div class="line"><a name="l01450"></a><span class="lineno"> 1450</span>&#160;        self._gradcheck_log_prob(LogNormal, (0.0, std))</div><div class="line"><a name="l01451"></a><span class="lineno"> 1451</span>&#160;</div><div class="line"><a name="l01452"></a><span class="lineno"> 1452</span>&#160;        <span class="comment"># check .log_prob() can broadcast.</span></div><div class="line"><a name="l01453"></a><span class="lineno"> 1453</span>&#160;        dist = LogNormal(torch.zeros(4), torch.ones(2, 1, 1))</div><div class="line"><a name="l01454"></a><span class="lineno"> 1454</span>&#160;        log_prob = dist.log_prob(torch.ones(3, 1))</div><div class="line"><a name="l01455"></a><span class="lineno"> 1455</span>&#160;        self.assertEqual(log_prob.shape, (2, 3, 4))</div><div class="line"><a name="l01456"></a><span class="lineno"> 1456</span>&#160;</div><div class="line"><a name="l01457"></a><span class="lineno"> 1457</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01458"></a><span class="lineno"> 1458</span>&#160;    <span class="keyword">def </span>test_lognormal_logprob(self):</div><div class="line"><a name="l01459"></a><span class="lineno"> 1459</span>&#160;        mean = torch.randn(5, 1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01460"></a><span class="lineno"> 1460</span>&#160;        std = torch.randn(5, 1).abs().requires_grad_()</div><div class="line"><a name="l01461"></a><span class="lineno"> 1461</span>&#160;</div><div class="line"><a name="l01462"></a><span class="lineno"> 1462</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01463"></a><span class="lineno"> 1463</span>&#160;            m = mean.view(-1)[idx].detach()</div><div class="line"><a name="l01464"></a><span class="lineno"> 1464</span>&#160;            s = std.view(-1)[idx].detach()</div><div class="line"><a name="l01465"></a><span class="lineno"> 1465</span>&#160;            expected = scipy.stats.lognorm(s=s, scale=math.exp(m)).logpdf(x)</div><div class="line"><a name="l01466"></a><span class="lineno"> 1466</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01467"></a><span class="lineno"> 1467</span>&#160;</div><div class="line"><a name="l01468"></a><span class="lineno"> 1468</span>&#160;        self._check_log_prob(LogNormal(mean, std), ref_log_prob)</div><div class="line"><a name="l01469"></a><span class="lineno"> 1469</span>&#160;</div><div class="line"><a name="l01470"></a><span class="lineno"> 1470</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01471"></a><span class="lineno"> 1471</span>&#160;    <span class="keyword">def </span>test_lognormal_sample(self):</div><div class="line"><a name="l01472"></a><span class="lineno"> 1472</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01473"></a><span class="lineno"> 1473</span>&#160;        <span class="keywordflow">for</span> mean, std <span class="keywordflow">in</span> product([-1.0, 0.0, 1.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l01474"></a><span class="lineno"> 1474</span>&#160;            self._check_sampler_sampler(LogNormal(mean, std),</div><div class="line"><a name="l01475"></a><span class="lineno"> 1475</span>&#160;                                        scipy.stats.lognorm(scale=math.exp(mean), s=std),</div><div class="line"><a name="l01476"></a><span class="lineno"> 1476</span>&#160;                                        <span class="stringliteral">&#39;LogNormal(loc={}, scale={})&#39;</span>.format(mean, std))</div><div class="line"><a name="l01477"></a><span class="lineno"> 1477</span>&#160;</div><div class="line"><a name="l01478"></a><span class="lineno"> 1478</span>&#160;    <span class="keyword">def </span>test_logisticnormal(self):</div><div class="line"><a name="l01479"></a><span class="lineno"> 1479</span>&#160;        mean = torch.randn(5, 5).requires_grad_()</div><div class="line"><a name="l01480"></a><span class="lineno"> 1480</span>&#160;        std = torch.randn(5, 5).abs().requires_grad_()</div><div class="line"><a name="l01481"></a><span class="lineno"> 1481</span>&#160;        mean_1d = torch.randn(1).requires_grad_()</div><div class="line"><a name="l01482"></a><span class="lineno"> 1482</span>&#160;        std_1d = torch.randn(1).requires_grad_()</div><div class="line"><a name="l01483"></a><span class="lineno"> 1483</span>&#160;        mean_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0])</div><div class="line"><a name="l01484"></a><span class="lineno"> 1484</span>&#160;        std_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5])</div><div class="line"><a name="l01485"></a><span class="lineno"> 1485</span>&#160;        self.assertEqual(LogisticNormal(mean, std).sample().size(), (5, 6))</div><div class="line"><a name="l01486"></a><span class="lineno"> 1486</span>&#160;        self.assertEqual(LogisticNormal(mean, std).sample((7,)).size(), (7, 5, 6))</div><div class="line"><a name="l01487"></a><span class="lineno"> 1487</span>&#160;        self.assertEqual(LogisticNormal(mean_1d, std_1d).sample((1,)).size(), (1, 2))</div><div class="line"><a name="l01488"></a><span class="lineno"> 1488</span>&#160;        self.assertEqual(LogisticNormal(mean_1d, std_1d).sample().size(), (2,))</div><div class="line"><a name="l01489"></a><span class="lineno"> 1489</span>&#160;        self.assertEqual(LogisticNormal(0.2, .6).sample((1,)).size(), (2,))</div><div class="line"><a name="l01490"></a><span class="lineno"> 1490</span>&#160;        self.assertEqual(LogisticNormal(-0.7, 50.0).sample((1,)).size(), (2,))</div><div class="line"><a name="l01491"></a><span class="lineno"> 1491</span>&#160;</div><div class="line"><a name="l01492"></a><span class="lineno"> 1492</span>&#160;        <span class="comment"># sample check for extreme value of mean, std</span></div><div class="line"><a name="l01493"></a><span class="lineno"> 1493</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01494"></a><span class="lineno"> 1494</span>&#160;        self.assertEqual(LogisticNormal(mean_delta, std_delta).sample(),</div><div class="line"><a name="l01495"></a><span class="lineno"> 1495</span>&#160;                         <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([math.exp(1) / (1. + 1. + math.exp(1)),</div><div class="line"><a name="l01496"></a><span class="lineno"> 1496</span>&#160;                                       1. / (1. + 1. + math.exp(1)),</div><div class="line"><a name="l01497"></a><span class="lineno"> 1497</span>&#160;                                       1. / (1. + 1. + math.exp(1))]),</div><div class="line"><a name="l01498"></a><span class="lineno"> 1498</span>&#160;                         prec=1e-4)</div><div class="line"><a name="l01499"></a><span class="lineno"> 1499</span>&#160;</div><div class="line"><a name="l01500"></a><span class="lineno"> 1500</span>&#160;        self._gradcheck_log_prob(LogisticNormal, (mean, std))</div><div class="line"><a name="l01501"></a><span class="lineno"> 1501</span>&#160;        self._gradcheck_log_prob(LogisticNormal, (mean, 1.0))</div><div class="line"><a name="l01502"></a><span class="lineno"> 1502</span>&#160;        self._gradcheck_log_prob(LogisticNormal, (0.0, std))</div><div class="line"><a name="l01503"></a><span class="lineno"> 1503</span>&#160;</div><div class="line"><a name="l01504"></a><span class="lineno"> 1504</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01505"></a><span class="lineno"> 1505</span>&#160;    <span class="keyword">def </span>test_logisticnormal_logprob(self):</div><div class="line"><a name="l01506"></a><span class="lineno"> 1506</span>&#160;        mean = torch.randn(5, 7).requires_grad_()</div><div class="line"><a name="l01507"></a><span class="lineno"> 1507</span>&#160;        std = torch.randn(5, 7).abs().requires_grad_()</div><div class="line"><a name="l01508"></a><span class="lineno"> 1508</span>&#160;</div><div class="line"><a name="l01509"></a><span class="lineno"> 1509</span>&#160;        <span class="comment"># Smoke test for now</span></div><div class="line"><a name="l01510"></a><span class="lineno"> 1510</span>&#160;        <span class="comment"># TODO: Once _check_log_prob works with multidimensional distributions,</span></div><div class="line"><a name="l01511"></a><span class="lineno"> 1511</span>&#160;        <span class="comment">#       add proper testing of the log probabilities.</span></div><div class="line"><a name="l01512"></a><span class="lineno"> 1512</span>&#160;        dist = LogisticNormal(mean, std)</div><div class="line"><a name="l01513"></a><span class="lineno"> 1513</span>&#160;        <span class="keyword">assert</span> dist.log_prob(dist.sample()).detach().cpu().numpy().shape == (5,)</div><div class="line"><a name="l01514"></a><span class="lineno"> 1514</span>&#160;</div><div class="line"><a name="l01515"></a><span class="lineno"> 1515</span>&#160;    <span class="keyword">def </span>_get_logistic_normal_ref_sampler(self, base_dist):</div><div class="line"><a name="l01516"></a><span class="lineno"> 1516</span>&#160;</div><div class="line"><a name="l01517"></a><span class="lineno"> 1517</span>&#160;        <span class="keyword">def </span>_sampler(num_samples):</div><div class="line"><a name="l01518"></a><span class="lineno"> 1518</span>&#160;            x = base_dist.rvs(num_samples)</div><div class="line"><a name="l01519"></a><span class="lineno"> 1519</span>&#160;            offset = np.log((x.shape[-1] + 1) - np.ones_like(x).cumsum(-1))</div><div class="line"><a name="l01520"></a><span class="lineno"> 1520</span>&#160;            z = 1. / (1. + np.exp(offset - x))</div><div class="line"><a name="l01521"></a><span class="lineno"> 1521</span>&#160;            z_cumprod = np.cumprod(1 - z, axis=-1)</div><div class="line"><a name="l01522"></a><span class="lineno"> 1522</span>&#160;            y1 = np.pad(z, ((0, 0), (0, 1)), mode=<span class="stringliteral">&#39;constant&#39;</span>, constant_values=1.)</div><div class="line"><a name="l01523"></a><span class="lineno"> 1523</span>&#160;            y2 = np.pad(z_cumprod, ((0, 0), (1, 0)), mode=<span class="stringliteral">&#39;constant&#39;</span>, constant_values=1.)</div><div class="line"><a name="l01524"></a><span class="lineno"> 1524</span>&#160;            <span class="keywordflow">return</span> y1 * y2</div><div class="line"><a name="l01525"></a><span class="lineno"> 1525</span>&#160;</div><div class="line"><a name="l01526"></a><span class="lineno"> 1526</span>&#160;        <span class="keywordflow">return</span> _sampler</div><div class="line"><a name="l01527"></a><span class="lineno"> 1527</span>&#160;</div><div class="line"><a name="l01528"></a><span class="lineno"> 1528</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01529"></a><span class="lineno"> 1529</span>&#160;    <span class="keyword">def </span>test_logisticnormal_sample(self):</div><div class="line"><a name="l01530"></a><span class="lineno"> 1530</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01531"></a><span class="lineno"> 1531</span>&#160;        means = map(np.asarray, [(-1.0, -1.0), (0.0, 0.0), (1.0, 1.0)])</div><div class="line"><a name="l01532"></a><span class="lineno"> 1532</span>&#160;        covs = map(np.diag, [(0.1, 0.1), (1.0, 1.0), (10.0, 10.0)])</div><div class="line"><a name="l01533"></a><span class="lineno"> 1533</span>&#160;        <span class="keywordflow">for</span> mean, cov <span class="keywordflow">in</span> product(means, covs):</div><div class="line"><a name="l01534"></a><span class="lineno"> 1534</span>&#160;            base_dist = scipy.stats.multivariate_normal(mean=mean, cov=cov)</div><div class="line"><a name="l01535"></a><span class="lineno"> 1535</span>&#160;            ref_dist = scipy.stats.multivariate_normal(mean=mean, cov=cov)</div><div class="line"><a name="l01536"></a><span class="lineno"> 1536</span>&#160;            ref_dist.rvs = self._get_logistic_normal_ref_sampler(base_dist)</div><div class="line"><a name="l01537"></a><span class="lineno"> 1537</span>&#160;            mean_th = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(mean)</div><div class="line"><a name="l01538"></a><span class="lineno"> 1538</span>&#160;            std_th = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(np.sqrt(np.diag(cov)))</div><div class="line"><a name="l01539"></a><span class="lineno"> 1539</span>&#160;            self._check_sampler_sampler(</div><div class="line"><a name="l01540"></a><span class="lineno"> 1540</span>&#160;                LogisticNormal(mean_th, std_th), ref_dist,</div><div class="line"><a name="l01541"></a><span class="lineno"> 1541</span>&#160;                <span class="stringliteral">&#39;LogisticNormal(loc={}, scale={})&#39;</span>.format(mean_th, std_th),</div><div class="line"><a name="l01542"></a><span class="lineno"> 1542</span>&#160;                multivariate=<span class="keyword">True</span>)</div><div class="line"><a name="l01543"></a><span class="lineno"> 1543</span>&#160;</div><div class="line"><a name="l01544"></a><span class="lineno"> 1544</span>&#160;    <span class="keyword">def </span>test_normal(self):</div><div class="line"><a name="l01545"></a><span class="lineno"> 1545</span>&#160;        loc = torch.randn(5, 5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01546"></a><span class="lineno"> 1546</span>&#160;        scale = torch.randn(5, 5).abs().requires_grad_()</div><div class="line"><a name="l01547"></a><span class="lineno"> 1547</span>&#160;        loc_1d = torch.randn(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01548"></a><span class="lineno"> 1548</span>&#160;        scale_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l01549"></a><span class="lineno"> 1549</span>&#160;        loc_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0])</div><div class="line"><a name="l01550"></a><span class="lineno"> 1550</span>&#160;        scale_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5])</div><div class="line"><a name="l01551"></a><span class="lineno"> 1551</span>&#160;        self.assertEqual(Normal(loc, scale).sample().size(), (5, 5))</div><div class="line"><a name="l01552"></a><span class="lineno"> 1552</span>&#160;        self.assertEqual(Normal(loc, scale).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01553"></a><span class="lineno"> 1553</span>&#160;        self.assertEqual(Normal(loc_1d, scale_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01554"></a><span class="lineno"> 1554</span>&#160;        self.assertEqual(Normal(loc_1d, scale_1d).sample().size(), (1,))</div><div class="line"><a name="l01555"></a><span class="lineno"> 1555</span>&#160;        self.assertEqual(Normal(0.2, .6).sample((1,)).size(), (1,))</div><div class="line"><a name="l01556"></a><span class="lineno"> 1556</span>&#160;        self.assertEqual(Normal(-0.7, 50.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01557"></a><span class="lineno"> 1557</span>&#160;</div><div class="line"><a name="l01558"></a><span class="lineno"> 1558</span>&#160;        <span class="comment"># sample check for extreme value of mean, std</span></div><div class="line"><a name="l01559"></a><span class="lineno"> 1559</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l01560"></a><span class="lineno"> 1560</span>&#160;        self.assertEqual(Normal(loc_delta, scale_delta).sample(sample_shape=(1, 2)),</div><div class="line"><a name="l01561"></a><span class="lineno"> 1561</span>&#160;                         <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[[1.0, 0.0], [1.0, 0.0]]]),</div><div class="line"><a name="l01562"></a><span class="lineno"> 1562</span>&#160;                         prec=1e-4)</div><div class="line"><a name="l01563"></a><span class="lineno"> 1563</span>&#160;</div><div class="line"><a name="l01564"></a><span class="lineno"> 1564</span>&#160;        self._gradcheck_log_prob(Normal, (loc, scale))</div><div class="line"><a name="l01565"></a><span class="lineno"> 1565</span>&#160;        self._gradcheck_log_prob(Normal, (loc, 1.0))</div><div class="line"><a name="l01566"></a><span class="lineno"> 1566</span>&#160;        self._gradcheck_log_prob(Normal, (0.0, scale))</div><div class="line"><a name="l01567"></a><span class="lineno"> 1567</span>&#160;</div><div class="line"><a name="l01568"></a><span class="lineno"> 1568</span>&#160;        state = torch.get_rng_state()</div><div class="line"><a name="l01569"></a><span class="lineno"> 1569</span>&#160;        eps = torch.normal(torch.zeros_like(loc), torch.ones_like(scale))</div><div class="line"><a name="l01570"></a><span class="lineno"> 1570</span>&#160;        torch.set_rng_state(state)</div><div class="line"><a name="l01571"></a><span class="lineno"> 1571</span>&#160;        z = Normal(loc, scale).rsample()</div><div class="line"><a name="l01572"></a><span class="lineno"> 1572</span>&#160;        z.backward(torch.ones_like(z))</div><div class="line"><a name="l01573"></a><span class="lineno"> 1573</span>&#160;        self.assertEqual(loc.grad, torch.ones_like(loc))</div><div class="line"><a name="l01574"></a><span class="lineno"> 1574</span>&#160;        self.assertEqual(scale.grad, eps)</div><div class="line"><a name="l01575"></a><span class="lineno"> 1575</span>&#160;        loc.grad.zero_()</div><div class="line"><a name="l01576"></a><span class="lineno"> 1576</span>&#160;        scale.grad.zero_()</div><div class="line"><a name="l01577"></a><span class="lineno"> 1577</span>&#160;        self.assertEqual(z.size(), (5, 5))</div><div class="line"><a name="l01578"></a><span class="lineno"> 1578</span>&#160;</div><div class="line"><a name="l01579"></a><span class="lineno"> 1579</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01580"></a><span class="lineno"> 1580</span>&#160;            m = loc.view(-1)[idx]</div><div class="line"><a name="l01581"></a><span class="lineno"> 1581</span>&#160;            s = scale.view(-1)[idx]</div><div class="line"><a name="l01582"></a><span class="lineno"> 1582</span>&#160;            expected = (math.exp(-(x - m) ** 2 / (2 * s ** 2)) /</div><div class="line"><a name="l01583"></a><span class="lineno"> 1583</span>&#160;                        math.sqrt(2 * math.pi * s ** 2))</div><div class="line"><a name="l01584"></a><span class="lineno"> 1584</span>&#160;            self.assertAlmostEqual(log_prob, math.log(expected), places=3)</div><div class="line"><a name="l01585"></a><span class="lineno"> 1585</span>&#160;</div><div class="line"><a name="l01586"></a><span class="lineno"> 1586</span>&#160;        self._check_log_prob(Normal(loc, scale), ref_log_prob)</div><div class="line"><a name="l01587"></a><span class="lineno"> 1587</span>&#160;</div><div class="line"><a name="l01588"></a><span class="lineno"> 1588</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01589"></a><span class="lineno"> 1589</span>&#160;    <span class="keyword">def </span>test_normal_sample(self):</div><div class="line"><a name="l01590"></a><span class="lineno"> 1590</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01591"></a><span class="lineno"> 1591</span>&#160;        <span class="keywordflow">for</span> loc, scale <span class="keywordflow">in</span> product([-1.0, 0.0, 1.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l01592"></a><span class="lineno"> 1592</span>&#160;            self._check_sampler_sampler(Normal(loc, scale),</div><div class="line"><a name="l01593"></a><span class="lineno"> 1593</span>&#160;                                        scipy.stats.norm(loc=loc, scale=scale),</div><div class="line"><a name="l01594"></a><span class="lineno"> 1594</span>&#160;                                        <span class="stringliteral">&#39;Normal(mean={}, std={})&#39;</span>.format(loc, scale))</div><div class="line"><a name="l01595"></a><span class="lineno"> 1595</span>&#160;</div><div class="line"><a name="l01596"></a><span class="lineno"> 1596</span>&#160;    <span class="keyword">def </span>test_lowrank_multivariate_normal_shape(self):</div><div class="line"><a name="l01597"></a><span class="lineno"> 1597</span>&#160;        mean = torch.randn(5, 3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01598"></a><span class="lineno"> 1598</span>&#160;        mean_no_batch = torch.randn(3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01599"></a><span class="lineno"> 1599</span>&#160;        mean_multi_batch = torch.randn(6, 5, 3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01600"></a><span class="lineno"> 1600</span>&#160;</div><div class="line"><a name="l01601"></a><span class="lineno"> 1601</span>&#160;        <span class="comment"># construct PSD covariance</span></div><div class="line"><a name="l01602"></a><span class="lineno"> 1602</span>&#160;        cov_factor = torch.randn(3, 1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01603"></a><span class="lineno"> 1603</span>&#160;        cov_diag = torch.randn(3).abs().requires_grad_()</div><div class="line"><a name="l01604"></a><span class="lineno"> 1604</span>&#160;</div><div class="line"><a name="l01605"></a><span class="lineno"> 1605</span>&#160;        <span class="comment"># construct batch of PSD covariances</span></div><div class="line"><a name="l01606"></a><span class="lineno"> 1606</span>&#160;        cov_factor_batched = torch.randn(6, 5, 3, 2, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01607"></a><span class="lineno"> 1607</span>&#160;        cov_diag_batched = torch.randn(6, 5, 3).abs().requires_grad_()</div><div class="line"><a name="l01608"></a><span class="lineno"> 1608</span>&#160;</div><div class="line"><a name="l01609"></a><span class="lineno"> 1609</span>&#160;        <span class="comment"># ensure that sample, batch, event shapes all handled correctly</span></div><div class="line"><a name="l01610"></a><span class="lineno"> 1610</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean, cov_factor, cov_diag)</div><div class="line"><a name="l01611"></a><span class="lineno"> 1611</span>&#160;                         .sample().size(), (5, 3))</div><div class="line"><a name="l01612"></a><span class="lineno"> 1612</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_no_batch, cov_factor, cov_diag)</div><div class="line"><a name="l01613"></a><span class="lineno"> 1613</span>&#160;                         .sample().size(), (3,))</div><div class="line"><a name="l01614"></a><span class="lineno"> 1614</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_multi_batch, cov_factor, cov_diag)</div><div class="line"><a name="l01615"></a><span class="lineno"> 1615</span>&#160;                         .sample().size(), (6, 5, 3))</div><div class="line"><a name="l01616"></a><span class="lineno"> 1616</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean, cov_factor, cov_diag)</div><div class="line"><a name="l01617"></a><span class="lineno"> 1617</span>&#160;                         .sample((2,)).size(), (2, 5, 3))</div><div class="line"><a name="l01618"></a><span class="lineno"> 1618</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_no_batch, cov_factor, cov_diag)</div><div class="line"><a name="l01619"></a><span class="lineno"> 1619</span>&#160;                         .sample((2,)).size(), (2, 3))</div><div class="line"><a name="l01620"></a><span class="lineno"> 1620</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_multi_batch, cov_factor, cov_diag)</div><div class="line"><a name="l01621"></a><span class="lineno"> 1621</span>&#160;                         .sample((2,)).size(), (2, 6, 5, 3))</div><div class="line"><a name="l01622"></a><span class="lineno"> 1622</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean, cov_factor, cov_diag)</div><div class="line"><a name="l01623"></a><span class="lineno"> 1623</span>&#160;                         .sample((2, 7)).size(), (2, 7, 5, 3))</div><div class="line"><a name="l01624"></a><span class="lineno"> 1624</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_no_batch, cov_factor, cov_diag)</div><div class="line"><a name="l01625"></a><span class="lineno"> 1625</span>&#160;                         .sample((2, 7)).size(), (2, 7, 3))</div><div class="line"><a name="l01626"></a><span class="lineno"> 1626</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_multi_batch, cov_factor, cov_diag)</div><div class="line"><a name="l01627"></a><span class="lineno"> 1627</span>&#160;                         .sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01628"></a><span class="lineno"> 1628</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean, cov_factor_batched, cov_diag_batched)</div><div class="line"><a name="l01629"></a><span class="lineno"> 1629</span>&#160;                         .sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01630"></a><span class="lineno"> 1630</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_no_batch, cov_factor_batched, cov_diag_batched)</div><div class="line"><a name="l01631"></a><span class="lineno"> 1631</span>&#160;                         .sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01632"></a><span class="lineno"> 1632</span>&#160;        self.assertEqual(LowRankMultivariateNormal(mean_multi_batch, cov_factor_batched, cov_diag_batched)</div><div class="line"><a name="l01633"></a><span class="lineno"> 1633</span>&#160;                         .sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01634"></a><span class="lineno"> 1634</span>&#160;</div><div class="line"><a name="l01635"></a><span class="lineno"> 1635</span>&#160;        <span class="comment"># check gradients</span></div><div class="line"><a name="l01636"></a><span class="lineno"> 1636</span>&#160;        self._gradcheck_log_prob(LowRankMultivariateNormal,</div><div class="line"><a name="l01637"></a><span class="lineno"> 1637</span>&#160;                                 (mean, cov_factor, cov_diag))</div><div class="line"><a name="l01638"></a><span class="lineno"> 1638</span>&#160;        self._gradcheck_log_prob(LowRankMultivariateNormal,</div><div class="line"><a name="l01639"></a><span class="lineno"> 1639</span>&#160;                                 (mean_multi_batch, cov_factor, cov_diag))</div><div class="line"><a name="l01640"></a><span class="lineno"> 1640</span>&#160;        self._gradcheck_log_prob(LowRankMultivariateNormal,</div><div class="line"><a name="l01641"></a><span class="lineno"> 1641</span>&#160;                                 (mean_multi_batch, cov_factor_batched, cov_diag_batched))</div><div class="line"><a name="l01642"></a><span class="lineno"> 1642</span>&#160;</div><div class="line"><a name="l01643"></a><span class="lineno"> 1643</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01644"></a><span class="lineno"> 1644</span>&#160;    <span class="keyword">def </span>test_lowrank_multivariate_normal_log_prob(self):</div><div class="line"><a name="l01645"></a><span class="lineno"> 1645</span>&#160;        mean = torch.randn(3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01646"></a><span class="lineno"> 1646</span>&#160;        cov_factor = torch.randn(3, 1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01647"></a><span class="lineno"> 1647</span>&#160;        cov_diag = torch.randn(3).abs().requires_grad_()</div><div class="line"><a name="l01648"></a><span class="lineno"> 1648</span>&#160;        cov = cov_factor.matmul(cov_factor.t()) + cov_diag.diag()</div><div class="line"><a name="l01649"></a><span class="lineno"> 1649</span>&#160;</div><div class="line"><a name="l01650"></a><span class="lineno"> 1650</span>&#160;        <span class="comment"># check that logprob values match scipy logpdf,</span></div><div class="line"><a name="l01651"></a><span class="lineno"> 1651</span>&#160;        <span class="comment"># and that covariance and scale_tril parameters are equivalent</span></div><div class="line"><a name="l01652"></a><span class="lineno"> 1652</span>&#160;        dist1 = LowRankMultivariateNormal(mean, cov_factor, cov_diag)</div><div class="line"><a name="l01653"></a><span class="lineno"> 1653</span>&#160;        ref_dist = scipy.stats.multivariate_normal(mean.detach().numpy(), cov.detach().numpy())</div><div class="line"><a name="l01654"></a><span class="lineno"> 1654</span>&#160;</div><div class="line"><a name="l01655"></a><span class="lineno"> 1655</span>&#160;        x = dist1.sample((10,))</div><div class="line"><a name="l01656"></a><span class="lineno"> 1656</span>&#160;        expected = ref_dist.logpdf(x.numpy())</div><div class="line"><a name="l01657"></a><span class="lineno"> 1657</span>&#160;</div><div class="line"><a name="l01658"></a><span class="lineno"> 1658</span>&#160;        self.assertAlmostEqual(0.0, np.mean((dist1.log_prob(x).detach().numpy() - expected)**2), places=3)</div><div class="line"><a name="l01659"></a><span class="lineno"> 1659</span>&#160;</div><div class="line"><a name="l01660"></a><span class="lineno"> 1660</span>&#160;        <span class="comment"># Double-check that batched versions behave the same as unbatched</span></div><div class="line"><a name="l01661"></a><span class="lineno"> 1661</span>&#160;        mean = torch.randn(5, 3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01662"></a><span class="lineno"> 1662</span>&#160;        cov_factor = torch.randn(5, 3, 2, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01663"></a><span class="lineno"> 1663</span>&#160;        cov_diag = torch.randn(5, 3).abs().requires_grad_()</div><div class="line"><a name="l01664"></a><span class="lineno"> 1664</span>&#160;</div><div class="line"><a name="l01665"></a><span class="lineno"> 1665</span>&#160;        dist_batched = LowRankMultivariateNormal(mean, cov_factor, cov_diag)</div><div class="line"><a name="l01666"></a><span class="lineno"> 1666</span>&#160;        dist_unbatched = [LowRankMultivariateNormal(mean[i], cov_factor[i], cov_diag[i])</div><div class="line"><a name="l01667"></a><span class="lineno"> 1667</span>&#160;                          <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(mean.size(0))]</div><div class="line"><a name="l01668"></a><span class="lineno"> 1668</span>&#160;</div><div class="line"><a name="l01669"></a><span class="lineno"> 1669</span>&#160;        x = dist_batched.sample((10,))</div><div class="line"><a name="l01670"></a><span class="lineno"> 1670</span>&#160;        batched_prob = dist_batched.log_prob(x)</div><div class="line"><a name="l01671"></a><span class="lineno"> 1671</span>&#160;        unbatched_prob = torch.stack([dist_unbatched[i].log_prob(x[:, i]) <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(5)]).t()</div><div class="line"><a name="l01672"></a><span class="lineno"> 1672</span>&#160;</div><div class="line"><a name="l01673"></a><span class="lineno"> 1673</span>&#160;        self.assertEqual(batched_prob.shape, unbatched_prob.shape)</div><div class="line"><a name="l01674"></a><span class="lineno"> 1674</span>&#160;        self.assertAlmostEqual(0.0, (batched_prob - unbatched_prob).abs().max(), places=3)</div><div class="line"><a name="l01675"></a><span class="lineno"> 1675</span>&#160;</div><div class="line"><a name="l01676"></a><span class="lineno"> 1676</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01677"></a><span class="lineno"> 1677</span>&#160;    <span class="keyword">def </span>test_lowrank_multivariate_normal_sample(self):</div><div class="line"><a name="l01678"></a><span class="lineno"> 1678</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01679"></a><span class="lineno"> 1679</span>&#160;        mean = torch.randn(5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01680"></a><span class="lineno"> 1680</span>&#160;        cov_factor = torch.randn(5, 1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01681"></a><span class="lineno"> 1681</span>&#160;        cov_diag = torch.randn(5).abs().requires_grad_()</div><div class="line"><a name="l01682"></a><span class="lineno"> 1682</span>&#160;        cov = cov_factor.matmul(cov_factor.t()) + cov_diag.diag()</div><div class="line"><a name="l01683"></a><span class="lineno"> 1683</span>&#160;</div><div class="line"><a name="l01684"></a><span class="lineno"> 1684</span>&#160;        self._check_sampler_sampler(LowRankMultivariateNormal(mean, cov_factor, cov_diag),</div><div class="line"><a name="l01685"></a><span class="lineno"> 1685</span>&#160;                                    scipy.stats.multivariate_normal(mean.detach().numpy(), cov.detach().numpy()),</div><div class="line"><a name="l01686"></a><span class="lineno"> 1686</span>&#160;                                    <span class="stringliteral">&#39;LowRankMultivariateNormal(loc={}, cov_factor={}, cov_diag={})&#39;</span></div><div class="line"><a name="l01687"></a><span class="lineno"> 1687</span>&#160;                                    .format(mean, cov_factor, cov_diag), multivariate=<span class="keyword">True</span>)</div><div class="line"><a name="l01688"></a><span class="lineno"> 1688</span>&#160;</div><div class="line"><a name="l01689"></a><span class="lineno"> 1689</span>&#160;    <span class="keyword">def </span>test_lowrank_multivariate_normal_properties(self):</div><div class="line"><a name="l01690"></a><span class="lineno"> 1690</span>&#160;        loc = torch.randn(5)</div><div class="line"><a name="l01691"></a><span class="lineno"> 1691</span>&#160;        cov_factor = torch.randn(5, 2)</div><div class="line"><a name="l01692"></a><span class="lineno"> 1692</span>&#160;        cov_diag = torch.randn(5).abs()</div><div class="line"><a name="l01693"></a><span class="lineno"> 1693</span>&#160;        cov = cov_factor.matmul(cov_factor.t()) + cov_diag.diag()</div><div class="line"><a name="l01694"></a><span class="lineno"> 1694</span>&#160;        m1 = LowRankMultivariateNormal(loc, cov_factor, cov_diag)</div><div class="line"><a name="l01695"></a><span class="lineno"> 1695</span>&#160;        m2 = MultivariateNormal(loc=loc, covariance_matrix=cov)</div><div class="line"><a name="l01696"></a><span class="lineno"> 1696</span>&#160;        self.assertEqual(m1.mean, m2.mean)</div><div class="line"><a name="l01697"></a><span class="lineno"> 1697</span>&#160;        self.assertEqual(m1.variance, m2.variance)</div><div class="line"><a name="l01698"></a><span class="lineno"> 1698</span>&#160;        self.assertEqual(m1.covariance_matrix, m2.covariance_matrix)</div><div class="line"><a name="l01699"></a><span class="lineno"> 1699</span>&#160;        self.assertEqual(m1.scale_tril, m2.scale_tril)</div><div class="line"><a name="l01700"></a><span class="lineno"> 1700</span>&#160;        self.assertEqual(m1.precision_matrix, m2.precision_matrix)</div><div class="line"><a name="l01701"></a><span class="lineno"> 1701</span>&#160;        self.assertEqual(m1.entropy(), m2.entropy())</div><div class="line"><a name="l01702"></a><span class="lineno"> 1702</span>&#160;</div><div class="line"><a name="l01703"></a><span class="lineno"> 1703</span>&#160;    <span class="keyword">def </span>test_lowrank_multivariate_normal_moments(self):</div><div class="line"><a name="l01704"></a><span class="lineno"> 1704</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01705"></a><span class="lineno"> 1705</span>&#160;        mean = torch.randn(5)</div><div class="line"><a name="l01706"></a><span class="lineno"> 1706</span>&#160;        cov_factor = torch.randn(5, 2)</div><div class="line"><a name="l01707"></a><span class="lineno"> 1707</span>&#160;        cov_diag = torch.randn(5).abs()</div><div class="line"><a name="l01708"></a><span class="lineno"> 1708</span>&#160;        d = LowRankMultivariateNormal(mean, cov_factor, cov_diag)</div><div class="line"><a name="l01709"></a><span class="lineno"> 1709</span>&#160;        samples = d.rsample((100000,))</div><div class="line"><a name="l01710"></a><span class="lineno"> 1710</span>&#160;        empirical_mean = samples.mean(0)</div><div class="line"><a name="l01711"></a><span class="lineno"> 1711</span>&#160;        self.assertEqual(d.mean, empirical_mean, prec=0.01)</div><div class="line"><a name="l01712"></a><span class="lineno"> 1712</span>&#160;        empirical_var = samples.var(0)</div><div class="line"><a name="l01713"></a><span class="lineno"> 1713</span>&#160;        self.assertEqual(d.variance, empirical_var, prec=0.02)</div><div class="line"><a name="l01714"></a><span class="lineno"> 1714</span>&#160;</div><div class="line"><a name="l01715"></a><span class="lineno"> 1715</span>&#160;    <span class="keyword">def </span>test_multivariate_normal_shape(self):</div><div class="line"><a name="l01716"></a><span class="lineno"> 1716</span>&#160;        mean = torch.randn(5, 3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01717"></a><span class="lineno"> 1717</span>&#160;        mean_no_batch = torch.randn(3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01718"></a><span class="lineno"> 1718</span>&#160;        mean_multi_batch = torch.randn(6, 5, 3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01719"></a><span class="lineno"> 1719</span>&#160;</div><div class="line"><a name="l01720"></a><span class="lineno"> 1720</span>&#160;        <span class="comment"># construct PSD covariance</span></div><div class="line"><a name="l01721"></a><span class="lineno"> 1721</span>&#160;        tmp = torch.randn(3, 10)</div><div class="line"><a name="l01722"></a><span class="lineno"> 1722</span>&#160;        cov = (torch.matmul(tmp, tmp.t()) / tmp.size(-1)).requires_grad_()</div><div class="line"><a name="l01723"></a><span class="lineno"> 1723</span>&#160;        prec = cov.inverse().requires_grad_()</div><div class="line"><a name="l01724"></a><span class="lineno"> 1724</span>&#160;        scale_tril = torch.cholesky(cov, upper=<span class="keyword">False</span>).requires_grad_()</div><div class="line"><a name="l01725"></a><span class="lineno"> 1725</span>&#160;</div><div class="line"><a name="l01726"></a><span class="lineno"> 1726</span>&#160;        <span class="comment"># construct batch of PSD covariances</span></div><div class="line"><a name="l01727"></a><span class="lineno"> 1727</span>&#160;        tmp = torch.randn(6, 5, 3, 10)</div><div class="line"><a name="l01728"></a><span class="lineno"> 1728</span>&#160;        cov_batched = (tmp.unsqueeze(-2) * tmp.unsqueeze(-3)).mean(-1).requires_grad_()</div><div class="line"><a name="l01729"></a><span class="lineno"> 1729</span>&#160;        prec_batched = [C.inverse() <span class="keywordflow">for</span> C <span class="keywordflow">in</span> cov_batched.view((-1, 3, 3))]</div><div class="line"><a name="l01730"></a><span class="lineno"> 1730</span>&#160;        prec_batched = torch.stack(prec_batched).view(cov_batched.shape)</div><div class="line"><a name="l01731"></a><span class="lineno"> 1731</span>&#160;        scale_tril_batched = [torch.cholesky(C, upper=<span class="keyword">False</span>) <span class="keywordflow">for</span> C <span class="keywordflow">in</span> cov_batched.view((-1, 3, 3))]</div><div class="line"><a name="l01732"></a><span class="lineno"> 1732</span>&#160;        scale_tril_batched = torch.stack(scale_tril_batched).view(cov_batched.shape)</div><div class="line"><a name="l01733"></a><span class="lineno"> 1733</span>&#160;</div><div class="line"><a name="l01734"></a><span class="lineno"> 1734</span>&#160;        <span class="comment"># ensure that sample, batch, event shapes all handled correctly</span></div><div class="line"><a name="l01735"></a><span class="lineno"> 1735</span>&#160;        self.assertEqual(MultivariateNormal(mean, cov).sample().size(), (5, 3))</div><div class="line"><a name="l01736"></a><span class="lineno"> 1736</span>&#160;        self.assertEqual(MultivariateNormal(mean_no_batch, cov).sample().size(), (3,))</div><div class="line"><a name="l01737"></a><span class="lineno"> 1737</span>&#160;        self.assertEqual(MultivariateNormal(mean_multi_batch, cov).sample().size(), (6, 5, 3))</div><div class="line"><a name="l01738"></a><span class="lineno"> 1738</span>&#160;        self.assertEqual(MultivariateNormal(mean, cov).sample((2,)).size(), (2, 5, 3))</div><div class="line"><a name="l01739"></a><span class="lineno"> 1739</span>&#160;        self.assertEqual(MultivariateNormal(mean_no_batch, cov).sample((2,)).size(), (2, 3))</div><div class="line"><a name="l01740"></a><span class="lineno"> 1740</span>&#160;        self.assertEqual(MultivariateNormal(mean_multi_batch, cov).sample((2,)).size(), (2, 6, 5, 3))</div><div class="line"><a name="l01741"></a><span class="lineno"> 1741</span>&#160;        self.assertEqual(MultivariateNormal(mean, cov).sample((2, 7)).size(), (2, 7, 5, 3))</div><div class="line"><a name="l01742"></a><span class="lineno"> 1742</span>&#160;        self.assertEqual(MultivariateNormal(mean_no_batch, cov).sample((2, 7)).size(), (2, 7, 3))</div><div class="line"><a name="l01743"></a><span class="lineno"> 1743</span>&#160;        self.assertEqual(MultivariateNormal(mean_multi_batch, cov).sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01744"></a><span class="lineno"> 1744</span>&#160;        self.assertEqual(MultivariateNormal(mean, cov_batched).sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01745"></a><span class="lineno"> 1745</span>&#160;        self.assertEqual(MultivariateNormal(mean_no_batch, cov_batched).sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01746"></a><span class="lineno"> 1746</span>&#160;        self.assertEqual(MultivariateNormal(mean_multi_batch, cov_batched).sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01747"></a><span class="lineno"> 1747</span>&#160;        self.assertEqual(MultivariateNormal(mean, precision_matrix=prec).sample((2, 7)).size(), (2, 7, 5, 3))</div><div class="line"><a name="l01748"></a><span class="lineno"> 1748</span>&#160;        self.assertEqual(MultivariateNormal(mean, precision_matrix=prec_batched).sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01749"></a><span class="lineno"> 1749</span>&#160;        self.assertEqual(MultivariateNormal(mean, scale_tril=scale_tril).sample((2, 7)).size(), (2, 7, 5, 3))</div><div class="line"><a name="l01750"></a><span class="lineno"> 1750</span>&#160;        self.assertEqual(MultivariateNormal(mean, scale_tril=scale_tril_batched).sample((2, 7)).size(), (2, 7, 6, 5, 3))</div><div class="line"><a name="l01751"></a><span class="lineno"> 1751</span>&#160;</div><div class="line"><a name="l01752"></a><span class="lineno"> 1752</span>&#160;        <span class="comment"># check gradients</span></div><div class="line"><a name="l01753"></a><span class="lineno"> 1753</span>&#160;        self._gradcheck_log_prob(MultivariateNormal, (mean, cov))</div><div class="line"><a name="l01754"></a><span class="lineno"> 1754</span>&#160;        self._gradcheck_log_prob(MultivariateNormal, (mean_multi_batch, cov))</div><div class="line"><a name="l01755"></a><span class="lineno"> 1755</span>&#160;        self._gradcheck_log_prob(MultivariateNormal, (mean_multi_batch, cov_batched))</div><div class="line"><a name="l01756"></a><span class="lineno"> 1756</span>&#160;        self._gradcheck_log_prob(MultivariateNormal, (mean, <span class="keywordtype">None</span>, prec))</div><div class="line"><a name="l01757"></a><span class="lineno"> 1757</span>&#160;        self._gradcheck_log_prob(MultivariateNormal, (mean_no_batch, <span class="keywordtype">None</span>, prec_batched))</div><div class="line"><a name="l01758"></a><span class="lineno"> 1758</span>&#160;        self._gradcheck_log_prob(MultivariateNormal, (mean, <span class="keywordtype">None</span>, <span class="keywordtype">None</span>, scale_tril))</div><div class="line"><a name="l01759"></a><span class="lineno"> 1759</span>&#160;        self._gradcheck_log_prob(MultivariateNormal, (mean_no_batch, <span class="keywordtype">None</span>, <span class="keywordtype">None</span>, scale_tril_batched))</div><div class="line"><a name="l01760"></a><span class="lineno"> 1760</span>&#160;</div><div class="line"><a name="l01761"></a><span class="lineno"> 1761</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01762"></a><span class="lineno"> 1762</span>&#160;    <span class="keyword">def </span>test_multivariate_normal_log_prob(self):</div><div class="line"><a name="l01763"></a><span class="lineno"> 1763</span>&#160;        mean = torch.randn(3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01764"></a><span class="lineno"> 1764</span>&#160;        tmp = torch.randn(3, 10)</div><div class="line"><a name="l01765"></a><span class="lineno"> 1765</span>&#160;        cov = (torch.matmul(tmp, tmp.t()) / tmp.size(-1)).requires_grad_()</div><div class="line"><a name="l01766"></a><span class="lineno"> 1766</span>&#160;        prec = cov.inverse().requires_grad_()</div><div class="line"><a name="l01767"></a><span class="lineno"> 1767</span>&#160;        scale_tril = torch.cholesky(cov, upper=<span class="keyword">False</span>).requires_grad_()</div><div class="line"><a name="l01768"></a><span class="lineno"> 1768</span>&#160;</div><div class="line"><a name="l01769"></a><span class="lineno"> 1769</span>&#160;        <span class="comment"># check that logprob values match scipy logpdf,</span></div><div class="line"><a name="l01770"></a><span class="lineno"> 1770</span>&#160;        <span class="comment"># and that covariance and scale_tril parameters are equivalent</span></div><div class="line"><a name="l01771"></a><span class="lineno"> 1771</span>&#160;        dist1 = MultivariateNormal(mean, cov)</div><div class="line"><a name="l01772"></a><span class="lineno"> 1772</span>&#160;        dist2 = MultivariateNormal(mean, precision_matrix=prec)</div><div class="line"><a name="l01773"></a><span class="lineno"> 1773</span>&#160;        dist3 = MultivariateNormal(mean, scale_tril=scale_tril)</div><div class="line"><a name="l01774"></a><span class="lineno"> 1774</span>&#160;        ref_dist = scipy.stats.multivariate_normal(mean.detach().numpy(), cov.detach().numpy())</div><div class="line"><a name="l01775"></a><span class="lineno"> 1775</span>&#160;</div><div class="line"><a name="l01776"></a><span class="lineno"> 1776</span>&#160;        x = dist1.sample((10,))</div><div class="line"><a name="l01777"></a><span class="lineno"> 1777</span>&#160;        expected = ref_dist.logpdf(x.numpy())</div><div class="line"><a name="l01778"></a><span class="lineno"> 1778</span>&#160;</div><div class="line"><a name="l01779"></a><span class="lineno"> 1779</span>&#160;        self.assertAlmostEqual(0.0, np.mean((dist1.log_prob(x).detach().numpy() - expected)**2), places=3)</div><div class="line"><a name="l01780"></a><span class="lineno"> 1780</span>&#160;        self.assertAlmostEqual(0.0, np.mean((dist2.log_prob(x).detach().numpy() - expected)**2), places=3)</div><div class="line"><a name="l01781"></a><span class="lineno"> 1781</span>&#160;        self.assertAlmostEqual(0.0, np.mean((dist3.log_prob(x).detach().numpy() - expected)**2), places=3)</div><div class="line"><a name="l01782"></a><span class="lineno"> 1782</span>&#160;</div><div class="line"><a name="l01783"></a><span class="lineno"> 1783</span>&#160;        <span class="comment"># Double-check that batched versions behave the same as unbatched</span></div><div class="line"><a name="l01784"></a><span class="lineno"> 1784</span>&#160;        mean = torch.randn(5, 3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01785"></a><span class="lineno"> 1785</span>&#160;        tmp = torch.randn(5, 3, 10)</div><div class="line"><a name="l01786"></a><span class="lineno"> 1786</span>&#160;        cov = (tmp.unsqueeze(-2) * tmp.unsqueeze(-3)).mean(-1).requires_grad_()</div><div class="line"><a name="l01787"></a><span class="lineno"> 1787</span>&#160;</div><div class="line"><a name="l01788"></a><span class="lineno"> 1788</span>&#160;        dist_batched = MultivariateNormal(mean, cov)</div><div class="line"><a name="l01789"></a><span class="lineno"> 1789</span>&#160;        dist_unbatched = [MultivariateNormal(mean[i], cov[i]) <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(mean.size(0))]</div><div class="line"><a name="l01790"></a><span class="lineno"> 1790</span>&#160;</div><div class="line"><a name="l01791"></a><span class="lineno"> 1791</span>&#160;        x = dist_batched.sample((10,))</div><div class="line"><a name="l01792"></a><span class="lineno"> 1792</span>&#160;        batched_prob = dist_batched.log_prob(x)</div><div class="line"><a name="l01793"></a><span class="lineno"> 1793</span>&#160;        unbatched_prob = torch.stack([dist_unbatched[i].log_prob(x[:, i]) <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(5)]).t()</div><div class="line"><a name="l01794"></a><span class="lineno"> 1794</span>&#160;</div><div class="line"><a name="l01795"></a><span class="lineno"> 1795</span>&#160;        self.assertEqual(batched_prob.shape, unbatched_prob.shape)</div><div class="line"><a name="l01796"></a><span class="lineno"> 1796</span>&#160;        self.assertAlmostEqual(0.0, (batched_prob - unbatched_prob).abs().max(), places=3)</div><div class="line"><a name="l01797"></a><span class="lineno"> 1797</span>&#160;</div><div class="line"><a name="l01798"></a><span class="lineno"> 1798</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01799"></a><span class="lineno"> 1799</span>&#160;    <span class="keyword">def </span>test_multivariate_normal_sample(self):</div><div class="line"><a name="l01800"></a><span class="lineno"> 1800</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01801"></a><span class="lineno"> 1801</span>&#160;        mean = torch.randn(3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01802"></a><span class="lineno"> 1802</span>&#160;        tmp = torch.randn(3, 10)</div><div class="line"><a name="l01803"></a><span class="lineno"> 1803</span>&#160;        cov = (torch.matmul(tmp, tmp.t()) / tmp.size(-1)).requires_grad_()</div><div class="line"><a name="l01804"></a><span class="lineno"> 1804</span>&#160;        prec = cov.inverse().requires_grad_()</div><div class="line"><a name="l01805"></a><span class="lineno"> 1805</span>&#160;        scale_tril = torch.cholesky(cov, upper=<span class="keyword">False</span>).requires_grad_()</div><div class="line"><a name="l01806"></a><span class="lineno"> 1806</span>&#160;</div><div class="line"><a name="l01807"></a><span class="lineno"> 1807</span>&#160;        self._check_sampler_sampler(MultivariateNormal(mean, cov),</div><div class="line"><a name="l01808"></a><span class="lineno"> 1808</span>&#160;                                    scipy.stats.multivariate_normal(mean.detach().numpy(), cov.detach().numpy()),</div><div class="line"><a name="l01809"></a><span class="lineno"> 1809</span>&#160;                                    <span class="stringliteral">&#39;MultivariateNormal(loc={}, cov={})&#39;</span>.format(mean, cov),</div><div class="line"><a name="l01810"></a><span class="lineno"> 1810</span>&#160;                                    multivariate=<span class="keyword">True</span>)</div><div class="line"><a name="l01811"></a><span class="lineno"> 1811</span>&#160;        self._check_sampler_sampler(MultivariateNormal(mean, precision_matrix=prec),</div><div class="line"><a name="l01812"></a><span class="lineno"> 1812</span>&#160;                                    scipy.stats.multivariate_normal(mean.detach().numpy(), cov.detach().numpy()),</div><div class="line"><a name="l01813"></a><span class="lineno"> 1813</span>&#160;                                    <span class="stringliteral">&#39;MultivariateNormal(loc={}, prec={})&#39;</span>.format(mean, prec),</div><div class="line"><a name="l01814"></a><span class="lineno"> 1814</span>&#160;                                    multivariate=<span class="keyword">True</span>)</div><div class="line"><a name="l01815"></a><span class="lineno"> 1815</span>&#160;        self._check_sampler_sampler(MultivariateNormal(mean, scale_tril=scale_tril),</div><div class="line"><a name="l01816"></a><span class="lineno"> 1816</span>&#160;                                    scipy.stats.multivariate_normal(mean.detach().numpy(), cov.detach().numpy()),</div><div class="line"><a name="l01817"></a><span class="lineno"> 1817</span>&#160;                                    <span class="stringliteral">&#39;MultivariateNormal(loc={}, scale_tril={})&#39;</span>.format(mean, scale_tril),</div><div class="line"><a name="l01818"></a><span class="lineno"> 1818</span>&#160;                                    multivariate=<span class="keyword">True</span>)</div><div class="line"><a name="l01819"></a><span class="lineno"> 1819</span>&#160;</div><div class="line"><a name="l01820"></a><span class="lineno"> 1820</span>&#160;    <span class="keyword">def </span>test_multivariate_normal_properties(self):</div><div class="line"><a name="l01821"></a><span class="lineno"> 1821</span>&#160;        loc = torch.randn(5)</div><div class="line"><a name="l01822"></a><span class="lineno"> 1822</span>&#160;        scale_tril = transform_to(constraints.lower_cholesky)(torch.randn(5, 5))</div><div class="line"><a name="l01823"></a><span class="lineno"> 1823</span>&#160;        m = MultivariateNormal(loc=loc, scale_tril=scale_tril)</div><div class="line"><a name="l01824"></a><span class="lineno"> 1824</span>&#160;        self.assertEqual(m.covariance_matrix, m.scale_tril.mm(m.scale_tril.t()))</div><div class="line"><a name="l01825"></a><span class="lineno"> 1825</span>&#160;        self.assertEqual(m.covariance_matrix.mm(m.precision_matrix), torch.eye(m.event_shape[0]))</div><div class="line"><a name="l01826"></a><span class="lineno"> 1826</span>&#160;        self.assertEqual(m.scale_tril, torch.cholesky(m.covariance_matrix, upper=<span class="keyword">False</span>))</div><div class="line"><a name="l01827"></a><span class="lineno"> 1827</span>&#160;</div><div class="line"><a name="l01828"></a><span class="lineno"> 1828</span>&#160;    <span class="keyword">def </span>test_multivariate_normal_moments(self):</div><div class="line"><a name="l01829"></a><span class="lineno"> 1829</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01830"></a><span class="lineno"> 1830</span>&#160;        mean = torch.randn(5)</div><div class="line"><a name="l01831"></a><span class="lineno"> 1831</span>&#160;        scale_tril = transform_to(constraints.lower_cholesky)(torch.randn(5, 5))</div><div class="line"><a name="l01832"></a><span class="lineno"> 1832</span>&#160;        d = MultivariateNormal(mean, scale_tril=scale_tril)</div><div class="line"><a name="l01833"></a><span class="lineno"> 1833</span>&#160;        samples = d.rsample((100000,))</div><div class="line"><a name="l01834"></a><span class="lineno"> 1834</span>&#160;        empirical_mean = samples.mean(0)</div><div class="line"><a name="l01835"></a><span class="lineno"> 1835</span>&#160;        self.assertEqual(d.mean, empirical_mean, prec=0.01)</div><div class="line"><a name="l01836"></a><span class="lineno"> 1836</span>&#160;        empirical_var = samples.var(0)</div><div class="line"><a name="l01837"></a><span class="lineno"> 1837</span>&#160;        self.assertEqual(d.variance, empirical_var, prec=0.05)</div><div class="line"><a name="l01838"></a><span class="lineno"> 1838</span>&#160;</div><div class="line"><a name="l01839"></a><span class="lineno"> 1839</span>&#160;    <span class="keyword">def </span>test_exponential(self):</div><div class="line"><a name="l01840"></a><span class="lineno"> 1840</span>&#160;        rate = torch.randn(5, 5).abs().requires_grad_()</div><div class="line"><a name="l01841"></a><span class="lineno"> 1841</span>&#160;        rate_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l01842"></a><span class="lineno"> 1842</span>&#160;        self.assertEqual(Exponential(rate).sample().size(), (5, 5))</div><div class="line"><a name="l01843"></a><span class="lineno"> 1843</span>&#160;        self.assertEqual(Exponential(rate).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01844"></a><span class="lineno"> 1844</span>&#160;        self.assertEqual(Exponential(rate_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01845"></a><span class="lineno"> 1845</span>&#160;        self.assertEqual(Exponential(rate_1d).sample().size(), (1,))</div><div class="line"><a name="l01846"></a><span class="lineno"> 1846</span>&#160;        self.assertEqual(Exponential(0.2).sample((1,)).size(), (1,))</div><div class="line"><a name="l01847"></a><span class="lineno"> 1847</span>&#160;        self.assertEqual(Exponential(50.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01848"></a><span class="lineno"> 1848</span>&#160;</div><div class="line"><a name="l01849"></a><span class="lineno"> 1849</span>&#160;        self._gradcheck_log_prob(Exponential, (rate,))</div><div class="line"><a name="l01850"></a><span class="lineno"> 1850</span>&#160;        state = torch.get_rng_state()</div><div class="line"><a name="l01851"></a><span class="lineno"> 1851</span>&#160;        eps = rate.new(rate.size()).exponential_()</div><div class="line"><a name="l01852"></a><span class="lineno"> 1852</span>&#160;        torch.set_rng_state(state)</div><div class="line"><a name="l01853"></a><span class="lineno"> 1853</span>&#160;        z = Exponential(rate).rsample()</div><div class="line"><a name="l01854"></a><span class="lineno"> 1854</span>&#160;        z.backward(torch.ones_like(z))</div><div class="line"><a name="l01855"></a><span class="lineno"> 1855</span>&#160;        self.assertEqual(rate.grad, -eps / rate**2)</div><div class="line"><a name="l01856"></a><span class="lineno"> 1856</span>&#160;        rate.grad.zero_()</div><div class="line"><a name="l01857"></a><span class="lineno"> 1857</span>&#160;        self.assertEqual(z.size(), (5, 5))</div><div class="line"><a name="l01858"></a><span class="lineno"> 1858</span>&#160;</div><div class="line"><a name="l01859"></a><span class="lineno"> 1859</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01860"></a><span class="lineno"> 1860</span>&#160;            m = rate.view(-1)[idx]</div><div class="line"><a name="l01861"></a><span class="lineno"> 1861</span>&#160;            expected = math.log(m) - m * x</div><div class="line"><a name="l01862"></a><span class="lineno"> 1862</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01863"></a><span class="lineno"> 1863</span>&#160;</div><div class="line"><a name="l01864"></a><span class="lineno"> 1864</span>&#160;        self._check_log_prob(Exponential(rate), ref_log_prob)</div><div class="line"><a name="l01865"></a><span class="lineno"> 1865</span>&#160;</div><div class="line"><a name="l01866"></a><span class="lineno"> 1866</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01867"></a><span class="lineno"> 1867</span>&#160;    <span class="keyword">def </span>test_exponential_sample(self):</div><div class="line"><a name="l01868"></a><span class="lineno"> 1868</span>&#160;        set_rng_seed(1)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01869"></a><span class="lineno"> 1869</span>&#160;        <span class="keywordflow">for</span> rate <span class="keywordflow">in</span> [1e-5, 1.0, 10.]:</div><div class="line"><a name="l01870"></a><span class="lineno"> 1870</span>&#160;            self._check_sampler_sampler(Exponential(rate),</div><div class="line"><a name="l01871"></a><span class="lineno"> 1871</span>&#160;                                        scipy.stats.expon(scale=1. / rate),</div><div class="line"><a name="l01872"></a><span class="lineno"> 1872</span>&#160;                                        <span class="stringliteral">&#39;Exponential(rate={})&#39;</span>.format(rate))</div><div class="line"><a name="l01873"></a><span class="lineno"> 1873</span>&#160;</div><div class="line"><a name="l01874"></a><span class="lineno"> 1874</span>&#160;    <span class="keyword">def </span>test_laplace(self):</div><div class="line"><a name="l01875"></a><span class="lineno"> 1875</span>&#160;        loc = torch.randn(5, 5, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01876"></a><span class="lineno"> 1876</span>&#160;        scale = torch.randn(5, 5).abs().requires_grad_()</div><div class="line"><a name="l01877"></a><span class="lineno"> 1877</span>&#160;        loc_1d = torch.randn(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01878"></a><span class="lineno"> 1878</span>&#160;        scale_1d = torch.randn(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l01879"></a><span class="lineno"> 1879</span>&#160;        loc_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.0, 0.0])</div><div class="line"><a name="l01880"></a><span class="lineno"> 1880</span>&#160;        scale_delta = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1e-5, 1e-5])</div><div class="line"><a name="l01881"></a><span class="lineno"> 1881</span>&#160;        self.assertEqual(Laplace(loc, scale).sample().size(), (5, 5))</div><div class="line"><a name="l01882"></a><span class="lineno"> 1882</span>&#160;        self.assertEqual(Laplace(loc, scale).sample((7,)).size(), (7, 5, 5))</div><div class="line"><a name="l01883"></a><span class="lineno"> 1883</span>&#160;        self.assertEqual(Laplace(loc_1d, scale_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01884"></a><span class="lineno"> 1884</span>&#160;        self.assertEqual(Laplace(loc_1d, scale_1d).sample().size(), (1,))</div><div class="line"><a name="l01885"></a><span class="lineno"> 1885</span>&#160;        self.assertEqual(Laplace(0.2, .6).sample((1,)).size(), (1,))</div><div class="line"><a name="l01886"></a><span class="lineno"> 1886</span>&#160;        self.assertEqual(Laplace(-0.7, 50.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l01887"></a><span class="lineno"> 1887</span>&#160;</div><div class="line"><a name="l01888"></a><span class="lineno"> 1888</span>&#160;        <span class="comment"># sample check for extreme value of mean, std</span></div><div class="line"><a name="l01889"></a><span class="lineno"> 1889</span>&#160;        set_rng_seed(0)</div><div class="line"><a name="l01890"></a><span class="lineno"> 1890</span>&#160;        self.assertEqual(Laplace(loc_delta, scale_delta).sample(sample_shape=(1, 2)),</div><div class="line"><a name="l01891"></a><span class="lineno"> 1891</span>&#160;                         <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[[1.0, 0.0], [1.0, 0.0]]]),</div><div class="line"><a name="l01892"></a><span class="lineno"> 1892</span>&#160;                         prec=1e-4)</div><div class="line"><a name="l01893"></a><span class="lineno"> 1893</span>&#160;</div><div class="line"><a name="l01894"></a><span class="lineno"> 1894</span>&#160;        self._gradcheck_log_prob(Laplace, (loc, scale))</div><div class="line"><a name="l01895"></a><span class="lineno"> 1895</span>&#160;        self._gradcheck_log_prob(Laplace, (loc, 1.0))</div><div class="line"><a name="l01896"></a><span class="lineno"> 1896</span>&#160;        self._gradcheck_log_prob(Laplace, (0.0, scale))</div><div class="line"><a name="l01897"></a><span class="lineno"> 1897</span>&#160;</div><div class="line"><a name="l01898"></a><span class="lineno"> 1898</span>&#160;        state = torch.get_rng_state()</div><div class="line"><a name="l01899"></a><span class="lineno"> 1899</span>&#160;        eps = torch.ones_like(loc).uniform_(-.5, .5)</div><div class="line"><a name="l01900"></a><span class="lineno"> 1900</span>&#160;        torch.set_rng_state(state)</div><div class="line"><a name="l01901"></a><span class="lineno"> 1901</span>&#160;        z = Laplace(loc, scale).rsample()</div><div class="line"><a name="l01902"></a><span class="lineno"> 1902</span>&#160;        z.backward(torch.ones_like(z))</div><div class="line"><a name="l01903"></a><span class="lineno"> 1903</span>&#160;        self.assertEqual(loc.grad, torch.ones_like(loc))</div><div class="line"><a name="l01904"></a><span class="lineno"> 1904</span>&#160;        self.assertEqual(scale.grad, -eps.sign() * torch.log1p(-2 * eps.abs()))</div><div class="line"><a name="l01905"></a><span class="lineno"> 1905</span>&#160;        loc.grad.zero_()</div><div class="line"><a name="l01906"></a><span class="lineno"> 1906</span>&#160;        scale.grad.zero_()</div><div class="line"><a name="l01907"></a><span class="lineno"> 1907</span>&#160;        self.assertEqual(z.size(), (5, 5))</div><div class="line"><a name="l01908"></a><span class="lineno"> 1908</span>&#160;</div><div class="line"><a name="l01909"></a><span class="lineno"> 1909</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01910"></a><span class="lineno"> 1910</span>&#160;            m = loc.view(-1)[idx]</div><div class="line"><a name="l01911"></a><span class="lineno"> 1911</span>&#160;            s = scale.view(-1)[idx]</div><div class="line"><a name="l01912"></a><span class="lineno"> 1912</span>&#160;            expected = (-math.log(2 * s) - abs(x - m) / s)</div><div class="line"><a name="l01913"></a><span class="lineno"> 1913</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01914"></a><span class="lineno"> 1914</span>&#160;</div><div class="line"><a name="l01915"></a><span class="lineno"> 1915</span>&#160;        self._check_log_prob(Laplace(loc, scale), ref_log_prob)</div><div class="line"><a name="l01916"></a><span class="lineno"> 1916</span>&#160;</div><div class="line"><a name="l01917"></a><span class="lineno"> 1917</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01918"></a><span class="lineno"> 1918</span>&#160;    <span class="keyword">def </span>test_laplace_sample(self):</div><div class="line"><a name="l01919"></a><span class="lineno"> 1919</span>&#160;        set_rng_seed(1)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01920"></a><span class="lineno"> 1920</span>&#160;        <span class="keywordflow">for</span> loc, scale <span class="keywordflow">in</span> product([-1.0, 0.0, 1.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l01921"></a><span class="lineno"> 1921</span>&#160;            self._check_sampler_sampler(Laplace(loc, scale),</div><div class="line"><a name="l01922"></a><span class="lineno"> 1922</span>&#160;                                        scipy.stats.laplace(loc=loc, scale=scale),</div><div class="line"><a name="l01923"></a><span class="lineno"> 1923</span>&#160;                                        <span class="stringliteral">&#39;Laplace(loc={}, scale={})&#39;</span>.format(loc, scale))</div><div class="line"><a name="l01924"></a><span class="lineno"> 1924</span>&#160;</div><div class="line"><a name="l01925"></a><span class="lineno"> 1925</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01926"></a><span class="lineno"> 1926</span>&#160;    <span class="keyword">def </span>test_gamma_shape(self):</div><div class="line"><a name="l01927"></a><span class="lineno"> 1927</span>&#160;        alpha = torch.randn(2, 3).exp().requires_grad_()</div><div class="line"><a name="l01928"></a><span class="lineno"> 1928</span>&#160;        beta = torch.randn(2, 3).exp().requires_grad_()</div><div class="line"><a name="l01929"></a><span class="lineno"> 1929</span>&#160;        alpha_1d = torch.randn(1).exp().requires_grad_()</div><div class="line"><a name="l01930"></a><span class="lineno"> 1930</span>&#160;        beta_1d = torch.randn(1).exp().requires_grad_()</div><div class="line"><a name="l01931"></a><span class="lineno"> 1931</span>&#160;        self.assertEqual(Gamma(alpha, beta).sample().size(), (2, 3))</div><div class="line"><a name="l01932"></a><span class="lineno"> 1932</span>&#160;        self.assertEqual(Gamma(alpha, beta).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l01933"></a><span class="lineno"> 1933</span>&#160;        self.assertEqual(Gamma(alpha_1d, beta_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01934"></a><span class="lineno"> 1934</span>&#160;        self.assertEqual(Gamma(alpha_1d, beta_1d).sample().size(), (1,))</div><div class="line"><a name="l01935"></a><span class="lineno"> 1935</span>&#160;        self.assertEqual(Gamma(0.5, 0.5).sample().size(), ())</div><div class="line"><a name="l01936"></a><span class="lineno"> 1936</span>&#160;        self.assertEqual(Gamma(0.5, 0.5).sample((1,)).size(), (1,))</div><div class="line"><a name="l01937"></a><span class="lineno"> 1937</span>&#160;</div><div class="line"><a name="l01938"></a><span class="lineno"> 1938</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01939"></a><span class="lineno"> 1939</span>&#160;            a = alpha.view(-1)[idx].detach()</div><div class="line"><a name="l01940"></a><span class="lineno"> 1940</span>&#160;            b = beta.view(-1)[idx].detach()</div><div class="line"><a name="l01941"></a><span class="lineno"> 1941</span>&#160;            expected = scipy.stats.gamma.logpdf(x, a, scale=1 / b)</div><div class="line"><a name="l01942"></a><span class="lineno"> 1942</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01943"></a><span class="lineno"> 1943</span>&#160;</div><div class="line"><a name="l01944"></a><span class="lineno"> 1944</span>&#160;        self._check_log_prob(Gamma(alpha, beta), ref_log_prob)</div><div class="line"><a name="l01945"></a><span class="lineno"> 1945</span>&#160;</div><div class="line"><a name="l01946"></a><span class="lineno"> 1946</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_CUDA, <span class="stringliteral">&quot;CUDA not found&quot;</span>)</div><div class="line"><a name="l01947"></a><span class="lineno"> 1947</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01948"></a><span class="lineno"> 1948</span>&#160;    <span class="keyword">def </span>test_gamma_gpu_shape(self):</div><div class="line"><a name="l01949"></a><span class="lineno"> 1949</span>&#160;        alpha = torch.randn(2, 3).cuda().exp().requires_grad_()</div><div class="line"><a name="l01950"></a><span class="lineno"> 1950</span>&#160;        beta = torch.randn(2, 3).cuda().exp().requires_grad_()</div><div class="line"><a name="l01951"></a><span class="lineno"> 1951</span>&#160;        alpha_1d = torch.randn(1).cuda().exp().requires_grad_()</div><div class="line"><a name="l01952"></a><span class="lineno"> 1952</span>&#160;        beta_1d = torch.randn(1).cuda().exp().requires_grad_()</div><div class="line"><a name="l01953"></a><span class="lineno"> 1953</span>&#160;        self.assertEqual(Gamma(alpha, beta).sample().size(), (2, 3))</div><div class="line"><a name="l01954"></a><span class="lineno"> 1954</span>&#160;        self.assertEqual(Gamma(alpha, beta).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l01955"></a><span class="lineno"> 1955</span>&#160;        self.assertEqual(Gamma(alpha_1d, beta_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01956"></a><span class="lineno"> 1956</span>&#160;        self.assertEqual(Gamma(alpha_1d, beta_1d).sample().size(), (1,))</div><div class="line"><a name="l01957"></a><span class="lineno"> 1957</span>&#160;        self.assertEqual(Gamma(0.5, 0.5).sample().size(), ())</div><div class="line"><a name="l01958"></a><span class="lineno"> 1958</span>&#160;        self.assertEqual(Gamma(0.5, 0.5).sample((1,)).size(), (1,))</div><div class="line"><a name="l01959"></a><span class="lineno"> 1959</span>&#160;</div><div class="line"><a name="l01960"></a><span class="lineno"> 1960</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l01961"></a><span class="lineno"> 1961</span>&#160;            a = alpha.view(-1)[idx].detach().cpu()</div><div class="line"><a name="l01962"></a><span class="lineno"> 1962</span>&#160;            b = beta.view(-1)[idx].detach().cpu()</div><div class="line"><a name="l01963"></a><span class="lineno"> 1963</span>&#160;            expected = scipy.stats.gamma.logpdf(x.cpu(), a, scale=1 / b)</div><div class="line"><a name="l01964"></a><span class="lineno"> 1964</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l01965"></a><span class="lineno"> 1965</span>&#160;</div><div class="line"><a name="l01966"></a><span class="lineno"> 1966</span>&#160;        self._check_log_prob(Gamma(alpha, beta), ref_log_prob)</div><div class="line"><a name="l01967"></a><span class="lineno"> 1967</span>&#160;</div><div class="line"><a name="l01968"></a><span class="lineno"> 1968</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01969"></a><span class="lineno"> 1969</span>&#160;    <span class="keyword">def </span>test_gamma_sample(self):</div><div class="line"><a name="l01970"></a><span class="lineno"> 1970</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l01971"></a><span class="lineno"> 1971</span>&#160;        <span class="keywordflow">for</span> alpha, beta <span class="keywordflow">in</span> product([0.1, 1.0, 5.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l01972"></a><span class="lineno"> 1972</span>&#160;            self._check_sampler_sampler(Gamma(alpha, beta),</div><div class="line"><a name="l01973"></a><span class="lineno"> 1973</span>&#160;                                        scipy.stats.gamma(alpha, scale=1.0 / beta),</div><div class="line"><a name="l01974"></a><span class="lineno"> 1974</span>&#160;                                        <span class="stringliteral">&#39;Gamma(concentration={}, rate={})&#39;</span>.format(alpha, beta))</div><div class="line"><a name="l01975"></a><span class="lineno"> 1975</span>&#160;</div><div class="line"><a name="l01976"></a><span class="lineno"> 1976</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_CUDA, <span class="stringliteral">&quot;CUDA not found&quot;</span>)</div><div class="line"><a name="l01977"></a><span class="lineno"> 1977</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l01978"></a><span class="lineno"> 1978</span>&#160;    @skipIfRocm</div><div class="line"><a name="l01979"></a><span class="lineno"> 1979</span>&#160;    <span class="keyword">def </span>test_gamma_gpu_sample(self):</div><div class="line"><a name="l01980"></a><span class="lineno"> 1980</span>&#160;        set_rng_seed(0)</div><div class="line"><a name="l01981"></a><span class="lineno"> 1981</span>&#160;        <span class="keywordflow">for</span> alpha, beta <span class="keywordflow">in</span> product([0.1, 1.0, 5.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l01982"></a><span class="lineno"> 1982</span>&#160;            a, b = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([alpha]).cuda(), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([beta]).cuda()</div><div class="line"><a name="l01983"></a><span class="lineno"> 1983</span>&#160;            self._check_sampler_sampler(Gamma(a, b),</div><div class="line"><a name="l01984"></a><span class="lineno"> 1984</span>&#160;                                        scipy.stats.gamma(alpha, scale=1.0 / beta),</div><div class="line"><a name="l01985"></a><span class="lineno"> 1985</span>&#160;                                        <span class="stringliteral">&#39;Gamma(alpha={}, beta={})&#39;</span>.format(alpha, beta),</div><div class="line"><a name="l01986"></a><span class="lineno"> 1986</span>&#160;                                        failure_rate=1e-4)</div><div class="line"><a name="l01987"></a><span class="lineno"> 1987</span>&#160;</div><div class="line"><a name="l01988"></a><span class="lineno"> 1988</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l01989"></a><span class="lineno"> 1989</span>&#160;    <span class="keyword">def </span>test_pareto(self):</div><div class="line"><a name="l01990"></a><span class="lineno"> 1990</span>&#160;        scale = torch.randn(2, 3).abs().requires_grad_()</div><div class="line"><a name="l01991"></a><span class="lineno"> 1991</span>&#160;        alpha = torch.randn(2, 3).abs().requires_grad_()</div><div class="line"><a name="l01992"></a><span class="lineno"> 1992</span>&#160;        scale_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l01993"></a><span class="lineno"> 1993</span>&#160;        alpha_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l01994"></a><span class="lineno"> 1994</span>&#160;        self.assertEqual(Pareto(scale_1d, 0.5).mean, inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l01995"></a><span class="lineno"> 1995</span>&#160;        self.assertEqual(Pareto(scale_1d, 0.5).variance, inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l01996"></a><span class="lineno"> 1996</span>&#160;        self.assertEqual(Pareto(scale, alpha).sample().size(), (2, 3))</div><div class="line"><a name="l01997"></a><span class="lineno"> 1997</span>&#160;        self.assertEqual(Pareto(scale, alpha).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l01998"></a><span class="lineno"> 1998</span>&#160;        self.assertEqual(Pareto(scale_1d, alpha_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l01999"></a><span class="lineno"> 1999</span>&#160;        self.assertEqual(Pareto(scale_1d, alpha_1d).sample().size(), (1,))</div><div class="line"><a name="l02000"></a><span class="lineno"> 2000</span>&#160;        self.assertEqual(Pareto(1.0, 1.0).sample().size(), ())</div><div class="line"><a name="l02001"></a><span class="lineno"> 2001</span>&#160;        self.assertEqual(Pareto(1.0, 1.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l02002"></a><span class="lineno"> 2002</span>&#160;</div><div class="line"><a name="l02003"></a><span class="lineno"> 2003</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l02004"></a><span class="lineno"> 2004</span>&#160;            s = scale.view(-1)[idx].detach()</div><div class="line"><a name="l02005"></a><span class="lineno"> 2005</span>&#160;            a = alpha.view(-1)[idx].detach()</div><div class="line"><a name="l02006"></a><span class="lineno"> 2006</span>&#160;            expected = scipy.stats.pareto.logpdf(x, a, scale=s)</div><div class="line"><a name="l02007"></a><span class="lineno"> 2007</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l02008"></a><span class="lineno"> 2008</span>&#160;</div><div class="line"><a name="l02009"></a><span class="lineno"> 2009</span>&#160;        self._check_log_prob(Pareto(scale, alpha), ref_log_prob)</div><div class="line"><a name="l02010"></a><span class="lineno"> 2010</span>&#160;</div><div class="line"><a name="l02011"></a><span class="lineno"> 2011</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02012"></a><span class="lineno"> 2012</span>&#160;    <span class="keyword">def </span>test_pareto_sample(self):</div><div class="line"><a name="l02013"></a><span class="lineno"> 2013</span>&#160;        set_rng_seed(1)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l02014"></a><span class="lineno"> 2014</span>&#160;        <span class="keywordflow">for</span> scale, alpha <span class="keywordflow">in</span> product([0.1, 1.0, 5.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l02015"></a><span class="lineno"> 2015</span>&#160;            self._check_sampler_sampler(Pareto(scale, alpha),</div><div class="line"><a name="l02016"></a><span class="lineno"> 2016</span>&#160;                                        scipy.stats.pareto(alpha, scale=scale),</div><div class="line"><a name="l02017"></a><span class="lineno"> 2017</span>&#160;                                        <span class="stringliteral">&#39;Pareto(scale={}, alpha={})&#39;</span>.format(scale, alpha))</div><div class="line"><a name="l02018"></a><span class="lineno"> 2018</span>&#160;</div><div class="line"><a name="l02019"></a><span class="lineno"> 2019</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02020"></a><span class="lineno"> 2020</span>&#160;    <span class="keyword">def </span>test_gumbel(self):</div><div class="line"><a name="l02021"></a><span class="lineno"> 2021</span>&#160;        loc = torch.randn(2, 3, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02022"></a><span class="lineno"> 2022</span>&#160;        scale = torch.randn(2, 3).abs().requires_grad_()</div><div class="line"><a name="l02023"></a><span class="lineno"> 2023</span>&#160;        loc_1d = torch.randn(1, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02024"></a><span class="lineno"> 2024</span>&#160;        scale_1d = torch.randn(1).abs().requires_grad_()</div><div class="line"><a name="l02025"></a><span class="lineno"> 2025</span>&#160;        self.assertEqual(Gumbel(loc, scale).sample().size(), (2, 3))</div><div class="line"><a name="l02026"></a><span class="lineno"> 2026</span>&#160;        self.assertEqual(Gumbel(loc, scale).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l02027"></a><span class="lineno"> 2027</span>&#160;        self.assertEqual(Gumbel(loc_1d, scale_1d).sample().size(), (1,))</div><div class="line"><a name="l02028"></a><span class="lineno"> 2028</span>&#160;        self.assertEqual(Gumbel(loc_1d, scale_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l02029"></a><span class="lineno"> 2029</span>&#160;        self.assertEqual(Gumbel(1.0, 1.0).sample().size(), ())</div><div class="line"><a name="l02030"></a><span class="lineno"> 2030</span>&#160;        self.assertEqual(Gumbel(1.0, 1.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l02031"></a><span class="lineno"> 2031</span>&#160;</div><div class="line"><a name="l02032"></a><span class="lineno"> 2032</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l02033"></a><span class="lineno"> 2033</span>&#160;            l = loc.view(-1)[idx].detach()</div><div class="line"><a name="l02034"></a><span class="lineno"> 2034</span>&#160;            s = scale.view(-1)[idx].detach()</div><div class="line"><a name="l02035"></a><span class="lineno"> 2035</span>&#160;            expected = scipy.stats.gumbel_r.logpdf(x, loc=l, scale=s)</div><div class="line"><a name="l02036"></a><span class="lineno"> 2036</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l02037"></a><span class="lineno"> 2037</span>&#160;</div><div class="line"><a name="l02038"></a><span class="lineno"> 2038</span>&#160;        self._check_log_prob(Gumbel(loc, scale), ref_log_prob)</div><div class="line"><a name="l02039"></a><span class="lineno"> 2039</span>&#160;</div><div class="line"><a name="l02040"></a><span class="lineno"> 2040</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02041"></a><span class="lineno"> 2041</span>&#160;    <span class="keyword">def </span>test_gumbel_sample(self):</div><div class="line"><a name="l02042"></a><span class="lineno"> 2042</span>&#160;        set_rng_seed(1)  <span class="comment"># see note [Randomized statistical tests]</span></div><div class="line"><a name="l02043"></a><span class="lineno"> 2043</span>&#160;        <span class="keywordflow">for</span> loc, scale <span class="keywordflow">in</span> product([-5.0, -1.0, -0.1, 0.1, 1.0, 5.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l02044"></a><span class="lineno"> 2044</span>&#160;            self._check_sampler_sampler(Gumbel(loc, scale),</div><div class="line"><a name="l02045"></a><span class="lineno"> 2045</span>&#160;                                        scipy.stats.gumbel_r(loc=loc, scale=scale),</div><div class="line"><a name="l02046"></a><span class="lineno"> 2046</span>&#160;                                        <span class="stringliteral">&#39;Gumbel(loc={}, scale={})&#39;</span>.format(loc, scale))</div><div class="line"><a name="l02047"></a><span class="lineno"> 2047</span>&#160;</div><div class="line"><a name="l02048"></a><span class="lineno"> 2048</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02049"></a><span class="lineno"> 2049</span>&#160;    <span class="keyword">def </span>test_fishersnedecor(self):</div><div class="line"><a name="l02050"></a><span class="lineno"> 2050</span>&#160;        df1 = torch.randn(2, 3).abs().requires_grad_()</div><div class="line"><a name="l02051"></a><span class="lineno"> 2051</span>&#160;        df2 = torch.randn(2, 3).abs().requires_grad_()</div><div class="line"><a name="l02052"></a><span class="lineno"> 2052</span>&#160;        df1_1d = torch.randn(1).abs()</div><div class="line"><a name="l02053"></a><span class="lineno"> 2053</span>&#160;        df2_1d = torch.randn(1).abs()</div><div class="line"><a name="l02054"></a><span class="lineno"> 2054</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(FisherSnedecor(1, 2).mean))</div><div class="line"><a name="l02055"></a><span class="lineno"> 2055</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(FisherSnedecor(1, 4).variance))</div><div class="line"><a name="l02056"></a><span class="lineno"> 2056</span>&#160;        self.assertEqual(FisherSnedecor(df1, df2).sample().size(), (2, 3))</div><div class="line"><a name="l02057"></a><span class="lineno"> 2057</span>&#160;        self.assertEqual(FisherSnedecor(df1, df2).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l02058"></a><span class="lineno"> 2058</span>&#160;        self.assertEqual(FisherSnedecor(df1_1d, df2_1d).sample().size(), (1,))</div><div class="line"><a name="l02059"></a><span class="lineno"> 2059</span>&#160;        self.assertEqual(FisherSnedecor(df1_1d, df2_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l02060"></a><span class="lineno"> 2060</span>&#160;        self.assertEqual(FisherSnedecor(1.0, 1.0).sample().size(), ())</div><div class="line"><a name="l02061"></a><span class="lineno"> 2061</span>&#160;        self.assertEqual(FisherSnedecor(1.0, 1.0).sample((1,)).size(), (1,))</div><div class="line"><a name="l02062"></a><span class="lineno"> 2062</span>&#160;</div><div class="line"><a name="l02063"></a><span class="lineno"> 2063</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l02064"></a><span class="lineno"> 2064</span>&#160;            f1 = df1.view(-1)[idx].detach()</div><div class="line"><a name="l02065"></a><span class="lineno"> 2065</span>&#160;            f2 = df2.view(-1)[idx].detach()</div><div class="line"><a name="l02066"></a><span class="lineno"> 2066</span>&#160;            expected = scipy.stats.f.logpdf(x, f1, f2)</div><div class="line"><a name="l02067"></a><span class="lineno"> 2067</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l02068"></a><span class="lineno"> 2068</span>&#160;</div><div class="line"><a name="l02069"></a><span class="lineno"> 2069</span>&#160;        self._check_log_prob(FisherSnedecor(df1, df2), ref_log_prob)</div><div class="line"><a name="l02070"></a><span class="lineno"> 2070</span>&#160;</div><div class="line"><a name="l02071"></a><span class="lineno"> 2071</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02072"></a><span class="lineno"> 2072</span>&#160;    <span class="keyword">def </span>test_fishersnedecor_sample(self):</div><div class="line"><a name="l02073"></a><span class="lineno"> 2073</span>&#160;        set_rng_seed(1)  <span class="comment"># see note [Randomized statistical tests]</span></div><div class="line"><a name="l02074"></a><span class="lineno"> 2074</span>&#160;        <span class="keywordflow">for</span> df1, df2 <span class="keywordflow">in</span> product([0.1, 0.5, 1.0, 5.0, 10.0], [0.1, 0.5, 1.0, 5.0, 10.0]):</div><div class="line"><a name="l02075"></a><span class="lineno"> 2075</span>&#160;            self._check_sampler_sampler(FisherSnedecor(df1, df2),</div><div class="line"><a name="l02076"></a><span class="lineno"> 2076</span>&#160;                                        scipy.stats.f(df1, df2),</div><div class="line"><a name="l02077"></a><span class="lineno"> 2077</span>&#160;                                        <span class="stringliteral">&#39;FisherSnedecor(loc={}, scale={})&#39;</span>.format(df1, df2))</div><div class="line"><a name="l02078"></a><span class="lineno"> 2078</span>&#160;</div><div class="line"><a name="l02079"></a><span class="lineno"> 2079</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02080"></a><span class="lineno"> 2080</span>&#160;    <span class="keyword">def </span>test_chi2_shape(self):</div><div class="line"><a name="l02081"></a><span class="lineno"> 2081</span>&#160;        df = torch.randn(2, 3).exp().requires_grad_()</div><div class="line"><a name="l02082"></a><span class="lineno"> 2082</span>&#160;        df_1d = torch.randn(1).exp().requires_grad_()</div><div class="line"><a name="l02083"></a><span class="lineno"> 2083</span>&#160;        self.assertEqual(Chi2(df).sample().size(), (2, 3))</div><div class="line"><a name="l02084"></a><span class="lineno"> 2084</span>&#160;        self.assertEqual(Chi2(df).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l02085"></a><span class="lineno"> 2085</span>&#160;        self.assertEqual(Chi2(df_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l02086"></a><span class="lineno"> 2086</span>&#160;        self.assertEqual(Chi2(df_1d).sample().size(), (1,))</div><div class="line"><a name="l02087"></a><span class="lineno"> 2087</span>&#160;        self.assertEqual(Chi2(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.5, requires_grad=<span class="keyword">True</span>)).sample().size(), ())</div><div class="line"><a name="l02088"></a><span class="lineno"> 2088</span>&#160;        self.assertEqual(Chi2(0.5).sample().size(), ())</div><div class="line"><a name="l02089"></a><span class="lineno"> 2089</span>&#160;        self.assertEqual(Chi2(0.5).sample((1,)).size(), (1,))</div><div class="line"><a name="l02090"></a><span class="lineno"> 2090</span>&#160;</div><div class="line"><a name="l02091"></a><span class="lineno"> 2091</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l02092"></a><span class="lineno"> 2092</span>&#160;            d = df.view(-1)[idx].detach()</div><div class="line"><a name="l02093"></a><span class="lineno"> 2093</span>&#160;            expected = scipy.stats.chi2.logpdf(x, d)</div><div class="line"><a name="l02094"></a><span class="lineno"> 2094</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l02095"></a><span class="lineno"> 2095</span>&#160;</div><div class="line"><a name="l02096"></a><span class="lineno"> 2096</span>&#160;        self._check_log_prob(Chi2(df), ref_log_prob)</div><div class="line"><a name="l02097"></a><span class="lineno"> 2097</span>&#160;</div><div class="line"><a name="l02098"></a><span class="lineno"> 2098</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02099"></a><span class="lineno"> 2099</span>&#160;    <span class="keyword">def </span>test_chi2_sample(self):</div><div class="line"><a name="l02100"></a><span class="lineno"> 2100</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l02101"></a><span class="lineno"> 2101</span>&#160;        <span class="keywordflow">for</span> df <span class="keywordflow">in</span> [0.1, 1.0, 5.0]:</div><div class="line"><a name="l02102"></a><span class="lineno"> 2102</span>&#160;            self._check_sampler_sampler(Chi2(df),</div><div class="line"><a name="l02103"></a><span class="lineno"> 2103</span>&#160;                                        scipy.stats.chi2(df),</div><div class="line"><a name="l02104"></a><span class="lineno"> 2104</span>&#160;                                        <span class="stringliteral">&#39;Chi2(df={})&#39;</span>.format(df))</div><div class="line"><a name="l02105"></a><span class="lineno"> 2105</span>&#160;</div><div class="line"><a name="l02106"></a><span class="lineno"> 2106</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l02107"></a><span class="lineno"> 2107</span>&#160;    <span class="keyword">def </span>test_studentT(self):</div><div class="line"><a name="l02108"></a><span class="lineno"> 2108</span>&#160;        df = torch.randn(2, 3).exp().requires_grad_()</div><div class="line"><a name="l02109"></a><span class="lineno"> 2109</span>&#160;        df_1d = torch.randn(1).exp().requires_grad_()</div><div class="line"><a name="l02110"></a><span class="lineno"> 2110</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(StudentT(1).mean))</div><div class="line"><a name="l02111"></a><span class="lineno"> 2111</span>&#160;        self.assertTrue(<a class="code" href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">is_all_nan</a>(StudentT(1).variance))</div><div class="line"><a name="l02112"></a><span class="lineno"> 2112</span>&#160;        self.assertEqual(StudentT(2).variance, inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l02113"></a><span class="lineno"> 2113</span>&#160;        self.assertEqual(StudentT(df).sample().size(), (2, 3))</div><div class="line"><a name="l02114"></a><span class="lineno"> 2114</span>&#160;        self.assertEqual(StudentT(df).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l02115"></a><span class="lineno"> 2115</span>&#160;        self.assertEqual(StudentT(df_1d).sample((1,)).size(), (1, 1))</div><div class="line"><a name="l02116"></a><span class="lineno"> 2116</span>&#160;        self.assertEqual(StudentT(df_1d).sample().size(), (1,))</div><div class="line"><a name="l02117"></a><span class="lineno"> 2117</span>&#160;        self.assertEqual(StudentT(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(0.5, requires_grad=<span class="keyword">True</span>)).sample().size(), ())</div><div class="line"><a name="l02118"></a><span class="lineno"> 2118</span>&#160;        self.assertEqual(StudentT(0.5).sample().size(), ())</div><div class="line"><a name="l02119"></a><span class="lineno"> 2119</span>&#160;        self.assertEqual(StudentT(0.5).sample((1,)).size(), (1,))</div><div class="line"><a name="l02120"></a><span class="lineno"> 2120</span>&#160;</div><div class="line"><a name="l02121"></a><span class="lineno"> 2121</span>&#160;        <span class="keyword">def </span>ref_log_prob(idx, x, log_prob):</div><div class="line"><a name="l02122"></a><span class="lineno"> 2122</span>&#160;            d = df.view(-1)[idx].detach()</div><div class="line"><a name="l02123"></a><span class="lineno"> 2123</span>&#160;            expected = scipy.stats.t.logpdf(x, d)</div><div class="line"><a name="l02124"></a><span class="lineno"> 2124</span>&#160;            self.assertAlmostEqual(log_prob, expected, places=3)</div><div class="line"><a name="l02125"></a><span class="lineno"> 2125</span>&#160;</div><div class="line"><a name="l02126"></a><span class="lineno"> 2126</span>&#160;        self._check_log_prob(StudentT(df), ref_log_prob)</div><div class="line"><a name="l02127"></a><span class="lineno"> 2127</span>&#160;</div><div class="line"><a name="l02128"></a><span class="lineno"> 2128</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l02129"></a><span class="lineno"> 2129</span>&#160;    <span class="keyword">def </span>test_studentT_sample(self):</div><div class="line"><a name="l02130"></a><span class="lineno"> 2130</span>&#160;        set_rng_seed(11)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l02131"></a><span class="lineno"> 2131</span>&#160;        <span class="keywordflow">for</span> df, loc, scale <span class="keywordflow">in</span> product([0.1, 1.0, 5.0, 10.0], [-1.0, 0.0, 1.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l02132"></a><span class="lineno"> 2132</span>&#160;            self._check_sampler_sampler(StudentT(df=df, loc=loc, scale=scale),</div><div class="line"><a name="l02133"></a><span class="lineno"> 2133</span>&#160;                                        scipy.stats.t(df=df, loc=loc, scale=scale),</div><div class="line"><a name="l02134"></a><span class="lineno"> 2134</span>&#160;                                        <span class="stringliteral">&#39;StudentT(df={}, loc={}, scale={})&#39;</span>.format(df, loc, scale))</div><div class="line"><a name="l02135"></a><span class="lineno"> 2135</span>&#160;</div><div class="line"><a name="l02136"></a><span class="lineno"> 2136</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;Numpy not found&quot;</span>)</div><div class="line"><a name="l02137"></a><span class="lineno"> 2137</span>&#160;    <span class="keyword">def </span>test_studentT_log_prob(self):</div><div class="line"><a name="l02138"></a><span class="lineno"> 2138</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l02139"></a><span class="lineno"> 2139</span>&#160;        num_samples = 10</div><div class="line"><a name="l02140"></a><span class="lineno"> 2140</span>&#160;        <span class="keywordflow">for</span> df, loc, scale <span class="keywordflow">in</span> product([0.1, 1.0, 5.0, 10.0], [-1.0, 0.0, 1.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l02141"></a><span class="lineno"> 2141</span>&#160;            dist = StudentT(df=df, loc=loc, scale=scale)</div><div class="line"><a name="l02142"></a><span class="lineno"> 2142</span>&#160;            x = dist.sample((num_samples,))</div><div class="line"><a name="l02143"></a><span class="lineno"> 2143</span>&#160;            actual_log_prob = dist.log_prob(x)</div><div class="line"><a name="l02144"></a><span class="lineno"> 2144</span>&#160;            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(num_samples):</div><div class="line"><a name="l02145"></a><span class="lineno"> 2145</span>&#160;                expected_log_prob = scipy.stats.t.logpdf(x[i], df=df, loc=loc, scale=scale)</div><div class="line"><a name="l02146"></a><span class="lineno"> 2146</span>&#160;                self.assertAlmostEqual(float(actual_log_prob[i]), float(expected_log_prob), places=3)</div><div class="line"><a name="l02147"></a><span class="lineno"> 2147</span>&#160;</div><div class="line"><a name="l02148"></a><span class="lineno"> 2148</span>&#160;    <span class="keyword">def </span>test_dirichlet_shape(self):</div><div class="line"><a name="l02149"></a><span class="lineno"> 2149</span>&#160;        alpha = torch.randn(2, 3).exp().requires_grad_()</div><div class="line"><a name="l02150"></a><span class="lineno"> 2150</span>&#160;        alpha_1d = torch.randn(4).exp().requires_grad_()</div><div class="line"><a name="l02151"></a><span class="lineno"> 2151</span>&#160;        self.assertEqual(Dirichlet(alpha).sample().size(), (2, 3))</div><div class="line"><a name="l02152"></a><span class="lineno"> 2152</span>&#160;        self.assertEqual(Dirichlet(alpha).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l02153"></a><span class="lineno"> 2153</span>&#160;        self.assertEqual(Dirichlet(alpha_1d).sample().size(), (4,))</div><div class="line"><a name="l02154"></a><span class="lineno"> 2154</span>&#160;        self.assertEqual(Dirichlet(alpha_1d).sample((1,)).size(), (1, 4))</div><div class="line"><a name="l02155"></a><span class="lineno"> 2155</span>&#160;</div><div class="line"><a name="l02156"></a><span class="lineno"> 2156</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02157"></a><span class="lineno"> 2157</span>&#160;    <span class="keyword">def </span>test_dirichlet_log_prob(self):</div><div class="line"><a name="l02158"></a><span class="lineno"> 2158</span>&#160;        num_samples = 10</div><div class="line"><a name="l02159"></a><span class="lineno"> 2159</span>&#160;        alpha = torch.exp(torch.randn(5))</div><div class="line"><a name="l02160"></a><span class="lineno"> 2160</span>&#160;        dist = Dirichlet(alpha)</div><div class="line"><a name="l02161"></a><span class="lineno"> 2161</span>&#160;        x = dist.sample((num_samples,))</div><div class="line"><a name="l02162"></a><span class="lineno"> 2162</span>&#160;        actual_log_prob = dist.log_prob(x)</div><div class="line"><a name="l02163"></a><span class="lineno"> 2163</span>&#160;        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(num_samples):</div><div class="line"><a name="l02164"></a><span class="lineno"> 2164</span>&#160;            expected_log_prob = scipy.stats.dirichlet.logpdf(x[i].numpy(), alpha.numpy())</div><div class="line"><a name="l02165"></a><span class="lineno"> 2165</span>&#160;            self.assertAlmostEqual(actual_log_prob[i], expected_log_prob, places=3)</div><div class="line"><a name="l02166"></a><span class="lineno"> 2166</span>&#160;</div><div class="line"><a name="l02167"></a><span class="lineno"> 2167</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02168"></a><span class="lineno"> 2168</span>&#160;    <span class="keyword">def </span>test_dirichlet_sample(self):</div><div class="line"><a name="l02169"></a><span class="lineno"> 2169</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l02170"></a><span class="lineno"> 2170</span>&#160;        alpha = torch.exp(torch.randn(3))</div><div class="line"><a name="l02171"></a><span class="lineno"> 2171</span>&#160;        self._check_sampler_sampler(Dirichlet(alpha),</div><div class="line"><a name="l02172"></a><span class="lineno"> 2172</span>&#160;                                    scipy.stats.dirichlet(alpha.numpy()),</div><div class="line"><a name="l02173"></a><span class="lineno"> 2173</span>&#160;                                    <span class="stringliteral">&#39;Dirichlet(alpha={})&#39;</span>.format(list(alpha)),</div><div class="line"><a name="l02174"></a><span class="lineno"> 2174</span>&#160;                                    multivariate=<span class="keyword">True</span>)</div><div class="line"><a name="l02175"></a><span class="lineno"> 2175</span>&#160;</div><div class="line"><a name="l02176"></a><span class="lineno"> 2176</span>&#160;    <span class="keyword">def </span>test_beta_shape(self):</div><div class="line"><a name="l02177"></a><span class="lineno"> 2177</span>&#160;        con1 = torch.randn(2, 3).exp().requires_grad_()</div><div class="line"><a name="l02178"></a><span class="lineno"> 2178</span>&#160;        con0 = torch.randn(2, 3).exp().requires_grad_()</div><div class="line"><a name="l02179"></a><span class="lineno"> 2179</span>&#160;        con1_1d = torch.randn(4).exp().requires_grad_()</div><div class="line"><a name="l02180"></a><span class="lineno"> 2180</span>&#160;        con0_1d = torch.randn(4).exp().requires_grad_()</div><div class="line"><a name="l02181"></a><span class="lineno"> 2181</span>&#160;        self.assertEqual(Beta(con1, con0).sample().size(), (2, 3))</div><div class="line"><a name="l02182"></a><span class="lineno"> 2182</span>&#160;        self.assertEqual(Beta(con1, con0).sample((5,)).size(), (5, 2, 3))</div><div class="line"><a name="l02183"></a><span class="lineno"> 2183</span>&#160;        self.assertEqual(Beta(con1_1d, con0_1d).sample().size(), (4,))</div><div class="line"><a name="l02184"></a><span class="lineno"> 2184</span>&#160;        self.assertEqual(Beta(con1_1d, con0_1d).sample((1,)).size(), (1, 4))</div><div class="line"><a name="l02185"></a><span class="lineno"> 2185</span>&#160;        self.assertEqual(Beta(0.1, 0.3).sample().size(), ())</div><div class="line"><a name="l02186"></a><span class="lineno"> 2186</span>&#160;        self.assertEqual(Beta(0.1, 0.3).sample((5,)).size(), (5,))</div><div class="line"><a name="l02187"></a><span class="lineno"> 2187</span>&#160;</div><div class="line"><a name="l02188"></a><span class="lineno"> 2188</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02189"></a><span class="lineno"> 2189</span>&#160;    <span class="keyword">def </span>test_beta_log_prob(self):</div><div class="line"><a name="l02190"></a><span class="lineno"> 2190</span>&#160;        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(100):</div><div class="line"><a name="l02191"></a><span class="lineno"> 2191</span>&#160;            con1 = np.exp(np.random.normal())</div><div class="line"><a name="l02192"></a><span class="lineno"> 2192</span>&#160;            con0 = np.exp(np.random.normal())</div><div class="line"><a name="l02193"></a><span class="lineno"> 2193</span>&#160;            dist = Beta(con1, con0)</div><div class="line"><a name="l02194"></a><span class="lineno"> 2194</span>&#160;            x = dist.sample()</div><div class="line"><a name="l02195"></a><span class="lineno"> 2195</span>&#160;            actual_log_prob = dist.log_prob(x).sum()</div><div class="line"><a name="l02196"></a><span class="lineno"> 2196</span>&#160;            expected_log_prob = scipy.stats.beta.logpdf(x, con1, con0)</div><div class="line"><a name="l02197"></a><span class="lineno"> 2197</span>&#160;            self.assertAlmostEqual(float(actual_log_prob), float(expected_log_prob), places=3, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l02198"></a><span class="lineno"> 2198</span>&#160;</div><div class="line"><a name="l02199"></a><span class="lineno"> 2199</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02200"></a><span class="lineno"> 2200</span>&#160;    <span class="keyword">def </span>test_beta_sample(self):</div><div class="line"><a name="l02201"></a><span class="lineno"> 2201</span>&#160;        set_rng_seed(1)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l02202"></a><span class="lineno"> 2202</span>&#160;        <span class="keywordflow">for</span> con1, con0 <span class="keywordflow">in</span> product([0.1, 1.0, 10.0], [0.1, 1.0, 10.0]):</div><div class="line"><a name="l02203"></a><span class="lineno"> 2203</span>&#160;            self._check_sampler_sampler(Beta(con1, con0),</div><div class="line"><a name="l02204"></a><span class="lineno"> 2204</span>&#160;                                        scipy.stats.beta(con1, con0),</div><div class="line"><a name="l02205"></a><span class="lineno"> 2205</span>&#160;                                        <span class="stringliteral">&#39;Beta(alpha={}, beta={})&#39;</span>.format(con1, con0))</div><div class="line"><a name="l02206"></a><span class="lineno"> 2206</span>&#160;        <span class="comment"># Check that small alphas do not cause NANs.</span></div><div class="line"><a name="l02207"></a><span class="lineno"> 2207</span>&#160;        <span class="keywordflow">for</span> Tensor <span class="keywordflow">in</span> [torch.FloatTensor, torch.DoubleTensor]:</div><div class="line"><a name="l02208"></a><span class="lineno"> 2208</span>&#160;            x = Beta(Tensor([1e-6]), Tensor([1e-6])).sample()[0]</div><div class="line"><a name="l02209"></a><span class="lineno"> 2209</span>&#160;            self.assertTrue(np.isfinite(x) <span class="keywordflow">and</span> x &gt; 0, <span class="stringliteral">&#39;Invalid Beta.sample(): {}&#39;</span>.format(x))</div><div class="line"><a name="l02210"></a><span class="lineno"> 2210</span>&#160;</div><div class="line"><a name="l02211"></a><span class="lineno"> 2211</span>&#160;    <span class="keyword">def </span>test_beta_underflow(self):</div><div class="line"><a name="l02212"></a><span class="lineno"> 2212</span>&#160;        <span class="comment"># For low values of (alpha, beta), the gamma samples can underflow</span></div><div class="line"><a name="l02213"></a><span class="lineno"> 2213</span>&#160;        <span class="comment"># with float32 and result in a spurious mode at 0.5. To prevent this,</span></div><div class="line"><a name="l02214"></a><span class="lineno"> 2214</span>&#160;        <span class="comment"># torch._sample_dirichlet works with double precision for intermediate</span></div><div class="line"><a name="l02215"></a><span class="lineno"> 2215</span>&#160;        <span class="comment"># calculations.</span></div><div class="line"><a name="l02216"></a><span class="lineno"> 2216</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l02217"></a><span class="lineno"> 2217</span>&#160;        num_samples = 50000</div><div class="line"><a name="l02218"></a><span class="lineno"> 2218</span>&#160;        <span class="keywordflow">for</span> dtype <span class="keywordflow">in</span> [torch.float, torch.double]:</div><div class="line"><a name="l02219"></a><span class="lineno"> 2219</span>&#160;            conc = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(1e-2, dtype=dtype)</div><div class="line"><a name="l02220"></a><span class="lineno"> 2220</span>&#160;            beta_samples = Beta(conc, conc).sample([num_samples])</div><div class="line"><a name="l02221"></a><span class="lineno"> 2221</span>&#160;            self.assertEqual((beta_samples == 0).sum(), 0)</div><div class="line"><a name="l02222"></a><span class="lineno"> 2222</span>&#160;            self.assertEqual((beta_samples == 1).sum(), 0)</div><div class="line"><a name="l02223"></a><span class="lineno"> 2223</span>&#160;            <span class="comment"># assert support is concentrated around 0 and 1</span></div><div class="line"><a name="l02224"></a><span class="lineno"> 2224</span>&#160;            frac_zeros = float((beta_samples &lt; 0.1).sum()) / num_samples</div><div class="line"><a name="l02225"></a><span class="lineno"> 2225</span>&#160;            frac_ones = float((beta_samples &gt; 0.9).sum()) / num_samples</div><div class="line"><a name="l02226"></a><span class="lineno"> 2226</span>&#160;            self.assertEqual(frac_zeros, 0.5, 0.05)</div><div class="line"><a name="l02227"></a><span class="lineno"> 2227</span>&#160;            self.assertEqual(frac_ones, 0.5, 0.05)</div><div class="line"><a name="l02228"></a><span class="lineno"> 2228</span>&#160;</div><div class="line"><a name="l02229"></a><span class="lineno"> 2229</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_CUDA, <span class="stringliteral">&quot;CUDA not found&quot;</span>)</div><div class="line"><a name="l02230"></a><span class="lineno"> 2230</span>&#160;    <span class="keyword">def </span>test_beta_underflow_gpu(self):</div><div class="line"><a name="l02231"></a><span class="lineno"> 2231</span>&#160;        set_rng_seed(1)</div><div class="line"><a name="l02232"></a><span class="lineno"> 2232</span>&#160;        num_samples = 50000</div><div class="line"><a name="l02233"></a><span class="lineno"> 2233</span>&#160;        conc = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(1e-2, dtype=torch.float64).cuda()</div><div class="line"><a name="l02234"></a><span class="lineno"> 2234</span>&#160;        beta_samples = Beta(conc, conc).sample([num_samples])</div><div class="line"><a name="l02235"></a><span class="lineno"> 2235</span>&#160;        self.assertEqual((beta_samples == 0).sum(), 0)</div><div class="line"><a name="l02236"></a><span class="lineno"> 2236</span>&#160;        self.assertEqual((beta_samples == 1).sum(), 0)</div><div class="line"><a name="l02237"></a><span class="lineno"> 2237</span>&#160;        <span class="comment"># assert support is concentrated around 0 and 1</span></div><div class="line"><a name="l02238"></a><span class="lineno"> 2238</span>&#160;        frac_zeros = float((beta_samples &lt; 0.1).sum()) / num_samples</div><div class="line"><a name="l02239"></a><span class="lineno"> 2239</span>&#160;        frac_ones = float((beta_samples &gt; 0.9).sum()) / num_samples</div><div class="line"><a name="l02240"></a><span class="lineno"> 2240</span>&#160;        <span class="comment"># TODO: increase precision once imbalance on GPU is fixed.</span></div><div class="line"><a name="l02241"></a><span class="lineno"> 2241</span>&#160;        self.assertEqual(frac_zeros, 0.5, 0.12)</div><div class="line"><a name="l02242"></a><span class="lineno"> 2242</span>&#160;        self.assertEqual(frac_ones, 0.5, 0.12)</div><div class="line"><a name="l02243"></a><span class="lineno"> 2243</span>&#160;</div><div class="line"><a name="l02244"></a><span class="lineno"> 2244</span>&#160;    <span class="keyword">def </span>test_independent_shape(self):</div><div class="line"><a name="l02245"></a><span class="lineno"> 2245</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l02246"></a><span class="lineno"> 2246</span>&#160;            <span class="keywordflow">for</span> param <span class="keywordflow">in</span> params:</div><div class="line"><a name="l02247"></a><span class="lineno"> 2247</span>&#160;                base_dist = Dist(**param)</div><div class="line"><a name="l02248"></a><span class="lineno"> 2248</span>&#160;                x = base_dist.sample()</div><div class="line"><a name="l02249"></a><span class="lineno"> 2249</span>&#160;                base_log_prob_shape = base_dist.log_prob(x).shape</div><div class="line"><a name="l02250"></a><span class="lineno"> 2250</span>&#160;                <span class="keywordflow">for</span> reinterpreted_batch_ndims <span class="keywordflow">in</span> range(len(base_dist.batch_shape) + 1):</div><div class="line"><a name="l02251"></a><span class="lineno"> 2251</span>&#160;                    indep_dist = Independent(base_dist, reinterpreted_batch_ndims)</div><div class="line"><a name="l02252"></a><span class="lineno"> 2252</span>&#160;                    indep_log_prob_shape = base_log_prob_shape[:len(base_log_prob_shape) - reinterpreted_batch_ndims]</div><div class="line"><a name="l02253"></a><span class="lineno"> 2253</span>&#160;                    self.assertEqual(indep_dist.log_prob(x).shape, indep_log_prob_shape)</div><div class="line"><a name="l02254"></a><span class="lineno"> 2254</span>&#160;                    self.assertEqual(indep_dist.sample().shape, base_dist.sample().shape)</div><div class="line"><a name="l02255"></a><span class="lineno"> 2255</span>&#160;                    self.assertEqual(indep_dist.has_rsample, base_dist.has_rsample)</div><div class="line"><a name="l02256"></a><span class="lineno"> 2256</span>&#160;                    <span class="keywordflow">if</span> indep_dist.has_rsample:</div><div class="line"><a name="l02257"></a><span class="lineno"> 2257</span>&#160;                        self.assertEqual(indep_dist.sample().shape, base_dist.sample().shape)</div><div class="line"><a name="l02258"></a><span class="lineno"> 2258</span>&#160;                    <span class="keywordflow">try</span>:</div><div class="line"><a name="l02259"></a><span class="lineno"> 2259</span>&#160;                        self.assertEqual(indep_dist.enumerate_support().shape, base_dist.enumerate_support().shape)</div><div class="line"><a name="l02260"></a><span class="lineno"> 2260</span>&#160;                        self.assertEqual(indep_dist.mean.shape, base_dist.mean.shape)</div><div class="line"><a name="l02261"></a><span class="lineno"> 2261</span>&#160;                    <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l02262"></a><span class="lineno"> 2262</span>&#160;                        <span class="keywordflow">pass</span></div><div class="line"><a name="l02263"></a><span class="lineno"> 2263</span>&#160;                    <span class="keywordflow">try</span>:</div><div class="line"><a name="l02264"></a><span class="lineno"> 2264</span>&#160;                        self.assertEqual(indep_dist.variance.shape, base_dist.variance.shape)</div><div class="line"><a name="l02265"></a><span class="lineno"> 2265</span>&#160;                    <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l02266"></a><span class="lineno"> 2266</span>&#160;                        <span class="keywordflow">pass</span></div><div class="line"><a name="l02267"></a><span class="lineno"> 2267</span>&#160;                    <span class="keywordflow">try</span>:</div><div class="line"><a name="l02268"></a><span class="lineno"> 2268</span>&#160;                        self.assertEqual(indep_dist.entropy().shape, indep_log_prob_shape)</div><div class="line"><a name="l02269"></a><span class="lineno"> 2269</span>&#160;                    <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l02270"></a><span class="lineno"> 2270</span>&#160;                        <span class="keywordflow">pass</span></div><div class="line"><a name="l02271"></a><span class="lineno"> 2271</span>&#160;</div><div class="line"><a name="l02272"></a><span class="lineno"> 2272</span>&#160;    <span class="keyword">def </span>test_independent_expand(self):</div><div class="line"><a name="l02273"></a><span class="lineno"> 2273</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l02274"></a><span class="lineno"> 2274</span>&#160;            <span class="keywordflow">for</span> param <span class="keywordflow">in</span> params:</div><div class="line"><a name="l02275"></a><span class="lineno"> 2275</span>&#160;                base_dist = Dist(**param)</div><div class="line"><a name="l02276"></a><span class="lineno"> 2276</span>&#160;                <span class="keywordflow">for</span> reinterpreted_batch_ndims <span class="keywordflow">in</span> range(len(base_dist.batch_shape) + 1):</div><div class="line"><a name="l02277"></a><span class="lineno"> 2277</span>&#160;                    <span class="keywordflow">for</span> s <span class="keywordflow">in</span> [torch.Size(), torch.Size((2,)), torch.Size((2, 3))]:</div><div class="line"><a name="l02278"></a><span class="lineno"> 2278</span>&#160;                        indep_dist = Independent(base_dist, reinterpreted_batch_ndims)</div><div class="line"><a name="l02279"></a><span class="lineno"> 2279</span>&#160;                        expanded_shape = s + indep_dist.batch_shape</div><div class="line"><a name="l02280"></a><span class="lineno"> 2280</span>&#160;                        expanded = indep_dist.expand(expanded_shape)</div><div class="line"><a name="l02281"></a><span class="lineno"> 2281</span>&#160;                        expanded_sample = expanded.sample()</div><div class="line"><a name="l02282"></a><span class="lineno"> 2282</span>&#160;                        expected_shape = expanded_shape + indep_dist.event_shape</div><div class="line"><a name="l02283"></a><span class="lineno"> 2283</span>&#160;                        self.assertEqual(expanded_sample.shape, expected_shape)</div><div class="line"><a name="l02284"></a><span class="lineno"> 2284</span>&#160;                        self.assertEqual(expanded.log_prob(expanded_sample),</div><div class="line"><a name="l02285"></a><span class="lineno"> 2285</span>&#160;                                         indep_dist.log_prob(expanded_sample))</div><div class="line"><a name="l02286"></a><span class="lineno"> 2286</span>&#160;                        self.assertEqual(expanded.event_shape, indep_dist.event_shape)</div><div class="line"><a name="l02287"></a><span class="lineno"> 2287</span>&#160;                        self.assertEqual(expanded.batch_shape, expanded_shape)</div><div class="line"><a name="l02288"></a><span class="lineno"> 2288</span>&#160;</div><div class="line"><a name="l02289"></a><span class="lineno"> 2289</span>&#160;    <span class="keyword">def </span>test_cdf_icdf_inverse(self):</div><div class="line"><a name="l02290"></a><span class="lineno"> 2290</span>&#160;        <span class="comment"># Tests the invertibility property on the distributions</span></div><div class="line"><a name="l02291"></a><span class="lineno"> 2291</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l02292"></a><span class="lineno"> 2292</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l02293"></a><span class="lineno"> 2293</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l02294"></a><span class="lineno"> 2294</span>&#160;                samples = dist.sample(sample_shape=(20,))</div><div class="line"><a name="l02295"></a><span class="lineno"> 2295</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l02296"></a><span class="lineno"> 2296</span>&#160;                    cdf = dist.cdf(samples)</div><div class="line"><a name="l02297"></a><span class="lineno"> 2297</span>&#160;                    actual = dist.icdf(cdf)</div><div class="line"><a name="l02298"></a><span class="lineno"> 2298</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l02299"></a><span class="lineno"> 2299</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l02300"></a><span class="lineno"> 2300</span>&#160;                rel_error = torch.abs(actual - samples) / (1e-10 + torch.abs(samples))</div><div class="line"><a name="l02301"></a><span class="lineno"> 2301</span>&#160;                self.assertLess(rel_error.max(), 1e-4, msg=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02302"></a><span class="lineno"> 2302</span>&#160;                    <span class="stringliteral">&#39;{} example {}/{}, icdf(cdf(x)) != x&#39;</span>.format(Dist.__name__, i + 1, len(params)),</div><div class="line"><a name="l02303"></a><span class="lineno"> 2303</span>&#160;                    <span class="stringliteral">&#39;x = {}&#39;</span>.format(samples),</div><div class="line"><a name="l02304"></a><span class="lineno"> 2304</span>&#160;                    <span class="stringliteral">&#39;cdf(x) = {}&#39;</span>.format(cdf),</div><div class="line"><a name="l02305"></a><span class="lineno"> 2305</span>&#160;                    <span class="stringliteral">&#39;icdf(cdf(x)) = {}&#39;</span>.format(actual),</div><div class="line"><a name="l02306"></a><span class="lineno"> 2306</span>&#160;                ]))</div><div class="line"><a name="l02307"></a><span class="lineno"> 2307</span>&#160;</div><div class="line"><a name="l02308"></a><span class="lineno"> 2308</span>&#160;    <span class="keyword">def </span>test_cdf_log_prob(self):</div><div class="line"><a name="l02309"></a><span class="lineno"> 2309</span>&#160;        <span class="comment"># Tests if the differentiation of the CDF gives the PDF at a given value</span></div><div class="line"><a name="l02310"></a><span class="lineno"> 2310</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l02311"></a><span class="lineno"> 2311</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l02312"></a><span class="lineno"> 2312</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l02313"></a><span class="lineno"> 2313</span>&#160;                samples = dist.sample()</div><div class="line"><a name="l02314"></a><span class="lineno"> 2314</span>&#160;                <span class="keywordflow">if</span> samples.dtype.is_floating_point:</div><div class="line"><a name="l02315"></a><span class="lineno"> 2315</span>&#160;                    samples.requires_grad_()</div><div class="line"><a name="l02316"></a><span class="lineno"> 2316</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l02317"></a><span class="lineno"> 2317</span>&#160;                    cdfs = dist.cdf(samples)</div><div class="line"><a name="l02318"></a><span class="lineno"> 2318</span>&#160;                    pdfs = dist.log_prob(samples).exp()</div><div class="line"><a name="l02319"></a><span class="lineno"> 2319</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l02320"></a><span class="lineno"> 2320</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l02321"></a><span class="lineno"> 2321</span>&#160;                cdfs_derivative = grad(cdfs.sum(), [samples])[0]  <span class="comment"># this should not be wrapped in torch.abs()</span></div><div class="line"><a name="l02322"></a><span class="lineno"> 2322</span>&#160;                self.assertEqual(cdfs_derivative, pdfs, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02323"></a><span class="lineno"> 2323</span>&#160;                    <span class="stringliteral">&#39;{} example {}/{}, d(cdf)/dx != pdf(x)&#39;</span>.format(Dist.__name__, i + 1, len(params)),</div><div class="line"><a name="l02324"></a><span class="lineno"> 2324</span>&#160;                    <span class="stringliteral">&#39;x = {}&#39;</span>.format(samples),</div><div class="line"><a name="l02325"></a><span class="lineno"> 2325</span>&#160;                    <span class="stringliteral">&#39;cdf = {}&#39;</span>.format(cdfs),</div><div class="line"><a name="l02326"></a><span class="lineno"> 2326</span>&#160;                    <span class="stringliteral">&#39;pdf = {}&#39;</span>.format(pdfs),</div><div class="line"><a name="l02327"></a><span class="lineno"> 2327</span>&#160;                    <span class="stringliteral">&#39;grad(cdf) = {}&#39;</span>.format(cdfs_derivative),</div><div class="line"><a name="l02328"></a><span class="lineno"> 2328</span>&#160;                ]))</div><div class="line"><a name="l02329"></a><span class="lineno"> 2329</span>&#160;</div><div class="line"><a name="l02330"></a><span class="lineno"> 2330</span>&#160;    <span class="keyword">def </span>test_valid_parameter_broadcasting(self):</div><div class="line"><a name="l02331"></a><span class="lineno"> 2331</span>&#160;        <span class="comment"># Test correct broadcasting of parameter sizes for distributions that have multiple</span></div><div class="line"><a name="l02332"></a><span class="lineno"> 2332</span>&#160;        <span class="comment"># parameters.</span></div><div class="line"><a name="l02333"></a><span class="lineno"> 2333</span>&#160;        <span class="comment"># example type (distribution instance, expected sample shape)</span></div><div class="line"><a name="l02334"></a><span class="lineno"> 2334</span>&#160;        valid_examples = [</div><div class="line"><a name="l02335"></a><span class="lineno"> 2335</span>&#160;            (Normal(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=1),</div><div class="line"><a name="l02336"></a><span class="lineno"> 2336</span>&#160;             (2,)),</div><div class="line"><a name="l02337"></a><span class="lineno"> 2337</span>&#160;            (Normal(loc=0, scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.])),</div><div class="line"><a name="l02338"></a><span class="lineno"> 2338</span>&#160;             (2,)),</div><div class="line"><a name="l02339"></a><span class="lineno"> 2339</span>&#160;            (Normal(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.])),</div><div class="line"><a name="l02340"></a><span class="lineno"> 2340</span>&#160;             (2,)),</div><div class="line"><a name="l02341"></a><span class="lineno"> 2341</span>&#160;            (Normal(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.]])),</div><div class="line"><a name="l02342"></a><span class="lineno"> 2342</span>&#160;             (2, 2)),</div><div class="line"><a name="l02343"></a><span class="lineno"> 2343</span>&#160;            (Normal(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02344"></a><span class="lineno"> 2344</span>&#160;             (1, 2)),</div><div class="line"><a name="l02345"></a><span class="lineno"> 2345</span>&#160;            (Normal(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02346"></a><span class="lineno"> 2346</span>&#160;             (1, 1)),</div><div class="line"><a name="l02347"></a><span class="lineno"> 2347</span>&#160;            (FisherSnedecor(df1=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), df2=1),</div><div class="line"><a name="l02348"></a><span class="lineno"> 2348</span>&#160;             (2,)),</div><div class="line"><a name="l02349"></a><span class="lineno"> 2349</span>&#160;            (FisherSnedecor(df1=1, df2=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.])),</div><div class="line"><a name="l02350"></a><span class="lineno"> 2350</span>&#160;             (2,)),</div><div class="line"><a name="l02351"></a><span class="lineno"> 2351</span>&#160;            (FisherSnedecor(df1=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), df2=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.])),</div><div class="line"><a name="l02352"></a><span class="lineno"> 2352</span>&#160;             (2,)),</div><div class="line"><a name="l02353"></a><span class="lineno"> 2353</span>&#160;            (FisherSnedecor(df1=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), df2=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.]])),</div><div class="line"><a name="l02354"></a><span class="lineno"> 2354</span>&#160;             (2, 2)),</div><div class="line"><a name="l02355"></a><span class="lineno"> 2355</span>&#160;            (FisherSnedecor(df1=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), df2=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02356"></a><span class="lineno"> 2356</span>&#160;             (1, 2)),</div><div class="line"><a name="l02357"></a><span class="lineno"> 2357</span>&#160;            (FisherSnedecor(df1=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.]), df2=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02358"></a><span class="lineno"> 2358</span>&#160;             (1, 1)),</div><div class="line"><a name="l02359"></a><span class="lineno"> 2359</span>&#160;            (Gamma(concentration=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), rate=1),</div><div class="line"><a name="l02360"></a><span class="lineno"> 2360</span>&#160;             (2,)),</div><div class="line"><a name="l02361"></a><span class="lineno"> 2361</span>&#160;            (Gamma(concentration=1, rate=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.])),</div><div class="line"><a name="l02362"></a><span class="lineno"> 2362</span>&#160;             (2,)),</div><div class="line"><a name="l02363"></a><span class="lineno"> 2363</span>&#160;            (Gamma(concentration=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), rate=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.], [1.]])),</div><div class="line"><a name="l02364"></a><span class="lineno"> 2364</span>&#160;             (3, 2)),</div><div class="line"><a name="l02365"></a><span class="lineno"> 2365</span>&#160;            (Gamma(concentration=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), rate=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.]])),</div><div class="line"><a name="l02366"></a><span class="lineno"> 2366</span>&#160;             (2, 2)),</div><div class="line"><a name="l02367"></a><span class="lineno"> 2367</span>&#160;            (Gamma(concentration=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), rate=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02368"></a><span class="lineno"> 2368</span>&#160;             (1, 2)),</div><div class="line"><a name="l02369"></a><span class="lineno"> 2369</span>&#160;            (Gamma(concentration=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.]), rate=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02370"></a><span class="lineno"> 2370</span>&#160;             (1, 1)),</div><div class="line"><a name="l02371"></a><span class="lineno"> 2371</span>&#160;            (Gumbel(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=1),</div><div class="line"><a name="l02372"></a><span class="lineno"> 2372</span>&#160;             (2,)),</div><div class="line"><a name="l02373"></a><span class="lineno"> 2373</span>&#160;            (Gumbel(loc=0, scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.])),</div><div class="line"><a name="l02374"></a><span class="lineno"> 2374</span>&#160;             (2,)),</div><div class="line"><a name="l02375"></a><span class="lineno"> 2375</span>&#160;            (Gumbel(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.])),</div><div class="line"><a name="l02376"></a><span class="lineno"> 2376</span>&#160;             (2,)),</div><div class="line"><a name="l02377"></a><span class="lineno"> 2377</span>&#160;            (Gumbel(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.]])),</div><div class="line"><a name="l02378"></a><span class="lineno"> 2378</span>&#160;             (2, 2)),</div><div class="line"><a name="l02379"></a><span class="lineno"> 2379</span>&#160;            (Gumbel(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02380"></a><span class="lineno"> 2380</span>&#160;             (1, 2)),</div><div class="line"><a name="l02381"></a><span class="lineno"> 2381</span>&#160;            (Gumbel(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02382"></a><span class="lineno"> 2382</span>&#160;             (1, 1)),</div><div class="line"><a name="l02383"></a><span class="lineno"> 2383</span>&#160;            (Laplace(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=1),</div><div class="line"><a name="l02384"></a><span class="lineno"> 2384</span>&#160;             (2,)),</div><div class="line"><a name="l02385"></a><span class="lineno"> 2385</span>&#160;            (Laplace(loc=0, scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.])),</div><div class="line"><a name="l02386"></a><span class="lineno"> 2386</span>&#160;             (2,)),</div><div class="line"><a name="l02387"></a><span class="lineno"> 2387</span>&#160;            (Laplace(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.])),</div><div class="line"><a name="l02388"></a><span class="lineno"> 2388</span>&#160;             (2,)),</div><div class="line"><a name="l02389"></a><span class="lineno"> 2389</span>&#160;            (Laplace(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.]])),</div><div class="line"><a name="l02390"></a><span class="lineno"> 2390</span>&#160;             (2, 2)),</div><div class="line"><a name="l02391"></a><span class="lineno"> 2391</span>&#160;            (Laplace(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02392"></a><span class="lineno"> 2392</span>&#160;             (1, 2)),</div><div class="line"><a name="l02393"></a><span class="lineno"> 2393</span>&#160;            (Laplace(loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02394"></a><span class="lineno"> 2394</span>&#160;             (1, 1)),</div><div class="line"><a name="l02395"></a><span class="lineno"> 2395</span>&#160;            (Pareto(scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), alpha=1),</div><div class="line"><a name="l02396"></a><span class="lineno"> 2396</span>&#160;             (2,)),</div><div class="line"><a name="l02397"></a><span class="lineno"> 2397</span>&#160;            (Pareto(scale=1, alpha=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.])),</div><div class="line"><a name="l02398"></a><span class="lineno"> 2398</span>&#160;             (2,)),</div><div class="line"><a name="l02399"></a><span class="lineno"> 2399</span>&#160;            (Pareto(scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), alpha=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.])),</div><div class="line"><a name="l02400"></a><span class="lineno"> 2400</span>&#160;             (2,)),</div><div class="line"><a name="l02401"></a><span class="lineno"> 2401</span>&#160;            (Pareto(scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), alpha=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.]])),</div><div class="line"><a name="l02402"></a><span class="lineno"> 2402</span>&#160;             (2, 2)),</div><div class="line"><a name="l02403"></a><span class="lineno"> 2403</span>&#160;            (Pareto(scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), alpha=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02404"></a><span class="lineno"> 2404</span>&#160;             (1, 2)),</div><div class="line"><a name="l02405"></a><span class="lineno"> 2405</span>&#160;            (Pareto(scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.]), alpha=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02406"></a><span class="lineno"> 2406</span>&#160;             (1, 1)),</div><div class="line"><a name="l02407"></a><span class="lineno"> 2407</span>&#160;            (StudentT(df=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), loc=1),</div><div class="line"><a name="l02408"></a><span class="lineno"> 2408</span>&#160;             (2,)),</div><div class="line"><a name="l02409"></a><span class="lineno"> 2409</span>&#160;            (StudentT(df=1, scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.])),</div><div class="line"><a name="l02410"></a><span class="lineno"> 2410</span>&#160;             (2,)),</div><div class="line"><a name="l02411"></a><span class="lineno"> 2411</span>&#160;            (StudentT(df=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.])),</div><div class="line"><a name="l02412"></a><span class="lineno"> 2412</span>&#160;             (2,)),</div><div class="line"><a name="l02413"></a><span class="lineno"> 2413</span>&#160;            (StudentT(df=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.], [1.]])),</div><div class="line"><a name="l02414"></a><span class="lineno"> 2414</span>&#160;             (2, 2)),</div><div class="line"><a name="l02415"></a><span class="lineno"> 2415</span>&#160;            (StudentT(df=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), loc=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02416"></a><span class="lineno"> 2416</span>&#160;             (1, 2)),</div><div class="line"><a name="l02417"></a><span class="lineno"> 2417</span>&#160;            (StudentT(df=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1.]), scale=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[1.]])),</div><div class="line"><a name="l02418"></a><span class="lineno"> 2418</span>&#160;             (1, 1)),</div><div class="line"><a name="l02419"></a><span class="lineno"> 2419</span>&#160;            (StudentT(df=1., loc=torch.zeros(5, 1), scale=torch.ones(3)),</div><div class="line"><a name="l02420"></a><span class="lineno"> 2420</span>&#160;             (5, 3)),</div><div class="line"><a name="l02421"></a><span class="lineno"> 2421</span>&#160;        ]</div><div class="line"><a name="l02422"></a><span class="lineno"> 2422</span>&#160;</div><div class="line"><a name="l02423"></a><span class="lineno"> 2423</span>&#160;        <span class="keywordflow">for</span> dist, expected_size <span class="keywordflow">in</span> valid_examples:</div><div class="line"><a name="l02424"></a><span class="lineno"> 2424</span>&#160;            actual_size = dist.sample().size()</div><div class="line"><a name="l02425"></a><span class="lineno"> 2425</span>&#160;            self.assertEqual(actual_size, expected_size,</div><div class="line"><a name="l02426"></a><span class="lineno"> 2426</span>&#160;                             <span class="stringliteral">&#39;{} actual size: {} != expected size: {}&#39;</span>.format(dist, actual_size, expected_size))</div><div class="line"><a name="l02427"></a><span class="lineno"> 2427</span>&#160;</div><div class="line"><a name="l02428"></a><span class="lineno"> 2428</span>&#160;            sample_shape = torch.Size((2,))</div><div class="line"><a name="l02429"></a><span class="lineno"> 2429</span>&#160;            expected_size = sample_shape + expected_size</div><div class="line"><a name="l02430"></a><span class="lineno"> 2430</span>&#160;            actual_size = dist.sample(sample_shape).size()</div><div class="line"><a name="l02431"></a><span class="lineno"> 2431</span>&#160;            self.assertEqual(actual_size, expected_size,</div><div class="line"><a name="l02432"></a><span class="lineno"> 2432</span>&#160;                             <span class="stringliteral">&#39;{} actual size: {} != expected size: {}&#39;</span>.format(dist, actual_size, expected_size))</div><div class="line"><a name="l02433"></a><span class="lineno"> 2433</span>&#160;</div><div class="line"><a name="l02434"></a><span class="lineno"> 2434</span>&#160;    <span class="keyword">def </span>test_invalid_parameter_broadcasting(self):</div><div class="line"><a name="l02435"></a><span class="lineno"> 2435</span>&#160;        <span class="comment"># invalid broadcasting cases; should throw error</span></div><div class="line"><a name="l02436"></a><span class="lineno"> 2436</span>&#160;        <span class="comment"># example type (distribution class, distribution params)</span></div><div class="line"><a name="l02437"></a><span class="lineno"> 2437</span>&#160;        invalid_examples = [</div><div class="line"><a name="l02438"></a><span class="lineno"> 2438</span>&#160;            (Normal, {</div><div class="line"><a name="l02439"></a><span class="lineno"> 2439</span>&#160;                <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0, 0]]),</div><div class="line"><a name="l02440"></a><span class="lineno"> 2440</span>&#160;                <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1, 1])</div><div class="line"><a name="l02441"></a><span class="lineno"> 2441</span>&#160;            }),</div><div class="line"><a name="l02442"></a><span class="lineno"> 2442</span>&#160;            (Normal, {</div><div class="line"><a name="l02443"></a><span class="lineno"> 2443</span>&#160;                <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[[0, 0, 0], [0, 0, 0]]]),</div><div class="line"><a name="l02444"></a><span class="lineno"> 2444</span>&#160;                <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1])</div><div class="line"><a name="l02445"></a><span class="lineno"> 2445</span>&#160;            }),</div><div class="line"><a name="l02446"></a><span class="lineno"> 2446</span>&#160;            (FisherSnedecor, {</div><div class="line"><a name="l02447"></a><span class="lineno"> 2447</span>&#160;                <span class="stringliteral">&#39;df1&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1]),</div><div class="line"><a name="l02448"></a><span class="lineno"> 2448</span>&#160;                <span class="stringliteral">&#39;df2&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1]),</div><div class="line"><a name="l02449"></a><span class="lineno"> 2449</span>&#160;            }),</div><div class="line"><a name="l02450"></a><span class="lineno"> 2450</span>&#160;            (Gumbel, {</div><div class="line"><a name="l02451"></a><span class="lineno"> 2451</span>&#160;                <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0, 0]]),</div><div class="line"><a name="l02452"></a><span class="lineno"> 2452</span>&#160;                <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1, 1])</div><div class="line"><a name="l02453"></a><span class="lineno"> 2453</span>&#160;            }),</div><div class="line"><a name="l02454"></a><span class="lineno"> 2454</span>&#160;            (Gumbel, {</div><div class="line"><a name="l02455"></a><span class="lineno"> 2455</span>&#160;                <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[[0, 0, 0], [0, 0, 0]]]),</div><div class="line"><a name="l02456"></a><span class="lineno"> 2456</span>&#160;                <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1])</div><div class="line"><a name="l02457"></a><span class="lineno"> 2457</span>&#160;            }),</div><div class="line"><a name="l02458"></a><span class="lineno"> 2458</span>&#160;            (Gamma, {</div><div class="line"><a name="l02459"></a><span class="lineno"> 2459</span>&#160;                <span class="stringliteral">&#39;concentration&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 0]),</div><div class="line"><a name="l02460"></a><span class="lineno"> 2460</span>&#160;                <span class="stringliteral">&#39;rate&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1])</div><div class="line"><a name="l02461"></a><span class="lineno"> 2461</span>&#160;            }),</div><div class="line"><a name="l02462"></a><span class="lineno"> 2462</span>&#160;            (Laplace, {</div><div class="line"><a name="l02463"></a><span class="lineno"> 2463</span>&#160;                <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 0]),</div><div class="line"><a name="l02464"></a><span class="lineno"> 2464</span>&#160;                <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1])</div><div class="line"><a name="l02465"></a><span class="lineno"> 2465</span>&#160;            }),</div><div class="line"><a name="l02466"></a><span class="lineno"> 2466</span>&#160;            (Pareto, {</div><div class="line"><a name="l02467"></a><span class="lineno"> 2467</span>&#160;                <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1]),</div><div class="line"><a name="l02468"></a><span class="lineno"> 2468</span>&#160;                <span class="stringliteral">&#39;alpha&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1])</div><div class="line"><a name="l02469"></a><span class="lineno"> 2469</span>&#160;            }),</div><div class="line"><a name="l02470"></a><span class="lineno"> 2470</span>&#160;            (StudentT, {</div><div class="line"><a name="l02471"></a><span class="lineno"> 2471</span>&#160;                <span class="stringliteral">&#39;df&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1]),</div><div class="line"><a name="l02472"></a><span class="lineno"> 2472</span>&#160;                <span class="stringliteral">&#39;scale&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1])</div><div class="line"><a name="l02473"></a><span class="lineno"> 2473</span>&#160;            }),</div><div class="line"><a name="l02474"></a><span class="lineno"> 2474</span>&#160;            (StudentT, {</div><div class="line"><a name="l02475"></a><span class="lineno"> 2475</span>&#160;                <span class="stringliteral">&#39;df&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1]),</div><div class="line"><a name="l02476"></a><span class="lineno"> 2476</span>&#160;                <span class="stringliteral">&#39;loc&#39;</span>: <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 1, 1])</div><div class="line"><a name="l02477"></a><span class="lineno"> 2477</span>&#160;            })</div><div class="line"><a name="l02478"></a><span class="lineno"> 2478</span>&#160;        ]</div><div class="line"><a name="l02479"></a><span class="lineno"> 2479</span>&#160;</div><div class="line"><a name="l02480"></a><span class="lineno"> 2480</span>&#160;        <span class="keywordflow">for</span> dist, kwargs <span class="keywordflow">in</span> invalid_examples:</div><div class="line"><a name="l02481"></a><span class="lineno"> 2481</span>&#160;            self.assertRaises(RuntimeError, dist, **kwargs)</div><div class="line"><a name="l02482"></a><span class="lineno"> 2482</span>&#160;</div><div class="line"><a name="l02483"></a><span class="lineno"> 2483</span>&#160;</div><div class="line"><a name="l02484"></a><span class="lineno"> 2484</span>&#160;<span class="comment"># These tests are only needed for a few distributions that implement custom</span></div><div class="line"><a name="l02485"></a><span class="lineno"> 2485</span>&#160;<span class="comment"># reparameterized gradients. Most .rsample() implementations simply rely on</span></div><div class="line"><a name="l02486"></a><span class="lineno"> 2486</span>&#160;<span class="comment"># the reparameterization trick and do not need to be tested for accuracy.</span></div><div class="line"><a name="l02487"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_rsample.html"> 2487</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_rsample.html">TestRsample</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l02488"></a><span class="lineno"> 2488</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02489"></a><span class="lineno"> 2489</span>&#160;    <span class="keyword">def </span>test_gamma(self):</div><div class="line"><a name="l02490"></a><span class="lineno"> 2490</span>&#160;        num_samples = 100</div><div class="line"><a name="l02491"></a><span class="lineno"> 2491</span>&#160;        <span class="keywordflow">for</span> alpha <span class="keywordflow">in</span> [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]:</div><div class="line"><a name="l02492"></a><span class="lineno"> 2492</span>&#160;            alphas = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([alpha] * num_samples, dtype=torch.float, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02493"></a><span class="lineno"> 2493</span>&#160;            betas = alphas.new_ones(num_samples)</div><div class="line"><a name="l02494"></a><span class="lineno"> 2494</span>&#160;            x = Gamma(alphas, betas).rsample()</div><div class="line"><a name="l02495"></a><span class="lineno"> 2495</span>&#160;            x.sum().backward()</div><div class="line"><a name="l02496"></a><span class="lineno"> 2496</span>&#160;            x, ind = x.sort()</div><div class="line"><a name="l02497"></a><span class="lineno"> 2497</span>&#160;            x = x.detach().numpy()</div><div class="line"><a name="l02498"></a><span class="lineno"> 2498</span>&#160;            actual_grad = alphas.grad[ind].numpy()</div><div class="line"><a name="l02499"></a><span class="lineno"> 2499</span>&#160;            <span class="comment"># Compare with expected gradient dx/dalpha along constant cdf(x,alpha).</span></div><div class="line"><a name="l02500"></a><span class="lineno"> 2500</span>&#160;            cdf = scipy.stats.gamma.cdf</div><div class="line"><a name="l02501"></a><span class="lineno"> 2501</span>&#160;            pdf = scipy.stats.gamma.pdf</div><div class="line"><a name="l02502"></a><span class="lineno"> 2502</span>&#160;            eps = 0.01 * alpha / (1.0 + alpha ** 0.5)</div><div class="line"><a name="l02503"></a><span class="lineno"> 2503</span>&#160;            cdf_alpha = (cdf(x, alpha + eps) - cdf(x, alpha - eps)) / (2 * eps)</div><div class="line"><a name="l02504"></a><span class="lineno"> 2504</span>&#160;            cdf_x = pdf(x, alpha)</div><div class="line"><a name="l02505"></a><span class="lineno"> 2505</span>&#160;            expected_grad = -cdf_alpha / cdf_x</div><div class="line"><a name="l02506"></a><span class="lineno"> 2506</span>&#160;            rel_error = np.abs(actual_grad - expected_grad) / (expected_grad + 1e-30)</div><div class="line"><a name="l02507"></a><span class="lineno"> 2507</span>&#160;            self.assertLess(np.max(rel_error), 0.0005, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02508"></a><span class="lineno"> 2508</span>&#160;                <span class="stringliteral">&#39;Bad gradient dx/alpha for x ~ Gamma({}, 1)&#39;</span>.format(alpha),</div><div class="line"><a name="l02509"></a><span class="lineno"> 2509</span>&#160;                <span class="stringliteral">&#39;x {}&#39;</span>.format(x),</div><div class="line"><a name="l02510"></a><span class="lineno"> 2510</span>&#160;                <span class="stringliteral">&#39;expected {}&#39;</span>.format(expected_grad),</div><div class="line"><a name="l02511"></a><span class="lineno"> 2511</span>&#160;                <span class="stringliteral">&#39;actual {}&#39;</span>.format(actual_grad),</div><div class="line"><a name="l02512"></a><span class="lineno"> 2512</span>&#160;                <span class="stringliteral">&#39;rel error {}&#39;</span>.format(rel_error),</div><div class="line"><a name="l02513"></a><span class="lineno"> 2513</span>&#160;                <span class="stringliteral">&#39;max error {}&#39;</span>.format(rel_error.max()),</div><div class="line"><a name="l02514"></a><span class="lineno"> 2514</span>&#160;                <span class="stringliteral">&#39;at alpha={}, x={}&#39;</span>.format(alpha, x[rel_error.argmax()]),</div><div class="line"><a name="l02515"></a><span class="lineno"> 2515</span>&#160;            ]))</div><div class="line"><a name="l02516"></a><span class="lineno"> 2516</span>&#160;</div><div class="line"><a name="l02517"></a><span class="lineno"> 2517</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02518"></a><span class="lineno"> 2518</span>&#160;    <span class="keyword">def </span>test_chi2(self):</div><div class="line"><a name="l02519"></a><span class="lineno"> 2519</span>&#160;        num_samples = 100</div><div class="line"><a name="l02520"></a><span class="lineno"> 2520</span>&#160;        <span class="keywordflow">for</span> df <span class="keywordflow">in</span> [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]:</div><div class="line"><a name="l02521"></a><span class="lineno"> 2521</span>&#160;            dfs = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([df] * num_samples, dtype=torch.float, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02522"></a><span class="lineno"> 2522</span>&#160;            x = Chi2(dfs).rsample()</div><div class="line"><a name="l02523"></a><span class="lineno"> 2523</span>&#160;            x.sum().backward()</div><div class="line"><a name="l02524"></a><span class="lineno"> 2524</span>&#160;            x, ind = x.sort()</div><div class="line"><a name="l02525"></a><span class="lineno"> 2525</span>&#160;            x = x.detach().numpy()</div><div class="line"><a name="l02526"></a><span class="lineno"> 2526</span>&#160;            actual_grad = dfs.grad[ind].numpy()</div><div class="line"><a name="l02527"></a><span class="lineno"> 2527</span>&#160;            <span class="comment"># Compare with expected gradient dx/ddf along constant cdf(x,df).</span></div><div class="line"><a name="l02528"></a><span class="lineno"> 2528</span>&#160;            cdf = scipy.stats.chi2.cdf</div><div class="line"><a name="l02529"></a><span class="lineno"> 2529</span>&#160;            pdf = scipy.stats.chi2.pdf</div><div class="line"><a name="l02530"></a><span class="lineno"> 2530</span>&#160;            eps = 0.01 * df / (1.0 + df ** 0.5)</div><div class="line"><a name="l02531"></a><span class="lineno"> 2531</span>&#160;            cdf_df = (cdf(x, df + eps) - cdf(x, df - eps)) / (2 * eps)</div><div class="line"><a name="l02532"></a><span class="lineno"> 2532</span>&#160;            cdf_x = pdf(x, df)</div><div class="line"><a name="l02533"></a><span class="lineno"> 2533</span>&#160;            expected_grad = -cdf_df / cdf_x</div><div class="line"><a name="l02534"></a><span class="lineno"> 2534</span>&#160;            rel_error = np.abs(actual_grad - expected_grad) / (expected_grad + 1e-30)</div><div class="line"><a name="l02535"></a><span class="lineno"> 2535</span>&#160;            self.assertLess(np.max(rel_error), 0.001, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02536"></a><span class="lineno"> 2536</span>&#160;                <span class="stringliteral">&#39;Bad gradient dx/ddf for x ~ Chi2({})&#39;</span>.format(df),</div><div class="line"><a name="l02537"></a><span class="lineno"> 2537</span>&#160;                <span class="stringliteral">&#39;x {}&#39;</span>.format(x),</div><div class="line"><a name="l02538"></a><span class="lineno"> 2538</span>&#160;                <span class="stringliteral">&#39;expected {}&#39;</span>.format(expected_grad),</div><div class="line"><a name="l02539"></a><span class="lineno"> 2539</span>&#160;                <span class="stringliteral">&#39;actual {}&#39;</span>.format(actual_grad),</div><div class="line"><a name="l02540"></a><span class="lineno"> 2540</span>&#160;                <span class="stringliteral">&#39;rel error {}&#39;</span>.format(rel_error),</div><div class="line"><a name="l02541"></a><span class="lineno"> 2541</span>&#160;                <span class="stringliteral">&#39;max error {}&#39;</span>.format(rel_error.max()),</div><div class="line"><a name="l02542"></a><span class="lineno"> 2542</span>&#160;            ]))</div><div class="line"><a name="l02543"></a><span class="lineno"> 2543</span>&#160;</div><div class="line"><a name="l02544"></a><span class="lineno"> 2544</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02545"></a><span class="lineno"> 2545</span>&#160;    <span class="keyword">def </span>test_dirichlet_on_diagonal(self):</div><div class="line"><a name="l02546"></a><span class="lineno"> 2546</span>&#160;        num_samples = 20</div><div class="line"><a name="l02547"></a><span class="lineno"> 2547</span>&#160;        grid = [1e-1, 1e0, 1e1]</div><div class="line"><a name="l02548"></a><span class="lineno"> 2548</span>&#160;        <span class="keywordflow">for</span> a0, a1, a2 <span class="keywordflow">in</span> product(grid, grid, grid):</div><div class="line"><a name="l02549"></a><span class="lineno"> 2549</span>&#160;            alphas = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[a0, a1, a2]] * num_samples, dtype=torch.float, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02550"></a><span class="lineno"> 2550</span>&#160;            x = Dirichlet(alphas).rsample()[:, 0]</div><div class="line"><a name="l02551"></a><span class="lineno"> 2551</span>&#160;            x.sum().backward()</div><div class="line"><a name="l02552"></a><span class="lineno"> 2552</span>&#160;            x, ind = x.sort()</div><div class="line"><a name="l02553"></a><span class="lineno"> 2553</span>&#160;            x = x.detach().numpy()</div><div class="line"><a name="l02554"></a><span class="lineno"> 2554</span>&#160;            actual_grad = alphas.grad[ind].numpy()[:, 0]</div><div class="line"><a name="l02555"></a><span class="lineno"> 2555</span>&#160;            <span class="comment"># Compare with expected gradient dx/dalpha0 along constant cdf(x,alpha).</span></div><div class="line"><a name="l02556"></a><span class="lineno"> 2556</span>&#160;            <span class="comment"># This reduces to a distribution Beta(alpha[0], alpha[1] + alpha[2]).</span></div><div class="line"><a name="l02557"></a><span class="lineno"> 2557</span>&#160;            cdf = scipy.stats.beta.cdf</div><div class="line"><a name="l02558"></a><span class="lineno"> 2558</span>&#160;            pdf = scipy.stats.beta.pdf</div><div class="line"><a name="l02559"></a><span class="lineno"> 2559</span>&#160;            alpha, beta = a0, a1 + a2</div><div class="line"><a name="l02560"></a><span class="lineno"> 2560</span>&#160;            eps = 0.01 * alpha / (1.0 + np.sqrt(alpha))</div><div class="line"><a name="l02561"></a><span class="lineno"> 2561</span>&#160;            cdf_alpha = (cdf(x, alpha + eps, beta) - cdf(x, alpha - eps, beta)) / (2 * eps)</div><div class="line"><a name="l02562"></a><span class="lineno"> 2562</span>&#160;            cdf_x = pdf(x, alpha, beta)</div><div class="line"><a name="l02563"></a><span class="lineno"> 2563</span>&#160;            expected_grad = -cdf_alpha / cdf_x</div><div class="line"><a name="l02564"></a><span class="lineno"> 2564</span>&#160;            rel_error = np.abs(actual_grad - expected_grad) / (expected_grad + 1e-30)</div><div class="line"><a name="l02565"></a><span class="lineno"> 2565</span>&#160;            self.assertLess(np.max(rel_error), 0.001, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02566"></a><span class="lineno"> 2566</span>&#160;                <span class="stringliteral">&#39;Bad gradient dx[0]/dalpha[0] for Dirichlet([{}, {}, {}])&#39;</span>.format(a0, a1, a2),</div><div class="line"><a name="l02567"></a><span class="lineno"> 2567</span>&#160;                <span class="stringliteral">&#39;x {}&#39;</span>.format(x),</div><div class="line"><a name="l02568"></a><span class="lineno"> 2568</span>&#160;                <span class="stringliteral">&#39;expected {}&#39;</span>.format(expected_grad),</div><div class="line"><a name="l02569"></a><span class="lineno"> 2569</span>&#160;                <span class="stringliteral">&#39;actual {}&#39;</span>.format(actual_grad),</div><div class="line"><a name="l02570"></a><span class="lineno"> 2570</span>&#160;                <span class="stringliteral">&#39;rel error {}&#39;</span>.format(rel_error),</div><div class="line"><a name="l02571"></a><span class="lineno"> 2571</span>&#160;                <span class="stringliteral">&#39;max error {}&#39;</span>.format(rel_error.max()),</div><div class="line"><a name="l02572"></a><span class="lineno"> 2572</span>&#160;                <span class="stringliteral">&#39;at x={}&#39;</span>.format(x[rel_error.argmax()]),</div><div class="line"><a name="l02573"></a><span class="lineno"> 2573</span>&#160;            ]))</div><div class="line"><a name="l02574"></a><span class="lineno"> 2574</span>&#160;</div><div class="line"><a name="l02575"></a><span class="lineno"> 2575</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02576"></a><span class="lineno"> 2576</span>&#160;    <span class="keyword">def </span>test_beta_wrt_alpha(self):</div><div class="line"><a name="l02577"></a><span class="lineno"> 2577</span>&#160;        num_samples = 20</div><div class="line"><a name="l02578"></a><span class="lineno"> 2578</span>&#160;        grid = [1e-2, 1e-1, 1e0, 1e1, 1e2]</div><div class="line"><a name="l02579"></a><span class="lineno"> 2579</span>&#160;        <span class="keywordflow">for</span> con1, con0 <span class="keywordflow">in</span> product(grid, grid):</div><div class="line"><a name="l02580"></a><span class="lineno"> 2580</span>&#160;            con1s = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([con1] * num_samples, dtype=torch.float, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02581"></a><span class="lineno"> 2581</span>&#160;            con0s = con1s.new_tensor([con0] * num_samples)</div><div class="line"><a name="l02582"></a><span class="lineno"> 2582</span>&#160;            x = Beta(con1s, con0s).rsample()</div><div class="line"><a name="l02583"></a><span class="lineno"> 2583</span>&#160;            x.sum().backward()</div><div class="line"><a name="l02584"></a><span class="lineno"> 2584</span>&#160;            x, ind = x.sort()</div><div class="line"><a name="l02585"></a><span class="lineno"> 2585</span>&#160;            x = x.detach().numpy()</div><div class="line"><a name="l02586"></a><span class="lineno"> 2586</span>&#160;            actual_grad = con1s.grad[ind].numpy()</div><div class="line"><a name="l02587"></a><span class="lineno"> 2587</span>&#160;            <span class="comment"># Compare with expected gradient dx/dcon1 along constant cdf(x,con1,con0).</span></div><div class="line"><a name="l02588"></a><span class="lineno"> 2588</span>&#160;            cdf = scipy.stats.beta.cdf</div><div class="line"><a name="l02589"></a><span class="lineno"> 2589</span>&#160;            pdf = scipy.stats.beta.pdf</div><div class="line"><a name="l02590"></a><span class="lineno"> 2590</span>&#160;            eps = 0.01 * con1 / (1.0 + np.sqrt(con1))</div><div class="line"><a name="l02591"></a><span class="lineno"> 2591</span>&#160;            cdf_alpha = (cdf(x, con1 + eps, con0) - cdf(x, con1 - eps, con0)) / (2 * eps)</div><div class="line"><a name="l02592"></a><span class="lineno"> 2592</span>&#160;            cdf_x = pdf(x, con1, con0)</div><div class="line"><a name="l02593"></a><span class="lineno"> 2593</span>&#160;            expected_grad = -cdf_alpha / cdf_x</div><div class="line"><a name="l02594"></a><span class="lineno"> 2594</span>&#160;            rel_error = np.abs(actual_grad - expected_grad) / (expected_grad + 1e-30)</div><div class="line"><a name="l02595"></a><span class="lineno"> 2595</span>&#160;            self.assertLess(np.max(rel_error), 0.005, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02596"></a><span class="lineno"> 2596</span>&#160;                <span class="stringliteral">&#39;Bad gradient dx/dcon1 for x ~ Beta({}, {})&#39;</span>.format(con1, con0),</div><div class="line"><a name="l02597"></a><span class="lineno"> 2597</span>&#160;                <span class="stringliteral">&#39;x {}&#39;</span>.format(x),</div><div class="line"><a name="l02598"></a><span class="lineno"> 2598</span>&#160;                <span class="stringliteral">&#39;expected {}&#39;</span>.format(expected_grad),</div><div class="line"><a name="l02599"></a><span class="lineno"> 2599</span>&#160;                <span class="stringliteral">&#39;actual {}&#39;</span>.format(actual_grad),</div><div class="line"><a name="l02600"></a><span class="lineno"> 2600</span>&#160;                <span class="stringliteral">&#39;rel error {}&#39;</span>.format(rel_error),</div><div class="line"><a name="l02601"></a><span class="lineno"> 2601</span>&#160;                <span class="stringliteral">&#39;max error {}&#39;</span>.format(rel_error.max()),</div><div class="line"><a name="l02602"></a><span class="lineno"> 2602</span>&#160;                <span class="stringliteral">&#39;at x = {}&#39;</span>.format(x[rel_error.argmax()]),</div><div class="line"><a name="l02603"></a><span class="lineno"> 2603</span>&#160;            ]))</div><div class="line"><a name="l02604"></a><span class="lineno"> 2604</span>&#160;</div><div class="line"><a name="l02605"></a><span class="lineno"> 2605</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l02606"></a><span class="lineno"> 2606</span>&#160;    <span class="keyword">def </span>test_beta_wrt_beta(self):</div><div class="line"><a name="l02607"></a><span class="lineno"> 2607</span>&#160;        num_samples = 20</div><div class="line"><a name="l02608"></a><span class="lineno"> 2608</span>&#160;        grid = [1e-2, 1e-1, 1e0, 1e1, 1e2]</div><div class="line"><a name="l02609"></a><span class="lineno"> 2609</span>&#160;        <span class="keywordflow">for</span> con1, con0 <span class="keywordflow">in</span> product(grid, grid):</div><div class="line"><a name="l02610"></a><span class="lineno"> 2610</span>&#160;            con0s = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([con0] * num_samples, dtype=torch.float, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02611"></a><span class="lineno"> 2611</span>&#160;            con1s = con0s.new_tensor([con1] * num_samples)</div><div class="line"><a name="l02612"></a><span class="lineno"> 2612</span>&#160;            x = Beta(con1s, con0s).rsample()</div><div class="line"><a name="l02613"></a><span class="lineno"> 2613</span>&#160;            x.sum().backward()</div><div class="line"><a name="l02614"></a><span class="lineno"> 2614</span>&#160;            x, ind = x.sort()</div><div class="line"><a name="l02615"></a><span class="lineno"> 2615</span>&#160;            x = x.detach().numpy()</div><div class="line"><a name="l02616"></a><span class="lineno"> 2616</span>&#160;            actual_grad = con0s.grad[ind].numpy()</div><div class="line"><a name="l02617"></a><span class="lineno"> 2617</span>&#160;            <span class="comment"># Compare with expected gradient dx/dcon0 along constant cdf(x,con1,con0).</span></div><div class="line"><a name="l02618"></a><span class="lineno"> 2618</span>&#160;            cdf = scipy.stats.beta.cdf</div><div class="line"><a name="l02619"></a><span class="lineno"> 2619</span>&#160;            pdf = scipy.stats.beta.pdf</div><div class="line"><a name="l02620"></a><span class="lineno"> 2620</span>&#160;            eps = 0.01 * con0 / (1.0 + np.sqrt(con0))</div><div class="line"><a name="l02621"></a><span class="lineno"> 2621</span>&#160;            cdf_beta = (cdf(x, con1, con0 + eps) - cdf(x, con1, con0 - eps)) / (2 * eps)</div><div class="line"><a name="l02622"></a><span class="lineno"> 2622</span>&#160;            cdf_x = pdf(x, con1, con0)</div><div class="line"><a name="l02623"></a><span class="lineno"> 2623</span>&#160;            expected_grad = -cdf_beta / cdf_x</div><div class="line"><a name="l02624"></a><span class="lineno"> 2624</span>&#160;            rel_error = np.abs(actual_grad - expected_grad) / (expected_grad + 1e-30)</div><div class="line"><a name="l02625"></a><span class="lineno"> 2625</span>&#160;            self.assertLess(np.max(rel_error), 0.005, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02626"></a><span class="lineno"> 2626</span>&#160;                <span class="stringliteral">&#39;Bad gradient dx/dcon0 for x ~ Beta({}, {})&#39;</span>.format(con1, con0),</div><div class="line"><a name="l02627"></a><span class="lineno"> 2627</span>&#160;                <span class="stringliteral">&#39;x {}&#39;</span>.format(x),</div><div class="line"><a name="l02628"></a><span class="lineno"> 2628</span>&#160;                <span class="stringliteral">&#39;expected {}&#39;</span>.format(expected_grad),</div><div class="line"><a name="l02629"></a><span class="lineno"> 2629</span>&#160;                <span class="stringliteral">&#39;actual {}&#39;</span>.format(actual_grad),</div><div class="line"><a name="l02630"></a><span class="lineno"> 2630</span>&#160;                <span class="stringliteral">&#39;rel error {}&#39;</span>.format(rel_error),</div><div class="line"><a name="l02631"></a><span class="lineno"> 2631</span>&#160;                <span class="stringliteral">&#39;max error {}&#39;</span>.format(rel_error.max()),</div><div class="line"><a name="l02632"></a><span class="lineno"> 2632</span>&#160;                <span class="stringliteral">&#39;at x = {!r}&#39;</span>.format(x[rel_error.argmax()]),</div><div class="line"><a name="l02633"></a><span class="lineno"> 2633</span>&#160;            ]))</div><div class="line"><a name="l02634"></a><span class="lineno"> 2634</span>&#160;</div><div class="line"><a name="l02635"></a><span class="lineno"> 2635</span>&#160;    <span class="keyword">def </span>test_dirichlet_multivariate(self):</div><div class="line"><a name="l02636"></a><span class="lineno"> 2636</span>&#160;        alpha_crit = 0.25 * (5.0 ** 0.5 - 1.0)</div><div class="line"><a name="l02637"></a><span class="lineno"> 2637</span>&#160;        num_samples = 100000</div><div class="line"><a name="l02638"></a><span class="lineno"> 2638</span>&#160;        <span class="keywordflow">for</span> shift <span class="keywordflow">in</span> [-0.1, -0.05, -0.01, 0.0, 0.01, 0.05, 0.10]:</div><div class="line"><a name="l02639"></a><span class="lineno"> 2639</span>&#160;            alpha = alpha_crit + shift</div><div class="line"><a name="l02640"></a><span class="lineno"> 2640</span>&#160;            alpha = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([alpha], dtype=torch.float, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l02641"></a><span class="lineno"> 2641</span>&#160;            alpha_vec = torch.cat([alpha, alpha, alpha.new([1])])</div><div class="line"><a name="l02642"></a><span class="lineno"> 2642</span>&#160;            z = Dirichlet(alpha_vec.expand(num_samples, 3)).rsample()</div><div class="line"><a name="l02643"></a><span class="lineno"> 2643</span>&#160;            mean_z3 = 1.0 / (2.0 * alpha + 1.0)</div><div class="line"><a name="l02644"></a><span class="lineno"> 2644</span>&#160;            loss = torch.pow(z[:, 2] - mean_z3, 2.0).mean()</div><div class="line"><a name="l02645"></a><span class="lineno"> 2645</span>&#160;            actual_grad = grad(loss, [alpha])[0]</div><div class="line"><a name="l02646"></a><span class="lineno"> 2646</span>&#160;            <span class="comment"># Compute expected gradient by hand.</span></div><div class="line"><a name="l02647"></a><span class="lineno"> 2647</span>&#160;            num = 1.0 - 2.0 * alpha - 4.0 * alpha**2</div><div class="line"><a name="l02648"></a><span class="lineno"> 2648</span>&#160;            den = (1.0 + alpha)**2 * (1.0 + 2.0 * alpha)**3</div><div class="line"><a name="l02649"></a><span class="lineno"> 2649</span>&#160;            expected_grad = num / den</div><div class="line"><a name="l02650"></a><span class="lineno"> 2650</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual_grad, expected_grad, 0.002, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02651"></a><span class="lineno"> 2651</span>&#160;                <span class="stringliteral">&quot;alpha = alpha_c + %.2g&quot;</span> % shift,</div><div class="line"><a name="l02652"></a><span class="lineno"> 2652</span>&#160;                <span class="stringliteral">&quot;expected_grad: %.5g&quot;</span> % expected_grad,</div><div class="line"><a name="l02653"></a><span class="lineno"> 2653</span>&#160;                <span class="stringliteral">&quot;actual_grad: %.5g&quot;</span> % actual_grad,</div><div class="line"><a name="l02654"></a><span class="lineno"> 2654</span>&#160;                <span class="stringliteral">&quot;error = %.2g&quot;</span> % torch.abs(expected_grad - actual_grad).max(),</div><div class="line"><a name="l02655"></a><span class="lineno"> 2655</span>&#160;            ]))</div><div class="line"><a name="l02656"></a><span class="lineno"> 2656</span>&#160;</div><div class="line"><a name="l02657"></a><span class="lineno"> 2657</span>&#160;    <span class="keyword">def </span>test_dirichlet_tangent_field(self):</div><div class="line"><a name="l02658"></a><span class="lineno"> 2658</span>&#160;        num_samples = 20</div><div class="line"><a name="l02659"></a><span class="lineno"> 2659</span>&#160;        alpha_grid = [0.5, 1.0, 2.0]</div><div class="line"><a name="l02660"></a><span class="lineno"> 2660</span>&#160;</div><div class="line"><a name="l02661"></a><span class="lineno"> 2661</span>&#160;        <span class="comment"># v = dx/dalpha[0] is the reparameterized gradient aka tangent field.</span></div><div class="line"><a name="l02662"></a><span class="lineno"> 2662</span>&#160;        <span class="keyword">def </span>compute_v(x, alpha):</div><div class="line"><a name="l02663"></a><span class="lineno"> 2663</span>&#160;            <span class="keywordflow">return</span> torch.stack([</div><div class="line"><a name="l02664"></a><span class="lineno"> 2664</span>&#160;                _Dirichlet_backward(x, alpha, torch.eye(3, 3)[i].expand_as(x))[:, 0]</div><div class="line"><a name="l02665"></a><span class="lineno"> 2665</span>&#160;                <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(3)</div><div class="line"><a name="l02666"></a><span class="lineno"> 2666</span>&#160;            ], dim=-1)</div><div class="line"><a name="l02667"></a><span class="lineno"> 2667</span>&#160;</div><div class="line"><a name="l02668"></a><span class="lineno"> 2668</span>&#160;        <span class="keywordflow">for</span> a1, a2, a3 <span class="keywordflow">in</span> product(alpha_grid, alpha_grid, alpha_grid):</div><div class="line"><a name="l02669"></a><span class="lineno"> 2669</span>&#160;            alpha = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([a1, a2, a3], requires_grad=<span class="keyword">True</span>).expand(num_samples, 3)</div><div class="line"><a name="l02670"></a><span class="lineno"> 2670</span>&#160;            x = Dirichlet(alpha).rsample()</div><div class="line"><a name="l02671"></a><span class="lineno"> 2671</span>&#160;            dlogp_da = grad([Dirichlet(alpha).log_prob(x.detach()).sum()],</div><div class="line"><a name="l02672"></a><span class="lineno"> 2672</span>&#160;                            [alpha], retain_graph=<span class="keyword">True</span>)[0][:, 0]</div><div class="line"><a name="l02673"></a><span class="lineno"> 2673</span>&#160;            dlogp_dx = grad([Dirichlet(alpha.detach()).log_prob(x).sum()],</div><div class="line"><a name="l02674"></a><span class="lineno"> 2674</span>&#160;                            [x], retain_graph=<span class="keyword">True</span>)[0]</div><div class="line"><a name="l02675"></a><span class="lineno"> 2675</span>&#160;            v = torch.stack([grad([x[:, i].sum()], [alpha], retain_graph=<span class="keyword">True</span>)[0][:, 0]</div><div class="line"><a name="l02676"></a><span class="lineno"> 2676</span>&#160;                             <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(3)], dim=-1)</div><div class="line"><a name="l02677"></a><span class="lineno"> 2677</span>&#160;            <span class="comment"># Compute ramaining properties by finite difference.</span></div><div class="line"><a name="l02678"></a><span class="lineno"> 2678</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(compute_v(x, alpha), v, message=<span class="stringliteral">&#39;Bug in compute_v() helper&#39;</span>)</div><div class="line"><a name="l02679"></a><span class="lineno"> 2679</span>&#160;            <span class="comment"># dx is an arbitrary orthonormal basis tangent to the simplex.</span></div><div class="line"><a name="l02680"></a><span class="lineno"> 2680</span>&#160;            dx = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[2., -1., -1.], [0., 1., -1.]])</div><div class="line"><a name="l02681"></a><span class="lineno"> 2681</span>&#160;            dx /= dx.norm(2, -1, <span class="keyword">True</span>)</div><div class="line"><a name="l02682"></a><span class="lineno"> 2682</span>&#160;            eps = 1e-2 * x.min(-1, <span class="keyword">True</span>)[0]  <span class="comment"># avoid boundary</span></div><div class="line"><a name="l02683"></a><span class="lineno"> 2683</span>&#160;            dv0 = (compute_v(x + eps * dx[0], alpha) - compute_v(x - eps * dx[0], alpha)) / (2 * eps)</div><div class="line"><a name="l02684"></a><span class="lineno"> 2684</span>&#160;            dv1 = (compute_v(x + eps * dx[1], alpha) - compute_v(x - eps * dx[1], alpha)) / (2 * eps)</div><div class="line"><a name="l02685"></a><span class="lineno"> 2685</span>&#160;            div_v = (dv0 * dx[0] + dv1 * dx[1]).sum(-1)</div><div class="line"><a name="l02686"></a><span class="lineno"> 2686</span>&#160;            <span class="comment"># This is a modification of the standard continuity equation, using the product rule to allow</span></div><div class="line"><a name="l02687"></a><span class="lineno"> 2687</span>&#160;            <span class="comment"># expression in terms of log_prob rather than the less numerically stable log_prob.exp().</span></div><div class="line"><a name="l02688"></a><span class="lineno"> 2688</span>&#160;            error = dlogp_da + (dlogp_dx * v).sum(-1) + div_v</div><div class="line"><a name="l02689"></a><span class="lineno"> 2689</span>&#160;            self.assertLess(torch.abs(error).max(), 0.005, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l02690"></a><span class="lineno"> 2690</span>&#160;                <span class="stringliteral">&#39;Dirichlet([{}, {}, {}]) gradient violates continuity equation:&#39;</span>.format(a1, a2, a3),</div><div class="line"><a name="l02691"></a><span class="lineno"> 2691</span>&#160;                <span class="stringliteral">&#39;error = {}&#39;</span>.format(error),</div><div class="line"><a name="l02692"></a><span class="lineno"> 2692</span>&#160;            ]))</div><div class="line"><a name="l02693"></a><span class="lineno"> 2693</span>&#160;</div><div class="line"><a name="l02694"></a><span class="lineno"> 2694</span>&#160;</div><div class="line"><a name="l02695"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_distribution_shapes.html"> 2695</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html">TestDistributionShapes</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l02696"></a><span class="lineno"> 2696</span>&#160;    <span class="keyword">def </span>setUp(self):</div><div class="line"><a name="l02697"></a><span class="lineno"> 2697</span>&#160;        super(TestDistributionShapes, self).setUp()</div><div class="line"><a name="l02698"></a><span class="lineno"> 2698</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a> = 1</div><div class="line"><a name="l02699"></a><span class="lineno"> 2699</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a> = torch.ones(3, 2)</div><div class="line"><a name="l02700"></a><span class="lineno"> 2700</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a> = torch.ones(3, 2, 3)</div><div class="line"><a name="l02701"></a><span class="lineno"> 2701</span>&#160;        Distribution.set_default_validate_args(<span class="keyword">True</span>)</div><div class="line"><a name="l02702"></a><span class="lineno"> 2702</span>&#160;</div><div class="line"><a name="l02703"></a><span class="lineno"> 2703</span>&#160;    <span class="keyword">def </span>tearDown(self):</div><div class="line"><a name="l02704"></a><span class="lineno"> 2704</span>&#160;        super(TestDistributionShapes, self).tearDown()</div><div class="line"><a name="l02705"></a><span class="lineno"> 2705</span>&#160;        Distribution.set_default_validate_args(<span class="keyword">False</span>)</div><div class="line"><a name="l02706"></a><span class="lineno"> 2706</span>&#160;</div><div class="line"><a name="l02707"></a><span class="lineno"> 2707</span>&#160;    <span class="keyword">def </span>test_entropy_shape(self):</div><div class="line"><a name="l02708"></a><span class="lineno"> 2708</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l02709"></a><span class="lineno"> 2709</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l02710"></a><span class="lineno"> 2710</span>&#160;                dist = Dist(validate_args=<span class="keyword">False</span>, **param)</div><div class="line"><a name="l02711"></a><span class="lineno"> 2711</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l02712"></a><span class="lineno"> 2712</span>&#160;                    actual_shape = dist.entropy().size()</div><div class="line"><a name="l02713"></a><span class="lineno"> 2713</span>&#160;                    expected_shape = dist.batch_shape <span class="keywordflow">if</span> dist.batch_shape <span class="keywordflow">else</span> torch.Size()</div><div class="line"><a name="l02714"></a><span class="lineno"> 2714</span>&#160;                    message = <span class="stringliteral">&#39;{} example {}/{}, shape mismatch. expected {}, actual {}&#39;</span>.format(</div><div class="line"><a name="l02715"></a><span class="lineno"> 2715</span>&#160;                        Dist.__name__, i + 1, len(params), expected_shape, actual_shape)</div><div class="line"><a name="l02716"></a><span class="lineno"> 2716</span>&#160;                    self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual_shape, expected_shape, message=message)</div><div class="line"><a name="l02717"></a><span class="lineno"> 2717</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l02718"></a><span class="lineno"> 2718</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l02719"></a><span class="lineno"> 2719</span>&#160;</div><div class="line"><a name="l02720"></a><span class="lineno"> 2720</span>&#160;    <span class="keyword">def </span>test_bernoulli_shape_scalar_params(self):</div><div class="line"><a name="l02721"></a><span class="lineno"> 2721</span>&#160;        bernoulli = Bernoulli(0.3)</div><div class="line"><a name="l02722"></a><span class="lineno"> 2722</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli._batch_shape, torch.Size())</div><div class="line"><a name="l02723"></a><span class="lineno"> 2723</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli._event_shape, torch.Size())</div><div class="line"><a name="l02724"></a><span class="lineno"> 2724</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.sample().size(), torch.Size())</div><div class="line"><a name="l02725"></a><span class="lineno"> 2725</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02726"></a><span class="lineno"> 2726</span>&#160;        self.assertRaises(ValueError, bernoulli.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02727"></a><span class="lineno"> 2727</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02728"></a><span class="lineno"> 2728</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02729"></a><span class="lineno"> 2729</span>&#160;</div><div class="line"><a name="l02730"></a><span class="lineno"> 2730</span>&#160;    <span class="keyword">def </span>test_bernoulli_shape_tensor_params(self):</div><div class="line"><a name="l02731"></a><span class="lineno"> 2731</span>&#160;        bernoulli = Bernoulli(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.6, 0.3], [0.6, 0.3], [0.6, 0.3]]))</div><div class="line"><a name="l02732"></a><span class="lineno"> 2732</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli._batch_shape, torch.Size((3, 2)))</div><div class="line"><a name="l02733"></a><span class="lineno"> 2733</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli._event_shape, torch.Size(()))</div><div class="line"><a name="l02734"></a><span class="lineno"> 2734</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.sample().size(), torch.Size((3, 2)))</div><div class="line"><a name="l02735"></a><span class="lineno"> 2735</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.sample((3, 2)).size(), torch.Size((3, 2, 3, 2)))</div><div class="line"><a name="l02736"></a><span class="lineno"> 2736</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02737"></a><span class="lineno"> 2737</span>&#160;        self.assertRaises(ValueError, bernoulli.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02738"></a><span class="lineno"> 2738</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(bernoulli.log_prob(torch.ones(3, 1, 1)).size(), torch.Size((3, 3, 2)))</div><div class="line"><a name="l02739"></a><span class="lineno"> 2739</span>&#160;</div><div class="line"><a name="l02740"></a><span class="lineno"> 2740</span>&#160;    <span class="keyword">def </span>test_geometric_shape_scalar_params(self):</div><div class="line"><a name="l02741"></a><span class="lineno"> 2741</span>&#160;        geometric = Geometric(0.3)</div><div class="line"><a name="l02742"></a><span class="lineno"> 2742</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric._batch_shape, torch.Size())</div><div class="line"><a name="l02743"></a><span class="lineno"> 2743</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric._event_shape, torch.Size())</div><div class="line"><a name="l02744"></a><span class="lineno"> 2744</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.sample().size(), torch.Size())</div><div class="line"><a name="l02745"></a><span class="lineno"> 2745</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02746"></a><span class="lineno"> 2746</span>&#160;        self.assertRaises(ValueError, geometric.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02747"></a><span class="lineno"> 2747</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02748"></a><span class="lineno"> 2748</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02749"></a><span class="lineno"> 2749</span>&#160;</div><div class="line"><a name="l02750"></a><span class="lineno"> 2750</span>&#160;    <span class="keyword">def </span>test_geometric_shape_tensor_params(self):</div><div class="line"><a name="l02751"></a><span class="lineno"> 2751</span>&#160;        geometric = Geometric(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.6, 0.3], [0.6, 0.3], [0.6, 0.3]]))</div><div class="line"><a name="l02752"></a><span class="lineno"> 2752</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric._batch_shape, torch.Size((3, 2)))</div><div class="line"><a name="l02753"></a><span class="lineno"> 2753</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric._event_shape, torch.Size(()))</div><div class="line"><a name="l02754"></a><span class="lineno"> 2754</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.sample().size(), torch.Size((3, 2)))</div><div class="line"><a name="l02755"></a><span class="lineno"> 2755</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.sample((3, 2)).size(), torch.Size((3, 2, 3, 2)))</div><div class="line"><a name="l02756"></a><span class="lineno"> 2756</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02757"></a><span class="lineno"> 2757</span>&#160;        self.assertRaises(ValueError, geometric.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02758"></a><span class="lineno"> 2758</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(geometric.log_prob(torch.ones(3, 1, 1)).size(), torch.Size((3, 3, 2)))</div><div class="line"><a name="l02759"></a><span class="lineno"> 2759</span>&#160;</div><div class="line"><a name="l02760"></a><span class="lineno"> 2760</span>&#160;    <span class="keyword">def </span>test_beta_shape_scalar_params(self):</div><div class="line"><a name="l02761"></a><span class="lineno"> 2761</span>&#160;        dist = Beta(0.1, 0.1)</div><div class="line"><a name="l02762"></a><span class="lineno"> 2762</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size())</div><div class="line"><a name="l02763"></a><span class="lineno"> 2763</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size())</div><div class="line"><a name="l02764"></a><span class="lineno"> 2764</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size())</div><div class="line"><a name="l02765"></a><span class="lineno"> 2765</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02766"></a><span class="lineno"> 2766</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02767"></a><span class="lineno"> 2767</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02768"></a><span class="lineno"> 2768</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02769"></a><span class="lineno"> 2769</span>&#160;</div><div class="line"><a name="l02770"></a><span class="lineno"> 2770</span>&#160;    <span class="keyword">def </span>test_beta_shape_tensor_params(self):</div><div class="line"><a name="l02771"></a><span class="lineno"> 2771</span>&#160;        dist = Beta(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]]),</div><div class="line"><a name="l02772"></a><span class="lineno"> 2772</span>&#160;                    <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]]))</div><div class="line"><a name="l02773"></a><span class="lineno"> 2773</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size((3, 2)))</div><div class="line"><a name="l02774"></a><span class="lineno"> 2774</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size(()))</div><div class="line"><a name="l02775"></a><span class="lineno"> 2775</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((3, 2)))</div><div class="line"><a name="l02776"></a><span class="lineno"> 2776</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2, 3, 2)))</div><div class="line"><a name="l02777"></a><span class="lineno"> 2777</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02778"></a><span class="lineno"> 2778</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02779"></a><span class="lineno"> 2779</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(torch.ones(3, 1, 1)).size(), torch.Size((3, 3, 2)))</div><div class="line"><a name="l02780"></a><span class="lineno"> 2780</span>&#160;</div><div class="line"><a name="l02781"></a><span class="lineno"> 2781</span>&#160;    <span class="keyword">def </span>test_binomial_shape(self):</div><div class="line"><a name="l02782"></a><span class="lineno"> 2782</span>&#160;        dist = Binomial(10, <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.6, 0.3]))</div><div class="line"><a name="l02783"></a><span class="lineno"> 2783</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l02784"></a><span class="lineno"> 2784</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size(()))</div><div class="line"><a name="l02785"></a><span class="lineno"> 2785</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l02786"></a><span class="lineno"> 2786</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l02787"></a><span class="lineno"> 2787</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02788"></a><span class="lineno"> 2788</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02789"></a><span class="lineno"> 2789</span>&#160;</div><div class="line"><a name="l02790"></a><span class="lineno"> 2790</span>&#160;    <span class="keyword">def </span>test_binomial_shape_vectorized_n(self):</div><div class="line"><a name="l02791"></a><span class="lineno"> 2791</span>&#160;        dist = Binomial(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[10, 3, 1], [4, 8, 4]]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.6, 0.3, 0.1]))</div><div class="line"><a name="l02792"></a><span class="lineno"> 2792</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size((2, 3)))</div><div class="line"><a name="l02793"></a><span class="lineno"> 2793</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size(()))</div><div class="line"><a name="l02794"></a><span class="lineno"> 2794</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((2, 3)))</div><div class="line"><a name="l02795"></a><span class="lineno"> 2795</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2, 2, 3)))</div><div class="line"><a name="l02796"></a><span class="lineno"> 2796</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02797"></a><span class="lineno"> 2797</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>)</div><div class="line"><a name="l02798"></a><span class="lineno"> 2798</span>&#160;</div><div class="line"><a name="l02799"></a><span class="lineno"> 2799</span>&#160;    <span class="keyword">def </span>test_multinomial_shape(self):</div><div class="line"><a name="l02800"></a><span class="lineno"> 2800</span>&#160;        dist = Multinomial(10, <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.6, 0.3], [0.6, 0.3], [0.6, 0.3]]))</div><div class="line"><a name="l02801"></a><span class="lineno"> 2801</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size((3,)))</div><div class="line"><a name="l02802"></a><span class="lineno"> 2802</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size((2,)))</div><div class="line"><a name="l02803"></a><span class="lineno"> 2803</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((3, 2)))</div><div class="line"><a name="l02804"></a><span class="lineno"> 2804</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2, 3, 2)))</div><div class="line"><a name="l02805"></a><span class="lineno"> 2805</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3,)))</div><div class="line"><a name="l02806"></a><span class="lineno"> 2806</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02807"></a><span class="lineno"> 2807</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(torch.ones(3, 1, 2)).size(), torch.Size((3, 3)))</div><div class="line"><a name="l02808"></a><span class="lineno"> 2808</span>&#160;</div><div class="line"><a name="l02809"></a><span class="lineno"> 2809</span>&#160;    <span class="keyword">def </span>test_categorical_shape(self):</div><div class="line"><a name="l02810"></a><span class="lineno"> 2810</span>&#160;        <span class="comment"># unbatched</span></div><div class="line"><a name="l02811"></a><span class="lineno"> 2811</span>&#160;        dist = Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.6, 0.3, 0.1]))</div><div class="line"><a name="l02812"></a><span class="lineno"> 2812</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size(()))</div><div class="line"><a name="l02813"></a><span class="lineno"> 2813</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size(()))</div><div class="line"><a name="l02814"></a><span class="lineno"> 2814</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size())</div><div class="line"><a name="l02815"></a><span class="lineno"> 2815</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2,)))</div><div class="line"><a name="l02816"></a><span class="lineno"> 2816</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02817"></a><span class="lineno"> 2817</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02818"></a><span class="lineno"> 2818</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(torch.ones(3, 1)).size(), torch.Size((3, 1)))</div><div class="line"><a name="l02819"></a><span class="lineno"> 2819</span>&#160;        <span class="comment"># batched</span></div><div class="line"><a name="l02820"></a><span class="lineno"> 2820</span>&#160;        dist = Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.6, 0.3], [0.6, 0.3], [0.6, 0.3]]))</div><div class="line"><a name="l02821"></a><span class="lineno"> 2821</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size((3,)))</div><div class="line"><a name="l02822"></a><span class="lineno"> 2822</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size(()))</div><div class="line"><a name="l02823"></a><span class="lineno"> 2823</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((3,)))</div><div class="line"><a name="l02824"></a><span class="lineno"> 2824</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2, 3,)))</div><div class="line"><a name="l02825"></a><span class="lineno"> 2825</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>)</div><div class="line"><a name="l02826"></a><span class="lineno"> 2826</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02827"></a><span class="lineno"> 2827</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(torch.ones(3, 1)).size(), torch.Size((3, 3)))</div><div class="line"><a name="l02828"></a><span class="lineno"> 2828</span>&#160;</div><div class="line"><a name="l02829"></a><span class="lineno"> 2829</span>&#160;    <span class="keyword">def </span>test_one_hot_categorical_shape(self):</div><div class="line"><a name="l02830"></a><span class="lineno"> 2830</span>&#160;        <span class="comment"># unbatched</span></div><div class="line"><a name="l02831"></a><span class="lineno"> 2831</span>&#160;        dist = OneHotCategorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.6, 0.3, 0.1]))</div><div class="line"><a name="l02832"></a><span class="lineno"> 2832</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size(()))</div><div class="line"><a name="l02833"></a><span class="lineno"> 2833</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size((3,)))</div><div class="line"><a name="l02834"></a><span class="lineno"> 2834</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((3,)))</div><div class="line"><a name="l02835"></a><span class="lineno"> 2835</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02836"></a><span class="lineno"> 2836</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>)</div><div class="line"><a name="l02837"></a><span class="lineno"> 2837</span>&#160;        simplex_sample = self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a> / self.tensor_sample_2.sum(-1, keepdim=<span class="keyword">True</span>)</div><div class="line"><a name="l02838"></a><span class="lineno"> 2838</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(simplex_sample).size(), torch.Size((3, 2,)))</div><div class="line"><a name="l02839"></a><span class="lineno"> 2839</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(dist.enumerate_support()).size(), torch.Size((3,)))</div><div class="line"><a name="l02840"></a><span class="lineno"> 2840</span>&#160;        simplex_sample = torch.ones(3, 3) / 3</div><div class="line"><a name="l02841"></a><span class="lineno"> 2841</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(simplex_sample).size(), torch.Size((3,)))</div><div class="line"><a name="l02842"></a><span class="lineno"> 2842</span>&#160;        <span class="comment"># batched</span></div><div class="line"><a name="l02843"></a><span class="lineno"> 2843</span>&#160;        dist = OneHotCategorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.6, 0.3], [0.6, 0.3], [0.6, 0.3]]))</div><div class="line"><a name="l02844"></a><span class="lineno"> 2844</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size((3,)))</div><div class="line"><a name="l02845"></a><span class="lineno"> 2845</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size((2,)))</div><div class="line"><a name="l02846"></a><span class="lineno"> 2846</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((3, 2)))</div><div class="line"><a name="l02847"></a><span class="lineno"> 2847</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((3, 2)).size(), torch.Size((3, 2, 3, 2)))</div><div class="line"><a name="l02848"></a><span class="lineno"> 2848</span>&#160;        simplex_sample = self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a> / self.tensor_sample_1.sum(-1, keepdim=<span class="keyword">True</span>)</div><div class="line"><a name="l02849"></a><span class="lineno"> 2849</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(simplex_sample).size(), torch.Size((3,)))</div><div class="line"><a name="l02850"></a><span class="lineno"> 2850</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02851"></a><span class="lineno"> 2851</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(dist.enumerate_support()).size(), torch.Size((2, 3)))</div><div class="line"><a name="l02852"></a><span class="lineno"> 2852</span>&#160;        simplex_sample = torch.ones(3, 1, 2) / 2</div><div class="line"><a name="l02853"></a><span class="lineno"> 2853</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(simplex_sample).size(), torch.Size((3, 3)))</div><div class="line"><a name="l02854"></a><span class="lineno"> 2854</span>&#160;</div><div class="line"><a name="l02855"></a><span class="lineno"> 2855</span>&#160;    <span class="keyword">def </span>test_cauchy_shape_scalar_params(self):</div><div class="line"><a name="l02856"></a><span class="lineno"> 2856</span>&#160;        cauchy = Cauchy(0, 1)</div><div class="line"><a name="l02857"></a><span class="lineno"> 2857</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy._batch_shape, torch.Size())</div><div class="line"><a name="l02858"></a><span class="lineno"> 2858</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy._event_shape, torch.Size())</div><div class="line"><a name="l02859"></a><span class="lineno"> 2859</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.sample().size(), torch.Size())</div><div class="line"><a name="l02860"></a><span class="lineno"> 2860</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.sample(torch.Size((3, 2))).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02861"></a><span class="lineno"> 2861</span>&#160;        self.assertRaises(ValueError, cauchy.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02862"></a><span class="lineno"> 2862</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02863"></a><span class="lineno"> 2863</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02864"></a><span class="lineno"> 2864</span>&#160;</div><div class="line"><a name="l02865"></a><span class="lineno"> 2865</span>&#160;    <span class="keyword">def </span>test_cauchy_shape_tensor_params(self):</div><div class="line"><a name="l02866"></a><span class="lineno"> 2866</span>&#160;        cauchy = Cauchy(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l02867"></a><span class="lineno"> 2867</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l02868"></a><span class="lineno"> 2868</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy._event_shape, torch.Size(()))</div><div class="line"><a name="l02869"></a><span class="lineno"> 2869</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l02870"></a><span class="lineno"> 2870</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.sample(torch.Size((3, 2))).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l02871"></a><span class="lineno"> 2871</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02872"></a><span class="lineno"> 2872</span>&#160;        self.assertRaises(ValueError, cauchy.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02873"></a><span class="lineno"> 2873</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cauchy.log_prob(torch.ones(2, 1)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l02874"></a><span class="lineno"> 2874</span>&#160;</div><div class="line"><a name="l02875"></a><span class="lineno"> 2875</span>&#160;    <span class="keyword">def </span>test_halfcauchy_shape_scalar_params(self):</div><div class="line"><a name="l02876"></a><span class="lineno"> 2876</span>&#160;        halfcauchy = HalfCauchy(1)</div><div class="line"><a name="l02877"></a><span class="lineno"> 2877</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy._batch_shape, torch.Size())</div><div class="line"><a name="l02878"></a><span class="lineno"> 2878</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy._event_shape, torch.Size())</div><div class="line"><a name="l02879"></a><span class="lineno"> 2879</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.sample().size(), torch.Size())</div><div class="line"><a name="l02880"></a><span class="lineno"> 2880</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.sample(torch.Size((3, 2))).size(),</div><div class="line"><a name="l02881"></a><span class="lineno"> 2881</span>&#160;                         torch.Size((3, 2)))</div><div class="line"><a name="l02882"></a><span class="lineno"> 2882</span>&#160;        self.assertRaises(ValueError, halfcauchy.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02883"></a><span class="lineno"> 2883</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(),</div><div class="line"><a name="l02884"></a><span class="lineno"> 2884</span>&#160;                         torch.Size((3, 2)))</div><div class="line"><a name="l02885"></a><span class="lineno"> 2885</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(),</div><div class="line"><a name="l02886"></a><span class="lineno"> 2886</span>&#160;                         torch.Size((3, 2, 3)))</div><div class="line"><a name="l02887"></a><span class="lineno"> 2887</span>&#160;</div><div class="line"><a name="l02888"></a><span class="lineno"> 2888</span>&#160;    <span class="keyword">def </span>test_halfcauchy_shape_tensor_params(self):</div><div class="line"><a name="l02889"></a><span class="lineno"> 2889</span>&#160;        halfcauchy = HalfCauchy(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l02890"></a><span class="lineno"> 2890</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l02891"></a><span class="lineno"> 2891</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy._event_shape, torch.Size(()))</div><div class="line"><a name="l02892"></a><span class="lineno"> 2892</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l02893"></a><span class="lineno"> 2893</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.sample(torch.Size((3, 2))).size(),</div><div class="line"><a name="l02894"></a><span class="lineno"> 2894</span>&#160;                         torch.Size((3, 2, 2)))</div><div class="line"><a name="l02895"></a><span class="lineno"> 2895</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(),</div><div class="line"><a name="l02896"></a><span class="lineno"> 2896</span>&#160;                         torch.Size((3, 2)))</div><div class="line"><a name="l02897"></a><span class="lineno"> 2897</span>&#160;        self.assertRaises(ValueError, halfcauchy.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02898"></a><span class="lineno"> 2898</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(halfcauchy.log_prob(torch.ones(2, 1)).size(),</div><div class="line"><a name="l02899"></a><span class="lineno"> 2899</span>&#160;                         torch.Size((2, 2)))</div><div class="line"><a name="l02900"></a><span class="lineno"> 2900</span>&#160;</div><div class="line"><a name="l02901"></a><span class="lineno"> 2901</span>&#160;    <span class="keyword">def </span>test_dirichlet_shape(self):</div><div class="line"><a name="l02902"></a><span class="lineno"> 2902</span>&#160;        dist = Dirichlet(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.6, 0.3], [1.6, 1.3], [2.6, 2.3]]))</div><div class="line"><a name="l02903"></a><span class="lineno"> 2903</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._batch_shape, torch.Size((3,)))</div><div class="line"><a name="l02904"></a><span class="lineno"> 2904</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist._event_shape, torch.Size((2,)))</div><div class="line"><a name="l02905"></a><span class="lineno"> 2905</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample().size(), torch.Size((3, 2)))</div><div class="line"><a name="l02906"></a><span class="lineno"> 2906</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.sample((5, 4)).size(), torch.Size((5, 4, 3, 2)))</div><div class="line"><a name="l02907"></a><span class="lineno"> 2907</span>&#160;        simplex_sample = self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a> / self.tensor_sample_1.sum(-1, keepdim=<span class="keyword">True</span>)</div><div class="line"><a name="l02908"></a><span class="lineno"> 2908</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(simplex_sample).size(), torch.Size((3,)))</div><div class="line"><a name="l02909"></a><span class="lineno"> 2909</span>&#160;        self.assertRaises(ValueError, dist.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02910"></a><span class="lineno"> 2910</span>&#160;        simplex_sample = torch.ones(3, 1, 2)</div><div class="line"><a name="l02911"></a><span class="lineno"> 2911</span>&#160;        simplex_sample = simplex_sample / simplex_sample.sum(-1).unsqueeze(-1)</div><div class="line"><a name="l02912"></a><span class="lineno"> 2912</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.log_prob(simplex_sample).size(), torch.Size((3, 3)))</div><div class="line"><a name="l02913"></a><span class="lineno"> 2913</span>&#160;</div><div class="line"><a name="l02914"></a><span class="lineno"> 2914</span>&#160;    <span class="keyword">def </span>test_gamma_shape_scalar_params(self):</div><div class="line"><a name="l02915"></a><span class="lineno"> 2915</span>&#160;        gamma = Gamma(1, 1)</div><div class="line"><a name="l02916"></a><span class="lineno"> 2916</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma._batch_shape, torch.Size())</div><div class="line"><a name="l02917"></a><span class="lineno"> 2917</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma._event_shape, torch.Size())</div><div class="line"><a name="l02918"></a><span class="lineno"> 2918</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.sample().size(), torch.Size())</div><div class="line"><a name="l02919"></a><span class="lineno"> 2919</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02920"></a><span class="lineno"> 2920</span>&#160;        self.assertRaises(ValueError, gamma.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02921"></a><span class="lineno"> 2921</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02922"></a><span class="lineno"> 2922</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02923"></a><span class="lineno"> 2923</span>&#160;</div><div class="line"><a name="l02924"></a><span class="lineno"> 2924</span>&#160;    <span class="keyword">def </span>test_gamma_shape_tensor_params(self):</div><div class="line"><a name="l02925"></a><span class="lineno"> 2925</span>&#160;        gamma = Gamma(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l02926"></a><span class="lineno"> 2926</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l02927"></a><span class="lineno"> 2927</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma._event_shape, torch.Size(()))</div><div class="line"><a name="l02928"></a><span class="lineno"> 2928</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l02929"></a><span class="lineno"> 2929</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.sample((3, 2)).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l02930"></a><span class="lineno"> 2930</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02931"></a><span class="lineno"> 2931</span>&#160;        self.assertRaises(ValueError, gamma.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02932"></a><span class="lineno"> 2932</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gamma.log_prob(torch.ones(2, 1)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l02933"></a><span class="lineno"> 2933</span>&#160;</div><div class="line"><a name="l02934"></a><span class="lineno"> 2934</span>&#160;    <span class="keyword">def </span>test_chi2_shape_scalar_params(self):</div><div class="line"><a name="l02935"></a><span class="lineno"> 2935</span>&#160;        chi2 = Chi2(1)</div><div class="line"><a name="l02936"></a><span class="lineno"> 2936</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2._batch_shape, torch.Size())</div><div class="line"><a name="l02937"></a><span class="lineno"> 2937</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2._event_shape, torch.Size())</div><div class="line"><a name="l02938"></a><span class="lineno"> 2938</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.sample().size(), torch.Size())</div><div class="line"><a name="l02939"></a><span class="lineno"> 2939</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02940"></a><span class="lineno"> 2940</span>&#160;        self.assertRaises(ValueError, chi2.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02941"></a><span class="lineno"> 2941</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02942"></a><span class="lineno"> 2942</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02943"></a><span class="lineno"> 2943</span>&#160;</div><div class="line"><a name="l02944"></a><span class="lineno"> 2944</span>&#160;    <span class="keyword">def </span>test_chi2_shape_tensor_params(self):</div><div class="line"><a name="l02945"></a><span class="lineno"> 2945</span>&#160;        chi2 = Chi2(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l02946"></a><span class="lineno"> 2946</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l02947"></a><span class="lineno"> 2947</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2._event_shape, torch.Size(()))</div><div class="line"><a name="l02948"></a><span class="lineno"> 2948</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l02949"></a><span class="lineno"> 2949</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.sample((3, 2)).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l02950"></a><span class="lineno"> 2950</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02951"></a><span class="lineno"> 2951</span>&#160;        self.assertRaises(ValueError, chi2.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02952"></a><span class="lineno"> 2952</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(chi2.log_prob(torch.ones(2, 1)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l02953"></a><span class="lineno"> 2953</span>&#160;</div><div class="line"><a name="l02954"></a><span class="lineno"> 2954</span>&#160;    <span class="keyword">def </span>test_studentT_shape_scalar_params(self):</div><div class="line"><a name="l02955"></a><span class="lineno"> 2955</span>&#160;        st = StudentT(1)</div><div class="line"><a name="l02956"></a><span class="lineno"> 2956</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st._batch_shape, torch.Size())</div><div class="line"><a name="l02957"></a><span class="lineno"> 2957</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st._event_shape, torch.Size())</div><div class="line"><a name="l02958"></a><span class="lineno"> 2958</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.sample().size(), torch.Size())</div><div class="line"><a name="l02959"></a><span class="lineno"> 2959</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02960"></a><span class="lineno"> 2960</span>&#160;        self.assertRaises(ValueError, st.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l02961"></a><span class="lineno"> 2961</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02962"></a><span class="lineno"> 2962</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02963"></a><span class="lineno"> 2963</span>&#160;</div><div class="line"><a name="l02964"></a><span class="lineno"> 2964</span>&#160;    <span class="keyword">def </span>test_studentT_shape_tensor_params(self):</div><div class="line"><a name="l02965"></a><span class="lineno"> 2965</span>&#160;        st = StudentT(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l02966"></a><span class="lineno"> 2966</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l02967"></a><span class="lineno"> 2967</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st._event_shape, torch.Size(()))</div><div class="line"><a name="l02968"></a><span class="lineno"> 2968</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l02969"></a><span class="lineno"> 2969</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.sample((3, 2)).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l02970"></a><span class="lineno"> 2970</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02971"></a><span class="lineno"> 2971</span>&#160;        self.assertRaises(ValueError, st.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l02972"></a><span class="lineno"> 2972</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(st.log_prob(torch.ones(2, 1)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l02973"></a><span class="lineno"> 2973</span>&#160;</div><div class="line"><a name="l02974"></a><span class="lineno"> 2974</span>&#160;    <span class="keyword">def </span>test_pareto_shape_scalar_params(self):</div><div class="line"><a name="l02975"></a><span class="lineno"> 2975</span>&#160;        pareto = Pareto(1, 1)</div><div class="line"><a name="l02976"></a><span class="lineno"> 2976</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pareto._batch_shape, torch.Size())</div><div class="line"><a name="l02977"></a><span class="lineno"> 2977</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pareto._event_shape, torch.Size())</div><div class="line"><a name="l02978"></a><span class="lineno"> 2978</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pareto.sample().size(), torch.Size())</div><div class="line"><a name="l02979"></a><span class="lineno"> 2979</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pareto.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02980"></a><span class="lineno"> 2980</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pareto.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a> + 1).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02981"></a><span class="lineno"> 2981</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pareto.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a> + 1).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02982"></a><span class="lineno"> 2982</span>&#160;</div><div class="line"><a name="l02983"></a><span class="lineno"> 2983</span>&#160;    <span class="keyword">def </span>test_gumbel_shape_scalar_params(self):</div><div class="line"><a name="l02984"></a><span class="lineno"> 2984</span>&#160;        gumbel = Gumbel(1, 1)</div><div class="line"><a name="l02985"></a><span class="lineno"> 2985</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gumbel._batch_shape, torch.Size())</div><div class="line"><a name="l02986"></a><span class="lineno"> 2986</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gumbel._event_shape, torch.Size())</div><div class="line"><a name="l02987"></a><span class="lineno"> 2987</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gumbel.sample().size(), torch.Size())</div><div class="line"><a name="l02988"></a><span class="lineno"> 2988</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gumbel.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02989"></a><span class="lineno"> 2989</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gumbel.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02990"></a><span class="lineno"> 2990</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(gumbel.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l02991"></a><span class="lineno"> 2991</span>&#160;</div><div class="line"><a name="l02992"></a><span class="lineno"> 2992</span>&#160;    <span class="keyword">def </span>test_weibull_scale_scalar_params(self):</div><div class="line"><a name="l02993"></a><span class="lineno"> 2993</span>&#160;        weibull = Weibull(1, 1)</div><div class="line"><a name="l02994"></a><span class="lineno"> 2994</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(weibull._batch_shape, torch.Size())</div><div class="line"><a name="l02995"></a><span class="lineno"> 2995</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(weibull._event_shape, torch.Size())</div><div class="line"><a name="l02996"></a><span class="lineno"> 2996</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(weibull.sample().size(), torch.Size())</div><div class="line"><a name="l02997"></a><span class="lineno"> 2997</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(weibull.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02998"></a><span class="lineno"> 2998</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(weibull.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l02999"></a><span class="lineno"> 2999</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(weibull.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l03000"></a><span class="lineno"> 3000</span>&#160;</div><div class="line"><a name="l03001"></a><span class="lineno"> 3001</span>&#160;    <span class="keyword">def </span>test_normal_shape_scalar_params(self):</div><div class="line"><a name="l03002"></a><span class="lineno"> 3002</span>&#160;        normal = Normal(0, 1)</div><div class="line"><a name="l03003"></a><span class="lineno"> 3003</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal._batch_shape, torch.Size())</div><div class="line"><a name="l03004"></a><span class="lineno"> 3004</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal._event_shape, torch.Size())</div><div class="line"><a name="l03005"></a><span class="lineno"> 3005</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.sample().size(), torch.Size())</div><div class="line"><a name="l03006"></a><span class="lineno"> 3006</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03007"></a><span class="lineno"> 3007</span>&#160;        self.assertRaises(ValueError, normal.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l03008"></a><span class="lineno"> 3008</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03009"></a><span class="lineno"> 3009</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l03010"></a><span class="lineno"> 3010</span>&#160;</div><div class="line"><a name="l03011"></a><span class="lineno"> 3011</span>&#160;    <span class="keyword">def </span>test_normal_shape_tensor_params(self):</div><div class="line"><a name="l03012"></a><span class="lineno"> 3012</span>&#160;        normal = Normal(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l03013"></a><span class="lineno"> 3013</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l03014"></a><span class="lineno"> 3014</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal._event_shape, torch.Size(()))</div><div class="line"><a name="l03015"></a><span class="lineno"> 3015</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l03016"></a><span class="lineno"> 3016</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.sample((3, 2)).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l03017"></a><span class="lineno"> 3017</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03018"></a><span class="lineno"> 3018</span>&#160;        self.assertRaises(ValueError, normal.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l03019"></a><span class="lineno"> 3019</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(normal.log_prob(torch.ones(2, 1)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l03020"></a><span class="lineno"> 3020</span>&#160;</div><div class="line"><a name="l03021"></a><span class="lineno"> 3021</span>&#160;    <span class="keyword">def </span>test_uniform_shape_scalar_params(self):</div><div class="line"><a name="l03022"></a><span class="lineno"> 3022</span>&#160;        uniform = Uniform(0, 1)</div><div class="line"><a name="l03023"></a><span class="lineno"> 3023</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform._batch_shape, torch.Size())</div><div class="line"><a name="l03024"></a><span class="lineno"> 3024</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform._event_shape, torch.Size())</div><div class="line"><a name="l03025"></a><span class="lineno"> 3025</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.sample().size(), torch.Size())</div><div class="line"><a name="l03026"></a><span class="lineno"> 3026</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.sample(torch.Size((3, 2))).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03027"></a><span class="lineno"> 3027</span>&#160;        self.assertRaises(ValueError, uniform.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l03028"></a><span class="lineno"> 3028</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03029"></a><span class="lineno"> 3029</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l03030"></a><span class="lineno"> 3030</span>&#160;</div><div class="line"><a name="l03031"></a><span class="lineno"> 3031</span>&#160;    <span class="keyword">def </span>test_uniform_shape_tensor_params(self):</div><div class="line"><a name="l03032"></a><span class="lineno"> 3032</span>&#160;        uniform = Uniform(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l03033"></a><span class="lineno"> 3033</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l03034"></a><span class="lineno"> 3034</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform._event_shape, torch.Size(()))</div><div class="line"><a name="l03035"></a><span class="lineno"> 3035</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l03036"></a><span class="lineno"> 3036</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.sample(torch.Size((3, 2))).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l03037"></a><span class="lineno"> 3037</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03038"></a><span class="lineno"> 3038</span>&#160;        self.assertRaises(ValueError, uniform.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l03039"></a><span class="lineno"> 3039</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(uniform.log_prob(torch.ones(2, 1)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l03040"></a><span class="lineno"> 3040</span>&#160;</div><div class="line"><a name="l03041"></a><span class="lineno"> 3041</span>&#160;    <span class="keyword">def </span>test_exponential_shape_scalar_param(self):</div><div class="line"><a name="l03042"></a><span class="lineno"> 3042</span>&#160;        expon = Exponential(1.)</div><div class="line"><a name="l03043"></a><span class="lineno"> 3043</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon._batch_shape, torch.Size())</div><div class="line"><a name="l03044"></a><span class="lineno"> 3044</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon._event_shape, torch.Size())</div><div class="line"><a name="l03045"></a><span class="lineno"> 3045</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.sample().size(), torch.Size())</div><div class="line"><a name="l03046"></a><span class="lineno"> 3046</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03047"></a><span class="lineno"> 3047</span>&#160;        self.assertRaises(ValueError, expon.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l03048"></a><span class="lineno"> 3048</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03049"></a><span class="lineno"> 3049</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l03050"></a><span class="lineno"> 3050</span>&#160;</div><div class="line"><a name="l03051"></a><span class="lineno"> 3051</span>&#160;    <span class="keyword">def </span>test_exponential_shape_tensor_param(self):</div><div class="line"><a name="l03052"></a><span class="lineno"> 3052</span>&#160;        expon = Exponential(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l03053"></a><span class="lineno"> 3053</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l03054"></a><span class="lineno"> 3054</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon._event_shape, torch.Size(()))</div><div class="line"><a name="l03055"></a><span class="lineno"> 3055</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l03056"></a><span class="lineno"> 3056</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.sample((3, 2)).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l03057"></a><span class="lineno"> 3057</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03058"></a><span class="lineno"> 3058</span>&#160;        self.assertRaises(ValueError, expon.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l03059"></a><span class="lineno"> 3059</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expon.log_prob(torch.ones(2, 2)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l03060"></a><span class="lineno"> 3060</span>&#160;</div><div class="line"><a name="l03061"></a><span class="lineno"> 3061</span>&#160;    <span class="keyword">def </span>test_laplace_shape_scalar_params(self):</div><div class="line"><a name="l03062"></a><span class="lineno"> 3062</span>&#160;        laplace = Laplace(0, 1)</div><div class="line"><a name="l03063"></a><span class="lineno"> 3063</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace._batch_shape, torch.Size())</div><div class="line"><a name="l03064"></a><span class="lineno"> 3064</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace._event_shape, torch.Size())</div><div class="line"><a name="l03065"></a><span class="lineno"> 3065</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.sample().size(), torch.Size())</div><div class="line"><a name="l03066"></a><span class="lineno"> 3066</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.sample((3, 2)).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03067"></a><span class="lineno"> 3067</span>&#160;        self.assertRaises(ValueError, laplace.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">scalar_sample</a>)</div><div class="line"><a name="l03068"></a><span class="lineno"> 3068</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03069"></a><span class="lineno"> 3069</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>).size(), torch.Size((3, 2, 3)))</div><div class="line"><a name="l03070"></a><span class="lineno"> 3070</span>&#160;</div><div class="line"><a name="l03071"></a><span class="lineno"> 3071</span>&#160;    <span class="keyword">def </span>test_laplace_shape_tensor_params(self):</div><div class="line"><a name="l03072"></a><span class="lineno"> 3072</span>&#160;        laplace = Laplace(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 0.]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 1.]))</div><div class="line"><a name="l03073"></a><span class="lineno"> 3073</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace._batch_shape, torch.Size((2,)))</div><div class="line"><a name="l03074"></a><span class="lineno"> 3074</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace._event_shape, torch.Size(()))</div><div class="line"><a name="l03075"></a><span class="lineno"> 3075</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.sample().size(), torch.Size((2,)))</div><div class="line"><a name="l03076"></a><span class="lineno"> 3076</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.sample((3, 2)).size(), torch.Size((3, 2, 2)))</div><div class="line"><a name="l03077"></a><span class="lineno"> 3077</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.log_prob(self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">tensor_sample_1</a>).size(), torch.Size((3, 2)))</div><div class="line"><a name="l03078"></a><span class="lineno"> 3078</span>&#160;        self.assertRaises(ValueError, laplace.log_prob, self.<a class="code" href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">tensor_sample_2</a>)</div><div class="line"><a name="l03079"></a><span class="lineno"> 3079</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(laplace.log_prob(torch.ones(2, 1)).size(), torch.Size((2, 2)))</div><div class="line"><a name="l03080"></a><span class="lineno"> 3080</span>&#160;</div><div class="line"><a name="l03081"></a><span class="lineno"> 3081</span>&#160;</div><div class="line"><a name="l03082"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_k_l.html"> 3082</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_k_l.html">TestKL</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l03083"></a><span class="lineno"> 3083</span>&#160;</div><div class="line"><a name="l03084"></a><span class="lineno"> 3084</span>&#160;    <span class="keyword">def </span>setUp(self):</div><div class="line"><a name="l03085"></a><span class="lineno"> 3085</span>&#160;        super(TestKL, self).setUp()</div><div class="line"><a name="l03086"></a><span class="lineno"> 3086</span>&#160;</div><div class="line"><a name="l03087"></a><span class="lineno"> 3087</span>&#160;        <span class="keyword">class </span>Binomial30(Binomial):</div><div class="line"><a name="l03088"></a><span class="lineno"> 3088</span>&#160;            <span class="keyword">def </span>__init__(self, probs):</div><div class="line"><a name="l03089"></a><span class="lineno"> 3089</span>&#160;                super(Binomial30, self).__init__(30, probs)</div><div class="line"><a name="l03090"></a><span class="lineno"> 3090</span>&#160;</div><div class="line"><a name="l03091"></a><span class="lineno"> 3091</span>&#160;        <span class="comment"># These are pairs of distributions with 4 x 4 parameters as specified.</span></div><div class="line"><a name="l03092"></a><span class="lineno"> 3092</span>&#160;        <span class="comment"># The first of the pair e.g. bernoulli[0] varies column-wise and the second</span></div><div class="line"><a name="l03093"></a><span class="lineno"> 3093</span>&#160;        <span class="comment"># e.g. bernoulli[1] varies row-wise; that way we test all param pairs.</span></div><div class="line"><a name="l03094"></a><span class="lineno"> 3094</span>&#160;        bernoulli = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Bernoulli, [0.1, 0.2, 0.6, 0.9])</div><div class="line"><a name="l03095"></a><span class="lineno"> 3095</span>&#160;        binomial30 = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Binomial30, [0.1, 0.2, 0.6, 0.9])</div><div class="line"><a name="l03096"></a><span class="lineno"> 3096</span>&#160;        binomial_vectorized_count = (Binomial(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([3, 4]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.4, 0.6])),</div><div class="line"><a name="l03097"></a><span class="lineno"> 3097</span>&#160;                                     Binomial(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([3, 4]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.5, 0.8])))</div><div class="line"><a name="l03098"></a><span class="lineno"> 3098</span>&#160;        beta = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Beta, [1.0, 2.5, 1.0, 2.5], [1.5, 1.5, 3.5, 3.5])</div><div class="line"><a name="l03099"></a><span class="lineno"> 3099</span>&#160;        categorical = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Categorical, [[0.4, 0.3, 0.3],</div><div class="line"><a name="l03100"></a><span class="lineno"> 3100</span>&#160;                                             [0.2, 0.7, 0.1],</div><div class="line"><a name="l03101"></a><span class="lineno"> 3101</span>&#160;                                             [0.33, 0.33, 0.34],</div><div class="line"><a name="l03102"></a><span class="lineno"> 3102</span>&#160;                                             [0.2, 0.2, 0.6]])</div><div class="line"><a name="l03103"></a><span class="lineno"> 3103</span>&#160;        chi2 = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Chi2, [1.0, 2.0, 2.5, 5.0])</div><div class="line"><a name="l03104"></a><span class="lineno"> 3104</span>&#160;        dirichlet = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Dirichlet, [[0.1, 0.2, 0.7],</div><div class="line"><a name="l03105"></a><span class="lineno"> 3105</span>&#160;                                         [0.5, 0.4, 0.1],</div><div class="line"><a name="l03106"></a><span class="lineno"> 3106</span>&#160;                                         [0.33, 0.33, 0.34],</div><div class="line"><a name="l03107"></a><span class="lineno"> 3107</span>&#160;                                         [0.2, 0.2, 0.4]])</div><div class="line"><a name="l03108"></a><span class="lineno"> 3108</span>&#160;        exponential = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Exponential, [1.0, 2.5, 5.0, 10.0])</div><div class="line"><a name="l03109"></a><span class="lineno"> 3109</span>&#160;        gamma = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Gamma, [1.0, 2.5, 1.0, 2.5], [1.5, 1.5, 3.5, 3.5])</div><div class="line"><a name="l03110"></a><span class="lineno"> 3110</span>&#160;        gumbel = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Gumbel, [-2.0, 4.0, -3.0, 6.0], [1.0, 2.5, 1.0, 2.5])</div><div class="line"><a name="l03111"></a><span class="lineno"> 3111</span>&#160;        halfnormal = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(HalfNormal, [1.0, 2.0, 1.0, 2.0])</div><div class="line"><a name="l03112"></a><span class="lineno"> 3112</span>&#160;        laplace = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Laplace, [-2.0, 4.0, -3.0, 6.0], [1.0, 2.5, 1.0, 2.5])</div><div class="line"><a name="l03113"></a><span class="lineno"> 3113</span>&#160;        lognormal = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(LogNormal, [-2.0, 2.0, -3.0, 3.0], [1.0, 2.0, 1.0, 2.0])</div><div class="line"><a name="l03114"></a><span class="lineno"> 3114</span>&#160;        normal = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Normal, [-2.0, 2.0, -3.0, 3.0], [1.0, 2.0, 1.0, 2.0])</div><div class="line"><a name="l03115"></a><span class="lineno"> 3115</span>&#160;        independent = (Independent(normal[0], 1), Independent(normal[1], 1))</div><div class="line"><a name="l03116"></a><span class="lineno"> 3116</span>&#160;        onehotcategorical = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(OneHotCategorical, [[0.4, 0.3, 0.3],</div><div class="line"><a name="l03117"></a><span class="lineno"> 3117</span>&#160;                                                         [0.2, 0.7, 0.1],</div><div class="line"><a name="l03118"></a><span class="lineno"> 3118</span>&#160;                                                         [0.33, 0.33, 0.34],</div><div class="line"><a name="l03119"></a><span class="lineno"> 3119</span>&#160;                                                         [0.2, 0.2, 0.6]])</div><div class="line"><a name="l03120"></a><span class="lineno"> 3120</span>&#160;        pareto = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Pareto, [2.5, 4.0, 2.5, 4.0], [2.25, 3.75, 2.25, 3.75])</div><div class="line"><a name="l03121"></a><span class="lineno"> 3121</span>&#160;        poisson = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Poisson, [0.3, 1.0, 5.0, 10.0])</div><div class="line"><a name="l03122"></a><span class="lineno"> 3122</span>&#160;        uniform_within_unit = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Uniform, [0.15, 0.95, 0.2, 0.8], [0.1, 0.9, 0.25, 0.75])</div><div class="line"><a name="l03123"></a><span class="lineno"> 3123</span>&#160;        uniform_positive = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Uniform, [1, 1.5, 2, 4], [1.2, 2.0, 3, 7])</div><div class="line"><a name="l03124"></a><span class="lineno"> 3124</span>&#160;        uniform_real = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Uniform, [-2., -1, 0, 2], [-1., 1, 1, 4])</div><div class="line"><a name="l03125"></a><span class="lineno"> 3125</span>&#160;        uniform_pareto = <a class="code" href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">pairwise</a>(Uniform, [6.5, 8.5, 6.5, 8.5], [7.5, 7.5, 9.5, 9.5])</div><div class="line"><a name="l03126"></a><span class="lineno"> 3126</span>&#160;</div><div class="line"><a name="l03127"></a><span class="lineno"> 3127</span>&#160;        <span class="comment"># These tests should pass with precision = 0.01, but that makes tests very expensive.</span></div><div class="line"><a name="l03128"></a><span class="lineno"> 3128</span>&#160;        <span class="comment"># Instead, we test with precision = 0.1 and only test with higher precision locally</span></div><div class="line"><a name="l03129"></a><span class="lineno"> 3129</span>&#160;        <span class="comment"># when adding a new KL implementation.</span></div><div class="line"><a name="l03130"></a><span class="lineno"> 3130</span>&#160;        <span class="comment"># The following pairs are not tested due to very high variance of the monte carlo</span></div><div class="line"><a name="l03131"></a><span class="lineno"> 3131</span>&#160;        <span class="comment"># estimator; their implementations have been reviewed with extra care:</span></div><div class="line"><a name="l03132"></a><span class="lineno"> 3132</span>&#160;        <span class="comment"># - (pareto, normal)</span></div><div class="line"><a name="l03133"></a><span class="lineno"> 3133</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a> = 0.1  <span class="comment"># Set this to 0.01 when testing a new KL implementation.</span></div><div class="line"><a name="l03134"></a><span class="lineno"> 3134</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a0388c47a2de7c23b9ed33337d2749ae8">max_samples</a> = int(1e07)  <span class="comment"># Increase this when testing at smaller precision.</span></div><div class="line"><a name="l03135"></a><span class="lineno"> 3135</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a95022d7b858c52c2cf58f3b0b19bc5d5">samples_per_batch</a> = int(1e04)</div><div class="line"><a name="l03136"></a><span class="lineno"> 3136</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a748a60ca6c8f5423a39dd96b8c53a7c1">finite_examples</a> = [</div><div class="line"><a name="l03137"></a><span class="lineno"> 3137</span>&#160;            (bernoulli, bernoulli),</div><div class="line"><a name="l03138"></a><span class="lineno"> 3138</span>&#160;            (bernoulli, poisson),</div><div class="line"><a name="l03139"></a><span class="lineno"> 3139</span>&#160;            (beta, beta),</div><div class="line"><a name="l03140"></a><span class="lineno"> 3140</span>&#160;            (beta, chi2),</div><div class="line"><a name="l03141"></a><span class="lineno"> 3141</span>&#160;            (beta, exponential),</div><div class="line"><a name="l03142"></a><span class="lineno"> 3142</span>&#160;            (beta, gamma),</div><div class="line"><a name="l03143"></a><span class="lineno"> 3143</span>&#160;            (beta, normal),</div><div class="line"><a name="l03144"></a><span class="lineno"> 3144</span>&#160;            (binomial30, binomial30),</div><div class="line"><a name="l03145"></a><span class="lineno"> 3145</span>&#160;            (binomial_vectorized_count, binomial_vectorized_count),</div><div class="line"><a name="l03146"></a><span class="lineno"> 3146</span>&#160;            (categorical, categorical),</div><div class="line"><a name="l03147"></a><span class="lineno"> 3147</span>&#160;            (chi2, chi2),</div><div class="line"><a name="l03148"></a><span class="lineno"> 3148</span>&#160;            (chi2, exponential),</div><div class="line"><a name="l03149"></a><span class="lineno"> 3149</span>&#160;            (chi2, gamma),</div><div class="line"><a name="l03150"></a><span class="lineno"> 3150</span>&#160;            (chi2, normal),</div><div class="line"><a name="l03151"></a><span class="lineno"> 3151</span>&#160;            (dirichlet, dirichlet),</div><div class="line"><a name="l03152"></a><span class="lineno"> 3152</span>&#160;            (exponential, chi2),</div><div class="line"><a name="l03153"></a><span class="lineno"> 3153</span>&#160;            (exponential, exponential),</div><div class="line"><a name="l03154"></a><span class="lineno"> 3154</span>&#160;            (exponential, gamma),</div><div class="line"><a name="l03155"></a><span class="lineno"> 3155</span>&#160;            (exponential, gumbel),</div><div class="line"><a name="l03156"></a><span class="lineno"> 3156</span>&#160;            (exponential, normal),</div><div class="line"><a name="l03157"></a><span class="lineno"> 3157</span>&#160;            (gamma, chi2),</div><div class="line"><a name="l03158"></a><span class="lineno"> 3158</span>&#160;            (gamma, exponential),</div><div class="line"><a name="l03159"></a><span class="lineno"> 3159</span>&#160;            (gamma, gamma),</div><div class="line"><a name="l03160"></a><span class="lineno"> 3160</span>&#160;            (gamma, gumbel),</div><div class="line"><a name="l03161"></a><span class="lineno"> 3161</span>&#160;            (gamma, normal),</div><div class="line"><a name="l03162"></a><span class="lineno"> 3162</span>&#160;            (gumbel, gumbel),</div><div class="line"><a name="l03163"></a><span class="lineno"> 3163</span>&#160;            (gumbel, normal),</div><div class="line"><a name="l03164"></a><span class="lineno"> 3164</span>&#160;            (halfnormal, halfnormal),</div><div class="line"><a name="l03165"></a><span class="lineno"> 3165</span>&#160;            (independent, independent),</div><div class="line"><a name="l03166"></a><span class="lineno"> 3166</span>&#160;            (laplace, laplace),</div><div class="line"><a name="l03167"></a><span class="lineno"> 3167</span>&#160;            (lognormal, lognormal),</div><div class="line"><a name="l03168"></a><span class="lineno"> 3168</span>&#160;            (laplace, normal),</div><div class="line"><a name="l03169"></a><span class="lineno"> 3169</span>&#160;            (normal, gumbel),</div><div class="line"><a name="l03170"></a><span class="lineno"> 3170</span>&#160;            (normal, normal),</div><div class="line"><a name="l03171"></a><span class="lineno"> 3171</span>&#160;            (onehotcategorical, onehotcategorical),</div><div class="line"><a name="l03172"></a><span class="lineno"> 3172</span>&#160;            (pareto, chi2),</div><div class="line"><a name="l03173"></a><span class="lineno"> 3173</span>&#160;            (pareto, pareto),</div><div class="line"><a name="l03174"></a><span class="lineno"> 3174</span>&#160;            (pareto, exponential),</div><div class="line"><a name="l03175"></a><span class="lineno"> 3175</span>&#160;            (pareto, gamma),</div><div class="line"><a name="l03176"></a><span class="lineno"> 3176</span>&#160;            (poisson, poisson),</div><div class="line"><a name="l03177"></a><span class="lineno"> 3177</span>&#160;            (uniform_within_unit, beta),</div><div class="line"><a name="l03178"></a><span class="lineno"> 3178</span>&#160;            (uniform_positive, chi2),</div><div class="line"><a name="l03179"></a><span class="lineno"> 3179</span>&#160;            (uniform_positive, exponential),</div><div class="line"><a name="l03180"></a><span class="lineno"> 3180</span>&#160;            (uniform_positive, gamma),</div><div class="line"><a name="l03181"></a><span class="lineno"> 3181</span>&#160;            (uniform_real, gumbel),</div><div class="line"><a name="l03182"></a><span class="lineno"> 3182</span>&#160;            (uniform_real, normal),</div><div class="line"><a name="l03183"></a><span class="lineno"> 3183</span>&#160;            (uniform_pareto, pareto),</div><div class="line"><a name="l03184"></a><span class="lineno"> 3184</span>&#160;        ]</div><div class="line"><a name="l03185"></a><span class="lineno"> 3185</span>&#160;</div><div class="line"><a name="l03186"></a><span class="lineno"> 3186</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a5edc7278f2b82b235b303a6e0c55bfe1">infinite_examples</a> = [</div><div class="line"><a name="l03187"></a><span class="lineno"> 3187</span>&#160;            (Bernoulli(0), Bernoulli(1)),</div><div class="line"><a name="l03188"></a><span class="lineno"> 3188</span>&#160;            (Bernoulli(1), Bernoulli(0)),</div><div class="line"><a name="l03189"></a><span class="lineno"> 3189</span>&#160;            (Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.9, 0.1])), Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 0.]))),</div><div class="line"><a name="l03190"></a><span class="lineno"> 3190</span>&#160;            (Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([[0.9, 0.1], [.9, .1]])), Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1., 0.]))),</div><div class="line"><a name="l03191"></a><span class="lineno"> 3191</span>&#160;            (Beta(1, 2), Uniform(0.25, 1)),</div><div class="line"><a name="l03192"></a><span class="lineno"> 3192</span>&#160;            (Beta(1, 2), Uniform(0, 0.75)),</div><div class="line"><a name="l03193"></a><span class="lineno"> 3193</span>&#160;            (Beta(1, 2), Uniform(0.25, 0.75)),</div><div class="line"><a name="l03194"></a><span class="lineno"> 3194</span>&#160;            (Beta(1, 2), Pareto(1, 2)),</div><div class="line"><a name="l03195"></a><span class="lineno"> 3195</span>&#160;            (Binomial(31, 0.7), Binomial(30, 0.3)),</div><div class="line"><a name="l03196"></a><span class="lineno"> 3196</span>&#160;            (Binomial(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([3, 4]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.4, 0.6])),</div><div class="line"><a name="l03197"></a><span class="lineno"> 3197</span>&#160;             Binomial(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([2, 3]), <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0.5, 0.8]))),</div><div class="line"><a name="l03198"></a><span class="lineno"> 3198</span>&#160;            (Chi2(1), Beta(2, 3)),</div><div class="line"><a name="l03199"></a><span class="lineno"> 3199</span>&#160;            (Chi2(1), Pareto(2, 3)),</div><div class="line"><a name="l03200"></a><span class="lineno"> 3200</span>&#160;            (Chi2(1), Uniform(-2, 3)),</div><div class="line"><a name="l03201"></a><span class="lineno"> 3201</span>&#160;            (Exponential(1), Beta(2, 3)),</div><div class="line"><a name="l03202"></a><span class="lineno"> 3202</span>&#160;            (Exponential(1), Pareto(2, 3)),</div><div class="line"><a name="l03203"></a><span class="lineno"> 3203</span>&#160;            (Exponential(1), Uniform(-2, 3)),</div><div class="line"><a name="l03204"></a><span class="lineno"> 3204</span>&#160;            (Gamma(1, 2), Beta(3, 4)),</div><div class="line"><a name="l03205"></a><span class="lineno"> 3205</span>&#160;            (Gamma(1, 2), Pareto(3, 4)),</div><div class="line"><a name="l03206"></a><span class="lineno"> 3206</span>&#160;            (Gamma(1, 2), Uniform(-3, 4)),</div><div class="line"><a name="l03207"></a><span class="lineno"> 3207</span>&#160;            (Gumbel(-1, 2), Beta(3, 4)),</div><div class="line"><a name="l03208"></a><span class="lineno"> 3208</span>&#160;            (Gumbel(-1, 2), Chi2(3)),</div><div class="line"><a name="l03209"></a><span class="lineno"> 3209</span>&#160;            (Gumbel(-1, 2), Exponential(3)),</div><div class="line"><a name="l03210"></a><span class="lineno"> 3210</span>&#160;            (Gumbel(-1, 2), Gamma(3, 4)),</div><div class="line"><a name="l03211"></a><span class="lineno"> 3211</span>&#160;            (Gumbel(-1, 2), Pareto(3, 4)),</div><div class="line"><a name="l03212"></a><span class="lineno"> 3212</span>&#160;            (Gumbel(-1, 2), Uniform(-3, 4)),</div><div class="line"><a name="l03213"></a><span class="lineno"> 3213</span>&#160;            (Laplace(-1, 2), Beta(3, 4)),</div><div class="line"><a name="l03214"></a><span class="lineno"> 3214</span>&#160;            (Laplace(-1, 2), Chi2(3)),</div><div class="line"><a name="l03215"></a><span class="lineno"> 3215</span>&#160;            (Laplace(-1, 2), Exponential(3)),</div><div class="line"><a name="l03216"></a><span class="lineno"> 3216</span>&#160;            (Laplace(-1, 2), Gamma(3, 4)),</div><div class="line"><a name="l03217"></a><span class="lineno"> 3217</span>&#160;            (Laplace(-1, 2), Pareto(3, 4)),</div><div class="line"><a name="l03218"></a><span class="lineno"> 3218</span>&#160;            (Laplace(-1, 2), Uniform(-3, 4)),</div><div class="line"><a name="l03219"></a><span class="lineno"> 3219</span>&#160;            (Normal(-1, 2), Beta(3, 4)),</div><div class="line"><a name="l03220"></a><span class="lineno"> 3220</span>&#160;            (Normal(-1, 2), Chi2(3)),</div><div class="line"><a name="l03221"></a><span class="lineno"> 3221</span>&#160;            (Normal(-1, 2), Exponential(3)),</div><div class="line"><a name="l03222"></a><span class="lineno"> 3222</span>&#160;            (Normal(-1, 2), Gamma(3, 4)),</div><div class="line"><a name="l03223"></a><span class="lineno"> 3223</span>&#160;            (Normal(-1, 2), Pareto(3, 4)),</div><div class="line"><a name="l03224"></a><span class="lineno"> 3224</span>&#160;            (Normal(-1, 2), Uniform(-3, 4)),</div><div class="line"><a name="l03225"></a><span class="lineno"> 3225</span>&#160;            (Pareto(2, 1), Chi2(3)),</div><div class="line"><a name="l03226"></a><span class="lineno"> 3226</span>&#160;            (Pareto(2, 1), Exponential(3)),</div><div class="line"><a name="l03227"></a><span class="lineno"> 3227</span>&#160;            (Pareto(2, 1), Gamma(3, 4)),</div><div class="line"><a name="l03228"></a><span class="lineno"> 3228</span>&#160;            (Pareto(1, 2), Normal(-3, 4)),</div><div class="line"><a name="l03229"></a><span class="lineno"> 3229</span>&#160;            (Pareto(1, 2), Pareto(3, 4)),</div><div class="line"><a name="l03230"></a><span class="lineno"> 3230</span>&#160;            (Poisson(2), Bernoulli(0.5)),</div><div class="line"><a name="l03231"></a><span class="lineno"> 3231</span>&#160;            (Poisson(2.3), Binomial(10, 0.2)),</div><div class="line"><a name="l03232"></a><span class="lineno"> 3232</span>&#160;            (Uniform(-1, 1), Beta(2, 2)),</div><div class="line"><a name="l03233"></a><span class="lineno"> 3233</span>&#160;            (Uniform(0, 2), Beta(3, 4)),</div><div class="line"><a name="l03234"></a><span class="lineno"> 3234</span>&#160;            (Uniform(-1, 2), Beta(3, 4)),</div><div class="line"><a name="l03235"></a><span class="lineno"> 3235</span>&#160;            (Uniform(-1, 2), Chi2(3)),</div><div class="line"><a name="l03236"></a><span class="lineno"> 3236</span>&#160;            (Uniform(-1, 2), Exponential(3)),</div><div class="line"><a name="l03237"></a><span class="lineno"> 3237</span>&#160;            (Uniform(-1, 2), Gamma(3, 4)),</div><div class="line"><a name="l03238"></a><span class="lineno"> 3238</span>&#160;            (Uniform(-1, 2), Pareto(3, 4)),</div><div class="line"><a name="l03239"></a><span class="lineno"> 3239</span>&#160;        ]</div><div class="line"><a name="l03240"></a><span class="lineno"> 3240</span>&#160;</div><div class="line"><a name="l03241"></a><span class="lineno"> 3241</span>&#160;    <span class="keyword">def </span>test_kl_monte_carlo(self):</div><div class="line"><a name="l03242"></a><span class="lineno"> 3242</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l03243"></a><span class="lineno"> 3243</span>&#160;        <span class="keywordflow">for</span> (p, _), (_, q) <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a748a60ca6c8f5423a39dd96b8c53a7c1">finite_examples</a>:</div><div class="line"><a name="l03244"></a><span class="lineno"> 3244</span>&#160;            actual = kl_divergence(p, q)</div><div class="line"><a name="l03245"></a><span class="lineno"> 3245</span>&#160;            numerator = 0</div><div class="line"><a name="l03246"></a><span class="lineno"> 3246</span>&#160;            denominator = 0</div><div class="line"><a name="l03247"></a><span class="lineno"> 3247</span>&#160;            <span class="keywordflow">while</span> denominator &lt; self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a0388c47a2de7c23b9ed33337d2749ae8">max_samples</a>:</div><div class="line"><a name="l03248"></a><span class="lineno"> 3248</span>&#160;                x = p.sample(sample_shape=(self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a95022d7b858c52c2cf58f3b0b19bc5d5">samples_per_batch</a>,))</div><div class="line"><a name="l03249"></a><span class="lineno"> 3249</span>&#160;                numerator += (p.log_prob(x) - q.log_prob(x)).sum(0)</div><div class="line"><a name="l03250"></a><span class="lineno"> 3250</span>&#160;                denominator += x.size(0)</div><div class="line"><a name="l03251"></a><span class="lineno"> 3251</span>&#160;                expected = numerator / denominator</div><div class="line"><a name="l03252"></a><span class="lineno"> 3252</span>&#160;                error = torch.abs(expected - actual) / (1 + expected)</div><div class="line"><a name="l03253"></a><span class="lineno"> 3253</span>&#160;                <span class="keywordflow">if</span> error[error == error].max() &lt; self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a>:</div><div class="line"><a name="l03254"></a><span class="lineno"> 3254</span>&#160;                    <span class="keywordflow">break</span></div><div class="line"><a name="l03255"></a><span class="lineno"> 3255</span>&#160;            self.assertLess(error[error == error].max(), self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a>, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03256"></a><span class="lineno"> 3256</span>&#160;                <span class="stringliteral">&#39;Incorrect KL({}, {}).&#39;</span>.format(type(p).__name__, type(q).__name__),</div><div class="line"><a name="l03257"></a><span class="lineno"> 3257</span>&#160;                <span class="stringliteral">&#39;Expected ({} Monte Carlo samples): {}&#39;</span>.format(denominator, expected),</div><div class="line"><a name="l03258"></a><span class="lineno"> 3258</span>&#160;                <span class="stringliteral">&#39;Actual (analytic): {}&#39;</span>.format(actual),</div><div class="line"><a name="l03259"></a><span class="lineno"> 3259</span>&#160;            ]))</div><div class="line"><a name="l03260"></a><span class="lineno"> 3260</span>&#160;</div><div class="line"><a name="l03261"></a><span class="lineno"> 3261</span>&#160;    <span class="comment"># Multivariate normal has a separate Monte Carlo based test due to the requirement of random generation of</span></div><div class="line"><a name="l03262"></a><span class="lineno"> 3262</span>&#160;    <span class="comment"># positive (semi) definite matrices. n is set to 5, but can be increased during testing.</span></div><div class="line"><a name="l03263"></a><span class="lineno"> 3263</span>&#160;    <span class="keyword">def </span>test_kl_multivariate_normal(self):</div><div class="line"><a name="l03264"></a><span class="lineno"> 3264</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l03265"></a><span class="lineno"> 3265</span>&#160;        n = 5  <span class="comment"># Number of tests for multivariate_normal</span></div><div class="line"><a name="l03266"></a><span class="lineno"> 3266</span>&#160;        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(0, n):</div><div class="line"><a name="l03267"></a><span class="lineno"> 3267</span>&#160;            loc = [torch.randn(4) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03268"></a><span class="lineno"> 3268</span>&#160;            scale_tril = [transform_to(constraints.lower_cholesky)(torch.randn(4, 4)) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03269"></a><span class="lineno"> 3269</span>&#160;            p = MultivariateNormal(loc=loc[0], scale_tril=scale_tril[0])</div><div class="line"><a name="l03270"></a><span class="lineno"> 3270</span>&#160;            q = MultivariateNormal(loc=loc[1], scale_tril=scale_tril[1])</div><div class="line"><a name="l03271"></a><span class="lineno"> 3271</span>&#160;            actual = kl_divergence(p, q)</div><div class="line"><a name="l03272"></a><span class="lineno"> 3272</span>&#160;            numerator = 0</div><div class="line"><a name="l03273"></a><span class="lineno"> 3273</span>&#160;            denominator = 0</div><div class="line"><a name="l03274"></a><span class="lineno"> 3274</span>&#160;            <span class="keywordflow">while</span> denominator &lt; self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a0388c47a2de7c23b9ed33337d2749ae8">max_samples</a>:</div><div class="line"><a name="l03275"></a><span class="lineno"> 3275</span>&#160;                x = p.sample(sample_shape=(self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a95022d7b858c52c2cf58f3b0b19bc5d5">samples_per_batch</a>,))</div><div class="line"><a name="l03276"></a><span class="lineno"> 3276</span>&#160;                numerator += (p.log_prob(x) - q.log_prob(x)).sum(0)</div><div class="line"><a name="l03277"></a><span class="lineno"> 3277</span>&#160;                denominator += x.size(0)</div><div class="line"><a name="l03278"></a><span class="lineno"> 3278</span>&#160;                expected = numerator / denominator</div><div class="line"><a name="l03279"></a><span class="lineno"> 3279</span>&#160;                error = torch.abs(expected - actual) / (1 + expected)</div><div class="line"><a name="l03280"></a><span class="lineno"> 3280</span>&#160;                <span class="keywordflow">if</span> error[error == error].max() &lt; self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a>:</div><div class="line"><a name="l03281"></a><span class="lineno"> 3281</span>&#160;                    <span class="keywordflow">break</span></div><div class="line"><a name="l03282"></a><span class="lineno"> 3282</span>&#160;            self.assertLess(error[error == error].max(), self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a>, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03283"></a><span class="lineno"> 3283</span>&#160;                <span class="stringliteral">&#39;Incorrect KL(MultivariateNormal, MultivariateNormal) instance {}/{}&#39;</span>.format(i + 1, n),</div><div class="line"><a name="l03284"></a><span class="lineno"> 3284</span>&#160;                <span class="stringliteral">&#39;Expected ({} Monte Carlo sample): {}&#39;</span>.format(denominator, expected),</div><div class="line"><a name="l03285"></a><span class="lineno"> 3285</span>&#160;                <span class="stringliteral">&#39;Actual (analytic): {}&#39;</span>.format(actual),</div><div class="line"><a name="l03286"></a><span class="lineno"> 3286</span>&#160;            ]))</div><div class="line"><a name="l03287"></a><span class="lineno"> 3287</span>&#160;</div><div class="line"><a name="l03288"></a><span class="lineno"> 3288</span>&#160;    <span class="keyword">def </span>test_kl_multivariate_normal_batched(self):</div><div class="line"><a name="l03289"></a><span class="lineno"> 3289</span>&#160;        b = 7  <span class="comment"># Number of batches</span></div><div class="line"><a name="l03290"></a><span class="lineno"> 3290</span>&#160;        loc = [torch.randn(b, 3) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03291"></a><span class="lineno"> 3291</span>&#160;        scale_tril = [transform_to(constraints.lower_cholesky)(torch.randn(b, 3, 3)) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03292"></a><span class="lineno"> 3292</span>&#160;        expected_kl = torch.stack([</div><div class="line"><a name="l03293"></a><span class="lineno"> 3293</span>&#160;            kl_divergence(MultivariateNormal(loc[0][i], scale_tril=scale_tril[0][i]),</div><div class="line"><a name="l03294"></a><span class="lineno"> 3294</span>&#160;                          MultivariateNormal(loc[1][i], scale_tril=scale_tril[1][i])) <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(0, b)])</div><div class="line"><a name="l03295"></a><span class="lineno"> 3295</span>&#160;        actual_kl = kl_divergence(MultivariateNormal(loc[0], scale_tril=scale_tril[0]),</div><div class="line"><a name="l03296"></a><span class="lineno"> 3296</span>&#160;                                  MultivariateNormal(loc[1], scale_tril=scale_tril[1]))</div><div class="line"><a name="l03297"></a><span class="lineno"> 3297</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected_kl, actual_kl)</div><div class="line"><a name="l03298"></a><span class="lineno"> 3298</span>&#160;</div><div class="line"><a name="l03299"></a><span class="lineno"> 3299</span>&#160;    <span class="keyword">def </span>test_kl_multivariate_normal_batched_broadcasted(self):</div><div class="line"><a name="l03300"></a><span class="lineno"> 3300</span>&#160;        b = 7  <span class="comment"># Number of batches</span></div><div class="line"><a name="l03301"></a><span class="lineno"> 3301</span>&#160;        loc = [torch.randn(b, 3) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03302"></a><span class="lineno"> 3302</span>&#160;        scale_tril = [transform_to(constraints.lower_cholesky)(torch.randn(b, 3, 3)),</div><div class="line"><a name="l03303"></a><span class="lineno"> 3303</span>&#160;                      transform_to(constraints.lower_cholesky)(torch.randn(3, 3))]</div><div class="line"><a name="l03304"></a><span class="lineno"> 3304</span>&#160;        expected_kl = torch.stack([</div><div class="line"><a name="l03305"></a><span class="lineno"> 3305</span>&#160;            kl_divergence(MultivariateNormal(loc[0][i], scale_tril=scale_tril[0][i]),</div><div class="line"><a name="l03306"></a><span class="lineno"> 3306</span>&#160;                          MultivariateNormal(loc[1][i], scale_tril=scale_tril[1])) <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(0, b)])</div><div class="line"><a name="l03307"></a><span class="lineno"> 3307</span>&#160;        actual_kl = kl_divergence(MultivariateNormal(loc[0], scale_tril=scale_tril[0]),</div><div class="line"><a name="l03308"></a><span class="lineno"> 3308</span>&#160;                                  MultivariateNormal(loc[1], scale_tril=scale_tril[1]))</div><div class="line"><a name="l03309"></a><span class="lineno"> 3309</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected_kl, actual_kl)</div><div class="line"><a name="l03310"></a><span class="lineno"> 3310</span>&#160;</div><div class="line"><a name="l03311"></a><span class="lineno"> 3311</span>&#160;    <span class="keyword">def </span>test_kl_lowrank_multivariate_normal(self):</div><div class="line"><a name="l03312"></a><span class="lineno"> 3312</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l03313"></a><span class="lineno"> 3313</span>&#160;        n = 5  <span class="comment"># Number of tests for lowrank_multivariate_normal</span></div><div class="line"><a name="l03314"></a><span class="lineno"> 3314</span>&#160;        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(0, n):</div><div class="line"><a name="l03315"></a><span class="lineno"> 3315</span>&#160;            loc = [torch.randn(4) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03316"></a><span class="lineno"> 3316</span>&#160;            cov_factor = [torch.randn(4, 3) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03317"></a><span class="lineno"> 3317</span>&#160;            cov_diag = [transform_to(constraints.positive)(torch.randn(4)) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03318"></a><span class="lineno"> 3318</span>&#160;            covariance_matrix = [cov_factor[i].matmul(cov_factor[i].t()) +</div><div class="line"><a name="l03319"></a><span class="lineno"> 3319</span>&#160;                                 cov_diag[i].diag() <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03320"></a><span class="lineno"> 3320</span>&#160;            p = LowRankMultivariateNormal(loc[0], cov_factor[0], cov_diag[0])</div><div class="line"><a name="l03321"></a><span class="lineno"> 3321</span>&#160;            q = LowRankMultivariateNormal(loc[1], cov_factor[1], cov_diag[1])</div><div class="line"><a name="l03322"></a><span class="lineno"> 3322</span>&#160;            p_full = MultivariateNormal(loc[0], covariance_matrix[0])</div><div class="line"><a name="l03323"></a><span class="lineno"> 3323</span>&#160;            q_full = MultivariateNormal(loc[1], covariance_matrix[1])</div><div class="line"><a name="l03324"></a><span class="lineno"> 3324</span>&#160;            expected = kl_divergence(p_full, q_full)</div><div class="line"><a name="l03325"></a><span class="lineno"> 3325</span>&#160;</div><div class="line"><a name="l03326"></a><span class="lineno"> 3326</span>&#160;            actual_lowrank_lowrank = kl_divergence(p, q)</div><div class="line"><a name="l03327"></a><span class="lineno"> 3327</span>&#160;            actual_lowrank_full = kl_divergence(p, q_full)</div><div class="line"><a name="l03328"></a><span class="lineno"> 3328</span>&#160;            actual_full_lowrank = kl_divergence(p_full, q)</div><div class="line"><a name="l03329"></a><span class="lineno"> 3329</span>&#160;</div><div class="line"><a name="l03330"></a><span class="lineno"> 3330</span>&#160;            error_lowrank_lowrank = torch.abs(actual_lowrank_lowrank - expected).max()</div><div class="line"><a name="l03331"></a><span class="lineno"> 3331</span>&#160;            self.assertLess(error_lowrank_lowrank, self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a>, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03332"></a><span class="lineno"> 3332</span>&#160;                <span class="stringliteral">&#39;Incorrect KL(LowRankMultivariateNormal, LowRankMultivariateNormal) instance {}/{}&#39;</span>.format(i + 1, n),</div><div class="line"><a name="l03333"></a><span class="lineno"> 3333</span>&#160;                <span class="stringliteral">&#39;Expected (from KL MultivariateNormal): {}&#39;</span>.format(expected),</div><div class="line"><a name="l03334"></a><span class="lineno"> 3334</span>&#160;                <span class="stringliteral">&#39;Actual (analytic): {}&#39;</span>.format(actual_lowrank_lowrank),</div><div class="line"><a name="l03335"></a><span class="lineno"> 3335</span>&#160;            ]))</div><div class="line"><a name="l03336"></a><span class="lineno"> 3336</span>&#160;</div><div class="line"><a name="l03337"></a><span class="lineno"> 3337</span>&#160;            error_lowrank_full = torch.abs(actual_lowrank_full - expected).max()</div><div class="line"><a name="l03338"></a><span class="lineno"> 3338</span>&#160;            self.assertLess(error_lowrank_full, self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a>, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03339"></a><span class="lineno"> 3339</span>&#160;                <span class="stringliteral">&#39;Incorrect KL(LowRankMultivariateNormal, MultivariateNormal) instance {}/{}&#39;</span>.format(i + 1, n),</div><div class="line"><a name="l03340"></a><span class="lineno"> 3340</span>&#160;                <span class="stringliteral">&#39;Expected (from KL MultivariateNormal): {}&#39;</span>.format(expected),</div><div class="line"><a name="l03341"></a><span class="lineno"> 3341</span>&#160;                <span class="stringliteral">&#39;Actual (analytic): {}&#39;</span>.format(actual_lowrank_full),</div><div class="line"><a name="l03342"></a><span class="lineno"> 3342</span>&#160;            ]))</div><div class="line"><a name="l03343"></a><span class="lineno"> 3343</span>&#160;</div><div class="line"><a name="l03344"></a><span class="lineno"> 3344</span>&#160;            error_full_lowrank = torch.abs(actual_full_lowrank - expected).max()</div><div class="line"><a name="l03345"></a><span class="lineno"> 3345</span>&#160;            self.assertLess(error_full_lowrank, self.<a class="code" href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">precision</a>, <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03346"></a><span class="lineno"> 3346</span>&#160;                <span class="stringliteral">&#39;Incorrect KL(MultivariateNormal, LowRankMultivariateNormal) instance {}/{}&#39;</span>.format(i + 1, n),</div><div class="line"><a name="l03347"></a><span class="lineno"> 3347</span>&#160;                <span class="stringliteral">&#39;Expected (from KL MultivariateNormal): {}&#39;</span>.format(expected),</div><div class="line"><a name="l03348"></a><span class="lineno"> 3348</span>&#160;                <span class="stringliteral">&#39;Actual (analytic): {}&#39;</span>.format(actual_full_lowrank),</div><div class="line"><a name="l03349"></a><span class="lineno"> 3349</span>&#160;            ]))</div><div class="line"><a name="l03350"></a><span class="lineno"> 3350</span>&#160;</div><div class="line"><a name="l03351"></a><span class="lineno"> 3351</span>&#160;    <span class="keyword">def </span>test_kl_lowrank_multivariate_normal_batched(self):</div><div class="line"><a name="l03352"></a><span class="lineno"> 3352</span>&#160;        b = 7  <span class="comment"># Number of batches</span></div><div class="line"><a name="l03353"></a><span class="lineno"> 3353</span>&#160;        loc = [torch.randn(b, 3) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03354"></a><span class="lineno"> 3354</span>&#160;        cov_factor = [torch.randn(b, 3, 2) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03355"></a><span class="lineno"> 3355</span>&#160;        cov_diag = [transform_to(constraints.positive)(torch.randn(b, 3)) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(0, 2)]</div><div class="line"><a name="l03356"></a><span class="lineno"> 3356</span>&#160;        expected_kl = torch.stack([</div><div class="line"><a name="l03357"></a><span class="lineno"> 3357</span>&#160;            kl_divergence(LowRankMultivariateNormal(loc[0][i], cov_factor[0][i], cov_diag[0][i]),</div><div class="line"><a name="l03358"></a><span class="lineno"> 3358</span>&#160;                          LowRankMultivariateNormal(loc[1][i], cov_factor[1][i], cov_diag[1][i]))</div><div class="line"><a name="l03359"></a><span class="lineno"> 3359</span>&#160;            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(0, b)])</div><div class="line"><a name="l03360"></a><span class="lineno"> 3360</span>&#160;        actual_kl = kl_divergence(LowRankMultivariateNormal(loc[0], cov_factor[0], cov_diag[0]),</div><div class="line"><a name="l03361"></a><span class="lineno"> 3361</span>&#160;                                  LowRankMultivariateNormal(loc[1], cov_factor[1], cov_diag[1]))</div><div class="line"><a name="l03362"></a><span class="lineno"> 3362</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected_kl, actual_kl)</div><div class="line"><a name="l03363"></a><span class="lineno"> 3363</span>&#160;</div><div class="line"><a name="l03364"></a><span class="lineno"> 3364</span>&#160;    <span class="keyword">def </span>test_kl_exponential_family(self):</div><div class="line"><a name="l03365"></a><span class="lineno"> 3365</span>&#160;        <span class="keywordflow">for</span> (p, _), (_, q) <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a748a60ca6c8f5423a39dd96b8c53a7c1">finite_examples</a>:</div><div class="line"><a name="l03366"></a><span class="lineno"> 3366</span>&#160;            <span class="keywordflow">if</span> type(p) == type(q) <span class="keywordflow">and</span> issubclass(type(p), ExponentialFamily):</div><div class="line"><a name="l03367"></a><span class="lineno"> 3367</span>&#160;                actual = kl_divergence(p, q)</div><div class="line"><a name="l03368"></a><span class="lineno"> 3368</span>&#160;                expected = _kl_expfamily_expfamily(p, q)</div><div class="line"><a name="l03369"></a><span class="lineno"> 3369</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual, expected, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03370"></a><span class="lineno"> 3370</span>&#160;                    <span class="stringliteral">&#39;Incorrect KL({}, {}).&#39;</span>.format(type(p).__name__, type(q).__name__),</div><div class="line"><a name="l03371"></a><span class="lineno"> 3371</span>&#160;                    <span class="stringliteral">&#39;Expected (using Bregman Divergence) {}&#39;</span>.format(expected),</div><div class="line"><a name="l03372"></a><span class="lineno"> 3372</span>&#160;                    <span class="stringliteral">&#39;Actual (analytic) {}&#39;</span>.format(actual),</div><div class="line"><a name="l03373"></a><span class="lineno"> 3373</span>&#160;                    <span class="stringliteral">&#39;max error = {}&#39;</span>.format(torch.abs(actual - expected).max())</div><div class="line"><a name="l03374"></a><span class="lineno"> 3374</span>&#160;                ]))</div><div class="line"><a name="l03375"></a><span class="lineno"> 3375</span>&#160;</div><div class="line"><a name="l03376"></a><span class="lineno"> 3376</span>&#160;    <span class="keyword">def </span>test_kl_infinite(self):</div><div class="line"><a name="l03377"></a><span class="lineno"> 3377</span>&#160;        <span class="keywordflow">for</span> p, q <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_k_l.html#a5edc7278f2b82b235b303a6e0c55bfe1">infinite_examples</a>:</div><div class="line"><a name="l03378"></a><span class="lineno"> 3378</span>&#160;            self.assertTrue((kl_divergence(p, q) == inf).all(),</div><div class="line"><a name="l03379"></a><span class="lineno"> 3379</span>&#160;                            <span class="stringliteral">&#39;Incorrect KL({}, {})&#39;</span>.format(type(p).__name__, type(q).__name__))</div><div class="line"><a name="l03380"></a><span class="lineno"> 3380</span>&#160;</div><div class="line"><a name="l03381"></a><span class="lineno"> 3381</span>&#160;    <span class="keyword">def </span>test_kl_edgecases(self):</div><div class="line"><a name="l03382"></a><span class="lineno"> 3382</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(kl_divergence(Bernoulli(0), Bernoulli(0)), 0)</div><div class="line"><a name="l03383"></a><span class="lineno"> 3383</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(kl_divergence(Bernoulli(1), Bernoulli(1)), 0)</div><div class="line"><a name="l03384"></a><span class="lineno"> 3384</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(kl_divergence(Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1.])), Categorical(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0., 1.]))), 0)</div><div class="line"><a name="l03385"></a><span class="lineno"> 3385</span>&#160;</div><div class="line"><a name="l03386"></a><span class="lineno"> 3386</span>&#160;    <span class="keyword">def </span>test_kl_shape(self):</div><div class="line"><a name="l03387"></a><span class="lineno"> 3387</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l03388"></a><span class="lineno"> 3388</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l03389"></a><span class="lineno"> 3389</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l03390"></a><span class="lineno"> 3390</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l03391"></a><span class="lineno"> 3391</span>&#160;                    kl = kl_divergence(dist, dist)</div><div class="line"><a name="l03392"></a><span class="lineno"> 3392</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03393"></a><span class="lineno"> 3393</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l03394"></a><span class="lineno"> 3394</span>&#160;                expected_shape = dist.batch_shape <span class="keywordflow">if</span> dist.batch_shape <span class="keywordflow">else</span> torch.Size()</div><div class="line"><a name="l03395"></a><span class="lineno"> 3395</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(kl.shape, expected_shape, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03396"></a><span class="lineno"> 3396</span>&#160;                    <span class="stringliteral">&#39;{} example {}/{}&#39;</span>.format(Dist.__name__, i + 1, len(params)),</div><div class="line"><a name="l03397"></a><span class="lineno"> 3397</span>&#160;                    <span class="stringliteral">&#39;Expected {}&#39;</span>.format(expected_shape),</div><div class="line"><a name="l03398"></a><span class="lineno"> 3398</span>&#160;                    <span class="stringliteral">&#39;Actual {}&#39;</span>.format(kl.shape),</div><div class="line"><a name="l03399"></a><span class="lineno"> 3399</span>&#160;                ]))</div><div class="line"><a name="l03400"></a><span class="lineno"> 3400</span>&#160;</div><div class="line"><a name="l03401"></a><span class="lineno"> 3401</span>&#160;    <span class="keyword">def </span>test_entropy_monte_carlo(self):</div><div class="line"><a name="l03402"></a><span class="lineno"> 3402</span>&#160;        set_rng_seed(0)  <span class="comment"># see Note [Randomized statistical tests]</span></div><div class="line"><a name="l03403"></a><span class="lineno"> 3403</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l03404"></a><span class="lineno"> 3404</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l03405"></a><span class="lineno"> 3405</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l03406"></a><span class="lineno"> 3406</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l03407"></a><span class="lineno"> 3407</span>&#160;                    actual = dist.entropy()</div><div class="line"><a name="l03408"></a><span class="lineno"> 3408</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03409"></a><span class="lineno"> 3409</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l03410"></a><span class="lineno"> 3410</span>&#160;                x = dist.sample(sample_shape=(60000,))</div><div class="line"><a name="l03411"></a><span class="lineno"> 3411</span>&#160;                expected = -dist.log_prob(x).mean(0)</div><div class="line"><a name="l03412"></a><span class="lineno"> 3412</span>&#160;                ignore = (expected == inf) | (expected == -inf)</div><div class="line"><a name="l03413"></a><span class="lineno"> 3413</span>&#160;                expected[ignore] = actual[ignore]</div><div class="line"><a name="l03414"></a><span class="lineno"> 3414</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual, expected, prec=0.2, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03415"></a><span class="lineno"> 3415</span>&#160;                    <span class="stringliteral">&#39;{} example {}/{}, incorrect .entropy().&#39;</span>.format(Dist.__name__, i + 1, len(params)),</div><div class="line"><a name="l03416"></a><span class="lineno"> 3416</span>&#160;                    <span class="stringliteral">&#39;Expected (monte carlo) {}&#39;</span>.format(expected),</div><div class="line"><a name="l03417"></a><span class="lineno"> 3417</span>&#160;                    <span class="stringliteral">&#39;Actual (analytic) {}&#39;</span>.format(actual),</div><div class="line"><a name="l03418"></a><span class="lineno"> 3418</span>&#160;                    <span class="stringliteral">&#39;max error = {}&#39;</span>.format(torch.abs(actual - expected).max()),</div><div class="line"><a name="l03419"></a><span class="lineno"> 3419</span>&#160;                ]))</div><div class="line"><a name="l03420"></a><span class="lineno"> 3420</span>&#160;</div><div class="line"><a name="l03421"></a><span class="lineno"> 3421</span>&#160;    <span class="keyword">def </span>test_entropy_exponential_family(self):</div><div class="line"><a name="l03422"></a><span class="lineno"> 3422</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l03423"></a><span class="lineno"> 3423</span>&#160;            <span class="keywordflow">if</span> <span class="keywordflow">not</span> issubclass(Dist, ExponentialFamily):</div><div class="line"><a name="l03424"></a><span class="lineno"> 3424</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03425"></a><span class="lineno"> 3425</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l03426"></a><span class="lineno"> 3426</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l03427"></a><span class="lineno"> 3427</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l03428"></a><span class="lineno"> 3428</span>&#160;                    actual = dist.entropy()</div><div class="line"><a name="l03429"></a><span class="lineno"> 3429</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03430"></a><span class="lineno"> 3430</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l03431"></a><span class="lineno"> 3431</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l03432"></a><span class="lineno"> 3432</span>&#160;                    expected = ExponentialFamily.entropy(dist)</div><div class="line"><a name="l03433"></a><span class="lineno"> 3433</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03434"></a><span class="lineno"> 3434</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l03435"></a><span class="lineno"> 3435</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual, expected, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03436"></a><span class="lineno"> 3436</span>&#160;                    <span class="stringliteral">&#39;{} example {}/{}, incorrect .entropy().&#39;</span>.format(Dist.__name__, i + 1, len(params)),</div><div class="line"><a name="l03437"></a><span class="lineno"> 3437</span>&#160;                    <span class="stringliteral">&#39;Expected (Bregman Divergence) {}&#39;</span>.format(expected),</div><div class="line"><a name="l03438"></a><span class="lineno"> 3438</span>&#160;                    <span class="stringliteral">&#39;Actual (analytic) {}&#39;</span>.format(actual),</div><div class="line"><a name="l03439"></a><span class="lineno"> 3439</span>&#160;                    <span class="stringliteral">&#39;max error = {}&#39;</span>.format(torch.abs(actual - expected).max())</div><div class="line"><a name="l03440"></a><span class="lineno"> 3440</span>&#160;                ]))</div><div class="line"><a name="l03441"></a><span class="lineno"> 3441</span>&#160;</div><div class="line"><a name="l03442"></a><span class="lineno"> 3442</span>&#160;</div><div class="line"><a name="l03443"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_constraints.html"> 3443</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_constraints.html">TestConstraints</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l03444"></a><span class="lineno"> 3444</span>&#160;    <span class="keyword">def </span>test_params_contains(self):</div><div class="line"><a name="l03445"></a><span class="lineno"> 3445</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l03446"></a><span class="lineno"> 3446</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l03447"></a><span class="lineno"> 3447</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l03448"></a><span class="lineno"> 3448</span>&#160;                <span class="keywordflow">for</span> name, value <span class="keywordflow">in</span> param.items():</div><div class="line"><a name="l03449"></a><span class="lineno"> 3449</span>&#160;                    <span class="keywordflow">if</span> isinstance(value, numbers.Number):</div><div class="line"><a name="l03450"></a><span class="lineno"> 3450</span>&#160;                        value = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([value])</div><div class="line"><a name="l03451"></a><span class="lineno"> 3451</span>&#160;                    <span class="keywordflow">if</span> Dist <span class="keywordflow">in</span> (Categorical, OneHotCategorical, Multinomial) <span class="keywordflow">and</span> name == <span class="stringliteral">&#39;probs&#39;</span>:</div><div class="line"><a name="l03452"></a><span class="lineno"> 3452</span>&#160;                        <span class="comment"># These distributions accept positive probs, but elsewhere we</span></div><div class="line"><a name="l03453"></a><span class="lineno"> 3453</span>&#160;                        <span class="comment"># use a stricter constraint to the simplex.</span></div><div class="line"><a name="l03454"></a><span class="lineno"> 3454</span>&#160;                        value = value / value.sum(-1, <span class="keyword">True</span>)</div><div class="line"><a name="l03455"></a><span class="lineno"> 3455</span>&#160;                    <span class="keywordflow">try</span>:</div><div class="line"><a name="l03456"></a><span class="lineno"> 3456</span>&#160;                        constraint = dist.arg_constraints[name]</div><div class="line"><a name="l03457"></a><span class="lineno"> 3457</span>&#160;                    <span class="keywordflow">except</span> KeyError:</div><div class="line"><a name="l03458"></a><span class="lineno"> 3458</span>&#160;                        <span class="keywordflow">continue</span>  <span class="comment"># ignore optional parameters</span></div><div class="line"><a name="l03459"></a><span class="lineno"> 3459</span>&#160;</div><div class="line"><a name="l03460"></a><span class="lineno"> 3460</span>&#160;                    <span class="keywordflow">if</span> is_dependent(constraint):</div><div class="line"><a name="l03461"></a><span class="lineno"> 3461</span>&#160;                        <span class="keywordflow">continue</span></div><div class="line"><a name="l03462"></a><span class="lineno"> 3462</span>&#160;</div><div class="line"><a name="l03463"></a><span class="lineno"> 3463</span>&#160;                    message = <span class="stringliteral">&#39;{} example {}/{} parameter {} = {}&#39;</span>.format(</div><div class="line"><a name="l03464"></a><span class="lineno"> 3464</span>&#160;                        Dist.__name__, i + 1, len(params), name, value)</div><div class="line"><a name="l03465"></a><span class="lineno"> 3465</span>&#160;                    self.assertTrue(constraint.check(value).all(), msg=message)</div><div class="line"><a name="l03466"></a><span class="lineno"> 3466</span>&#160;</div><div class="line"><a name="l03467"></a><span class="lineno"> 3467</span>&#160;    <span class="keyword">def </span>test_support_contains(self):</div><div class="line"><a name="l03468"></a><span class="lineno"> 3468</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l03469"></a><span class="lineno"> 3469</span>&#160;            self.assertIsInstance(Dist.support, Constraint)</div><div class="line"><a name="l03470"></a><span class="lineno"> 3470</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l03471"></a><span class="lineno"> 3471</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l03472"></a><span class="lineno"> 3472</span>&#160;                value = dist.sample()</div><div class="line"><a name="l03473"></a><span class="lineno"> 3473</span>&#160;                constraint = dist.support</div><div class="line"><a name="l03474"></a><span class="lineno"> 3474</span>&#160;                message = <span class="stringliteral">&#39;{} example {}/{} sample = {}&#39;</span>.format(</div><div class="line"><a name="l03475"></a><span class="lineno"> 3475</span>&#160;                    Dist.__name__, i + 1, len(params), value)</div><div class="line"><a name="l03476"></a><span class="lineno"> 3476</span>&#160;                self.assertTrue(constraint.check(value).all(), msg=message)</div><div class="line"><a name="l03477"></a><span class="lineno"> 3477</span>&#160;</div><div class="line"><a name="l03478"></a><span class="lineno"> 3478</span>&#160;</div><div class="line"><a name="l03479"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_numerical_stability.html"> 3479</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_numerical_stability.html">TestNumericalStability</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l03480"></a><span class="lineno"> 3480</span>&#160;    <span class="keyword">def </span>_test_pdf_score(self,</div><div class="line"><a name="l03481"></a><span class="lineno"> 3481</span>&#160;                        dist_class,</div><div class="line"><a name="l03482"></a><span class="lineno"> 3482</span>&#160;                        x,</div><div class="line"><a name="l03483"></a><span class="lineno"> 3483</span>&#160;                        expected_value,</div><div class="line"><a name="l03484"></a><span class="lineno"> 3484</span>&#160;                        probs=<span class="keywordtype">None</span>,</div><div class="line"><a name="l03485"></a><span class="lineno"> 3485</span>&#160;                        logits=<span class="keywordtype">None</span>,</div><div class="line"><a name="l03486"></a><span class="lineno"> 3486</span>&#160;                        expected_gradient=<span class="keywordtype">None</span>,</div><div class="line"><a name="l03487"></a><span class="lineno"> 3487</span>&#160;                        prec=1e-5):</div><div class="line"><a name="l03488"></a><span class="lineno"> 3488</span>&#160;        <span class="keywordflow">if</span> probs <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l03489"></a><span class="lineno"> 3489</span>&#160;            p = probs.detach().requires_grad_()</div><div class="line"><a name="l03490"></a><span class="lineno"> 3490</span>&#160;            dist = dist_class(p)</div><div class="line"><a name="l03491"></a><span class="lineno"> 3491</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l03492"></a><span class="lineno"> 3492</span>&#160;            p = logits.detach().requires_grad_()</div><div class="line"><a name="l03493"></a><span class="lineno"> 3493</span>&#160;            dist = dist_class(logits=p)</div><div class="line"><a name="l03494"></a><span class="lineno"> 3494</span>&#160;        log_pdf = dist.log_prob(x)</div><div class="line"><a name="l03495"></a><span class="lineno"> 3495</span>&#160;        log_pdf.sum().backward()</div><div class="line"><a name="l03496"></a><span class="lineno"> 3496</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(log_pdf,</div><div class="line"><a name="l03497"></a><span class="lineno"> 3497</span>&#160;                         expected_value,</div><div class="line"><a name="l03498"></a><span class="lineno"> 3498</span>&#160;                         prec=prec,</div><div class="line"><a name="l03499"></a><span class="lineno"> 3499</span>&#160;                         message=<span class="stringliteral">&#39;Incorrect value for tensor type: {}. Expected = {}, Actual = {}&#39;</span></div><div class="line"><a name="l03500"></a><span class="lineno"> 3500</span>&#160;                         .format(type(x), expected_value, log_pdf))</div><div class="line"><a name="l03501"></a><span class="lineno"> 3501</span>&#160;        <span class="keywordflow">if</span> expected_gradient <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l03502"></a><span class="lineno"> 3502</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(p.grad,</div><div class="line"><a name="l03503"></a><span class="lineno"> 3503</span>&#160;                             expected_gradient,</div><div class="line"><a name="l03504"></a><span class="lineno"> 3504</span>&#160;                             prec=prec,</div><div class="line"><a name="l03505"></a><span class="lineno"> 3505</span>&#160;                             message=<span class="stringliteral">&#39;Incorrect gradient for tensor type: {}. Expected = {}, Actual = {}&#39;</span></div><div class="line"><a name="l03506"></a><span class="lineno"> 3506</span>&#160;                             .format(type(x), expected_gradient, p.grad))</div><div class="line"><a name="l03507"></a><span class="lineno"> 3507</span>&#160;</div><div class="line"><a name="l03508"></a><span class="lineno"> 3508</span>&#160;    <span class="keyword">def </span>test_bernoulli_gradient(self):</div><div class="line"><a name="l03509"></a><span class="lineno"> 3509</span>&#160;        <span class="keywordflow">for</span> tensor_type <span class="keywordflow">in</span> [torch.FloatTensor, torch.DoubleTensor]:</div><div class="line"><a name="l03510"></a><span class="lineno"> 3510</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">_test_pdf_score</a>(dist_class=Bernoulli,</div><div class="line"><a name="l03511"></a><span class="lineno"> 3511</span>&#160;                                 probs=tensor_type([0]),</div><div class="line"><a name="l03512"></a><span class="lineno"> 3512</span>&#160;                                 x=tensor_type([0]),</div><div class="line"><a name="l03513"></a><span class="lineno"> 3513</span>&#160;                                 expected_value=tensor_type([0]),</div><div class="line"><a name="l03514"></a><span class="lineno"> 3514</span>&#160;                                 expected_gradient=tensor_type([0]))</div><div class="line"><a name="l03515"></a><span class="lineno"> 3515</span>&#160;</div><div class="line"><a name="l03516"></a><span class="lineno"> 3516</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">_test_pdf_score</a>(dist_class=Bernoulli,</div><div class="line"><a name="l03517"></a><span class="lineno"> 3517</span>&#160;                                 probs=tensor_type([0]),</div><div class="line"><a name="l03518"></a><span class="lineno"> 3518</span>&#160;                                 x=tensor_type([1]),</div><div class="line"><a name="l03519"></a><span class="lineno"> 3519</span>&#160;                                 expected_value=tensor_type([torch.finfo(tensor_type([]).dtype).eps]).log(),</div><div class="line"><a name="l03520"></a><span class="lineno"> 3520</span>&#160;                                 expected_gradient=tensor_type([0]))</div><div class="line"><a name="l03521"></a><span class="lineno"> 3521</span>&#160;</div><div class="line"><a name="l03522"></a><span class="lineno"> 3522</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">_test_pdf_score</a>(dist_class=Bernoulli,</div><div class="line"><a name="l03523"></a><span class="lineno"> 3523</span>&#160;                                 probs=tensor_type([1e-4]),</div><div class="line"><a name="l03524"></a><span class="lineno"> 3524</span>&#160;                                 x=tensor_type([1]),</div><div class="line"><a name="l03525"></a><span class="lineno"> 3525</span>&#160;                                 expected_value=tensor_type([math.log(1e-4)]),</div><div class="line"><a name="l03526"></a><span class="lineno"> 3526</span>&#160;                                 expected_gradient=tensor_type([10000]))</div><div class="line"><a name="l03527"></a><span class="lineno"> 3527</span>&#160;</div><div class="line"><a name="l03528"></a><span class="lineno"> 3528</span>&#160;            <span class="comment"># Lower precision due to:</span></div><div class="line"><a name="l03529"></a><span class="lineno"> 3529</span>&#160;            <span class="comment"># &gt;&gt;&gt; 1 / (1 - torch.FloatTensor([0.9999]))</span></div><div class="line"><a name="l03530"></a><span class="lineno"> 3530</span>&#160;            <span class="comment"># 9998.3408</span></div><div class="line"><a name="l03531"></a><span class="lineno"> 3531</span>&#160;            <span class="comment"># [torch.FloatTensor of size 1]</span></div><div class="line"><a name="l03532"></a><span class="lineno"> 3532</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">_test_pdf_score</a>(dist_class=Bernoulli,</div><div class="line"><a name="l03533"></a><span class="lineno"> 3533</span>&#160;                                 probs=tensor_type([1 - 1e-4]),</div><div class="line"><a name="l03534"></a><span class="lineno"> 3534</span>&#160;                                 x=tensor_type([0]),</div><div class="line"><a name="l03535"></a><span class="lineno"> 3535</span>&#160;                                 expected_value=tensor_type([math.log(1e-4)]),</div><div class="line"><a name="l03536"></a><span class="lineno"> 3536</span>&#160;                                 expected_gradient=tensor_type([-10000]),</div><div class="line"><a name="l03537"></a><span class="lineno"> 3537</span>&#160;                                 prec=2)</div><div class="line"><a name="l03538"></a><span class="lineno"> 3538</span>&#160;</div><div class="line"><a name="l03539"></a><span class="lineno"> 3539</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">_test_pdf_score</a>(dist_class=Bernoulli,</div><div class="line"><a name="l03540"></a><span class="lineno"> 3540</span>&#160;                                 logits=tensor_type([math.log(9999)]),</div><div class="line"><a name="l03541"></a><span class="lineno"> 3541</span>&#160;                                 x=tensor_type([0]),</div><div class="line"><a name="l03542"></a><span class="lineno"> 3542</span>&#160;                                 expected_value=tensor_type([math.log(1e-4)]),</div><div class="line"><a name="l03543"></a><span class="lineno"> 3543</span>&#160;                                 expected_gradient=tensor_type([-1]),</div><div class="line"><a name="l03544"></a><span class="lineno"> 3544</span>&#160;                                 prec=1e-3)</div><div class="line"><a name="l03545"></a><span class="lineno"> 3545</span>&#160;</div><div class="line"><a name="l03546"></a><span class="lineno"> 3546</span>&#160;    <span class="keyword">def </span>test_bernoulli_with_logits_underflow(self):</div><div class="line"><a name="l03547"></a><span class="lineno"> 3547</span>&#160;        <span class="keywordflow">for</span> tensor_type, lim <span class="keywordflow">in</span> ([(torch.FloatTensor, -1e38),</div><div class="line"><a name="l03548"></a><span class="lineno"> 3548</span>&#160;                                  (torch.DoubleTensor, -1e308)]):</div><div class="line"><a name="l03549"></a><span class="lineno"> 3549</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">_test_pdf_score</a>(dist_class=Bernoulli,</div><div class="line"><a name="l03550"></a><span class="lineno"> 3550</span>&#160;                                 logits=tensor_type([lim]),</div><div class="line"><a name="l03551"></a><span class="lineno"> 3551</span>&#160;                                 x=tensor_type([0]),</div><div class="line"><a name="l03552"></a><span class="lineno"> 3552</span>&#160;                                 expected_value=tensor_type([0]),</div><div class="line"><a name="l03553"></a><span class="lineno"> 3553</span>&#160;                                 expected_gradient=tensor_type([0]))</div><div class="line"><a name="l03554"></a><span class="lineno"> 3554</span>&#160;</div><div class="line"><a name="l03555"></a><span class="lineno"> 3555</span>&#160;    <span class="keyword">def </span>test_bernoulli_with_logits_overflow(self):</div><div class="line"><a name="l03556"></a><span class="lineno"> 3556</span>&#160;        <span class="keywordflow">for</span> tensor_type, lim <span class="keywordflow">in</span> ([(torch.FloatTensor, 1e38),</div><div class="line"><a name="l03557"></a><span class="lineno"> 3557</span>&#160;                                  (torch.DoubleTensor, 1e308)]):</div><div class="line"><a name="l03558"></a><span class="lineno"> 3558</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">_test_pdf_score</a>(dist_class=Bernoulli,</div><div class="line"><a name="l03559"></a><span class="lineno"> 3559</span>&#160;                                 logits=tensor_type([lim]),</div><div class="line"><a name="l03560"></a><span class="lineno"> 3560</span>&#160;                                 x=tensor_type([1]),</div><div class="line"><a name="l03561"></a><span class="lineno"> 3561</span>&#160;                                 expected_value=tensor_type([0]),</div><div class="line"><a name="l03562"></a><span class="lineno"> 3562</span>&#160;                                 expected_gradient=tensor_type([0]))</div><div class="line"><a name="l03563"></a><span class="lineno"> 3563</span>&#160;</div><div class="line"><a name="l03564"></a><span class="lineno"> 3564</span>&#160;    <span class="keyword">def </span>test_categorical_log_prob(self):</div><div class="line"><a name="l03565"></a><span class="lineno"> 3565</span>&#160;        <span class="keywordflow">for</span> dtype <span class="keywordflow">in</span> ([torch.float, torch.double]):</div><div class="line"><a name="l03566"></a><span class="lineno"> 3566</span>&#160;            p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 1], dtype=dtype, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l03567"></a><span class="lineno"> 3567</span>&#160;            categorical = OneHotCategorical(p)</div><div class="line"><a name="l03568"></a><span class="lineno"> 3568</span>&#160;            log_pdf = categorical.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 1], dtype=dtype))</div><div class="line"><a name="l03569"></a><span class="lineno"> 3569</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(log_pdf.item(), 0)</div><div class="line"><a name="l03570"></a><span class="lineno"> 3570</span>&#160;</div><div class="line"><a name="l03571"></a><span class="lineno"> 3571</span>&#160;    <span class="keyword">def </span>test_categorical_log_prob_with_logits(self):</div><div class="line"><a name="l03572"></a><span class="lineno"> 3572</span>&#160;        <span class="keywordflow">for</span> dtype <span class="keywordflow">in</span> ([torch.float, torch.double]):</div><div class="line"><a name="l03573"></a><span class="lineno"> 3573</span>&#160;            p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-inf, 0], dtype=dtype, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l03574"></a><span class="lineno"> 3574</span>&#160;            categorical = OneHotCategorical(logits=p)</div><div class="line"><a name="l03575"></a><span class="lineno"> 3575</span>&#160;            log_pdf_prob_1 = categorical.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 1], dtype=dtype))</div><div class="line"><a name="l03576"></a><span class="lineno"> 3576</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(log_pdf_prob_1.item(), 0)</div><div class="line"><a name="l03577"></a><span class="lineno"> 3577</span>&#160;            log_pdf_prob_0 = categorical.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([1, 0], dtype=dtype))</div><div class="line"><a name="l03578"></a><span class="lineno"> 3578</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(log_pdf_prob_0.item(), -inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l03579"></a><span class="lineno"> 3579</span>&#160;</div><div class="line"><a name="l03580"></a><span class="lineno"> 3580</span>&#160;    <span class="keyword">def </span>test_multinomial_log_prob(self):</div><div class="line"><a name="l03581"></a><span class="lineno"> 3581</span>&#160;        <span class="keywordflow">for</span> dtype <span class="keywordflow">in</span> ([torch.float, torch.double]):</div><div class="line"><a name="l03582"></a><span class="lineno"> 3582</span>&#160;            p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 1], dtype=dtype, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l03583"></a><span class="lineno"> 3583</span>&#160;            s = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 10], dtype=dtype)</div><div class="line"><a name="l03584"></a><span class="lineno"> 3584</span>&#160;            multinomial = Multinomial(10, p)</div><div class="line"><a name="l03585"></a><span class="lineno"> 3585</span>&#160;            log_pdf = multinomial.log_prob(s)</div><div class="line"><a name="l03586"></a><span class="lineno"> 3586</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(log_pdf.item(), 0)</div><div class="line"><a name="l03587"></a><span class="lineno"> 3587</span>&#160;</div><div class="line"><a name="l03588"></a><span class="lineno"> 3588</span>&#160;    <span class="keyword">def </span>test_multinomial_log_prob_with_logits(self):</div><div class="line"><a name="l03589"></a><span class="lineno"> 3589</span>&#160;        <span class="keywordflow">for</span> dtype <span class="keywordflow">in</span> ([torch.float, torch.double]):</div><div class="line"><a name="l03590"></a><span class="lineno"> 3590</span>&#160;            p = <a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([-inf, 0], dtype=dtype, requires_grad=<span class="keyword">True</span>)</div><div class="line"><a name="l03591"></a><span class="lineno"> 3591</span>&#160;            multinomial = Multinomial(10, logits=p)</div><div class="line"><a name="l03592"></a><span class="lineno"> 3592</span>&#160;            log_pdf_prob_1 = multinomial.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([0, 10], dtype=dtype))</div><div class="line"><a name="l03593"></a><span class="lineno"> 3593</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(log_pdf_prob_1.item(), 0)</div><div class="line"><a name="l03594"></a><span class="lineno"> 3594</span>&#160;            log_pdf_prob_0 = multinomial.log_prob(<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>([10, 0], dtype=dtype))</div><div class="line"><a name="l03595"></a><span class="lineno"> 3595</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(log_pdf_prob_0.item(), -inf, allow_inf=<span class="keyword">True</span>)</div><div class="line"><a name="l03596"></a><span class="lineno"> 3596</span>&#160;</div><div class="line"><a name="l03597"></a><span class="lineno"> 3597</span>&#160;</div><div class="line"><a name="l03598"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_lazy_logits_initialization.html"> 3598</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_lazy_logits_initialization.html">TestLazyLogitsInitialization</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l03599"></a><span class="lineno"> 3599</span>&#160;    <span class="keyword">def </span>setUp(self):</div><div class="line"><a name="l03600"></a><span class="lineno"> 3600</span>&#160;        super(TestLazyLogitsInitialization, self).setUp()</div><div class="line"><a name="l03601"></a><span class="lineno"> 3601</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_lazy_logits_initialization.html#a3dc4a8de65764827e3e6e0d1b7a5d124">examples</a> = [e <span class="keywordflow">for</span> e <span class="keywordflow">in</span> EXAMPLES <span class="keywordflow">if</span> e.Dist <span class="keywordflow">in</span></div><div class="line"><a name="l03602"></a><span class="lineno"> 3602</span>&#160;                         (Categorical, OneHotCategorical, Bernoulli, Binomial, Multinomial)]</div><div class="line"><a name="l03603"></a><span class="lineno"> 3603</span>&#160;</div><div class="line"><a name="l03604"></a><span class="lineno"> 3604</span>&#160;    <span class="keyword">def </span>test_lazy_logits_initialization(self):</div><div class="line"><a name="l03605"></a><span class="lineno"> 3605</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_lazy_logits_initialization.html#a3dc4a8de65764827e3e6e0d1b7a5d124">examples</a>:</div><div class="line"><a name="l03606"></a><span class="lineno"> 3606</span>&#160;            param = params[0]</div><div class="line"><a name="l03607"></a><span class="lineno"> 3607</span>&#160;            <span class="keywordflow">if</span> <span class="stringliteral">&#39;probs&#39;</span> <span class="keywordflow">in</span> param:</div><div class="line"><a name="l03608"></a><span class="lineno"> 3608</span>&#160;                probs = param.pop(<span class="stringliteral">&#39;probs&#39;</span>)</div><div class="line"><a name="l03609"></a><span class="lineno"> 3609</span>&#160;                param[<span class="stringliteral">&#39;logits&#39;</span>] = probs_to_logits(probs)</div><div class="line"><a name="l03610"></a><span class="lineno"> 3610</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l03611"></a><span class="lineno"> 3611</span>&#160;                shape = (1,) <span class="keywordflow">if</span> <span class="keywordflow">not</span> dist.event_shape <span class="keywordflow">else</span> dist.event_shape</div><div class="line"><a name="l03612"></a><span class="lineno"> 3612</span>&#160;                dist.log_prob(torch.ones(shape))</div><div class="line"><a name="l03613"></a><span class="lineno"> 3613</span>&#160;                message = <span class="stringliteral">&#39;Failed for {} example 0/{}&#39;</span>.format(Dist.__name__, len(params))</div><div class="line"><a name="l03614"></a><span class="lineno"> 3614</span>&#160;                self.assertFalse(<span class="stringliteral">&#39;probs&#39;</span> <span class="keywordflow">in</span> vars(dist), msg=message)</div><div class="line"><a name="l03615"></a><span class="lineno"> 3615</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l03616"></a><span class="lineno"> 3616</span>&#160;                    dist.enumerate_support()</div><div class="line"><a name="l03617"></a><span class="lineno"> 3617</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03618"></a><span class="lineno"> 3618</span>&#160;                    <span class="keywordflow">pass</span></div><div class="line"><a name="l03619"></a><span class="lineno"> 3619</span>&#160;                self.assertFalse(<span class="stringliteral">&#39;probs&#39;</span> <span class="keywordflow">in</span> vars(dist), msg=message)</div><div class="line"><a name="l03620"></a><span class="lineno"> 3620</span>&#160;                batch_shape, event_shape = dist.batch_shape, dist.event_shape</div><div class="line"><a name="l03621"></a><span class="lineno"> 3621</span>&#160;                self.assertFalse(<span class="stringliteral">&#39;probs&#39;</span> <span class="keywordflow">in</span> vars(dist), msg=message)</div><div class="line"><a name="l03622"></a><span class="lineno"> 3622</span>&#160;</div><div class="line"><a name="l03623"></a><span class="lineno"> 3623</span>&#160;    <span class="keyword">def </span>test_lazy_probs_initialization(self):</div><div class="line"><a name="l03624"></a><span class="lineno"> 3624</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_lazy_logits_initialization.html#a3dc4a8de65764827e3e6e0d1b7a5d124">examples</a>:</div><div class="line"><a name="l03625"></a><span class="lineno"> 3625</span>&#160;            param = params[0]</div><div class="line"><a name="l03626"></a><span class="lineno"> 3626</span>&#160;            <span class="keywordflow">if</span> <span class="stringliteral">&#39;probs&#39;</span> <span class="keywordflow">in</span> param:</div><div class="line"><a name="l03627"></a><span class="lineno"> 3627</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l03628"></a><span class="lineno"> 3628</span>&#160;                dist.sample()</div><div class="line"><a name="l03629"></a><span class="lineno"> 3629</span>&#160;                message = <span class="stringliteral">&#39;Failed for {} example 0/{}&#39;</span>.format(Dist.__name__, len(params))</div><div class="line"><a name="l03630"></a><span class="lineno"> 3630</span>&#160;                self.assertFalse(<span class="stringliteral">&#39;logits&#39;</span> <span class="keywordflow">in</span> vars(dist), msg=message)</div><div class="line"><a name="l03631"></a><span class="lineno"> 3631</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l03632"></a><span class="lineno"> 3632</span>&#160;                    dist.enumerate_support()</div><div class="line"><a name="l03633"></a><span class="lineno"> 3633</span>&#160;                <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03634"></a><span class="lineno"> 3634</span>&#160;                    <span class="keywordflow">pass</span></div><div class="line"><a name="l03635"></a><span class="lineno"> 3635</span>&#160;                self.assertFalse(<span class="stringliteral">&#39;logits&#39;</span> <span class="keywordflow">in</span> vars(dist), msg=message)</div><div class="line"><a name="l03636"></a><span class="lineno"> 3636</span>&#160;                batch_shape, event_shape = dist.batch_shape, dist.event_shape</div><div class="line"><a name="l03637"></a><span class="lineno"> 3637</span>&#160;                self.assertFalse(<span class="stringliteral">&#39;logits&#39;</span> <span class="keywordflow">in</span> vars(dist), msg=message)</div><div class="line"><a name="l03638"></a><span class="lineno"> 3638</span>&#160;</div><div class="line"><a name="l03639"></a><span class="lineno"> 3639</span>&#160;</div><div class="line"><a name="l03640"></a><span class="lineno"> 3640</span>&#160;@unittest.skipIf(<span class="keywordflow">not</span> TEST_NUMPY, <span class="stringliteral">&quot;NumPy not found&quot;</span>)</div><div class="line"><a name="l03641"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_against_scipy.html"> 3641</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_against_scipy.html">TestAgainstScipy</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l03642"></a><span class="lineno"> 3642</span>&#160;    <span class="keyword">def </span>setUp(self):</div><div class="line"><a name="l03643"></a><span class="lineno"> 3643</span>&#160;        super(TestAgainstScipy, self).setUp()</div><div class="line"><a name="l03644"></a><span class="lineno"> 3644</span>&#160;        positive_var = torch.randn(20).exp()</div><div class="line"><a name="l03645"></a><span class="lineno"> 3645</span>&#160;        positive_var2 = torch.randn(20).exp()</div><div class="line"><a name="l03646"></a><span class="lineno"> 3646</span>&#160;        random_var = torch.randn(20)</div><div class="line"><a name="l03647"></a><span class="lineno"> 3647</span>&#160;        simplex_tensor = softmax(torch.randn(20), dim=-1)</div><div class="line"><a name="l03648"></a><span class="lineno"> 3648</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_against_scipy.html#aea37f74bd64d97ea97c6db81aa19b70f">distribution_pairs</a> = [</div><div class="line"><a name="l03649"></a><span class="lineno"> 3649</span>&#160;            (</div><div class="line"><a name="l03650"></a><span class="lineno"> 3650</span>&#160;                Bernoulli(simplex_tensor),</div><div class="line"><a name="l03651"></a><span class="lineno"> 3651</span>&#160;                scipy.stats.bernoulli(simplex_tensor)</div><div class="line"><a name="l03652"></a><span class="lineno"> 3652</span>&#160;            ),</div><div class="line"><a name="l03653"></a><span class="lineno"> 3653</span>&#160;            (</div><div class="line"><a name="l03654"></a><span class="lineno"> 3654</span>&#160;                Beta(positive_var, positive_var2),</div><div class="line"><a name="l03655"></a><span class="lineno"> 3655</span>&#160;                scipy.stats.beta(positive_var, positive_var2)</div><div class="line"><a name="l03656"></a><span class="lineno"> 3656</span>&#160;            ),</div><div class="line"><a name="l03657"></a><span class="lineno"> 3657</span>&#160;            (</div><div class="line"><a name="l03658"></a><span class="lineno"> 3658</span>&#160;                Binomial(10, simplex_tensor),</div><div class="line"><a name="l03659"></a><span class="lineno"> 3659</span>&#160;                scipy.stats.binom(10 * np.ones(simplex_tensor.shape), simplex_tensor.numpy())</div><div class="line"><a name="l03660"></a><span class="lineno"> 3660</span>&#160;            ),</div><div class="line"><a name="l03661"></a><span class="lineno"> 3661</span>&#160;            (</div><div class="line"><a name="l03662"></a><span class="lineno"> 3662</span>&#160;                Cauchy(random_var, positive_var),</div><div class="line"><a name="l03663"></a><span class="lineno"> 3663</span>&#160;                scipy.stats.cauchy(loc=random_var, scale=positive_var)</div><div class="line"><a name="l03664"></a><span class="lineno"> 3664</span>&#160;            ),</div><div class="line"><a name="l03665"></a><span class="lineno"> 3665</span>&#160;            (</div><div class="line"><a name="l03666"></a><span class="lineno"> 3666</span>&#160;                Dirichlet(positive_var),</div><div class="line"><a name="l03667"></a><span class="lineno"> 3667</span>&#160;                scipy.stats.dirichlet(positive_var)</div><div class="line"><a name="l03668"></a><span class="lineno"> 3668</span>&#160;            ),</div><div class="line"><a name="l03669"></a><span class="lineno"> 3669</span>&#160;            (</div><div class="line"><a name="l03670"></a><span class="lineno"> 3670</span>&#160;                Exponential(positive_var),</div><div class="line"><a name="l03671"></a><span class="lineno"> 3671</span>&#160;                scipy.stats.expon(scale=positive_var.reciprocal())</div><div class="line"><a name="l03672"></a><span class="lineno"> 3672</span>&#160;            ),</div><div class="line"><a name="l03673"></a><span class="lineno"> 3673</span>&#160;            (</div><div class="line"><a name="l03674"></a><span class="lineno"> 3674</span>&#160;                FisherSnedecor(positive_var, 4 + positive_var2),  <span class="comment"># var for df2&lt;=4 is undefined</span></div><div class="line"><a name="l03675"></a><span class="lineno"> 3675</span>&#160;                scipy.stats.f(positive_var, 4 + positive_var2)</div><div class="line"><a name="l03676"></a><span class="lineno"> 3676</span>&#160;            ),</div><div class="line"><a name="l03677"></a><span class="lineno"> 3677</span>&#160;            (</div><div class="line"><a name="l03678"></a><span class="lineno"> 3678</span>&#160;                Gamma(positive_var, positive_var2),</div><div class="line"><a name="l03679"></a><span class="lineno"> 3679</span>&#160;                scipy.stats.gamma(positive_var, scale=positive_var2.reciprocal())</div><div class="line"><a name="l03680"></a><span class="lineno"> 3680</span>&#160;            ),</div><div class="line"><a name="l03681"></a><span class="lineno"> 3681</span>&#160;            (</div><div class="line"><a name="l03682"></a><span class="lineno"> 3682</span>&#160;                Geometric(simplex_tensor),</div><div class="line"><a name="l03683"></a><span class="lineno"> 3683</span>&#160;                scipy.stats.geom(simplex_tensor, loc=-1)</div><div class="line"><a name="l03684"></a><span class="lineno"> 3684</span>&#160;            ),</div><div class="line"><a name="l03685"></a><span class="lineno"> 3685</span>&#160;            (</div><div class="line"><a name="l03686"></a><span class="lineno"> 3686</span>&#160;                Gumbel(random_var, positive_var2),</div><div class="line"><a name="l03687"></a><span class="lineno"> 3687</span>&#160;                scipy.stats.gumbel_r(random_var, positive_var2)</div><div class="line"><a name="l03688"></a><span class="lineno"> 3688</span>&#160;            ),</div><div class="line"><a name="l03689"></a><span class="lineno"> 3689</span>&#160;            (</div><div class="line"><a name="l03690"></a><span class="lineno"> 3690</span>&#160;                HalfCauchy(positive_var),</div><div class="line"><a name="l03691"></a><span class="lineno"> 3691</span>&#160;                scipy.stats.halfcauchy(scale=positive_var)</div><div class="line"><a name="l03692"></a><span class="lineno"> 3692</span>&#160;            ),</div><div class="line"><a name="l03693"></a><span class="lineno"> 3693</span>&#160;            (</div><div class="line"><a name="l03694"></a><span class="lineno"> 3694</span>&#160;                HalfNormal(positive_var2),</div><div class="line"><a name="l03695"></a><span class="lineno"> 3695</span>&#160;                scipy.stats.halfnorm(scale=positive_var2)</div><div class="line"><a name="l03696"></a><span class="lineno"> 3696</span>&#160;            ),</div><div class="line"><a name="l03697"></a><span class="lineno"> 3697</span>&#160;            (</div><div class="line"><a name="l03698"></a><span class="lineno"> 3698</span>&#160;                Laplace(random_var, positive_var2),</div><div class="line"><a name="l03699"></a><span class="lineno"> 3699</span>&#160;                scipy.stats.laplace(random_var, positive_var2)</div><div class="line"><a name="l03700"></a><span class="lineno"> 3700</span>&#160;            ),</div><div class="line"><a name="l03701"></a><span class="lineno"> 3701</span>&#160;            (</div><div class="line"><a name="l03702"></a><span class="lineno"> 3702</span>&#160;                <span class="comment"># Tests fail 1e-5 threshold if scale &gt; 3</span></div><div class="line"><a name="l03703"></a><span class="lineno"> 3703</span>&#160;                LogNormal(random_var, positive_var.clamp(max=3)),</div><div class="line"><a name="l03704"></a><span class="lineno"> 3704</span>&#160;                scipy.stats.lognorm(s=positive_var.clamp(max=3), scale=random_var.exp())</div><div class="line"><a name="l03705"></a><span class="lineno"> 3705</span>&#160;            ),</div><div class="line"><a name="l03706"></a><span class="lineno"> 3706</span>&#160;            (</div><div class="line"><a name="l03707"></a><span class="lineno"> 3707</span>&#160;                LowRankMultivariateNormal(random_var, torch.zeros(20, 1), positive_var2),</div><div class="line"><a name="l03708"></a><span class="lineno"> 3708</span>&#160;                scipy.stats.multivariate_normal(random_var, torch.diag(positive_var2))</div><div class="line"><a name="l03709"></a><span class="lineno"> 3709</span>&#160;            ),</div><div class="line"><a name="l03710"></a><span class="lineno"> 3710</span>&#160;            (</div><div class="line"><a name="l03711"></a><span class="lineno"> 3711</span>&#160;                Multinomial(10, simplex_tensor),</div><div class="line"><a name="l03712"></a><span class="lineno"> 3712</span>&#160;                scipy.stats.multinomial(10, simplex_tensor)</div><div class="line"><a name="l03713"></a><span class="lineno"> 3713</span>&#160;            ),</div><div class="line"><a name="l03714"></a><span class="lineno"> 3714</span>&#160;            (</div><div class="line"><a name="l03715"></a><span class="lineno"> 3715</span>&#160;                MultivariateNormal(random_var, torch.diag(positive_var2)),</div><div class="line"><a name="l03716"></a><span class="lineno"> 3716</span>&#160;                scipy.stats.multivariate_normal(random_var, torch.diag(positive_var2))</div><div class="line"><a name="l03717"></a><span class="lineno"> 3717</span>&#160;            ),</div><div class="line"><a name="l03718"></a><span class="lineno"> 3718</span>&#160;            (</div><div class="line"><a name="l03719"></a><span class="lineno"> 3719</span>&#160;                Normal(random_var, positive_var2),</div><div class="line"><a name="l03720"></a><span class="lineno"> 3720</span>&#160;                scipy.stats.norm(random_var, positive_var2)</div><div class="line"><a name="l03721"></a><span class="lineno"> 3721</span>&#160;            ),</div><div class="line"><a name="l03722"></a><span class="lineno"> 3722</span>&#160;            (</div><div class="line"><a name="l03723"></a><span class="lineno"> 3723</span>&#160;                OneHotCategorical(simplex_tensor),</div><div class="line"><a name="l03724"></a><span class="lineno"> 3724</span>&#160;                scipy.stats.multinomial(1, simplex_tensor)</div><div class="line"><a name="l03725"></a><span class="lineno"> 3725</span>&#160;            ),</div><div class="line"><a name="l03726"></a><span class="lineno"> 3726</span>&#160;            (</div><div class="line"><a name="l03727"></a><span class="lineno"> 3727</span>&#160;                Pareto(positive_var, 2 + positive_var2),</div><div class="line"><a name="l03728"></a><span class="lineno"> 3728</span>&#160;                scipy.stats.pareto(2 + positive_var2, scale=positive_var)</div><div class="line"><a name="l03729"></a><span class="lineno"> 3729</span>&#160;            ),</div><div class="line"><a name="l03730"></a><span class="lineno"> 3730</span>&#160;            (</div><div class="line"><a name="l03731"></a><span class="lineno"> 3731</span>&#160;                Poisson(positive_var),</div><div class="line"><a name="l03732"></a><span class="lineno"> 3732</span>&#160;                scipy.stats.poisson(positive_var)</div><div class="line"><a name="l03733"></a><span class="lineno"> 3733</span>&#160;            ),</div><div class="line"><a name="l03734"></a><span class="lineno"> 3734</span>&#160;            (</div><div class="line"><a name="l03735"></a><span class="lineno"> 3735</span>&#160;                StudentT(2 + positive_var, random_var, positive_var2),</div><div class="line"><a name="l03736"></a><span class="lineno"> 3736</span>&#160;                scipy.stats.t(2 + positive_var, random_var, positive_var2)</div><div class="line"><a name="l03737"></a><span class="lineno"> 3737</span>&#160;            ),</div><div class="line"><a name="l03738"></a><span class="lineno"> 3738</span>&#160;            (</div><div class="line"><a name="l03739"></a><span class="lineno"> 3739</span>&#160;                Uniform(random_var, random_var + positive_var),</div><div class="line"><a name="l03740"></a><span class="lineno"> 3740</span>&#160;                scipy.stats.uniform(random_var, positive_var)</div><div class="line"><a name="l03741"></a><span class="lineno"> 3741</span>&#160;            ),</div><div class="line"><a name="l03742"></a><span class="lineno"> 3742</span>&#160;            (</div><div class="line"><a name="l03743"></a><span class="lineno"> 3743</span>&#160;                Weibull(positive_var[0], positive_var2[0]),  <span class="comment"># scipy var for Weibull only supports scalars</span></div><div class="line"><a name="l03744"></a><span class="lineno"> 3744</span>&#160;                scipy.stats.weibull_min(c=positive_var2[0], scale=positive_var[0])</div><div class="line"><a name="l03745"></a><span class="lineno"> 3745</span>&#160;            )</div><div class="line"><a name="l03746"></a><span class="lineno"> 3746</span>&#160;        ]</div><div class="line"><a name="l03747"></a><span class="lineno"> 3747</span>&#160;</div><div class="line"><a name="l03748"></a><span class="lineno"> 3748</span>&#160;    <span class="keyword">def </span>test_mean(self):</div><div class="line"><a name="l03749"></a><span class="lineno"> 3749</span>&#160;        <span class="keywordflow">for</span> pytorch_dist, scipy_dist <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_against_scipy.html#aea37f74bd64d97ea97c6db81aa19b70f">distribution_pairs</a>:</div><div class="line"><a name="l03750"></a><span class="lineno"> 3750</span>&#160;            <span class="keywordflow">if</span> isinstance(pytorch_dist, (Cauchy, HalfCauchy)):</div><div class="line"><a name="l03751"></a><span class="lineno"> 3751</span>&#160;                <span class="comment"># Cauchy, HalfCauchy distributions&#39; mean is nan, skipping check</span></div><div class="line"><a name="l03752"></a><span class="lineno"> 3752</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03753"></a><span class="lineno"> 3753</span>&#160;            <span class="keywordflow">elif</span> isinstance(pytorch_dist, (LowRankMultivariateNormal, MultivariateNormal)):</div><div class="line"><a name="l03754"></a><span class="lineno"> 3754</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.mean, scipy_dist.mean, allow_inf=<span class="keyword">True</span>, message=pytorch_dist)</div><div class="line"><a name="l03755"></a><span class="lineno"> 3755</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l03756"></a><span class="lineno"> 3756</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.mean, scipy_dist.mean(), allow_inf=<span class="keyword">True</span>, message=pytorch_dist)</div><div class="line"><a name="l03757"></a><span class="lineno"> 3757</span>&#160;</div><div class="line"><a name="l03758"></a><span class="lineno"> 3758</span>&#160;    <span class="keyword">def </span>test_variance_stddev(self):</div><div class="line"><a name="l03759"></a><span class="lineno"> 3759</span>&#160;        <span class="keywordflow">for</span> pytorch_dist, scipy_dist <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_against_scipy.html#aea37f74bd64d97ea97c6db81aa19b70f">distribution_pairs</a>:</div><div class="line"><a name="l03760"></a><span class="lineno"> 3760</span>&#160;            <span class="keywordflow">if</span> isinstance(pytorch_dist, (Cauchy, HalfCauchy)):</div><div class="line"><a name="l03761"></a><span class="lineno"> 3761</span>&#160;                <span class="comment"># Cauchy, HalfCauchy distributions&#39; standard deviation is nan, skipping check</span></div><div class="line"><a name="l03762"></a><span class="lineno"> 3762</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03763"></a><span class="lineno"> 3763</span>&#160;            <span class="keywordflow">elif</span> isinstance(pytorch_dist, (Multinomial, OneHotCategorical)):</div><div class="line"><a name="l03764"></a><span class="lineno"> 3764</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.variance, np.diag(scipy_dist.cov()), message=pytorch_dist)</div><div class="line"><a name="l03765"></a><span class="lineno"> 3765</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.stddev, np.diag(scipy_dist.cov()) ** 0.5, message=pytorch_dist)</div><div class="line"><a name="l03766"></a><span class="lineno"> 3766</span>&#160;            <span class="keywordflow">elif</span> isinstance(pytorch_dist, (LowRankMultivariateNormal, MultivariateNormal)):</div><div class="line"><a name="l03767"></a><span class="lineno"> 3767</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.variance, np.diag(scipy_dist.cov), message=pytorch_dist)</div><div class="line"><a name="l03768"></a><span class="lineno"> 3768</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.stddev, np.diag(scipy_dist.cov) ** 0.5, message=pytorch_dist)</div><div class="line"><a name="l03769"></a><span class="lineno"> 3769</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l03770"></a><span class="lineno"> 3770</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.variance, scipy_dist.var(), allow_inf=<span class="keyword">True</span>, message=pytorch_dist)</div><div class="line"><a name="l03771"></a><span class="lineno"> 3771</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(pytorch_dist.stddev, scipy_dist.var() ** 0.5, message=pytorch_dist)</div><div class="line"><a name="l03772"></a><span class="lineno"> 3772</span>&#160;</div><div class="line"><a name="l03773"></a><span class="lineno"> 3773</span>&#160;    <span class="keyword">def </span>test_cdf(self):</div><div class="line"><a name="l03774"></a><span class="lineno"> 3774</span>&#160;        <span class="keywordflow">for</span> pytorch_dist, scipy_dist <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_against_scipy.html#aea37f74bd64d97ea97c6db81aa19b70f">distribution_pairs</a>:</div><div class="line"><a name="l03775"></a><span class="lineno"> 3775</span>&#160;            samples = pytorch_dist.sample((5,))</div><div class="line"><a name="l03776"></a><span class="lineno"> 3776</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l03777"></a><span class="lineno"> 3777</span>&#160;                cdf = pytorch_dist.cdf(samples)</div><div class="line"><a name="l03778"></a><span class="lineno"> 3778</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03779"></a><span class="lineno"> 3779</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03780"></a><span class="lineno"> 3780</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(cdf, scipy_dist.cdf(samples), message=pytorch_dist)</div><div class="line"><a name="l03781"></a><span class="lineno"> 3781</span>&#160;</div><div class="line"><a name="l03782"></a><span class="lineno"> 3782</span>&#160;    <span class="keyword">def </span>test_icdf(self):</div><div class="line"><a name="l03783"></a><span class="lineno"> 3783</span>&#160;        <span class="keywordflow">for</span> pytorch_dist, scipy_dist <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_against_scipy.html#aea37f74bd64d97ea97c6db81aa19b70f">distribution_pairs</a>:</div><div class="line"><a name="l03784"></a><span class="lineno"> 3784</span>&#160;            samples = torch.rand((5,) + pytorch_dist.batch_shape)</div><div class="line"><a name="l03785"></a><span class="lineno"> 3785</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l03786"></a><span class="lineno"> 3786</span>&#160;                icdf = pytorch_dist.icdf(samples)</div><div class="line"><a name="l03787"></a><span class="lineno"> 3787</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03788"></a><span class="lineno"> 3788</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03789"></a><span class="lineno"> 3789</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(icdf, scipy_dist.ppf(samples), message=pytorch_dist)</div><div class="line"><a name="l03790"></a><span class="lineno"> 3790</span>&#160;</div><div class="line"><a name="l03791"></a><span class="lineno"> 3791</span>&#160;</div><div class="line"><a name="l03792"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_transforms.html"> 3792</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_transforms.html">TestTransforms</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l03793"></a><span class="lineno"> 3793</span>&#160;    <span class="keyword">def </span>setUp(self):</div><div class="line"><a name="l03794"></a><span class="lineno"> 3794</span>&#160;        super(TestTransforms, self).setUp()</div><div class="line"><a name="l03795"></a><span class="lineno"> 3795</span>&#160;        self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a> = []</div><div class="line"><a name="l03796"></a><span class="lineno"> 3796</span>&#160;        transforms_by_cache_size = {}</div><div class="line"><a name="l03797"></a><span class="lineno"> 3797</span>&#160;        <span class="keywordflow">for</span> cache_size <span class="keywordflow">in</span> [0, 1]:</div><div class="line"><a name="l03798"></a><span class="lineno"> 3798</span>&#160;            transforms = [</div><div class="line"><a name="l03799"></a><span class="lineno"> 3799</span>&#160;                AbsTransform(cache_size=cache_size),</div><div class="line"><a name="l03800"></a><span class="lineno"> 3800</span>&#160;                ExpTransform(cache_size=cache_size),</div><div class="line"><a name="l03801"></a><span class="lineno"> 3801</span>&#160;                PowerTransform(exponent=2,</div><div class="line"><a name="l03802"></a><span class="lineno"> 3802</span>&#160;                               cache_size=cache_size),</div><div class="line"><a name="l03803"></a><span class="lineno"> 3803</span>&#160;                PowerTransform(exponent=<a class="code" href="namespacetorch_1_1tensor.html">torch.tensor</a>(5.).normal_(),</div><div class="line"><a name="l03804"></a><span class="lineno"> 3804</span>&#160;                               cache_size=cache_size),</div><div class="line"><a name="l03805"></a><span class="lineno"> 3805</span>&#160;                SigmoidTransform(cache_size=cache_size),</div><div class="line"><a name="l03806"></a><span class="lineno"> 3806</span>&#160;                AffineTransform(0, 1, cache_size=cache_size),</div><div class="line"><a name="l03807"></a><span class="lineno"> 3807</span>&#160;                AffineTransform(1, -2, cache_size=cache_size),</div><div class="line"><a name="l03808"></a><span class="lineno"> 3808</span>&#160;                AffineTransform(torch.randn(5),</div><div class="line"><a name="l03809"></a><span class="lineno"> 3809</span>&#160;                                torch.randn(5),</div><div class="line"><a name="l03810"></a><span class="lineno"> 3810</span>&#160;                                cache_size=cache_size),</div><div class="line"><a name="l03811"></a><span class="lineno"> 3811</span>&#160;                AffineTransform(torch.randn(4, 5),</div><div class="line"><a name="l03812"></a><span class="lineno"> 3812</span>&#160;                                torch.randn(4, 5),</div><div class="line"><a name="l03813"></a><span class="lineno"> 3813</span>&#160;                                cache_size=cache_size),</div><div class="line"><a name="l03814"></a><span class="lineno"> 3814</span>&#160;                SoftmaxTransform(cache_size=cache_size),</div><div class="line"><a name="l03815"></a><span class="lineno"> 3815</span>&#160;                StickBreakingTransform(cache_size=cache_size),</div><div class="line"><a name="l03816"></a><span class="lineno"> 3816</span>&#160;                LowerCholeskyTransform(cache_size=cache_size),</div><div class="line"><a name="l03817"></a><span class="lineno"> 3817</span>&#160;                ComposeTransform([</div><div class="line"><a name="l03818"></a><span class="lineno"> 3818</span>&#160;                    AffineTransform(torch.randn(4, 5),</div><div class="line"><a name="l03819"></a><span class="lineno"> 3819</span>&#160;                                    torch.randn(4, 5),</div><div class="line"><a name="l03820"></a><span class="lineno"> 3820</span>&#160;                                    cache_size=cache_size),</div><div class="line"><a name="l03821"></a><span class="lineno"> 3821</span>&#160;                ]),</div><div class="line"><a name="l03822"></a><span class="lineno"> 3822</span>&#160;                ComposeTransform([</div><div class="line"><a name="l03823"></a><span class="lineno"> 3823</span>&#160;                    AffineTransform(torch.randn(4, 5),</div><div class="line"><a name="l03824"></a><span class="lineno"> 3824</span>&#160;                                    torch.randn(4, 5),</div><div class="line"><a name="l03825"></a><span class="lineno"> 3825</span>&#160;                                    cache_size=cache_size),</div><div class="line"><a name="l03826"></a><span class="lineno"> 3826</span>&#160;                    ExpTransform(cache_size=cache_size),</div><div class="line"><a name="l03827"></a><span class="lineno"> 3827</span>&#160;                ]),</div><div class="line"><a name="l03828"></a><span class="lineno"> 3828</span>&#160;                ComposeTransform([</div><div class="line"><a name="l03829"></a><span class="lineno"> 3829</span>&#160;                    AffineTransform(0, 1, cache_size=cache_size),</div><div class="line"><a name="l03830"></a><span class="lineno"> 3830</span>&#160;                    AffineTransform(torch.randn(4, 5),</div><div class="line"><a name="l03831"></a><span class="lineno"> 3831</span>&#160;                                    torch.randn(4, 5),</div><div class="line"><a name="l03832"></a><span class="lineno"> 3832</span>&#160;                                    cache_size=cache_size),</div><div class="line"><a name="l03833"></a><span class="lineno"> 3833</span>&#160;                    AffineTransform(1, -2, cache_size=cache_size),</div><div class="line"><a name="l03834"></a><span class="lineno"> 3834</span>&#160;                    AffineTransform(torch.randn(4, 5),</div><div class="line"><a name="l03835"></a><span class="lineno"> 3835</span>&#160;                                    torch.randn(4, 5),</div><div class="line"><a name="l03836"></a><span class="lineno"> 3836</span>&#160;                                    cache_size=cache_size),</div><div class="line"><a name="l03837"></a><span class="lineno"> 3837</span>&#160;                ]),</div><div class="line"><a name="l03838"></a><span class="lineno"> 3838</span>&#160;            ]</div><div class="line"><a name="l03839"></a><span class="lineno"> 3839</span>&#160;            <span class="keywordflow">for</span> t <span class="keywordflow">in</span> transforms[:]:</div><div class="line"><a name="l03840"></a><span class="lineno"> 3840</span>&#160;                transforms.append(t.inv)</div><div class="line"><a name="l03841"></a><span class="lineno"> 3841</span>&#160;            transforms.append(identity_transform)</div><div class="line"><a name="l03842"></a><span class="lineno"> 3842</span>&#160;            self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a> += transforms</div><div class="line"><a name="l03843"></a><span class="lineno"> 3843</span>&#160;            <span class="keywordflow">if</span> cache_size == 0:</div><div class="line"><a name="l03844"></a><span class="lineno"> 3844</span>&#160;                self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#acf329454d378ae6acfeb91b63a915c10">unique_transforms</a> = transforms[:]</div><div class="line"><a name="l03845"></a><span class="lineno"> 3845</span>&#160;</div><div class="line"><a name="l03846"></a><span class="lineno"> 3846</span>&#160;    <span class="keyword">def </span>_generate_data(self, transform):</div><div class="line"><a name="l03847"></a><span class="lineno"> 3847</span>&#160;        domain = transform.domain</div><div class="line"><a name="l03848"></a><span class="lineno"> 3848</span>&#160;        codomain = transform.codomain</div><div class="line"><a name="l03849"></a><span class="lineno"> 3849</span>&#160;        x = torch.empty(4, 5)</div><div class="line"><a name="l03850"></a><span class="lineno"> 3850</span>&#160;        <span class="keywordflow">if</span> domain <span class="keywordflow">is</span> constraints.lower_cholesky <span class="keywordflow">or</span> codomain <span class="keywordflow">is</span> constraints.lower_cholesky:</div><div class="line"><a name="l03851"></a><span class="lineno"> 3851</span>&#160;            x = torch.empty(6, 6)</div><div class="line"><a name="l03852"></a><span class="lineno"> 3852</span>&#160;            x = x.normal_()</div><div class="line"><a name="l03853"></a><span class="lineno"> 3853</span>&#160;            <span class="keywordflow">return</span> x</div><div class="line"><a name="l03854"></a><span class="lineno"> 3854</span>&#160;        <span class="keywordflow">elif</span> domain <span class="keywordflow">is</span> constraints.real:</div><div class="line"><a name="l03855"></a><span class="lineno"> 3855</span>&#160;            <span class="keywordflow">return</span> x.normal_()</div><div class="line"><a name="l03856"></a><span class="lineno"> 3856</span>&#160;        <span class="keywordflow">elif</span> domain <span class="keywordflow">is</span> constraints.positive:</div><div class="line"><a name="l03857"></a><span class="lineno"> 3857</span>&#160;            <span class="keywordflow">return</span> x.normal_().exp()</div><div class="line"><a name="l03858"></a><span class="lineno"> 3858</span>&#160;        <span class="keywordflow">elif</span> domain <span class="keywordflow">is</span> constraints.unit_interval:</div><div class="line"><a name="l03859"></a><span class="lineno"> 3859</span>&#160;            <span class="keywordflow">return</span> x.uniform_()</div><div class="line"><a name="l03860"></a><span class="lineno"> 3860</span>&#160;        <span class="keywordflow">elif</span> domain <span class="keywordflow">is</span> constraints.simplex:</div><div class="line"><a name="l03861"></a><span class="lineno"> 3861</span>&#160;            x = x.normal_().exp()</div><div class="line"><a name="l03862"></a><span class="lineno"> 3862</span>&#160;            x /= x.sum(-1, <span class="keyword">True</span>)</div><div class="line"><a name="l03863"></a><span class="lineno"> 3863</span>&#160;            <span class="keywordflow">return</span> x</div><div class="line"><a name="l03864"></a><span class="lineno"> 3864</span>&#160;        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;Unsupported domain: {}&#39;</span>.format(domain))</div><div class="line"><a name="l03865"></a><span class="lineno"> 3865</span>&#160;</div><div class="line"><a name="l03866"></a><span class="lineno"> 3866</span>&#160;    <span class="keyword">def </span>test_inv_inv(self):</div><div class="line"><a name="l03867"></a><span class="lineno"> 3867</span>&#160;        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a>:</div><div class="line"><a name="l03868"></a><span class="lineno"> 3868</span>&#160;            self.assertTrue(t.inv.inv <span class="keywordflow">is</span> t)</div><div class="line"><a name="l03869"></a><span class="lineno"> 3869</span>&#160;</div><div class="line"><a name="l03870"></a><span class="lineno"> 3870</span>&#160;    <span class="keyword">def </span>test_equality(self):</div><div class="line"><a name="l03871"></a><span class="lineno"> 3871</span>&#160;        transforms = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#acf329454d378ae6acfeb91b63a915c10">unique_transforms</a></div><div class="line"><a name="l03872"></a><span class="lineno"> 3872</span>&#160;        <span class="keywordflow">for</span> x, y <span class="keywordflow">in</span> product(transforms, transforms):</div><div class="line"><a name="l03873"></a><span class="lineno"> 3873</span>&#160;            <span class="keywordflow">if</span> x <span class="keywordflow">is</span> y:</div><div class="line"><a name="l03874"></a><span class="lineno"> 3874</span>&#160;                self.assertTrue(x == y)</div><div class="line"><a name="l03875"></a><span class="lineno"> 3875</span>&#160;                self.assertFalse(x != y)</div><div class="line"><a name="l03876"></a><span class="lineno"> 3876</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l03877"></a><span class="lineno"> 3877</span>&#160;                self.assertFalse(x == y)</div><div class="line"><a name="l03878"></a><span class="lineno"> 3878</span>&#160;                self.assertTrue(x != y)</div><div class="line"><a name="l03879"></a><span class="lineno"> 3879</span>&#160;</div><div class="line"><a name="l03880"></a><span class="lineno"> 3880</span>&#160;        self.assertTrue(identity_transform == identity_transform.inv)</div><div class="line"><a name="l03881"></a><span class="lineno"> 3881</span>&#160;        self.assertFalse(identity_transform != identity_transform.inv)</div><div class="line"><a name="l03882"></a><span class="lineno"> 3882</span>&#160;</div><div class="line"><a name="l03883"></a><span class="lineno"> 3883</span>&#160;    <span class="keyword">def </span>test_forward_inverse_cache(self):</div><div class="line"><a name="l03884"></a><span class="lineno"> 3884</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a>:</div><div class="line"><a name="l03885"></a><span class="lineno"> 3885</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform).requires_grad_()</div><div class="line"><a name="l03886"></a><span class="lineno"> 3886</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l03887"></a><span class="lineno"> 3887</span>&#160;                y = transform(x)</div><div class="line"><a name="l03888"></a><span class="lineno"> 3888</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03889"></a><span class="lineno"> 3889</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03890"></a><span class="lineno"> 3890</span>&#160;            x2 = transform.inv(y)  <span class="comment"># should be implemented at least by caching</span></div><div class="line"><a name="l03891"></a><span class="lineno"> 3891</span>&#160;            y2 = transform(x2)  <span class="comment"># should be implemented at least by caching</span></div><div class="line"><a name="l03892"></a><span class="lineno"> 3892</span>&#160;            <span class="keywordflow">if</span> transform.bijective:</div><div class="line"><a name="l03893"></a><span class="lineno"> 3893</span>&#160;                <span class="comment"># verify function inverse</span></div><div class="line"><a name="l03894"></a><span class="lineno"> 3894</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(x2, x, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03895"></a><span class="lineno"> 3895</span>&#160;                    <span class="stringliteral">&#39;{} t.inv(t(-)) error&#39;</span>.format(transform),</div><div class="line"><a name="l03896"></a><span class="lineno"> 3896</span>&#160;                    <span class="stringliteral">&#39;x = {}&#39;</span>.format(x),</div><div class="line"><a name="l03897"></a><span class="lineno"> 3897</span>&#160;                    <span class="stringliteral">&#39;y = t(x) = {}&#39;</span>.format(y),</div><div class="line"><a name="l03898"></a><span class="lineno"> 3898</span>&#160;                    <span class="stringliteral">&#39;x2 = t.inv(y) = {}&#39;</span>.format(x2),</div><div class="line"><a name="l03899"></a><span class="lineno"> 3899</span>&#160;                ]))</div><div class="line"><a name="l03900"></a><span class="lineno"> 3900</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l03901"></a><span class="lineno"> 3901</span>&#160;                <span class="comment"># verify weaker function pseudo-inverse</span></div><div class="line"><a name="l03902"></a><span class="lineno"> 3902</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(y2, y, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03903"></a><span class="lineno"> 3903</span>&#160;                    <span class="stringliteral">&#39;{} t(t.inv(t(-))) error&#39;</span>.format(transform),</div><div class="line"><a name="l03904"></a><span class="lineno"> 3904</span>&#160;                    <span class="stringliteral">&#39;x = {}&#39;</span>.format(x),</div><div class="line"><a name="l03905"></a><span class="lineno"> 3905</span>&#160;                    <span class="stringliteral">&#39;y = t(x) = {}&#39;</span>.format(y),</div><div class="line"><a name="l03906"></a><span class="lineno"> 3906</span>&#160;                    <span class="stringliteral">&#39;x2 = t.inv(y) = {}&#39;</span>.format(x2),</div><div class="line"><a name="l03907"></a><span class="lineno"> 3907</span>&#160;                    <span class="stringliteral">&#39;y2 = t(x2) = {}&#39;</span>.format(y2),</div><div class="line"><a name="l03908"></a><span class="lineno"> 3908</span>&#160;                ]))</div><div class="line"><a name="l03909"></a><span class="lineno"> 3909</span>&#160;</div><div class="line"><a name="l03910"></a><span class="lineno"> 3910</span>&#160;    <span class="keyword">def </span>test_forward_inverse_no_cache(self):</div><div class="line"><a name="l03911"></a><span class="lineno"> 3911</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a>:</div><div class="line"><a name="l03912"></a><span class="lineno"> 3912</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform).requires_grad_()</div><div class="line"><a name="l03913"></a><span class="lineno"> 3913</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l03914"></a><span class="lineno"> 3914</span>&#160;                y = transform(x)</div><div class="line"><a name="l03915"></a><span class="lineno"> 3915</span>&#160;                x2 = transform.inv(y.clone())  <span class="comment"># bypass cache</span></div><div class="line"><a name="l03916"></a><span class="lineno"> 3916</span>&#160;                y2 = transform(x2)</div><div class="line"><a name="l03917"></a><span class="lineno"> 3917</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03918"></a><span class="lineno"> 3918</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03919"></a><span class="lineno"> 3919</span>&#160;            <span class="keywordflow">if</span> transform.bijective:</div><div class="line"><a name="l03920"></a><span class="lineno"> 3920</span>&#160;                <span class="comment"># verify function inverse</span></div><div class="line"><a name="l03921"></a><span class="lineno"> 3921</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(x2, x, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03922"></a><span class="lineno"> 3922</span>&#160;                    <span class="stringliteral">&#39;{} t.inv(t(-)) error&#39;</span>.format(transform),</div><div class="line"><a name="l03923"></a><span class="lineno"> 3923</span>&#160;                    <span class="stringliteral">&#39;x = {}&#39;</span>.format(x),</div><div class="line"><a name="l03924"></a><span class="lineno"> 3924</span>&#160;                    <span class="stringliteral">&#39;y = t(x) = {}&#39;</span>.format(y),</div><div class="line"><a name="l03925"></a><span class="lineno"> 3925</span>&#160;                    <span class="stringliteral">&#39;x2 = t.inv(y) = {}&#39;</span>.format(x2),</div><div class="line"><a name="l03926"></a><span class="lineno"> 3926</span>&#160;                ]))</div><div class="line"><a name="l03927"></a><span class="lineno"> 3927</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l03928"></a><span class="lineno"> 3928</span>&#160;                <span class="comment"># verify weaker function pseudo-inverse</span></div><div class="line"><a name="l03929"></a><span class="lineno"> 3929</span>&#160;                self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(y2, y, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03930"></a><span class="lineno"> 3930</span>&#160;                    <span class="stringliteral">&#39;{} t(t.inv(t(-))) error&#39;</span>.format(transform),</div><div class="line"><a name="l03931"></a><span class="lineno"> 3931</span>&#160;                    <span class="stringliteral">&#39;x = {}&#39;</span>.format(x),</div><div class="line"><a name="l03932"></a><span class="lineno"> 3932</span>&#160;                    <span class="stringliteral">&#39;y = t(x) = {}&#39;</span>.format(y),</div><div class="line"><a name="l03933"></a><span class="lineno"> 3933</span>&#160;                    <span class="stringliteral">&#39;x2 = t.inv(y) = {}&#39;</span>.format(x2),</div><div class="line"><a name="l03934"></a><span class="lineno"> 3934</span>&#160;                    <span class="stringliteral">&#39;y2 = t(x2) = {}&#39;</span>.format(y2),</div><div class="line"><a name="l03935"></a><span class="lineno"> 3935</span>&#160;                ]))</div><div class="line"><a name="l03936"></a><span class="lineno"> 3936</span>&#160;</div><div class="line"><a name="l03937"></a><span class="lineno"> 3937</span>&#160;    <span class="keyword">def </span>test_univariate_forward_jacobian(self):</div><div class="line"><a name="l03938"></a><span class="lineno"> 3938</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a>:</div><div class="line"><a name="l03939"></a><span class="lineno"> 3939</span>&#160;            <span class="keywordflow">if</span> transform.event_dim &gt; 0:</div><div class="line"><a name="l03940"></a><span class="lineno"> 3940</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03941"></a><span class="lineno"> 3941</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform).requires_grad_()</div><div class="line"><a name="l03942"></a><span class="lineno"> 3942</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l03943"></a><span class="lineno"> 3943</span>&#160;                y = transform(x)</div><div class="line"><a name="l03944"></a><span class="lineno"> 3944</span>&#160;                actual = transform.log_abs_det_jacobian(x, y)</div><div class="line"><a name="l03945"></a><span class="lineno"> 3945</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03946"></a><span class="lineno"> 3946</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03947"></a><span class="lineno"> 3947</span>&#160;            expected = torch.abs(grad([y.sum()], [x])[0]).log()</div><div class="line"><a name="l03948"></a><span class="lineno"> 3948</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual, expected, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03949"></a><span class="lineno"> 3949</span>&#160;                <span class="stringliteral">&#39;Bad {}.log_abs_det_jacobian() disagrees with ()&#39;</span>.format(transform),</div><div class="line"><a name="l03950"></a><span class="lineno"> 3950</span>&#160;                <span class="stringliteral">&#39;Expected: {}&#39;</span>.format(expected),</div><div class="line"><a name="l03951"></a><span class="lineno"> 3951</span>&#160;                <span class="stringliteral">&#39;Actual: {}&#39;</span>.format(actual),</div><div class="line"><a name="l03952"></a><span class="lineno"> 3952</span>&#160;            ]))</div><div class="line"><a name="l03953"></a><span class="lineno"> 3953</span>&#160;</div><div class="line"><a name="l03954"></a><span class="lineno"> 3954</span>&#160;    <span class="keyword">def </span>test_univariate_inverse_jacobian(self):</div><div class="line"><a name="l03955"></a><span class="lineno"> 3955</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a>:</div><div class="line"><a name="l03956"></a><span class="lineno"> 3956</span>&#160;            <span class="keywordflow">if</span> transform.event_dim &gt; 0:</div><div class="line"><a name="l03957"></a><span class="lineno"> 3957</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03958"></a><span class="lineno"> 3958</span>&#160;            y = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform.inv).requires_grad_()</div><div class="line"><a name="l03959"></a><span class="lineno"> 3959</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l03960"></a><span class="lineno"> 3960</span>&#160;                x = transform.inv(y)</div><div class="line"><a name="l03961"></a><span class="lineno"> 3961</span>&#160;                actual = transform.log_abs_det_jacobian(x, y)</div><div class="line"><a name="l03962"></a><span class="lineno"> 3962</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03963"></a><span class="lineno"> 3963</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03964"></a><span class="lineno"> 3964</span>&#160;            expected = -torch.abs(grad([x.sum()], [y])[0]).log()</div><div class="line"><a name="l03965"></a><span class="lineno"> 3965</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual, expected, message=<span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l03966"></a><span class="lineno"> 3966</span>&#160;                <span class="stringliteral">&#39;{}.log_abs_det_jacobian() disagrees with .inv()&#39;</span>.format(transform),</div><div class="line"><a name="l03967"></a><span class="lineno"> 3967</span>&#160;                <span class="stringliteral">&#39;Expected: {}&#39;</span>.format(expected),</div><div class="line"><a name="l03968"></a><span class="lineno"> 3968</span>&#160;                <span class="stringliteral">&#39;Actual: {}&#39;</span>.format(actual),</div><div class="line"><a name="l03969"></a><span class="lineno"> 3969</span>&#160;            ]))</div><div class="line"><a name="l03970"></a><span class="lineno"> 3970</span>&#160;</div><div class="line"><a name="l03971"></a><span class="lineno"> 3971</span>&#160;    <span class="keyword">def </span>test_jacobian_shape(self):</div><div class="line"><a name="l03972"></a><span class="lineno"> 3972</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">transforms</a>:</div><div class="line"><a name="l03973"></a><span class="lineno"> 3973</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform)</div><div class="line"><a name="l03974"></a><span class="lineno"> 3974</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l03975"></a><span class="lineno"> 3975</span>&#160;                y = transform(x)</div><div class="line"><a name="l03976"></a><span class="lineno"> 3976</span>&#160;                actual = transform.log_abs_det_jacobian(x, y)</div><div class="line"><a name="l03977"></a><span class="lineno"> 3977</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l03978"></a><span class="lineno"> 3978</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l03979"></a><span class="lineno"> 3979</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(actual.shape, x.shape[:x.dim() - transform.event_dim])</div><div class="line"><a name="l03980"></a><span class="lineno"> 3980</span>&#160;</div><div class="line"><a name="l03981"></a><span class="lineno"> 3981</span>&#160;    <span class="keyword">def </span>test_transform_shapes(self):</div><div class="line"><a name="l03982"></a><span class="lineno"> 3982</span>&#160;        transform0 = ExpTransform()</div><div class="line"><a name="l03983"></a><span class="lineno"> 3983</span>&#160;        transform1 = SoftmaxTransform()</div><div class="line"><a name="l03984"></a><span class="lineno"> 3984</span>&#160;        transform2 = LowerCholeskyTransform()</div><div class="line"><a name="l03985"></a><span class="lineno"> 3985</span>&#160;</div><div class="line"><a name="l03986"></a><span class="lineno"> 3986</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(transform0.event_dim, 0)</div><div class="line"><a name="l03987"></a><span class="lineno"> 3987</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(transform1.event_dim, 1)</div><div class="line"><a name="l03988"></a><span class="lineno"> 3988</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(transform2.event_dim, 2)</div><div class="line"><a name="l03989"></a><span class="lineno"> 3989</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(ComposeTransform([transform0, transform1]).event_dim, 1)</div><div class="line"><a name="l03990"></a><span class="lineno"> 3990</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(ComposeTransform([transform0, transform2]).event_dim, 2)</div><div class="line"><a name="l03991"></a><span class="lineno"> 3991</span>&#160;        self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(ComposeTransform([transform1, transform2]).event_dim, 2)</div><div class="line"><a name="l03992"></a><span class="lineno"> 3992</span>&#160;</div><div class="line"><a name="l03993"></a><span class="lineno"> 3993</span>&#160;    <span class="keyword">def </span>test_transformed_distribution_shapes(self):</div><div class="line"><a name="l03994"></a><span class="lineno"> 3994</span>&#160;        transform0 = ExpTransform()</div><div class="line"><a name="l03995"></a><span class="lineno"> 3995</span>&#160;        transform1 = SoftmaxTransform()</div><div class="line"><a name="l03996"></a><span class="lineno"> 3996</span>&#160;        transform2 = LowerCholeskyTransform()</div><div class="line"><a name="l03997"></a><span class="lineno"> 3997</span>&#160;        base_dist0 = Normal(torch.zeros(4, 4), torch.ones(4, 4))</div><div class="line"><a name="l03998"></a><span class="lineno"> 3998</span>&#160;        base_dist1 = Dirichlet(torch.ones(4, 4))</div><div class="line"><a name="l03999"></a><span class="lineno"> 3999</span>&#160;        base_dist2 = Normal(torch.zeros(3, 4, 4), torch.ones(3, 4, 4))</div><div class="line"><a name="l04000"></a><span class="lineno"> 4000</span>&#160;        examples = [</div><div class="line"><a name="l04001"></a><span class="lineno"> 4001</span>&#160;            ((4, 4), (), base_dist0),</div><div class="line"><a name="l04002"></a><span class="lineno"> 4002</span>&#160;            ((4,), (4,), base_dist1),</div><div class="line"><a name="l04003"></a><span class="lineno"> 4003</span>&#160;            ((4, 4), (), TransformedDistribution(base_dist0, [transform0])),</div><div class="line"><a name="l04004"></a><span class="lineno"> 4004</span>&#160;            ((4,), (4,), TransformedDistribution(base_dist0, [transform1])),</div><div class="line"><a name="l04005"></a><span class="lineno"> 4005</span>&#160;            ((4,), (4,), TransformedDistribution(base_dist0, [transform0, transform1])),</div><div class="line"><a name="l04006"></a><span class="lineno"> 4006</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist0, [transform0, transform2])),</div><div class="line"><a name="l04007"></a><span class="lineno"> 4007</span>&#160;            ((4,), (4,), TransformedDistribution(base_dist0, [transform1, transform0])),</div><div class="line"><a name="l04008"></a><span class="lineno"> 4008</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist0, [transform1, transform2])),</div><div class="line"><a name="l04009"></a><span class="lineno"> 4009</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist0, [transform2, transform0])),</div><div class="line"><a name="l04010"></a><span class="lineno"> 4010</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist0, [transform2, transform1])),</div><div class="line"><a name="l04011"></a><span class="lineno"> 4011</span>&#160;            ((4,), (4,), TransformedDistribution(base_dist1, [transform0])),</div><div class="line"><a name="l04012"></a><span class="lineno"> 4012</span>&#160;            ((4,), (4,), TransformedDistribution(base_dist1, [transform1])),</div><div class="line"><a name="l04013"></a><span class="lineno"> 4013</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist1, [transform2])),</div><div class="line"><a name="l04014"></a><span class="lineno"> 4014</span>&#160;            ((4,), (4,), TransformedDistribution(base_dist1, [transform0, transform1])),</div><div class="line"><a name="l04015"></a><span class="lineno"> 4015</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist1, [transform0, transform2])),</div><div class="line"><a name="l04016"></a><span class="lineno"> 4016</span>&#160;            ((4,), (4,), TransformedDistribution(base_dist1, [transform1, transform0])),</div><div class="line"><a name="l04017"></a><span class="lineno"> 4017</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist1, [transform1, transform2])),</div><div class="line"><a name="l04018"></a><span class="lineno"> 4018</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist1, [transform2, transform0])),</div><div class="line"><a name="l04019"></a><span class="lineno"> 4019</span>&#160;            ((), (4, 4), TransformedDistribution(base_dist1, [transform2, transform1])),</div><div class="line"><a name="l04020"></a><span class="lineno"> 4020</span>&#160;            ((3, 4, 4), (), base_dist2),</div><div class="line"><a name="l04021"></a><span class="lineno"> 4021</span>&#160;            ((3,), (4, 4), TransformedDistribution(base_dist2, [transform2])),</div><div class="line"><a name="l04022"></a><span class="lineno"> 4022</span>&#160;            ((3,), (4, 4), TransformedDistribution(base_dist2, [transform0, transform2])),</div><div class="line"><a name="l04023"></a><span class="lineno"> 4023</span>&#160;            ((3,), (4, 4), TransformedDistribution(base_dist2, [transform1, transform2])),</div><div class="line"><a name="l04024"></a><span class="lineno"> 4024</span>&#160;            ((3,), (4, 4), TransformedDistribution(base_dist2, [transform2, transform0])),</div><div class="line"><a name="l04025"></a><span class="lineno"> 4025</span>&#160;            ((3,), (4, 4), TransformedDistribution(base_dist2, [transform2, transform1])),</div><div class="line"><a name="l04026"></a><span class="lineno"> 4026</span>&#160;        ]</div><div class="line"><a name="l04027"></a><span class="lineno"> 4027</span>&#160;        <span class="keywordflow">for</span> batch_shape, event_shape, dist <span class="keywordflow">in</span> examples:</div><div class="line"><a name="l04028"></a><span class="lineno"> 4028</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.batch_shape, batch_shape)</div><div class="line"><a name="l04029"></a><span class="lineno"> 4029</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(dist.event_shape, event_shape)</div><div class="line"><a name="l04030"></a><span class="lineno"> 4030</span>&#160;            x = dist.rsample()</div><div class="line"><a name="l04031"></a><span class="lineno"> 4031</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04032"></a><span class="lineno"> 4032</span>&#160;                dist.log_prob(x)  <span class="comment"># this should not crash</span></div><div class="line"><a name="l04033"></a><span class="lineno"> 4033</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04034"></a><span class="lineno"> 4034</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04035"></a><span class="lineno"> 4035</span>&#160;</div><div class="line"><a name="l04036"></a><span class="lineno"> 4036</span>&#160;    <span class="keyword">def </span>test_jit_fwd(self):</div><div class="line"><a name="l04037"></a><span class="lineno"> 4037</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#acf329454d378ae6acfeb91b63a915c10">unique_transforms</a>:</div><div class="line"><a name="l04038"></a><span class="lineno"> 4038</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform).requires_grad_()</div><div class="line"><a name="l04039"></a><span class="lineno"> 4039</span>&#160;</div><div class="line"><a name="l04040"></a><span class="lineno"> 4040</span>&#160;            <span class="keyword">def </span>f(x):</div><div class="line"><a name="l04041"></a><span class="lineno"> 4041</span>&#160;                <span class="keywordflow">return</span> transform(x)</div><div class="line"><a name="l04042"></a><span class="lineno"> 4042</span>&#160;</div><div class="line"><a name="l04043"></a><span class="lineno"> 4043</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04044"></a><span class="lineno"> 4044</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, (x,))</div><div class="line"><a name="l04045"></a><span class="lineno"> 4045</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04046"></a><span class="lineno"> 4046</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04047"></a><span class="lineno"> 4047</span>&#160;</div><div class="line"><a name="l04048"></a><span class="lineno"> 4048</span>&#160;            <span class="comment"># check on different inputs</span></div><div class="line"><a name="l04049"></a><span class="lineno"> 4049</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform).requires_grad_()</div><div class="line"><a name="l04050"></a><span class="lineno"> 4050</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(f(x), traced_f(x))</div><div class="line"><a name="l04051"></a><span class="lineno"> 4051</span>&#160;</div><div class="line"><a name="l04052"></a><span class="lineno"> 4052</span>&#160;    <span class="keyword">def </span>test_jit_inv(self):</div><div class="line"><a name="l04053"></a><span class="lineno"> 4053</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#acf329454d378ae6acfeb91b63a915c10">unique_transforms</a>:</div><div class="line"><a name="l04054"></a><span class="lineno"> 4054</span>&#160;            y = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform.inv).requires_grad_()</div><div class="line"><a name="l04055"></a><span class="lineno"> 4055</span>&#160;</div><div class="line"><a name="l04056"></a><span class="lineno"> 4056</span>&#160;            <span class="keyword">def </span>f(y):</div><div class="line"><a name="l04057"></a><span class="lineno"> 4057</span>&#160;                <span class="keywordflow">return</span> transform.inv(y)</div><div class="line"><a name="l04058"></a><span class="lineno"> 4058</span>&#160;</div><div class="line"><a name="l04059"></a><span class="lineno"> 4059</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04060"></a><span class="lineno"> 4060</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, (y,))</div><div class="line"><a name="l04061"></a><span class="lineno"> 4061</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04062"></a><span class="lineno"> 4062</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04063"></a><span class="lineno"> 4063</span>&#160;</div><div class="line"><a name="l04064"></a><span class="lineno"> 4064</span>&#160;            <span class="comment"># check on different inputs</span></div><div class="line"><a name="l04065"></a><span class="lineno"> 4065</span>&#160;            y = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform.inv).requires_grad_()</div><div class="line"><a name="l04066"></a><span class="lineno"> 4066</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(f(y), traced_f(y))</div><div class="line"><a name="l04067"></a><span class="lineno"> 4067</span>&#160;</div><div class="line"><a name="l04068"></a><span class="lineno"> 4068</span>&#160;    <span class="keyword">def </span>test_jit_jacobian(self):</div><div class="line"><a name="l04069"></a><span class="lineno"> 4069</span>&#160;        <span class="keywordflow">for</span> transform <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#acf329454d378ae6acfeb91b63a915c10">unique_transforms</a>:</div><div class="line"><a name="l04070"></a><span class="lineno"> 4070</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform).requires_grad_()</div><div class="line"><a name="l04071"></a><span class="lineno"> 4071</span>&#160;</div><div class="line"><a name="l04072"></a><span class="lineno"> 4072</span>&#160;            <span class="keyword">def </span>f(x):</div><div class="line"><a name="l04073"></a><span class="lineno"> 4073</span>&#160;                y = transform(x)</div><div class="line"><a name="l04074"></a><span class="lineno"> 4074</span>&#160;                <span class="keywordflow">return</span> transform.log_abs_det_jacobian(x, y)</div><div class="line"><a name="l04075"></a><span class="lineno"> 4075</span>&#160;</div><div class="line"><a name="l04076"></a><span class="lineno"> 4076</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04077"></a><span class="lineno"> 4077</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, (x,))</div><div class="line"><a name="l04078"></a><span class="lineno"> 4078</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04079"></a><span class="lineno"> 4079</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04080"></a><span class="lineno"> 4080</span>&#160;</div><div class="line"><a name="l04081"></a><span class="lineno"> 4081</span>&#160;            <span class="comment"># check on different inputs</span></div><div class="line"><a name="l04082"></a><span class="lineno"> 4082</span>&#160;            x = self.<a class="code" href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">_generate_data</a>(transform).requires_grad_()</div><div class="line"><a name="l04083"></a><span class="lineno"> 4083</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(f(x), traced_f(x))</div><div class="line"><a name="l04084"></a><span class="lineno"> 4084</span>&#160;</div><div class="line"><a name="l04085"></a><span class="lineno"> 4085</span>&#160;</div><div class="line"><a name="l04086"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_constraint_registry.html"> 4086</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_constraint_registry.html">TestConstraintRegistry</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l04087"></a><span class="lineno"> 4087</span>&#160;    <span class="keyword">def </span>get_constraints(self, is_cuda=False):</div><div class="line"><a name="l04088"></a><span class="lineno"> 4088</span>&#160;        tensor = torch.cuda.DoubleTensor <span class="keywordflow">if</span> is_cuda <span class="keywordflow">else</span> torch.DoubleTensor</div><div class="line"><a name="l04089"></a><span class="lineno"> 4089</span>&#160;        <span class="keywordflow">return</span> [</div><div class="line"><a name="l04090"></a><span class="lineno"> 4090</span>&#160;            constraints.real,</div><div class="line"><a name="l04091"></a><span class="lineno"> 4091</span>&#160;            constraints.positive,</div><div class="line"><a name="l04092"></a><span class="lineno"> 4092</span>&#160;            constraints.greater_than(tensor([-10., -2, 0, 2, 10])),</div><div class="line"><a name="l04093"></a><span class="lineno"> 4093</span>&#160;            constraints.greater_than(0),</div><div class="line"><a name="l04094"></a><span class="lineno"> 4094</span>&#160;            constraints.greater_than(2),</div><div class="line"><a name="l04095"></a><span class="lineno"> 4095</span>&#160;            constraints.greater_than(-2),</div><div class="line"><a name="l04096"></a><span class="lineno"> 4096</span>&#160;            constraints.greater_than_eq(0),</div><div class="line"><a name="l04097"></a><span class="lineno"> 4097</span>&#160;            constraints.greater_than_eq(2),</div><div class="line"><a name="l04098"></a><span class="lineno"> 4098</span>&#160;            constraints.greater_than_eq(-2),</div><div class="line"><a name="l04099"></a><span class="lineno"> 4099</span>&#160;            constraints.less_than(tensor([-10., -2, 0, 2, 10])),</div><div class="line"><a name="l04100"></a><span class="lineno"> 4100</span>&#160;            constraints.less_than(0),</div><div class="line"><a name="l04101"></a><span class="lineno"> 4101</span>&#160;            constraints.less_than(2),</div><div class="line"><a name="l04102"></a><span class="lineno"> 4102</span>&#160;            constraints.less_than(-2),</div><div class="line"><a name="l04103"></a><span class="lineno"> 4103</span>&#160;            constraints.unit_interval,</div><div class="line"><a name="l04104"></a><span class="lineno"> 4104</span>&#160;            constraints.interval(tensor([-4., -2, 0, 2, 4]),</div><div class="line"><a name="l04105"></a><span class="lineno"> 4105</span>&#160;                                 tensor([-3., 3, 1, 5, 5])),</div><div class="line"><a name="l04106"></a><span class="lineno"> 4106</span>&#160;            constraints.interval(-2, -1),</div><div class="line"><a name="l04107"></a><span class="lineno"> 4107</span>&#160;            constraints.interval(1, 2),</div><div class="line"><a name="l04108"></a><span class="lineno"> 4108</span>&#160;            constraints.half_open_interval(tensor([-4., -2, 0, 2, 4]),</div><div class="line"><a name="l04109"></a><span class="lineno"> 4109</span>&#160;                                           tensor([-3., 3, 1, 5, 5])),</div><div class="line"><a name="l04110"></a><span class="lineno"> 4110</span>&#160;            constraints.half_open_interval(-2, -1),</div><div class="line"><a name="l04111"></a><span class="lineno"> 4111</span>&#160;            constraints.half_open_interval(1, 2),</div><div class="line"><a name="l04112"></a><span class="lineno"> 4112</span>&#160;            constraints.simplex,</div><div class="line"><a name="l04113"></a><span class="lineno"> 4113</span>&#160;            constraints.lower_cholesky,</div><div class="line"><a name="l04114"></a><span class="lineno"> 4114</span>&#160;        ]</div><div class="line"><a name="l04115"></a><span class="lineno"> 4115</span>&#160;</div><div class="line"><a name="l04116"></a><span class="lineno"> 4116</span>&#160;    <span class="keyword">def </span>test_biject_to(self):</div><div class="line"><a name="l04117"></a><span class="lineno"> 4117</span>&#160;        <span class="keywordflow">for</span> constraint <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_constraint_registry.html#a15277412888f9d4921348a8ed1ac1041">get_constraints</a>():</div><div class="line"><a name="l04118"></a><span class="lineno"> 4118</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04119"></a><span class="lineno"> 4119</span>&#160;                t = biject_to(constraint)</div><div class="line"><a name="l04120"></a><span class="lineno"> 4120</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04121"></a><span class="lineno"> 4121</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04122"></a><span class="lineno"> 4122</span>&#160;            self.assertTrue(t.bijective, <span class="stringliteral">&quot;biject_to({}) is not bijective&quot;</span>.format(constraint))</div><div class="line"><a name="l04123"></a><span class="lineno"> 4123</span>&#160;            x = torch.randn(5, 5)</div><div class="line"><a name="l04124"></a><span class="lineno"> 4124</span>&#160;            y = t(x)</div><div class="line"><a name="l04125"></a><span class="lineno"> 4125</span>&#160;            self.assertTrue(constraint.check(y).all(), <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l04126"></a><span class="lineno"> 4126</span>&#160;                <span class="stringliteral">&quot;Failed to biject_to({})&quot;</span>.format(constraint),</div><div class="line"><a name="l04127"></a><span class="lineno"> 4127</span>&#160;                <span class="stringliteral">&quot;x = {}&quot;</span>.format(x),</div><div class="line"><a name="l04128"></a><span class="lineno"> 4128</span>&#160;                <span class="stringliteral">&quot;biject_to(...)(x) = {}&quot;</span>.format(y),</div><div class="line"><a name="l04129"></a><span class="lineno"> 4129</span>&#160;            ]))</div><div class="line"><a name="l04130"></a><span class="lineno"> 4130</span>&#160;            x2 = t.inv(y)</div><div class="line"><a name="l04131"></a><span class="lineno"> 4131</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(x, x2, message=<span class="stringliteral">&quot;Error in biject_to({}) inverse&quot;</span>.format(constraint))</div><div class="line"><a name="l04132"></a><span class="lineno"> 4132</span>&#160;</div><div class="line"><a name="l04133"></a><span class="lineno"> 4133</span>&#160;            j = t.log_abs_det_jacobian(x, y)</div><div class="line"><a name="l04134"></a><span class="lineno"> 4134</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(j.shape, x.shape[:x.dim() - t.event_dim])</div><div class="line"><a name="l04135"></a><span class="lineno"> 4135</span>&#160;</div><div class="line"><a name="l04136"></a><span class="lineno"> 4136</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_CUDA, <span class="stringliteral">&quot;CUDA not found&quot;</span>)</div><div class="line"><a name="l04137"></a><span class="lineno"> 4137</span>&#160;    <span class="keyword">def </span>test_biject_to_cuda(self):</div><div class="line"><a name="l04138"></a><span class="lineno"> 4138</span>&#160;        <span class="keywordflow">for</span> constraint <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_constraint_registry.html#a15277412888f9d4921348a8ed1ac1041">get_constraints</a>(is_cuda=<span class="keyword">True</span>):</div><div class="line"><a name="l04139"></a><span class="lineno"> 4139</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04140"></a><span class="lineno"> 4140</span>&#160;                t = biject_to(constraint)</div><div class="line"><a name="l04141"></a><span class="lineno"> 4141</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04142"></a><span class="lineno"> 4142</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04143"></a><span class="lineno"> 4143</span>&#160;            self.assertTrue(t.bijective, <span class="stringliteral">&quot;biject_to({}) is not bijective&quot;</span>.format(constraint))</div><div class="line"><a name="l04144"></a><span class="lineno"> 4144</span>&#160;            <span class="comment"># x = torch.randn(5, 5, device=&quot;cuda&quot;)</span></div><div class="line"><a name="l04145"></a><span class="lineno"> 4145</span>&#160;            x = torch.randn(5, 5).cuda()</div><div class="line"><a name="l04146"></a><span class="lineno"> 4146</span>&#160;            y = t(x)</div><div class="line"><a name="l04147"></a><span class="lineno"> 4147</span>&#160;            self.assertTrue(constraint.check(y).all(), <span class="stringliteral">&#39;\n&#39;</span>.join([</div><div class="line"><a name="l04148"></a><span class="lineno"> 4148</span>&#160;                <span class="stringliteral">&quot;Failed to biject_to({})&quot;</span>.format(constraint),</div><div class="line"><a name="l04149"></a><span class="lineno"> 4149</span>&#160;                <span class="stringliteral">&quot;x = {}&quot;</span>.format(x),</div><div class="line"><a name="l04150"></a><span class="lineno"> 4150</span>&#160;                <span class="stringliteral">&quot;biject_to(...)(x) = {}&quot;</span>.format(y),</div><div class="line"><a name="l04151"></a><span class="lineno"> 4151</span>&#160;            ]))</div><div class="line"><a name="l04152"></a><span class="lineno"> 4152</span>&#160;            x2 = t.inv(y)</div><div class="line"><a name="l04153"></a><span class="lineno"> 4153</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(x, x2, message=<span class="stringliteral">&quot;Error in biject_to({}) inverse&quot;</span>.format(constraint))</div><div class="line"><a name="l04154"></a><span class="lineno"> 4154</span>&#160;</div><div class="line"><a name="l04155"></a><span class="lineno"> 4155</span>&#160;            j = t.log_abs_det_jacobian(x, y)</div><div class="line"><a name="l04156"></a><span class="lineno"> 4156</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(j.shape, x.shape[:x.dim() - t.event_dim])</div><div class="line"><a name="l04157"></a><span class="lineno"> 4157</span>&#160;</div><div class="line"><a name="l04158"></a><span class="lineno"> 4158</span>&#160;    <span class="keyword">def </span>test_transform_to(self):</div><div class="line"><a name="l04159"></a><span class="lineno"> 4159</span>&#160;        <span class="keywordflow">for</span> constraint <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_constraint_registry.html#a15277412888f9d4921348a8ed1ac1041">get_constraints</a>():</div><div class="line"><a name="l04160"></a><span class="lineno"> 4160</span>&#160;            t = transform_to(constraint)</div><div class="line"><a name="l04161"></a><span class="lineno"> 4161</span>&#160;            x = torch.randn(5, 5)</div><div class="line"><a name="l04162"></a><span class="lineno"> 4162</span>&#160;            y = t(x)</div><div class="line"><a name="l04163"></a><span class="lineno"> 4163</span>&#160;            self.assertTrue(constraint.check(y).all(), <span class="stringliteral">&quot;Failed to transform_to({})&quot;</span>.format(constraint))</div><div class="line"><a name="l04164"></a><span class="lineno"> 4164</span>&#160;            x2 = t.inv(y)</div><div class="line"><a name="l04165"></a><span class="lineno"> 4165</span>&#160;            y2 = t(x2)</div><div class="line"><a name="l04166"></a><span class="lineno"> 4166</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(y, y2, message=<span class="stringliteral">&quot;Error in transform_to({}) pseudoinverse&quot;</span>.format(constraint))</div><div class="line"><a name="l04167"></a><span class="lineno"> 4167</span>&#160;</div><div class="line"><a name="l04168"></a><span class="lineno"> 4168</span>&#160;    @unittest.skipIf(<span class="keywordflow">not</span> TEST_CUDA, <span class="stringliteral">&quot;CUDA not found&quot;</span>)</div><div class="line"><a name="l04169"></a><span class="lineno"> 4169</span>&#160;    <span class="keyword">def </span>test_transform_to_cuda(self):</div><div class="line"><a name="l04170"></a><span class="lineno"> 4170</span>&#160;        <span class="keywordflow">for</span> constraint <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_constraint_registry.html#a15277412888f9d4921348a8ed1ac1041">get_constraints</a>(is_cuda=<span class="keyword">True</span>):</div><div class="line"><a name="l04171"></a><span class="lineno"> 4171</span>&#160;            t = transform_to(constraint)</div><div class="line"><a name="l04172"></a><span class="lineno"> 4172</span>&#160;            <span class="comment"># x = torch.randn(5, 5, device=&quot;cuda&quot;)</span></div><div class="line"><a name="l04173"></a><span class="lineno"> 4173</span>&#160;            x = torch.randn(5, 5).cuda()</div><div class="line"><a name="l04174"></a><span class="lineno"> 4174</span>&#160;            y = t(x)</div><div class="line"><a name="l04175"></a><span class="lineno"> 4175</span>&#160;            self.assertTrue(constraint.check(y).all(), <span class="stringliteral">&quot;Failed to transform_to({})&quot;</span>.format(constraint))</div><div class="line"><a name="l04176"></a><span class="lineno"> 4176</span>&#160;            x2 = t.inv(y)</div><div class="line"><a name="l04177"></a><span class="lineno"> 4177</span>&#160;            y2 = t(x2)</div><div class="line"><a name="l04178"></a><span class="lineno"> 4178</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(y, y2, message=<span class="stringliteral">&quot;Error in transform_to({}) pseudoinverse&quot;</span>.format(constraint))</div><div class="line"><a name="l04179"></a><span class="lineno"> 4179</span>&#160;</div><div class="line"><a name="l04180"></a><span class="lineno"> 4180</span>&#160;</div><div class="line"><a name="l04181"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_validation.html"> 4181</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_validation.html">TestValidation</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l04182"></a><span class="lineno"> 4182</span>&#160;    <span class="keyword">def </span>setUp(self):</div><div class="line"><a name="l04183"></a><span class="lineno"> 4183</span>&#160;        super(TestCase, self).setUp()</div><div class="line"><a name="l04184"></a><span class="lineno"> 4184</span>&#160;        Distribution.set_default_validate_args(<span class="keyword">True</span>)</div><div class="line"><a name="l04185"></a><span class="lineno"> 4185</span>&#160;</div><div class="line"><a name="l04186"></a><span class="lineno"> 4186</span>&#160;    <span class="keyword">def </span>test_valid(self):</div><div class="line"><a name="l04187"></a><span class="lineno"> 4187</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l04188"></a><span class="lineno"> 4188</span>&#160;            <span class="keywordflow">for</span> param <span class="keywordflow">in</span> params:</div><div class="line"><a name="l04189"></a><span class="lineno"> 4189</span>&#160;                Dist(validate_args=<span class="keyword">True</span>, **param)</div><div class="line"><a name="l04190"></a><span class="lineno"> 4190</span>&#160;</div><div class="line"><a name="l04191"></a><span class="lineno"> 4191</span>&#160;    @unittest.skipIf(TEST_WITH_UBSAN, <span class="stringliteral">&quot;division-by-zero error with UBSAN&quot;</span>)</div><div class="line"><a name="l04192"></a><span class="lineno"> 4192</span>&#160;    <span class="keyword">def </span>test_invalid(self):</div><div class="line"><a name="l04193"></a><span class="lineno"> 4193</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> BAD_EXAMPLES:</div><div class="line"><a name="l04194"></a><span class="lineno"> 4194</span>&#160;            <span class="keywordflow">for</span> i, param <span class="keywordflow">in</span> enumerate(params):</div><div class="line"><a name="l04195"></a><span class="lineno"> 4195</span>&#160;                <span class="keywordflow">try</span>:</div><div class="line"><a name="l04196"></a><span class="lineno"> 4196</span>&#160;                    with self.assertRaises(ValueError):</div><div class="line"><a name="l04197"></a><span class="lineno"> 4197</span>&#160;                        Dist(validate_args=<span class="keyword">True</span>, **param)</div><div class="line"><a name="l04198"></a><span class="lineno"> 4198</span>&#160;                <span class="keywordflow">except</span> AssertionError:</div><div class="line"><a name="l04199"></a><span class="lineno"> 4199</span>&#160;                    fail_string = <span class="stringliteral">&#39;ValueError not raised for {} example {}/{}&#39;</span></div><div class="line"><a name="l04200"></a><span class="lineno"> 4200</span>&#160;                    <span class="keywordflow">raise</span> AssertionError(fail_string.format(Dist.__name__, i + 1, len(params)))</div><div class="line"><a name="l04201"></a><span class="lineno"> 4201</span>&#160;</div><div class="line"><a name="l04202"></a><span class="lineno"> 4202</span>&#160;    <span class="keyword">def </span>tearDown(self):</div><div class="line"><a name="l04203"></a><span class="lineno"> 4203</span>&#160;        super(TestValidation, self).tearDown()</div><div class="line"><a name="l04204"></a><span class="lineno"> 4204</span>&#160;        Distribution.set_default_validate_args(<span class="keyword">False</span>)</div><div class="line"><a name="l04205"></a><span class="lineno"> 4205</span>&#160;</div><div class="line"><a name="l04206"></a><span class="lineno"> 4206</span>&#160;</div><div class="line"><a name="l04207"></a><span class="lineno"><a class="line" href="classtest__distributions_1_1_test_jit.html"> 4207</a></span>&#160;<span class="keyword">class </span><a class="code" href="classtest__distributions_1_1_test_jit.html">TestJit</a>(<a class="code" href="classcommon__utils_1_1_test_case.html">TestCase</a>):</div><div class="line"><a name="l04208"></a><span class="lineno"> 4208</span>&#160;    <span class="keyword">def </span>_examples(self):</div><div class="line"><a name="l04209"></a><span class="lineno"> 4209</span>&#160;        <span class="keywordflow">for</span> Dist, params <span class="keywordflow">in</span> EXAMPLES:</div><div class="line"><a name="l04210"></a><span class="lineno"> 4210</span>&#160;            <span class="keywordflow">for</span> param <span class="keywordflow">in</span> params:</div><div class="line"><a name="l04211"></a><span class="lineno"> 4211</span>&#160;                keys = param.keys()</div><div class="line"><a name="l04212"></a><span class="lineno"> 4212</span>&#160;                values = tuple(param[key] <span class="keywordflow">for</span> key <span class="keywordflow">in</span> keys)</div><div class="line"><a name="l04213"></a><span class="lineno"> 4213</span>&#160;                <span class="keywordflow">if</span> <span class="keywordflow">not</span> all(isinstance(x, torch.Tensor) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> values):</div><div class="line"><a name="l04214"></a><span class="lineno"> 4214</span>&#160;                    <span class="keywordflow">continue</span></div><div class="line"><a name="l04215"></a><span class="lineno"> 4215</span>&#160;                sample = Dist(**param).sample()</div><div class="line"><a name="l04216"></a><span class="lineno"> 4216</span>&#160;                <span class="keywordflow">yield</span> Dist, keys, values, sample</div><div class="line"><a name="l04217"></a><span class="lineno"> 4217</span>&#160;</div><div class="line"><a name="l04218"></a><span class="lineno"> 4218</span>&#160;    <span class="keyword">def </span>_perturb_tensor(self, value, constraint):</div><div class="line"><a name="l04219"></a><span class="lineno"> 4219</span>&#160;        <span class="keywordflow">if</span> isinstance(constraint, constraints._IntegerGreaterThan):</div><div class="line"><a name="l04220"></a><span class="lineno"> 4220</span>&#160;            <span class="keywordflow">return</span> value + 1</div><div class="line"><a name="l04221"></a><span class="lineno"> 4221</span>&#160;        <span class="keywordflow">if</span> isinstance(constraint, constraints._PositiveDefinite):</div><div class="line"><a name="l04222"></a><span class="lineno"> 4222</span>&#160;            <span class="keywordflow">return</span> value + torch.eye(value.shape[-1])</div><div class="line"><a name="l04223"></a><span class="lineno"> 4223</span>&#160;        <span class="keywordflow">if</span> value.dtype <span class="keywordflow">in</span> [torch.float, torch.double]:</div><div class="line"><a name="l04224"></a><span class="lineno"> 4224</span>&#160;            transform = transform_to(constraint)</div><div class="line"><a name="l04225"></a><span class="lineno"> 4225</span>&#160;            delta = value.new(value.shape).normal_()</div><div class="line"><a name="l04226"></a><span class="lineno"> 4226</span>&#160;            <span class="keywordflow">return</span> transform(transform.inv(value) + delta)</div><div class="line"><a name="l04227"></a><span class="lineno"> 4227</span>&#160;        <span class="keywordflow">if</span> value.dtype == torch.long:</div><div class="line"><a name="l04228"></a><span class="lineno"> 4228</span>&#160;            result = value.clone()</div><div class="line"><a name="l04229"></a><span class="lineno"> 4229</span>&#160;            result[value == 0] = 1</div><div class="line"><a name="l04230"></a><span class="lineno"> 4230</span>&#160;            result[value == 1] = 0</div><div class="line"><a name="l04231"></a><span class="lineno"> 4231</span>&#160;            <span class="keywordflow">return</span> result</div><div class="line"><a name="l04232"></a><span class="lineno"> 4232</span>&#160;        <span class="keywordflow">raise</span> NotImplementedError</div><div class="line"><a name="l04233"></a><span class="lineno"> 4233</span>&#160;</div><div class="line"><a name="l04234"></a><span class="lineno"> 4234</span>&#160;    <span class="keyword">def </span>_perturb(self, Dist, keys, values, sample):</div><div class="line"><a name="l04235"></a><span class="lineno"> 4235</span>&#160;        with torch.no_grad():</div><div class="line"><a name="l04236"></a><span class="lineno"> 4236</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">is</span> Uniform:</div><div class="line"><a name="l04237"></a><span class="lineno"> 4237</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04238"></a><span class="lineno"> 4238</span>&#160;                param[<span class="stringliteral">&#39;low&#39;</span>] = param[<span class="stringliteral">&#39;low&#39;</span>] - torch.rand(param[<span class="stringliteral">&#39;low&#39;</span>].shape)</div><div class="line"><a name="l04239"></a><span class="lineno"> 4239</span>&#160;                param[<span class="stringliteral">&#39;high&#39;</span>] = param[<span class="stringliteral">&#39;high&#39;</span>] + torch.rand(param[<span class="stringliteral">&#39;high&#39;</span>].shape)</div><div class="line"><a name="l04240"></a><span class="lineno"> 4240</span>&#160;                values = [param[key] <span class="keywordflow">for</span> key <span class="keywordflow">in</span> keys]</div><div class="line"><a name="l04241"></a><span class="lineno"> 4241</span>&#160;            <span class="keywordflow">else</span>:</div><div class="line"><a name="l04242"></a><span class="lineno"> 4242</span>&#160;                values = [self.<a class="code" href="classtest__distributions_1_1_test_jit.html#a059f35ea60496079ef98bf736e8aa710">_perturb_tensor</a>(value, Dist.arg_constraints.get(key, constraints.real))</div><div class="line"><a name="l04243"></a><span class="lineno"> 4243</span>&#160;                          <span class="keywordflow">for</span> key, value <span class="keywordflow">in</span> zip(keys, values)]</div><div class="line"><a name="l04244"></a><span class="lineno"> 4244</span>&#160;            param = dict(zip(keys, values))</div><div class="line"><a name="l04245"></a><span class="lineno"> 4245</span>&#160;            sample = Dist(**param).sample()</div><div class="line"><a name="l04246"></a><span class="lineno"> 4246</span>&#160;            <span class="keywordflow">return</span> values, sample</div><div class="line"><a name="l04247"></a><span class="lineno"> 4247</span>&#160;</div><div class="line"><a name="l04248"></a><span class="lineno"> 4248</span>&#160;    <span class="keyword">def </span>test_sample(self):</div><div class="line"><a name="l04249"></a><span class="lineno"> 4249</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04250"></a><span class="lineno"> 4250</span>&#160;</div><div class="line"><a name="l04251"></a><span class="lineno"> 4251</span>&#160;            <span class="keyword">def </span>f(*values):</div><div class="line"><a name="l04252"></a><span class="lineno"> 4252</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04253"></a><span class="lineno"> 4253</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04254"></a><span class="lineno"> 4254</span>&#160;                <span class="keywordflow">return</span> dist.sample()</div><div class="line"><a name="l04255"></a><span class="lineno"> 4255</span>&#160;</div><div class="line"><a name="l04256"></a><span class="lineno"> 4256</span>&#160;            traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, values, check_trace=<span class="keyword">False</span>)</div><div class="line"><a name="l04257"></a><span class="lineno"> 4257</span>&#160;</div><div class="line"><a name="l04258"></a><span class="lineno"> 4258</span>&#160;            <span class="comment"># FIXME Schema not found for node</span></div><div class="line"><a name="l04259"></a><span class="lineno"> 4259</span>&#160;            xfail = [</div><div class="line"><a name="l04260"></a><span class="lineno"> 4260</span>&#160;                Cauchy,  <span class="comment"># aten::cauchy(Double(2,1), float, float, Generator)</span></div><div class="line"><a name="l04261"></a><span class="lineno"> 4261</span>&#160;                HalfCauchy,  <span class="comment"># aten::cauchy(Double(2, 1), float, float, Generator)</span></div><div class="line"><a name="l04262"></a><span class="lineno"> 4262</span>&#160;            ]</div><div class="line"><a name="l04263"></a><span class="lineno"> 4263</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">in</span> xfail:</div><div class="line"><a name="l04264"></a><span class="lineno"> 4264</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04265"></a><span class="lineno"> 4265</span>&#160;</div><div class="line"><a name="l04266"></a><span class="lineno"> 4266</span>&#160;            with <a class="code" href="random_8py.html#a9d768e347a5358db5b556d88e569850d">torch.random.fork_rng</a>():</div><div class="line"><a name="l04267"></a><span class="lineno"> 4267</span>&#160;                sample = f(*values)</div><div class="line"><a name="l04268"></a><span class="lineno"> 4268</span>&#160;            traced_sample = traced_f(*values)</div><div class="line"><a name="l04269"></a><span class="lineno"> 4269</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(sample, traced_sample)</div><div class="line"><a name="l04270"></a><span class="lineno"> 4270</span>&#160;</div><div class="line"><a name="l04271"></a><span class="lineno"> 4271</span>&#160;            <span class="comment"># FIXME no nondeterministic nodes found in trace</span></div><div class="line"><a name="l04272"></a><span class="lineno"> 4272</span>&#160;            xfail = [Beta, Dirichlet]</div><div class="line"><a name="l04273"></a><span class="lineno"> 4273</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">not</span> <span class="keywordflow">in</span> xfail:</div><div class="line"><a name="l04274"></a><span class="lineno"> 4274</span>&#160;                self.assertTrue(any(n.isNondeterministic() <span class="keywordflow">for</span> n <span class="keywordflow">in</span> traced_f.graph.nodes()))</div><div class="line"><a name="l04275"></a><span class="lineno"> 4275</span>&#160;</div><div class="line"><a name="l04276"></a><span class="lineno"> 4276</span>&#160;    <span class="keyword">def </span>test_rsample(self):</div><div class="line"><a name="l04277"></a><span class="lineno"> 4277</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04278"></a><span class="lineno"> 4278</span>&#160;            <span class="keywordflow">if</span> <span class="keywordflow">not</span> Dist.has_rsample:</div><div class="line"><a name="l04279"></a><span class="lineno"> 4279</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04280"></a><span class="lineno"> 4280</span>&#160;</div><div class="line"><a name="l04281"></a><span class="lineno"> 4281</span>&#160;            <span class="keyword">def </span>f(*values):</div><div class="line"><a name="l04282"></a><span class="lineno"> 4282</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04283"></a><span class="lineno"> 4283</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04284"></a><span class="lineno"> 4284</span>&#160;                <span class="keywordflow">return</span> dist.rsample()</div><div class="line"><a name="l04285"></a><span class="lineno"> 4285</span>&#160;</div><div class="line"><a name="l04286"></a><span class="lineno"> 4286</span>&#160;            traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, values, check_trace=<span class="keyword">False</span>)</div><div class="line"><a name="l04287"></a><span class="lineno"> 4287</span>&#160;</div><div class="line"><a name="l04288"></a><span class="lineno"> 4288</span>&#160;            <span class="comment"># FIXME Schema not found for node</span></div><div class="line"><a name="l04289"></a><span class="lineno"> 4289</span>&#160;            xfail = [</div><div class="line"><a name="l04290"></a><span class="lineno"> 4290</span>&#160;                Cauchy,  <span class="comment"># aten::cauchy(Double(2,1), float, float, Generator)</span></div><div class="line"><a name="l04291"></a><span class="lineno"> 4291</span>&#160;                HalfCauchy,  <span class="comment"># aten::cauchy(Double(2, 1), float, float, Generator)</span></div><div class="line"><a name="l04292"></a><span class="lineno"> 4292</span>&#160;            ]</div><div class="line"><a name="l04293"></a><span class="lineno"> 4293</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">in</span> xfail:</div><div class="line"><a name="l04294"></a><span class="lineno"> 4294</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04295"></a><span class="lineno"> 4295</span>&#160;</div><div class="line"><a name="l04296"></a><span class="lineno"> 4296</span>&#160;            with <a class="code" href="random_8py.html#a9d768e347a5358db5b556d88e569850d">torch.random.fork_rng</a>():</div><div class="line"><a name="l04297"></a><span class="lineno"> 4297</span>&#160;                sample = f(*values)</div><div class="line"><a name="l04298"></a><span class="lineno"> 4298</span>&#160;            traced_sample = traced_f(*values)</div><div class="line"><a name="l04299"></a><span class="lineno"> 4299</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(sample, traced_sample)</div><div class="line"><a name="l04300"></a><span class="lineno"> 4300</span>&#160;</div><div class="line"><a name="l04301"></a><span class="lineno"> 4301</span>&#160;            <span class="comment"># FIXME no nondeterministic nodes found in trace</span></div><div class="line"><a name="l04302"></a><span class="lineno"> 4302</span>&#160;            xfail = [Beta, Dirichlet]</div><div class="line"><a name="l04303"></a><span class="lineno"> 4303</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">not</span> <span class="keywordflow">in</span> xfail:</div><div class="line"><a name="l04304"></a><span class="lineno"> 4304</span>&#160;                self.assertTrue(any(n.isNondeterministic() <span class="keywordflow">for</span> n <span class="keywordflow">in</span> traced_f.graph.nodes()))</div><div class="line"><a name="l04305"></a><span class="lineno"> 4305</span>&#160;</div><div class="line"><a name="l04306"></a><span class="lineno"> 4306</span>&#160;    <span class="keyword">def </span>test_log_prob(self):</div><div class="line"><a name="l04307"></a><span class="lineno"> 4307</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04308"></a><span class="lineno"> 4308</span>&#160;            <span class="comment"># FIXME traced functions produce incorrect results</span></div><div class="line"><a name="l04309"></a><span class="lineno"> 4309</span>&#160;            xfail = [LowRankMultivariateNormal, MultivariateNormal]</div><div class="line"><a name="l04310"></a><span class="lineno"> 4310</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">in</span> xfail:</div><div class="line"><a name="l04311"></a><span class="lineno"> 4311</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04312"></a><span class="lineno"> 4312</span>&#160;</div><div class="line"><a name="l04313"></a><span class="lineno"> 4313</span>&#160;            <span class="keyword">def </span>f(sample, *values):</div><div class="line"><a name="l04314"></a><span class="lineno"> 4314</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04315"></a><span class="lineno"> 4315</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04316"></a><span class="lineno"> 4316</span>&#160;                <span class="keywordflow">return</span> dist.log_prob(sample)</div><div class="line"><a name="l04317"></a><span class="lineno"> 4317</span>&#160;</div><div class="line"><a name="l04318"></a><span class="lineno"> 4318</span>&#160;            traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, (sample,) + values)</div><div class="line"><a name="l04319"></a><span class="lineno"> 4319</span>&#160;</div><div class="line"><a name="l04320"></a><span class="lineno"> 4320</span>&#160;            <span class="comment"># check on different data</span></div><div class="line"><a name="l04321"></a><span class="lineno"> 4321</span>&#160;            values, sample = self.<a class="code" href="classtest__distributions_1_1_test_jit.html#aa1882d0ba6611d7217688a5d114d2c28">_perturb</a>(Dist, keys, values, sample)</div><div class="line"><a name="l04322"></a><span class="lineno"> 4322</span>&#160;            expected = f(sample, *values)</div><div class="line"><a name="l04323"></a><span class="lineno"> 4323</span>&#160;            actual = traced_f(sample, *values)</div><div class="line"><a name="l04324"></a><span class="lineno"> 4324</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected, actual,</div><div class="line"><a name="l04325"></a><span class="lineno"> 4325</span>&#160;                             message=<span class="stringliteral">&#39;{}\nExpected:\n{}\nActual:\n{}&#39;</span>.format(Dist.__name__, expected, actual))</div><div class="line"><a name="l04326"></a><span class="lineno"> 4326</span>&#160;</div><div class="line"><a name="l04327"></a><span class="lineno"> 4327</span>&#160;    <span class="keyword">def </span>test_enumerate_support(self):</div><div class="line"><a name="l04328"></a><span class="lineno"> 4328</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04329"></a><span class="lineno"> 4329</span>&#160;            <span class="comment"># FIXME traced functions produce incorrect results</span></div><div class="line"><a name="l04330"></a><span class="lineno"> 4330</span>&#160;            xfail = [Binomial]</div><div class="line"><a name="l04331"></a><span class="lineno"> 4331</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">in</span> xfail:</div><div class="line"><a name="l04332"></a><span class="lineno"> 4332</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04333"></a><span class="lineno"> 4333</span>&#160;</div><div class="line"><a name="l04334"></a><span class="lineno"> 4334</span>&#160;            <span class="keyword">def </span>f(*values):</div><div class="line"><a name="l04335"></a><span class="lineno"> 4335</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04336"></a><span class="lineno"> 4336</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04337"></a><span class="lineno"> 4337</span>&#160;                <span class="keywordflow">return</span> dist.enumerate_support()</div><div class="line"><a name="l04338"></a><span class="lineno"> 4338</span>&#160;</div><div class="line"><a name="l04339"></a><span class="lineno"> 4339</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04340"></a><span class="lineno"> 4340</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, values)</div><div class="line"><a name="l04341"></a><span class="lineno"> 4341</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04342"></a><span class="lineno"> 4342</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04343"></a><span class="lineno"> 4343</span>&#160;</div><div class="line"><a name="l04344"></a><span class="lineno"> 4344</span>&#160;            <span class="comment"># check on different data</span></div><div class="line"><a name="l04345"></a><span class="lineno"> 4345</span>&#160;            values, sample = self.<a class="code" href="classtest__distributions_1_1_test_jit.html#aa1882d0ba6611d7217688a5d114d2c28">_perturb</a>(Dist, keys, values, sample)</div><div class="line"><a name="l04346"></a><span class="lineno"> 4346</span>&#160;            expected = f(*values)</div><div class="line"><a name="l04347"></a><span class="lineno"> 4347</span>&#160;            actual = traced_f(*values)</div><div class="line"><a name="l04348"></a><span class="lineno"> 4348</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected, actual,</div><div class="line"><a name="l04349"></a><span class="lineno"> 4349</span>&#160;                             message=<span class="stringliteral">&#39;{}\nExpected:\n{}\nActual:\n{}&#39;</span>.format(Dist.__name__, expected, actual))</div><div class="line"><a name="l04350"></a><span class="lineno"> 4350</span>&#160;</div><div class="line"><a name="l04351"></a><span class="lineno"> 4351</span>&#160;    <span class="keyword">def </span>test_mean(self):</div><div class="line"><a name="l04352"></a><span class="lineno"> 4352</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04353"></a><span class="lineno"> 4353</span>&#160;</div><div class="line"><a name="l04354"></a><span class="lineno"> 4354</span>&#160;            <span class="keyword">def </span>f(*values):</div><div class="line"><a name="l04355"></a><span class="lineno"> 4355</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04356"></a><span class="lineno"> 4356</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04357"></a><span class="lineno"> 4357</span>&#160;                <span class="keywordflow">return</span> dist.mean</div><div class="line"><a name="l04358"></a><span class="lineno"> 4358</span>&#160;</div><div class="line"><a name="l04359"></a><span class="lineno"> 4359</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04360"></a><span class="lineno"> 4360</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, values)</div><div class="line"><a name="l04361"></a><span class="lineno"> 4361</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04362"></a><span class="lineno"> 4362</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04363"></a><span class="lineno"> 4363</span>&#160;</div><div class="line"><a name="l04364"></a><span class="lineno"> 4364</span>&#160;            <span class="comment"># check on different data</span></div><div class="line"><a name="l04365"></a><span class="lineno"> 4365</span>&#160;            values, sample = self.<a class="code" href="classtest__distributions_1_1_test_jit.html#aa1882d0ba6611d7217688a5d114d2c28">_perturb</a>(Dist, keys, values, sample)</div><div class="line"><a name="l04366"></a><span class="lineno"> 4366</span>&#160;            expected = f(*values)</div><div class="line"><a name="l04367"></a><span class="lineno"> 4367</span>&#160;            actual = traced_f(*values)</div><div class="line"><a name="l04368"></a><span class="lineno"> 4368</span>&#160;            expected[expected == float(<span class="stringliteral">&#39;inf&#39;</span>)] = 0.</div><div class="line"><a name="l04369"></a><span class="lineno"> 4369</span>&#160;            actual[actual == float(<span class="stringliteral">&#39;inf&#39;</span>)] = 0.</div><div class="line"><a name="l04370"></a><span class="lineno"> 4370</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected, actual, allow_inf=<span class="keyword">True</span>,</div><div class="line"><a name="l04371"></a><span class="lineno"> 4371</span>&#160;                             message=<span class="stringliteral">&#39;{}\nExpected:\n{}\nActual:\n{}&#39;</span>.format(Dist.__name__, expected, actual))</div><div class="line"><a name="l04372"></a><span class="lineno"> 4372</span>&#160;</div><div class="line"><a name="l04373"></a><span class="lineno"> 4373</span>&#160;    <span class="keyword">def </span>test_variance(self):</div><div class="line"><a name="l04374"></a><span class="lineno"> 4374</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04375"></a><span class="lineno"> 4375</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">in</span> [Cauchy, HalfCauchy]:</div><div class="line"><a name="l04376"></a><span class="lineno"> 4376</span>&#160;                <span class="keywordflow">continue</span>  <span class="comment"># infinite variance</span></div><div class="line"><a name="l04377"></a><span class="lineno"> 4377</span>&#160;</div><div class="line"><a name="l04378"></a><span class="lineno"> 4378</span>&#160;            <span class="keyword">def </span>f(*values):</div><div class="line"><a name="l04379"></a><span class="lineno"> 4379</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04380"></a><span class="lineno"> 4380</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04381"></a><span class="lineno"> 4381</span>&#160;                <span class="keywordflow">return</span> dist.variance</div><div class="line"><a name="l04382"></a><span class="lineno"> 4382</span>&#160;</div><div class="line"><a name="l04383"></a><span class="lineno"> 4383</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04384"></a><span class="lineno"> 4384</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, values)</div><div class="line"><a name="l04385"></a><span class="lineno"> 4385</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04386"></a><span class="lineno"> 4386</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04387"></a><span class="lineno"> 4387</span>&#160;</div><div class="line"><a name="l04388"></a><span class="lineno"> 4388</span>&#160;            <span class="comment"># check on different data</span></div><div class="line"><a name="l04389"></a><span class="lineno"> 4389</span>&#160;            values, sample = self.<a class="code" href="classtest__distributions_1_1_test_jit.html#aa1882d0ba6611d7217688a5d114d2c28">_perturb</a>(Dist, keys, values, sample)</div><div class="line"><a name="l04390"></a><span class="lineno"> 4390</span>&#160;            expected = f(*values)</div><div class="line"><a name="l04391"></a><span class="lineno"> 4391</span>&#160;            actual = traced_f(*values)</div><div class="line"><a name="l04392"></a><span class="lineno"> 4392</span>&#160;            expected[expected == float(<span class="stringliteral">&#39;inf&#39;</span>)] = 0.</div><div class="line"><a name="l04393"></a><span class="lineno"> 4393</span>&#160;            actual[actual == float(<span class="stringliteral">&#39;inf&#39;</span>)] = 0.</div><div class="line"><a name="l04394"></a><span class="lineno"> 4394</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected, actual, allow_inf=<span class="keyword">True</span>,</div><div class="line"><a name="l04395"></a><span class="lineno"> 4395</span>&#160;                             message=<span class="stringliteral">&#39;{}\nExpected:\n{}\nActual:\n{}&#39;</span>.format(Dist.__name__, expected, actual))</div><div class="line"><a name="l04396"></a><span class="lineno"> 4396</span>&#160;</div><div class="line"><a name="l04397"></a><span class="lineno"> 4397</span>&#160;    <span class="keyword">def </span>test_entropy(self):</div><div class="line"><a name="l04398"></a><span class="lineno"> 4398</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04399"></a><span class="lineno"> 4399</span>&#160;            <span class="comment"># FIXME traced functions produce incorrect results</span></div><div class="line"><a name="l04400"></a><span class="lineno"> 4400</span>&#160;            xfail = [LowRankMultivariateNormal, MultivariateNormal]</div><div class="line"><a name="l04401"></a><span class="lineno"> 4401</span>&#160;            <span class="keywordflow">if</span> Dist <span class="keywordflow">in</span> xfail:</div><div class="line"><a name="l04402"></a><span class="lineno"> 4402</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04403"></a><span class="lineno"> 4403</span>&#160;</div><div class="line"><a name="l04404"></a><span class="lineno"> 4404</span>&#160;            <span class="keyword">def </span>f(*values):</div><div class="line"><a name="l04405"></a><span class="lineno"> 4405</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04406"></a><span class="lineno"> 4406</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04407"></a><span class="lineno"> 4407</span>&#160;                <span class="keywordflow">return</span> dist.entropy()</div><div class="line"><a name="l04408"></a><span class="lineno"> 4408</span>&#160;</div><div class="line"><a name="l04409"></a><span class="lineno"> 4409</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04410"></a><span class="lineno"> 4410</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, values)</div><div class="line"><a name="l04411"></a><span class="lineno"> 4411</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04412"></a><span class="lineno"> 4412</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04413"></a><span class="lineno"> 4413</span>&#160;</div><div class="line"><a name="l04414"></a><span class="lineno"> 4414</span>&#160;            <span class="comment"># check on different data</span></div><div class="line"><a name="l04415"></a><span class="lineno"> 4415</span>&#160;            values, sample = self.<a class="code" href="classtest__distributions_1_1_test_jit.html#aa1882d0ba6611d7217688a5d114d2c28">_perturb</a>(Dist, keys, values, sample)</div><div class="line"><a name="l04416"></a><span class="lineno"> 4416</span>&#160;            expected = f(*values)</div><div class="line"><a name="l04417"></a><span class="lineno"> 4417</span>&#160;            actual = traced_f(*values)</div><div class="line"><a name="l04418"></a><span class="lineno"> 4418</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected, actual, allow_inf=<span class="keyword">True</span>,</div><div class="line"><a name="l04419"></a><span class="lineno"> 4419</span>&#160;                             message=<span class="stringliteral">&#39;{}\nExpected:\n{}\nActual:\n{}&#39;</span>.format(Dist.__name__, expected, actual))</div><div class="line"><a name="l04420"></a><span class="lineno"> 4420</span>&#160;</div><div class="line"><a name="l04421"></a><span class="lineno"> 4421</span>&#160;    <span class="keyword">def </span>test_cdf(self):</div><div class="line"><a name="l04422"></a><span class="lineno"> 4422</span>&#160;        <span class="keywordflow">for</span> Dist, keys, values, sample <span class="keywordflow">in</span> self.<a class="code" href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">_examples</a>():</div><div class="line"><a name="l04423"></a><span class="lineno"> 4423</span>&#160;</div><div class="line"><a name="l04424"></a><span class="lineno"> 4424</span>&#160;            <span class="keyword">def </span>f(sample, *values):</div><div class="line"><a name="l04425"></a><span class="lineno"> 4425</span>&#160;                param = dict(zip(keys, values))</div><div class="line"><a name="l04426"></a><span class="lineno"> 4426</span>&#160;                dist = Dist(**param)</div><div class="line"><a name="l04427"></a><span class="lineno"> 4427</span>&#160;                cdf = dist.cdf(sample)</div><div class="line"><a name="l04428"></a><span class="lineno"> 4428</span>&#160;                <span class="keywordflow">return</span> dist.icdf(cdf)</div><div class="line"><a name="l04429"></a><span class="lineno"> 4429</span>&#160;</div><div class="line"><a name="l04430"></a><span class="lineno"> 4430</span>&#160;            <span class="keywordflow">try</span>:</div><div class="line"><a name="l04431"></a><span class="lineno"> 4431</span>&#160;                traced_f = <a class="code" href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a>(f, (sample,) + values)</div><div class="line"><a name="l04432"></a><span class="lineno"> 4432</span>&#160;            <span class="keywordflow">except</span> NotImplementedError:</div><div class="line"><a name="l04433"></a><span class="lineno"> 4433</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l04434"></a><span class="lineno"> 4434</span>&#160;</div><div class="line"><a name="l04435"></a><span class="lineno"> 4435</span>&#160;            <span class="comment"># check on different data</span></div><div class="line"><a name="l04436"></a><span class="lineno"> 4436</span>&#160;            values, sample = self.<a class="code" href="classtest__distributions_1_1_test_jit.html#aa1882d0ba6611d7217688a5d114d2c28">_perturb</a>(Dist, keys, values, sample)</div><div class="line"><a name="l04437"></a><span class="lineno"> 4437</span>&#160;            expected = f(sample, *values)</div><div class="line"><a name="l04438"></a><span class="lineno"> 4438</span>&#160;            actual = traced_f(sample, *values)</div><div class="line"><a name="l04439"></a><span class="lineno"> 4439</span>&#160;            self.<a class="code" href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">assertEqual</a>(expected, actual, allow_inf=<span class="keyword">True</span>,</div><div class="line"><a name="l04440"></a><span class="lineno"> 4440</span>&#160;                             message=<span class="stringliteral">&#39;{}\nExpected:\n{}\nActual:\n{}&#39;</span>.format(Dist.__name__, expected, actual))</div><div class="line"><a name="l04441"></a><span class="lineno"> 4441</span>&#160;</div><div class="line"><a name="l04442"></a><span class="lineno"> 4442</span>&#160;</div><div class="line"><a name="l04443"></a><span class="lineno"> 4443</span>&#160;<span class="keywordflow">if</span> __name__ == <span class="stringliteral">&#39;__main__&#39;</span> <span class="keywordflow">and</span> torch._C.has_lapack:</div><div class="line"><a name="l04444"></a><span class="lineno"> 4444</span>&#160;    run_tests()</div><div class="ttc" id="classcommon__utils_1_1_test_case_html_a12e26f2214e4fabb9a6b862b0d985c33"><div class="ttname"><a href="classcommon__utils_1_1_test_case.html#a12e26f2214e4fabb9a6b862b0d985c33">common_utils.TestCase.assertEqual</a></div><div class="ttdeci">def assertEqual(self, x, y, prec=None, message='', allow_inf=False)</div><div class="ttdef"><b>Definition:</b> <a href="common__utils_8py_source.html#l00406">common_utils.py:406</a></div></div>
<div class="ttc" id="namespacetorch_1_1distributions_1_1kl_html"><div class="ttname"><a href="namespacetorch_1_1distributions_1_1kl.html">torch.distributions.kl</a></div><div class="ttdef"><b>Definition:</b> <a href="kl_8py_source.html#l00001">kl.py:1</a></div></div>
<div class="ttc" id="namespacetest__distributions_html_a016ebb8b6b09407c043e05054a688b6a"><div class="ttname"><a href="namespacetest__distributions.html#a016ebb8b6b09407c043e05054a688b6a">test_distributions.pairwise</a></div><div class="ttdeci">def pairwise(Dist, params)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l00076">test_distributions.py:76</a></div></div>
<div class="ttc" id="namespacetorch_1_1distributions_1_1utils_html"><div class="ttname"><a href="namespacetorch_1_1distributions_1_1utils.html">torch.distributions.utils</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2distributions_2utils_8py_source.html#l00001">utils.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_jit_html_ad21683fe0c0828c3d622b91dab3a2f7e"><div class="ttname"><a href="classtest__distributions_1_1_test_jit.html#ad21683fe0c0828c3d622b91dab3a2f7e">test_distributions.TestJit._examples</a></div><div class="ttdeci">def _examples(self)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l04208">test_distributions.py:4208</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_k_l_html_a748a60ca6c8f5423a39dd96b8c53a7c1"><div class="ttname"><a href="classtest__distributions_1_1_test_k_l.html#a748a60ca6c8f5423a39dd96b8c53a7c1">test_distributions.TestKL.finite_examples</a></div><div class="ttdeci">finite_examples</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03136">test_distributions.py:3136</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_distribution_shapes_html_acea204162993e18ed4c3f52721616c22"><div class="ttname"><a href="classtest__distributions_1_1_test_distribution_shapes.html#acea204162993e18ed4c3f52721616c22">test_distributions.TestDistributionShapes.tensor_sample_2</a></div><div class="ttdeci">tensor_sample_2</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l02700">test_distributions.py:2700</a></div></div>
<div class="ttc" id="namespacetorch_1_1distributions_1_1dirichlet_html"><div class="ttname"><a href="namespacetorch_1_1distributions_1_1dirichlet.html">torch.distributions.dirichlet</a></div><div class="ttdef"><b>Definition:</b> <a href="dirichlet_8py_source.html#l00001">dirichlet.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_numerical_stability_html"><div class="ttname"><a href="classtest__distributions_1_1_test_numerical_stability.html">test_distributions.TestNumericalStability</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03479">test_distributions.py:3479</a></div></div>
<div class="ttc" id="namespacetest_html"><div class="ttname"><a href="namespacetest.html">test</a></div><div class="ttdef"><b>Definition:</b> <a href="bottleneck_2test_8py_source.html#l00001">test.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_constraints_html"><div class="ttname"><a href="classtest__distributions_1_1_test_constraints.html">test_distributions.TestConstraints</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03443">test_distributions.py:3443</a></div></div>
<div class="ttc" id="namespacetorch_1_1__six_html"><div class="ttname"><a href="namespacetorch_1_1__six.html">torch._six</a></div><div class="ttdef"><b>Definition:</b> <a href="__six_8py_source.html#l00001">_six.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_rsample_html"><div class="ttname"><a href="classtest__distributions_1_1_test_rsample.html">test_distributions.TestRsample</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l02487">test_distributions.py:2487</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_distributions_html"><div class="ttname"><a href="classtest__distributions_1_1_test_distributions.html">test_distributions.TestDistributions</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l00652">test_distributions.py:652</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_k_l_html_a95022d7b858c52c2cf58f3b0b19bc5d5"><div class="ttname"><a href="classtest__distributions_1_1_test_k_l.html#a95022d7b858c52c2cf58f3b0b19bc5d5">test_distributions.TestKL.samples_per_batch</a></div><div class="ttdeci">samples_per_batch</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03135">test_distributions.py:3135</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_jit_html"><div class="ttname"><a href="classtest__distributions_1_1_test_jit.html">test_distributions.TestJit</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l04207">test_distributions.py:4207</a></div></div>
<div class="ttc" id="torch_2jit_2____init_____8py_html_a24258382e5e90bb4bba39bee8134ddc1"><div class="ttname"><a href="torch_2jit_2____init_____8py.html#a24258382e5e90bb4bba39bee8134ddc1">torch.jit.trace</a></div><div class="ttdeci">def trace(func, example_inputs, optimize=True, check_trace=True, check_inputs=None, check_tolerance=1e-5, _force_outplace=False, _module_class=None)</div><div class="ttdef"><b>Definition:</b> <a href="torch_2jit_2____init_____8py_source.html#l00596">__init__.py:596</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_lazy_logits_initialization_html"><div class="ttname"><a href="classtest__distributions_1_1_test_lazy_logits_initialization.html">test_distributions.TestLazyLogitsInitialization</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03598">test_distributions.py:3598</a></div></div>
<div class="ttc" id="namespacetorch_1_1distributions_html"><div class="ttname"><a href="namespacetorch_1_1distributions.html">torch.distributions</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2distributions_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_validation_html"><div class="ttname"><a href="classtest__distributions_1_1_test_validation.html">test_distributions.TestValidation</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l04181">test_distributions.py:4181</a></div></div>
<div class="ttc" id="random_8py_html_a9d768e347a5358db5b556d88e569850d"><div class="ttname"><a href="random_8py.html#a9d768e347a5358db5b556d88e569850d">torch.random.fork_rng</a></div><div class="ttdeci">def fork_rng(devices=None, enabled=True, _caller=&quot;fork_rng&quot;, _devices_kw=&quot;devices&quot;)</div><div class="ttdef"><b>Definition:</b> <a href="random_8py_source.html#l00049">random.py:49</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_against_scipy_html"><div class="ttname"><a href="classtest__distributions_1_1_test_against_scipy.html">test_distributions.TestAgainstScipy</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03641">test_distributions.py:3641</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_k_l_html_a5edc7278f2b82b235b303a6e0c55bfe1"><div class="ttname"><a href="classtest__distributions_1_1_test_k_l.html#a5edc7278f2b82b235b303a6e0c55bfe1">test_distributions.TestKL.infinite_examples</a></div><div class="ttdeci">infinite_examples</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03186">test_distributions.py:3186</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_jit_html_a059f35ea60496079ef98bf736e8aa710"><div class="ttname"><a href="classtest__distributions_1_1_test_jit.html#a059f35ea60496079ef98bf736e8aa710">test_distributions.TestJit._perturb_tensor</a></div><div class="ttdeci">def _perturb_tensor(self, value, constraint)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l04218">test_distributions.py:4218</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_transforms_html_a7a5718944399ce9eddabec7a45abb20f"><div class="ttname"><a href="classtest__distributions_1_1_test_transforms.html#a7a5718944399ce9eddabec7a45abb20f">test_distributions.TestTransforms._generate_data</a></div><div class="ttdeci">def _generate_data(self, transform)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03846">test_distributions.py:3846</a></div></div>
<div class="ttc" id="namespacetorch_1_1nn_1_1functional_html"><div class="ttname"><a href="namespacetorch_1_1nn_1_1functional.html">torch.nn.functional</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2nn_2functional_8py_source.html#l00001">functional.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_against_scipy_html_aea37f74bd64d97ea97c6db81aa19b70f"><div class="ttname"><a href="classtest__distributions_1_1_test_against_scipy.html#aea37f74bd64d97ea97c6db81aa19b70f">test_distributions.TestAgainstScipy.distribution_pairs</a></div><div class="ttdeci">distribution_pairs</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03648">test_distributions.py:3648</a></div></div>
<div class="ttc" id="namespacetorch_1_1autograd_html"><div class="ttname"><a href="namespacetorch_1_1autograd.html">torch.autograd</a></div><div class="ttdef"><b>Definition:</b> <a href="torch_2autograd_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="namespacetest__distributions_html_a6adcfb09238e6efbe76a080bd30fc8f5"><div class="ttname"><a href="namespacetest__distributions.html#a6adcfb09238e6efbe76a080bd30fc8f5">test_distributions.is_all_nan</a></div><div class="ttdeci">def is_all_nan(tensor)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l00086">test_distributions.py:86</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_lazy_logits_initialization_html_a3dc4a8de65764827e3e6e0d1b7a5d124"><div class="ttname"><a href="classtest__distributions_1_1_test_lazy_logits_initialization.html#a3dc4a8de65764827e3e6e0d1b7a5d124">test_distributions.TestLazyLogitsInitialization.examples</a></div><div class="ttdeci">examples</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03601">test_distributions.py:3601</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_transforms_html"><div class="ttname"><a href="classtest__distributions_1_1_test_transforms.html">test_distributions.TestTransforms</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03792">test_distributions.py:3792</a></div></div>
<div class="ttc" id="classcommon__utils_1_1_test_case_html"><div class="ttname"><a href="classcommon__utils_1_1_test_case.html">common_utils.TestCase</a></div><div class="ttdef"><b>Definition:</b> <a href="common__utils_8py_source.html#l00285">common_utils.py:285</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_constraint_registry_html_a15277412888f9d4921348a8ed1ac1041"><div class="ttname"><a href="classtest__distributions_1_1_test_constraint_registry.html#a15277412888f9d4921348a8ed1ac1041">test_distributions.TestConstraintRegistry.get_constraints</a></div><div class="ttdeci">def get_constraints(self, is_cuda=False)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l04087">test_distributions.py:4087</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_transforms_html_ac3cf45f71d412fea39a50242da9eecc6"><div class="ttname"><a href="classtest__distributions_1_1_test_transforms.html#ac3cf45f71d412fea39a50242da9eecc6">test_distributions.TestTransforms.transforms</a></div><div class="ttdeci">transforms</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03795">test_distributions.py:3795</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_constraint_registry_html"><div class="ttname"><a href="classtest__distributions_1_1_test_constraint_registry.html">test_distributions.TestConstraintRegistry</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l04086">test_distributions.py:4086</a></div></div>
<div class="ttc" id="classcommon__utils_1_1_test_case_html_a26fb11590c98ceb81b5e6fef6547bee0"><div class="ttname"><a href="classcommon__utils_1_1_test_case.html#a26fb11590c98ceb81b5e6fef6547bee0">common_utils.TestCase.precision</a></div><div class="ttdeci">int precision</div><div class="ttdef"><b>Definition:</b> <a href="common__utils_8py_source.html#l00286">common_utils.py:286</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_jit_html_aa1882d0ba6611d7217688a5d114d2c28"><div class="ttname"><a href="classtest__distributions_1_1_test_jit.html#aa1882d0ba6611d7217688a5d114d2c28">test_distributions.TestJit._perturb</a></div><div class="ttdeci">def _perturb(self, Dist, keys, values, sample)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l04234">test_distributions.py:4234</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_distribution_shapes_html"><div class="ttname"><a href="classtest__distributions_1_1_test_distribution_shapes.html">test_distributions.TestDistributionShapes</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l02695">test_distributions.py:2695</a></div></div>
<div class="ttc" id="namespacetorch_1_1distributions_1_1constraints_html"><div class="ttname"><a href="namespacetorch_1_1distributions_1_1constraints.html">torch.distributions.constraints</a></div><div class="ttdef"><b>Definition:</b> <a href="constraints_8py_source.html#l00001">constraints.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_numerical_stability_html_add7e1c62122e3160f4c607ec4a69e2c7"><div class="ttname"><a href="classtest__distributions_1_1_test_numerical_stability.html#add7e1c62122e3160f4c607ec4a69e2c7">test_distributions.TestNumericalStability._test_pdf_score</a></div><div class="ttdeci">def _test_pdf_score(self, dist_class, x, expected_value, probs=None, logits=None, expected_gradient=None, prec=1e-5)</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03487">test_distributions.py:3487</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_k_l_html_a0388c47a2de7c23b9ed33337d2749ae8"><div class="ttname"><a href="classtest__distributions_1_1_test_k_l.html#a0388c47a2de7c23b9ed33337d2749ae8">test_distributions.TestKL.max_samples</a></div><div class="ttdeci">max_samples</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03134">test_distributions.py:3134</a></div></div>
<div class="ttc" id="namespacetorch_1_1distributions_1_1constraint__registry_html"><div class="ttname"><a href="namespacetorch_1_1distributions_1_1constraint__registry.html">torch.distributions.constraint_registry</a></div><div class="ttdef"><b>Definition:</b> <a href="constraint__registry_8py_source.html#l00001">constraint_registry.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_k_l_html"><div class="ttname"><a href="classtest__distributions_1_1_test_k_l.html">test_distributions.TestKL</a></div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03082">test_distributions.py:3082</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_distribution_shapes_html_ae0a541d7602d44152804aa6370a19abb"><div class="ttname"><a href="classtest__distributions_1_1_test_distribution_shapes.html#ae0a541d7602d44152804aa6370a19abb">test_distributions.TestDistributionShapes.tensor_sample_1</a></div><div class="ttdeci">tensor_sample_1</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l02699">test_distributions.py:2699</a></div></div>
<div class="ttc" id="namespacetorch_1_1distributions_1_1transforms_html"><div class="ttname"><a href="namespacetorch_1_1distributions_1_1transforms.html">torch.distributions.transforms</a></div><div class="ttdef"><b>Definition:</b> <a href="transforms_8py_source.html#l00001">transforms.py:1</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_transforms_html_acf329454d378ae6acfeb91b63a915c10"><div class="ttname"><a href="classtest__distributions_1_1_test_transforms.html#acf329454d378ae6acfeb91b63a915c10">test_distributions.TestTransforms.unique_transforms</a></div><div class="ttdeci">unique_transforms</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l03844">test_distributions.py:3844</a></div></div>
<div class="ttc" id="classtest__distributions_1_1_test_distribution_shapes_html_a839bdf47c5e2621d6447a9e887ee6976"><div class="ttname"><a href="classtest__distributions_1_1_test_distribution_shapes.html#a839bdf47c5e2621d6447a9e887ee6976">test_distributions.TestDistributionShapes.scalar_sample</a></div><div class="ttdeci">scalar_sample</div><div class="ttdef"><b>Definition:</b> <a href="test__distributions_8py_source.html#l02698">test_distributions.py:2698</a></div></div>
<div class="ttc" id="namespacetorch_1_1tensor_html"><div class="ttname"><a href="namespacetorch_1_1tensor.html">torch.tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="tensor_8py_source.html#l00001">tensor.py:1</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.14-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sun Mar 24 2019 13:06:37 for Caffe2 - Python API by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
<div class="footerContainer">
  <div id="footer_wrap" class="wrapper footerWrapper">
    <div class="footerBlocks">
      <div id="fb_oss" class="footerSection fbOpenSourceFooter">
          <svg class="facebookOSSLogoSvg" viewBox="0 0 1133.9 1133.9" x="0px" y="0px" height=50 width=50>
            <g>
              <path class="logoRing outerRing" d="M 498.3 3.7 c 153.6 88.9 307.3 177.7 461.1 266.2 c 7.6 4.4 10.3 9.1 10.3 17.8 c -0.3 179.1 -0.2 358.3 0 537.4 c 0 8.1 -2.4 12.8 -9.7 17.1 c -154.5 88.9 -308.8 178.1 -462.9 267.5 c -9 5.2 -15.5 5.3 -24.6 0.1 c -153.9 -89.2 -307.9 -178 -462.1 -266.8 C 3 838.8 0 833.9 0 825.1 c 0.3 -179.1 0.2 -358.3 0 -537.4 c 0 -8.6 2.6 -13.6 10.2 -18 C 164.4 180.9 318.4 92 472.4 3 C 477 -1.5 494.3 -0.7 498.3 3.7 Z M 48.8 555.3 c 0 79.9 0.2 159.9 -0.2 239.8 c -0.1 10 3 15.6 11.7 20.6 c 137.2 78.8 274.2 157.8 411 237.3 c 9.9 5.7 17 5.7 26.8 0.1 c 137.5 -79.8 275.2 -159.2 412.9 -238.5 c 7.4 -4.3 10.5 -8.9 10.5 -17.8 c -0.3 -160.2 -0.3 -320.5 0 -480.7 c 0 -8.8 -2.8 -13.6 -10.3 -18 C 772.1 218 633.1 137.8 494.2 57.4 c -6.5 -3.8 -11.5 -4.5 -18.5 -0.5 C 336.8 137.4 197.9 217.7 58.8 297.7 c -7.7 4.4 -10.2 9.2 -10.2 17.9 C 48.9 395.5 48.8 475.4 48.8 555.3 Z" />
              <path class="logoRing middleRing" d="M 184.4 555.9 c 0 -33.3 -1 -66.7 0.3 -100 c 1.9 -48 24.1 -86 64.7 -110.9 c 54.8 -33.6 110.7 -65.5 167 -96.6 c 45.7 -25.2 92.9 -24.7 138.6 1 c 54.4 30.6 108.7 61.5 162.2 93.7 c 44 26.5 67.3 66.8 68 118.4 c 0.9 63.2 0.9 126.5 0 189.7 c -0.7 50.6 -23.4 90.7 -66.6 116.9 c -55 33.4 -110.8 65.4 -167.1 96.5 c -43.4 24 -89 24.2 -132.3 0.5 c -57.5 -31.3 -114.2 -64 -170 -98.3 c -41 -25.1 -62.9 -63.7 -64.5 -112.2 C 183.5 621.9 184.3 588.9 184.4 555.9 Z M 232.9 556.3 c 0 29.5 0.5 59.1 -0.1 88.6 c -0.8 39.2 16.9 67.1 50.2 86.2 c 51.2 29.4 102.2 59.2 153.4 88.4 c 31.4 17.9 63.6 18.3 95 0.6 c 53.7 -30.3 107.1 -61.2 160.3 -92.5 c 29.7 -17.5 45 -44.5 45.3 -78.8 c 0.6 -61.7 0.5 -123.5 0 -185.2 c -0.3 -34.4 -15.3 -61.5 -44.9 -79 C 637.7 352.6 583 320.8 527.9 290 c -27.5 -15.4 -57.2 -16.1 -84.7 -0.7 c -56.9 31.6 -113.4 64 -169.1 97.6 c -26.4 15.9 -40.7 41.3 -41.1 72.9 C 232.6 491.9 232.9 524.1 232.9 556.3 Z" />
              <path class="logoRing innerRing" d="M 484.9 424.4 c 69.8 -2.8 133.2 57.8 132.6 132 C 617 630 558.5 688.7 484.9 689.1 c -75.1 0.4 -132.6 -63.6 -132.7 -132.7 C 352.1 485 413.4 421.5 484.9 424.4 Z M 401.3 556.7 c -3.4 37.2 30.5 83.6 83 84.1 c 46.6 0.4 84.8 -37.6 84.9 -84 c 0.1 -46.6 -37.2 -84.4 -84.2 -84.6 C 432.2 472.1 397.9 518.3 401.3 556.7 Z" />
            </g>
          </svg>
        <h2>Facebook Open Source</h2>
      </div>
      <div class="footerSection">
        <a class="footerLink" href="https://code.facebook.com/projects/" target="_blank">Open Source Projects</a>
        <a class="footerLink" href="https://github.com/facebook/" target="_blank">GitHub</a>
        <a class="footerLink" href="https://twitter.com/fbOpenSource" target="_blank">Twitter</a>
      </div>
      <div class="footerSection rightAlign">
        <a class="footerLink" href="https://github.com/caffe2/caffe2" target="_blank">Contribute to this project on GitHub</a>
      </div>
    </div>
  </div>
</div>
<script type="text/javascript" src="/js/jekyll-link-anchors.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', '{{ site.gacode }}', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
